

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Jclian91">
  <meta name="keywords" content="">
  
    <meta name="description" content="本文是tensorflow框架的基础入门第一篇文章。">
<meta property="og:type" content="article">
<meta property="og:title" content="tensorflow（1）基础入门">
<meta property="og:url" content="https://percent4.github.io/tensorflow%EF%BC%881%EF%BC%89%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/index.html">
<meta property="og:site_name" content="My Github Blog">
<meta property="og:description" content="本文是tensorflow框架的基础入门第一篇文章。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://percent4.github.io/img/tf1_1.png">
<meta property="og:image" content="https://percent4.github.io/img/tf1_2.png">
<meta property="og:image" content="https://percent4.github.io/img/tf1_3.png">
<meta property="og:image" content="https://percent4.github.io/img/tf1_4.png">
<meta property="og:image" content="https://percent4.github.io/img/tf1_5.png">
<meta property="og:image" content="https://percent4.github.io/img/tf1_6.png">
<meta property="og:image" content="https://percent4.github.io/img/tf1_7.png">
<meta property="og:image" content="https://percent4.github.io/img/tf1_8.png">
<meta property="og:image" content="https://percent4.github.io/img/tf1_9.png">
<meta property="og:image" content="https://percent4.github.io/img/tf1_10.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg">
<meta property="article:published_time" content="2023-08-15T14:04:50.000Z">
<meta property="article:modified_time" content="2024-01-18T05:48:51.429Z">
<meta property="article:author" content="Jclian91">
<meta property="article:tag" content="tensorflow">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://percent4.github.io/img/tf1_1.png">
  
  
  
  <title>tensorflow（1）基础入门 - My Github Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/csdn/iconfont.css">
<link rel="stylesheet" href="/css/toutiao/iconfont.css">
<link rel="stylesheet" href="/css/huggingface/iconfont.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"percent4.github.io","root":"/","version":"1.9.5-a","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"YUsFSnlfB9167rgyk6dKxO3n-gzGzoHsz","app_key":"MCARXkAOuxb8aiWTb3WdAsyn","server_url":"https://yusfsnlf.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  
    
  



  
  <meta name="google-site-verification" content="iwt9R4ZjOOtNMseCGP-F5CgwNqJSQ8hf1OsBse50Cyo" />
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="tensorflow（1）基础入门"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-08-15 22:04" pubdate>
          星期二, 八月 15日 2023, 10:04 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          16k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          131 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">tensorflow（1）基础入门</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="tensorflow-is-coming-part-1">TensorFlow Is Coming ( Part 1
)</h2>
<h3 id="目录">目录</h3>
<ol type="1">
<li>TensorFlow简介</li>
<li>TensorFlow基本概念</li>
<li>Using TensorFlow</li>
<li>Optimization &amp; Linear Regression &amp; Logistic Regression</li>
</ol>
<h3 id="tensorflow简介">1. TensorFlow简介</h3>
<p>TensorFlow由Google的Brain Team创立，于2015年11月9日开源。</p>
<p>TensorFlow中文社区网站：http://www.tensorfly.cn 。</p>
<p>TensorFlow, 其含义为 Tensor + Flow, 具体说来：</p>
<ul>
<li>Tensor（张量）：N维数组</li>
<li>Flow（流图）： 基于数据流图（Data Flow Graph）的计算</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://www.tensorfly.cn/">TensorFlow的特征</a>：</p>
<ol type="1">
<li>高度的灵活性</li>
<li>真正的可移植性（Portability）</li>
<li>将科研和产品联系在一起</li>
<li>自动求微分</li>
<li>多语言支持</li>
<li>性能最优化</li>
</ol>
<p>TensorFlow Python API
在数据结构和基于多维数组的计算与NumPy有许多相似之处，其安装方式：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> tensorflow<br></code></pre></td></tr></table></figure>
<p>一个简单的例子："Hello world" with TensorFlow</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>h = tf.constant(<span class="hljs-string">&quot;Hello&quot;</span>)<br>w = tf.constant(<span class="hljs-string">&quot; World!&quot;</span>)<br>hw = h + w<br><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>    ans = sess.run(hw)<br><span class="hljs-built_in">print</span> (ans)<br></code></pre></td></tr></table></figure>
<h3 id="tensorflow基本概念">2. TensorFlow基本概念</h3>
<p>本节目录：</p>
<ol type="1">
<li>Constant</li>
<li>Tensor</li>
<li>Computation Graphs</li>
<li>Variables</li>
<li>Placeholder Variables</li>
</ol>
<h4 id="constant">Constant</h4>
<p>TensorFlow中的常量用constant()函数构造。</p>
<h4 id="tensor">Tensor</h4>
<p><img src="/img/tf1_1.png" srcset="/img/loading.gif" lazyload /> <img src="/img/tf1_2.png" srcset="/img/loading.gif" lazyload /></p>
<p>Tensor的创建：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">a = tf.constant(<span class="hljs-number">2</span>)        <span class="hljs-comment"># 标量</span><br>b = tf.constant([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])    <span class="hljs-comment"># 一维向量</span><br>c = tf.constant([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],<br>                 [<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]])  <span class="hljs-comment"># 二维向量</span><br></code></pre></td></tr></table></figure>
<p>也可以指定维度（shape）以及数据类型(dtype)。比如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">a = tf.constant(np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]), shape=(<span class="hljs-number">3</span>,<span class="hljs-number">2</span>),dtype=tf.int64)<br>a = tf.constant(np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],<br>                          [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]]),<br>                          shape=(<span class="hljs-number">3</span>,<span class="hljs-number">2</span>),<br>                          dtype=tf.float64)<br></code></pre></td></tr></table></figure>
<figure>
<img src="/img/tf1_3.png" srcset="/img/loading.gif" lazyload alt="数据类型" />
<figcaption aria-hidden="true">数据类型</figcaption>
</figure>
<h4 id="computation-graphs">Computation Graphs</h4>
<p>Generally, the typical workflow in TensorFlow can be summarized as
follows:</p>
<ul>
<li>Build a computational graph</li>
<li>Start a new session to evaluate the graph
<ol type="1">
<li>Initialize variables</li>
<li>Execute the operations in the compiled graph</li>
</ol></li>
</ul>
<p>例1：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>a = tf.constant(<span class="hljs-number">5</span>)<br>b = tf.constant(<span class="hljs-number">2</span>)<br>c = tf.constant(<span class="hljs-number">3</span>)<br><br>d = tf.multiply(a,b)<br>e = tf.add(c,b)<br>f = tf.subtract(d,e)<br><br><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>    res = sess.run(f)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;f is %s&#x27;</span>%res)<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">f is 5<br></code></pre></td></tr></table></figure>
<p>在上述程序中，Computation Graph 示意图如下：</p>
<p><img src="/img/tf1_4.png" srcset="/img/loading.gif" lazyload /></p>
<p>在TensorBoard中，Computation Graph如下：</p>
<p><img src="/img/tf1_5.png" srcset="/img/loading.gif" lazyload /></p>
<p>常用的TensorFlow运算函数：</p>
<p><img src="/img/tf1_6.png" srcset="/img/loading.gif" lazyload /></p>
<p>例2：使用Graph及Session</p>
<p>未使用Session</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.constant([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>,<span class="hljs-number">6.</span>]], dtype=tf.float64)<br>    col_sum = tf.reduce_sum(tf_x, axis=<span class="hljs-number">0</span>) <span class="hljs-comment"># 按列求和</span><br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;tf_x:\n&#x27;</span>, tf_x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;col_sum:\n&#x27;</span>, col_sum)<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">tf_x:<br> Tensor(<span class="hljs-string">&quot;Const:0&quot;</span>, shape=(3, 2), dtype=float64)<br>col_sum:<br> Tensor(<span class="hljs-string">&quot;Sum:0&quot;</span>, shape=(2,), dtype=float64)<br></code></pre></td></tr></table></figure>
<p>使用Session（获取计算结果）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.constant([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>,<span class="hljs-number">6.</span>]], dtype=tf.float64)<br>    col_sum = tf.reduce_sum(tf_x, axis=<span class="hljs-number">0</span>) <span class="hljs-comment"># 按列求和</span><br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    mat, csum = sess.run([tf_x, col_sum])<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;tf_x:\n&#x27;</span>, mat)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;col_sum:\n&#x27;</span>, csum)<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">tf_x:<br> [[1. 2.]<br>  [3. 4.]<br>  [5. 6.]]<br>col_sum:<br> [ 9. 12.]<br></code></pre></td></tr></table></figure>
<p>TensorFlow背后的运行原理图：</p>
<figure>
<img src="/img/tf1_7.png" srcset="/img/loading.gif" lazyload alt="运行原理图" />
<figcaption aria-hidden="true">运行原理图</figcaption>
</figure>
<p>为什么要采用Computation Graphs？</p>
<ul>
<li>TensorFlow optimizes its computations based on the graph’s
connectivity.</li>
<li>Each graph has its own set of node dependencies.Being able to locate
dependencies between units of our model allows us to both distribute
computations across available resources and avoid performing redundant
computations of irrelevant subsets, resulting in a faster and more
efficient way of computing things.</li>
</ul>
<p><img src="/img/tf1_8.png" srcset="/img/loading.gif" lazyload /></p>
<h4 id="variables">Variables</h4>
<p>Variables are constructs in TensorFlow that allows us to store and
update parameters of our models in the current session during training.
To define a “variable” tensor, we use TensorFlow’s Variable()
constructor. to execute a computational graph that contains variables,
we must initialize all variables in the active session first (using
tf.global_variables_initializer()).</p>
<p>例1：使用Variables</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]], dtype=tf.float32)<br>    x = tf.constant(<span class="hljs-number">1.</span>, dtype=tf.float32)<br><br>    <span class="hljs-comment"># add a constant to the matrix:</span><br>    tf_x = tf_x + x<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    result = sess.run(tf_x)<br><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[2. 3.]<br> [4. 5.]<br> [6. 7.]]<br></code></pre></td></tr></table></figure>
<p>例2： 运行两遍？</p>
<p>运行两遍， 存在的问题：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]], dtype=tf.float32)<br>    x = tf.constant(<span class="hljs-number">1.</span>, dtype=tf.float32)<br><br>    <span class="hljs-comment"># add a constant to the matrix:</span><br>    tf_x = tf_x + x<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    result = sess.run(tf_x)<br>    result = sess.run(tf_x) <span class="hljs-comment"># 运行两遍</span><br><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[2. 3.]<br> [4. 5.]<br> [6. 7.]]<br></code></pre></td></tr></table></figure>
<p>解决办法？ 使用tf.assign()函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]], dtype=tf.float32)<br>    x = tf.constant(<span class="hljs-number">1.</span>, dtype=tf.float32)<br><br>    <span class="hljs-comment"># add a constant to the matrix:</span><br>    update_tf_x = tf.assign(tf_x, tf_x + x)<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    result = sess.run(update_tf_x)<br>    result = sess.run(update_tf_x) <span class="hljs-comment"># 运行两遍</span><br><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<p>此时的输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[3. 4.]<br> [5. 6.]<br> [7. 8.]]<br></code></pre></td></tr></table></figure>
<h4 id="placeholder-variables">Placeholder Variables</h4>
<p><strong>Placeholder variables</strong> allow us to feed the
computational graph with numerical values in an active session at
runtime. <strong>Placeholders</strong> have an optional shape argument.
If a shape is not fed or is passed as <strong>None</strong>, then the
placeholder can be fed with data of any size.</p>
<p>例：矩阵相乘</p>
<p>指定行数与列数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.placeholder(dtype=tf.float32,shape=(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>))<br><br>    output = tf.matmul(tf_x, tf.transpose(tf_x)) <span class="hljs-comment"># 矩阵乘以它的转置</span><br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    <span class="hljs-comment"># 创建3*2矩阵</span><br>    np_ary = np.array([[<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                       [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>],<br>                       [<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>]])<br><br>    <span class="hljs-built_in">print</span>(sess.run(output, &#123;tf_x: np_ary&#125;))<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[ 25.  39.  53.]<br> [ 39.  61.  83.]<br> [ 53.  83. 113.]]<br></code></pre></td></tr></table></figure>
<p>指定列数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.placeholder(dtype=tf.float32,shape=(<span class="hljs-literal">None</span>, <span class="hljs-number">2</span>))<br><br>    output = tf.matmul(tf_x, tf.transpose(tf_x)) <span class="hljs-comment"># 矩阵乘以它的转置</span><br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    <span class="hljs-comment"># 创建3*2矩阵</span><br>    np_ary1 = np.array([[<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                       [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>],<br>                       [<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>]])<br><br>    <span class="hljs-built_in">print</span>(sess.run(output, &#123;tf_x: np_ary1&#125;))<br><br>    <span class="hljs-comment"># 创建4*2矩阵</span><br>    np_ary2 = np.array([[<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>],<br>                        [<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>],<br>                        [<span class="hljs-number">9.</span>,<span class="hljs-number">10.</span>]])<br><br>    <span class="hljs-built_in">print</span>(sess.run(output, &#123;tf_x: np_ary2&#125;))<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[ 25.  39.  53.]<br> [ 39.  61.  83.]<br> [ 53.  83. 113.]]<br>[[ 25.  39.  53.  67.]<br> [ 39.  61.  83. 105.]<br> [ 53.  83. 113. 143.]<br> [ 67. 105. 143. 181.]]<br></code></pre></td></tr></table></figure>
<p>未指定shape</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.placeholder(dtype=tf.float32)<br><br>    output = tf.matmul(tf_x, tf.transpose(tf_x)) <span class="hljs-comment"># 矩阵乘以它的转置</span><br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    <span class="hljs-comment"># 创建3*3矩阵</span><br>    np_ary1 = np.array([[<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>, <span class="hljs-number">5.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">7.</span>],<br>                        [<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>, <span class="hljs-number">9.</span>]])<br><br>    <span class="hljs-built_in">print</span>(sess.run(output, &#123;tf_x: np_ary1&#125;))<br><br>    <span class="hljs-comment"># 创建4*2矩阵</span><br>    np_ary2 = np.array([[<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>],<br>                        [<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>],<br>                        [<span class="hljs-number">9.</span>,<span class="hljs-number">10.</span>]])<br><br>    <span class="hljs-built_in">print</span>(sess.run(output, &#123;tf_x: np_ary2&#125;))<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[ 50.  74.  98.]<br> [ 74. 110. 146.]<br> [ 98. 146. 194.]]<br>[[ 25.  39.  53.  67.]<br> [ 39.  61.  83. 105.]<br> [ 53.  83. 113. 143.]<br> [ 67. 105. 143. 181.]]<br></code></pre></td></tr></table></figure>
<h4 id="using-tensorflow">3. Using TensorFlow</h4>
<p>本节目录:</p>
<ul>
<li>Saving and Restoring Models</li>
<li>Naming TensorFlow Objects</li>
<li>CPU and GPU</li>
<li>Control Flow</li>
<li>TensorBoard</li>
</ul>
<h5 id="saving-and-restoring-models">Saving and Restoring Models</h5>
<p>例：</p>
<p><strong>Saving Models</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br><br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]], dtype=tf.float32)<br>    x = tf.constant(<span class="hljs-number">1.</span>, dtype=tf.float32)<br><br>    update_tf_x = tf.assign(tf_x, tf_x + x)<br><br>    <span class="hljs-comment"># initialize a Saver, which gets all variables</span><br>    <span class="hljs-comment"># within this computation graph context</span><br>    saver = tf.train.Saver()<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    result = sess.run(update_tf_x)<br><br>    <span class="hljs-comment"># save the model</span><br>    saver.save(sess, save_path=<span class="hljs-string">&#x27;E://flag/my-model.ckpt&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>保存的文件：</p>
<figure>
<img src="/img/tf1_9.png" srcset="/img/loading.gif" lazyload alt="保存的文件" />
<figcaption aria-hidden="true">保存的文件</figcaption>
</figure>
<p>The file my-model.ckpt.data-00000-of-00001 saves our main variable
values, the .index file keeps track of the data structures, and the
.meta file describes the structure of our computational graph that we
executed.</p>
<p><strong>Restoring Models:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br><br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]], dtype=tf.float32)<br>    x = tf.constant(<span class="hljs-number">1.</span>, dtype=tf.float32)<br><br>    update_tf_x = tf.assign(tf_x, tf_x + x)<br><br>    <span class="hljs-comment"># initialize a Saver, which gets all variables</span><br>    <span class="hljs-comment"># within this computation graph context</span><br>    saver = tf.train.Saver()<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    saver.restore(sess, save_path=<span class="hljs-string">&#x27;E://flag/my-model.ckpt&#x27;</span>)<br>    result = sess.run(update_tf_x)<br>    <span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[3. 4.]<br> [5. 6.]<br> [7. 8.]]<br></code></pre></td></tr></table></figure>
<h4 id="naming-tensorflow-objects">Naming TensorFlow Objects</h4>
<p>Each Tensor object also has an identifying name. This name is an
intrinsic string name, not to be confused with the name of the variable.
As with dtype, we can use the .name attribute to see the name of the
object:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    c1 = tf.constant(<span class="hljs-number">4</span>, dtype=tf.float64, name=<span class="hljs-string">&#x27;c&#x27;</span>)<br>    c2 = tf.constant(<span class="hljs-number">4</span>, dtype=tf.int32, name=<span class="hljs-string">&#x27;c&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(c1.name)<br><span class="hljs-built_in">print</span>(c2.name)<br></code></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">c:0<br>c_1:0<br></code></pre></td></tr></table></figure>
<p><strong>Name scopes</strong></p>
<p>Sometimes when dealing with a large, complicated graph, we would like
to create some node grouping to make it easier to follow and manage. For
that we can hierarchically group nodes together by name. We do so by
using tf.name_scope("prefix") together with the useful with clause
again:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    c1 = tf.constant(<span class="hljs-number">4</span>, dtype=tf.float64, name=<span class="hljs-string">&#x27;c&#x27;</span>)<br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&quot;prefix_name&quot;</span>):<br>        c2 = tf.constant(<span class="hljs-number">4</span>, dtype=tf.int32, name=<span class="hljs-string">&#x27;c&#x27;</span>)<br>        c3 = tf.constant(<span class="hljs-number">4</span>, dtype=tf.float64, name=<span class="hljs-string">&#x27;c&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(c1.name)<br><span class="hljs-built_in">print</span>(c2.name)<br><span class="hljs-built_in">print</span>(c3.name)<br></code></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">c:0<br>prefix_name/c:0<br>prefix_name/c_1:0<br></code></pre></td></tr></table></figure>
<h4 id="cpu-and-gpu">CPU and GPU</h4>
<p>All TensorFlow operations in general, can be executed on a
<strong>CPU</strong>. If you have a <strong>GPU</strong> version of
TensorFlow installed, TensorFlow will automatically execute those
operations that have <strong>GPU</strong> support on GPUs and use your
machine’s <strong>CPU</strong>, otherwise.</p>
<h4 id="control-flow">Control Flow</h4>
<p>例： if-else结构</p>
<p>简单的if-else语句</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>addition = <span class="hljs-literal">True</span><br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    x = tf.placeholder(dtype=tf.float32, shape=<span class="hljs-literal">None</span>)<br>    <span class="hljs-keyword">if</span> addition:<br>        y = x + <span class="hljs-number">1.</span><br>    <span class="hljs-keyword">else</span>:<br>        y = x - <span class="hljs-number">1.</span><br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    result = sess.run(y, feed_dict=&#123;x: <span class="hljs-number">1.</span>&#125;)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Result:\n&#x27;</span>, result)<br></code></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">Result:<br> 2.0<br></code></pre></td></tr></table></figure>
<p>使用tf.cond()代替上面的if-else语句</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    addition = tf.placeholder(dtype=tf.<span class="hljs-built_in">bool</span>, shape=<span class="hljs-literal">None</span>)<br>    x = tf.placeholder(dtype=tf.float32, shape=<span class="hljs-literal">None</span>)<br><br>    y = tf.cond(addition,<br>                true_fn=<span class="hljs-keyword">lambda</span>: tf.add(x, <span class="hljs-number">1.</span>),<br>                false_fn=<span class="hljs-keyword">lambda</span>: tf.subtract(x, <span class="hljs-number">1.</span>))<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    result = sess.run(y, feed_dict=&#123;addition:<span class="hljs-literal">True</span>,x: <span class="hljs-number">1.</span>&#125;)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Result:\n&#x27;</span>, result)<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">Result:<br> 2.0<br></code></pre></td></tr></table></figure>
<h4 id="tensorboard">TensorBoard</h4>
<p>TensorBoard is one of the coolest features of TensorFlow, which
provides us with a suite of tools to visualize our computational graphs
and operations before and during runtime.</p>
<p>例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br><br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]],<br>                        name=<span class="hljs-string">&#x27;tf_x_0&#x27;</span>,<br>                        dtype=tf.float32)<br><br>    tf_y = tf.Variable([[<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>],<br>                        [<span class="hljs-number">9.</span>, <span class="hljs-number">10.</span>],<br>                        [<span class="hljs-number">11.</span>, <span class="hljs-number">12.</span>]],<br>                        name=<span class="hljs-string">&#x27;tf_y_0&#x27;</span>,<br>                        dtype=tf.float32)<br><br>    output = tf_x + tf_y<br>    output = tf.matmul(tf.transpose(tf_x), output)<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br><br>    <span class="hljs-comment"># create FileWrite object that writes the logs</span><br>    file_writer = tf.summary.FileWriter(logdir=<span class="hljs-string">&#x27;E://flag/logs/1&#x27;</span>, graph=g)<br>    result = sess.run(output)<br>    <span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[124. 142.]<br> [160. 184.]]<br></code></pre></td></tr></table></figure>
<p>使用Tensorboard查看Computation Graph:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tensorboard --logdir E://flag/logs/1<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">C:\Users\HP&gt;tensorboard --logdir E://flag/logs/1<br>TensorBoard 1.10.0 at http://DESKTOP-28K2SLS:6006 (Press CTRL+C to quit)<br></code></pre></td></tr></table></figure>
<p>在浏览器中输入http://DESKTOP-28K2SLS:6006即可查看Computation
Graph，截图如下：</p>
<p><img src="/img/tf1_10.png" srcset="/img/loading.gif" lazyload /></p>
<h3 id="optimization-linear-regression-logistic-regression">4.
Optimization &amp; Linear Regression &amp; Logistic Regression</h3>
<p><strong>Optimization Steps:</strong></p>
<ol type="1">
<li>Defining a model</li>
<li>Defining loss function</li>
<li>Optimizer(The gradient descent)</li>
<li>Try to predict</li>
</ol>
<p>Gradient Descent的三种形式：</p>
<table>
<thead>
<tr class="header">
<th>描述</th>
<th>GD</th>
<th>Minth-Batches GD</th>
<th>SGD</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>单次迭代样本数</td>
<td>整个训练集</td>
<td>训练集的子集</td>
<td>单个样本</td>
</tr>
<tr class="even">
<td>算法复杂度</td>
<td>高</td>
<td>一般</td>
<td>低</td>
</tr>
<tr class="odd">
<td>运行速度</td>
<td>慢</td>
<td>较快</td>
<td>快</td>
</tr>
<tr class="even">
<td>收敛性</td>
<td>稳定</td>
<td>较稳定</td>
<td>不稳定</td>
</tr>
<tr class="odd">
<td>陷入局部最优点的可能性</td>
<td>大</td>
<td>较大</td>
<td>小</td>
</tr>
</tbody>
</table>
<p><strong>Linear Regression</strong></p>
<ol type="1">
<li>Model</li>
</ol>
<p><span class="math display">\[y = \sum\limits_{i=1}^{n}w_{i}x_{i} +
b\]</span></p>
<ol start="2" type="1">
<li>Loss function: MSE</li>
</ol>
<p><span class="math display">\[loss =
\frac{1}{2m}\sum\limits_{i=1}^{m}(y_{true} -
(\sum\limits_{i=1}^{n}w_{i}x_{i}+b))^{2}\]</span></p>
<ol start="3" type="1">
<li>The gradient descent optimizer(SGD)</li>
</ol>
<p>指定 loss function 和 learning_rate</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = tf.train.GradientDescentOptimizer(learning_rate)<br>train = optimizer.minimize(loss)<br></code></pre></td></tr></table></figure>
<ol start="4" type="1">
<li>predict on new sample</li>
</ol>
<p>Linear Regression的例子：</p>
<p>数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">x_data = np.random.randn(<span class="hljs-number">200</span>, <span class="hljs-number">3</span>)<br>w_real = [<span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.1</span>]<br>b_real = -<span class="hljs-number">0.2</span><br>noise = np.random.randn(<span class="hljs-number">1</span>, <span class="hljs-number">200</span>)*<span class="hljs-number">0.1</span><br>y_data = np.matmul(w_real, x_data.T) + b_real + noise<br></code></pre></td></tr></table></figure>
<p>示例代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> linear_model<br><br><span class="hljs-comment"># 样本数据集</span><br>x_data = np.random.randn(<span class="hljs-number">200</span>, <span class="hljs-number">3</span>)<br>w_real = [<span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.1</span>]<br>b_real = -<span class="hljs-number">0.2</span><br>noise = np.random.randn(<span class="hljs-number">1</span>, <span class="hljs-number">200</span>)*<span class="hljs-number">0.1</span><br>y_data = np.matmul(w_real, x_data.T) + b_real + noise<br><br><span class="hljs-comment"># 使用Sklearn进行一元线性回归建模</span><br>regr = linear_model.LinearRegression()<br><br><span class="hljs-comment"># Train the model using the data</span><br>regr.fit(x_data, y_data.transpose())<br><br><span class="hljs-comment"># The coefficients</span><br>w, b = regr.coef_[<span class="hljs-number">0</span>], regr.intercept_<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;用Sklearn计算得到的线性回归系数:\n w:%s\tb:%s&#x27;</span>%(w, b))<br><br>NUM_STEPS = <span class="hljs-number">100</span>                                         <span class="hljs-comment"># 循环次数</span><br>g = tf.Graph()                                          <span class="hljs-comment"># 创建图</span><br>wb_ = []                                                <span class="hljs-comment"># 记录结果的列表</span><br><br><span class="hljs-keyword">with</span> g.as_default():<br>    x = tf.placeholder(tf.float32, shape=[<span class="hljs-literal">None</span>,<span class="hljs-number">3</span>])       <span class="hljs-comment"># 样本中的x值</span><br>    y_true = tf.placeholder(tf.float32, shape=<span class="hljs-literal">None</span>)      <span class="hljs-comment"># 样本中的真实的y值</span><br><br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&#x27;inference&#x27;</span>) <span class="hljs-keyword">as</span> scope:<br>        w = tf.Variable([[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]], dtype=tf.float32, name=<span class="hljs-string">&#x27;weights&#x27;</span>)  <span class="hljs-comment"># w系数</span><br>        b = tf.Variable(<span class="hljs-number">0</span>, dtype=tf.float32, name=<span class="hljs-string">&#x27;bias&#x27;</span>)             <span class="hljs-comment"># 截距b</span><br>        y_pred = tf.matmul(w, tf.transpose(x)) + b                    <span class="hljs-comment"># y的预测值</span><br><br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&#x27;loss&#x27;</span>) <span class="hljs-keyword">as</span> scope:                              <span class="hljs-comment"># 定义损失函数</span><br>        loss = tf.reduce_mean(tf.square(y_true-y_pred))<br><br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&#x27;train&#x27;</span>) <span class="hljs-keyword">as</span> scope:                             <span class="hljs-comment">#定义optimization</span><br>        learning_rate = <span class="hljs-number">0.5</span><br>        optimizer = tf.train.GradientDescentOptimizer(learning_rate)<br>        train = optimizer.minimize(loss)<br><br>        <span class="hljs-comment"># Before starting, initialize the variables. We will &#x27;run&#x27; this first.</span><br>        init = tf.global_variables_initializer()<br><br>        <span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>            sess.run(init)<br>            <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_STEPS):<br>                sess.run(train, &#123;x: x_data, y_true: y_data&#125;)<br>            wb_.append(sess.run([w, b]))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;用TensorFlow计算得到的线性回归系数:\n&quot;</span>)<br><span class="hljs-built_in">print</span>(wb_)<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">用Sklearn计算得到的线性回归系数:<br> w:[0.29638914 0.49420393 0.096624  ]	b:[-0.21690145]<br>用TensorFlow计算得到的线性回归系数:<br>[[array([[0.29638913, 0.49420393, 0.096624  ]], dtype=float32), -0.21690145]]<br></code></pre></td></tr></table></figure>
<p><strong>Logistic Regression</strong></p>
<ol type="1">
<li>Model</li>
</ol>
<p><span class="math display">\[\ln{(\frac{p}{1-p})} =
\sum\limits_{i=1}^{n}w_{i}x_{i} + b\]</span></p>
<ol start="2" type="1">
<li>Loss function: Cross Entropy (OR log loss function)</li>
</ol>
<p><span class="math display">\[
loss = H(p,q) = \sum\limits_{x} p(x)\log{q(x)}
\]</span></p>
<ol start="3" type="1">
<li>The gradient descent optimizer(SGD)</li>
</ol>
<p>指定 loss function 和 learning_rate</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = tf.train.GradientDescentOptimizer(learning_rate)<br>train = optimizer.minimize(loss)<br></code></pre></td></tr></table></figure>
<ol start="4" type="1">
<li>predict on new samples</li>
</ol>
<p>例子：</p>
<p>样本数据集：</p>
<p>https://github.com/percent4/tensorflow_js_learning/blob/master/USA_vote.csv</p>
<p>Python代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><br><span class="hljs-comment">#read data from other places, e.g. csv</span><br><span class="hljs-comment">#drop_list: variables that are not used</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_data</span>(<span class="hljs-params">file_path, drop_list=[]</span>):<br>    dataSet = pd.read_csv(file_path,sep=<span class="hljs-string">&#x27;,&#x27;</span>)<br>    <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> drop_list:<br>        dataSet = dataSet.drop(col,axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> dataSet<br><br><span class="hljs-comment"># CSV文件存放目录</span><br>path = <span class="hljs-string">&#x27;E://USA_vote.csv&#x27;</span><br><span class="hljs-comment"># 读取CSV文件中的数据</span><br>dataSet = read_data(path)<br><br><span class="hljs-comment"># 利用sklearn中的LogisticRegression模型进行建模</span><br>clf = LogisticRegression(C=<span class="hljs-number">1e9</span>)<br>X, y = dataSet.iloc[:,<span class="hljs-number">0</span>:-<span class="hljs-number">1</span>], dataSet.iloc[:, -<span class="hljs-number">1</span>]<br>clf.fit(X,y)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Sklearn中的逻辑回归模型计算结果：&#x27;</span>)<br><span class="hljs-built_in">print</span>(clf.coef_)<br><span class="hljs-built_in">print</span>(clf.intercept_)<br><br>y_samples = np.array(y)    <span class="hljs-comment"># 样本中的y标签</span><br>x_samples = np.array(X)    <span class="hljs-comment"># 样本中的x标签</span><br>samples_num, var_num = x_samples.shape<br><br>NUM_STEPS = <span class="hljs-number">20000</span>    <span class="hljs-comment"># 总的训练次数</span><br>g = tf.Graph()<br>wb_ = []<br><br><br><span class="hljs-comment"># tensorflow训练模型</span><br><span class="hljs-keyword">with</span> g.as_default():<br>    x = tf.placeholder(tf.float32, shape=[<span class="hljs-literal">None</span>, var_num])<br>    y_true = tf.placeholder(tf.float32, shape=<span class="hljs-literal">None</span>)<br><br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&#x27;inference&#x27;</span>) <span class="hljs-keyword">as</span> scope:<br>        w = tf.Variable([[-<span class="hljs-number">1</span>]*var_num], dtype=tf.float32, name=<span class="hljs-string">&#x27;weights&#x27;</span>)<br>        b = tf.Variable(<span class="hljs-number">0</span>, dtype=tf.float32, name=<span class="hljs-string">&#x27;bias&#x27;</span>)<br>        y_pred = tf.matmul(w, tf.transpose(x)) + b<br><br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&#x27;train&#x27;</span>) <span class="hljs-keyword">as</span> scope:<br>        <span class="hljs-comment"># labels: ture output of y, i.e. 0 and 1, logits: the model&#x27;s linear prediction</span><br>        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)<br>        loss = tf.reduce_mean(cross_entropy)<br><br>        learning_rate = <span class="hljs-number">0.5</span><br>        optimizer = tf.train.GradientDescentOptimizer(learning_rate)<br>        train = optimizer.minimize(loss)<br><br>        <span class="hljs-comment"># Before starting, initialize the variables. We will &#x27;run&#x27; this first.</span><br>        init = tf.global_variables_initializer()<br><br>        <span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>            sess.run(init)<br><br>            <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_STEPS):<br>                sess.run(train, &#123;x: x_samples, y_true: y_samples&#125;)<br>                <span class="hljs-keyword">if</span> (step % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>):<br>                    <span class="hljs-comment"># print(step, sess.run([w, b]))</span><br>                    wb_.append(sess.run([w, b]))<br><br>            <span class="hljs-built_in">print</span>(NUM_STEPS, sess.run([w, b]))<br>            sess.close()<br></code></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">Sklearn中的逻辑回归模型计算结果：<br>[[ 0.34827234 -1.23053489 -2.74406079  6.85275877 -0.95313362 -0.47709861<br>   1.36435858 -1.85956934 -1.3986284   1.54663297 -3.14095297  0.78882048<br>   0.15680863  0.37217971 -1.44617613  0.59043785]]<br>[-1.56742975]<br>TensorFlow的计算结果：<br>20000 [array([[ 0.3481937 , -1.2305422 , -2.743876  ,  6.8526907 , -0.95355535,<br>        -0.47679362,  1.3641126 , -1.8595191 , -1.3984671 ,  1.5464842 ,<br>        -3.1406438 ,  0.7888262 ,  0.15678449,  0.37208068, -1.4461256 ,<br>         0.5904298 ]], dtype=float32), -1.56729]<br></code></pre></td></tr></table></figure>
<h3 id="homework">Homework</h3>
<p>尝试着用Ridge Regression（岭回归）解决一个线性回归问题，关于Ridge
Regression,
可以参考网址：https://blog.csdn.net/u012102306/article/details/52988660</p>
欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。
<center>
<img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" srcset="/img/loading.gif" lazyload style="width:200px;">
</center>
<p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p>
<center>
<img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" srcset="/img/loading.gif" lazyload style="width:200px;">
</center>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/" class="category-chain-item">深度学习框架</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/tensorflow/" class="print-no-link">#tensorflow</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>tensorflow（1）基础入门</div>
      <div>https://percent4.github.io/tensorflow（1）基础入门/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Jclian91</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年8月15日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7coverage%E7%9A%84%E9%AB%98%E9%98%B6%E4%BD%BF%E7%94%A8/" title="测试工具coverage的高阶使用">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">测试工具coverage的高阶使用</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/%E3%80%8A%E6%96%87%E6%B2%BB%E6%97%B6%E4%BB%A3%EF%BC%9A%E4%BA%94%E4%BB%A3%E5%8D%81%E5%9B%BD%E3%80%81%E4%B8%A4%E5%AE%8B%E3%80%8B%E6%91%98%E6%8A%84/" title="《文治时代：五代十国、两宋》摘抄">
                        <span class="hidden-mobile">《文治时代：五代十国、两宋》摘抄</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"YUsFSnlfB9167rgyk6dKxO3n-gzGzoHsz","appKey":"MCARXkAOuxb8aiWTb3WdAsyn","path":"window.location.pathname","placeholder":"文章对您有启发吗？","avatar":"retro","meta":["nick"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":true,"recordIP":true,"serverURLs":"https://yusfsnlf.lc-cn-n1-shared.com","emojiCDN":null,"emojiMaps":null,"enableQQ":false,"appid":"YUsFSnlfB9167rgyk6dKxO3n-gzGzoHsz","appkey":"MCARXkAOuxb8aiWTb3WdAsyn","mathJax":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <br> <span id="runtime_span"></span> <script type="text/javascript">function show_runtime(){window.setTimeout("show_runtime()",1000);X=new Date("7/6/2023 13:03:50");Y=new Date();T=(Y.getTime()-X.getTime());M=24*60*60*1000;a=T/M;A=Math.floor(a);b=(a-A)*24;B=Math.floor(b);c=(b-B)*60;C=Math.floor((b-B)*60);D=Math.floor((c-C)*60);runtime_span.innerHTML="本站已运行"+A+"天"+B+"小时"+C+"分"+D+"秒"}show_runtime();</script> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
