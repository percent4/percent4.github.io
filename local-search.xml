<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>使用ElasticSearch实现文本相似性搜索</title>
    <link href="/%E4%BD%BF%E7%94%A8ElasticSearch%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2/"/>
    <url>/%E4%BD%BF%E7%94%A8ElasticSearch%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何使用ElastiSearch来部署文本嵌入（Embedding）模型，并实现之前向量数据库中的文本相似性搜索功能。</p></blockquote><p>在文章<a href="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486651&amp;idx=1&amp;sn=d40fa08af20a79dfe03ceefddd27c036&amp;chksm=fcb9b52bcbce3c3d0ff8b61dba68022c978c418235ed8d49182235aecc58a79b8a39c38cf3a7&amp;token=772020212&amp;lang=zh_CN#rd">使用ElasticSearch进行自然语言处理：以命名实体识别为例</a>中，我们介绍了如何使用ElasticSearch来部署NER模型，并在ElasticSearch中利用部署的NLP模型来进行智能文本分析：从文本中提取实体，并形成词云图。</p><p>在文章<a href="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486606&amp;idx=1&amp;sn=fcbb4031dfe2badb11083b3ad3997075&amp;chksm=fcb9b51ecbce3c0873fd5d9e5afd6d90c08816f5e50f542f2f5bc9dd0b2da75a90d22c903dc1&amp;token=772020212&amp;lang=zh_CN#rd">向量数据库入门（一）文本相似性搜索</a>中，笔者利用向量数据库如<code>faiss</code>，<code>Milvus</code>, <code>Qdrant</code>来实现文本相似性搜索。</p><p>本文将会在此基础上，使用ElastiSearch来部署文本嵌入（Embedding）模型，并实现之前向量数据库中的文本相似性搜索功能。</p><h3 id="文本嵌入模型部署">文本嵌入模型部署</h3><p>我们在这里使用的文本嵌入模型为<code>BAAI/bge-base-zh-v1.5</code>,其网址为: <a href="https://huggingface.co/BAAI/bge-base-zh-v1.5">https://huggingface.co/BAAI/bge-base-zh-v1.5</a> .该模型支持中文文本嵌入（Embedding），输出的向量维度为768，L2范数为1，即单位向量。</p><p>在文章<a href="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486651&amp;idx=1&amp;sn=d40fa08af20a79dfe03ceefddd27c036&amp;chksm=fcb9b52bcbce3c3d0ff8b61dba68022c978c418235ed8d49182235aecc58a79b8a39c38cf3a7&amp;token=772020212&amp;lang=zh_CN#rd">使用ElasticSearch进行自然语言处理：以命名实体识别为例</a>中，我们介绍了如何使用ElasticSearch来部署NER模型。类似地，我们可以部署文本嵌入模型，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -itd --<span class="hljs-built_in">rm</span> docker.elastic.co/eland/eland \<br>    eland_import_hub_model --url http://localhost:9200 \<br>    --hub-model-id BAAI/bge-base-zh-v1.5 \<br>    --task-type text_embedding \<br>    --start --clear-previous<br></code></pre></td></tr></table></figure><p>在Kibana界面中的Machine Learning -&gt; Model Management -&gt; Trained Models中，可查看部署的模型信息如下：</p><p><img src="https://s2.loli.net/2024/04/06/1TZOSnesW3Ec2kx.png" alt="文本嵌入模型信息"></p><p>在Dev Tools页面，使用API调用该模型，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">POST _ml/trained_models/baai__bge-base-zh-v1.5/_infer<br>&#123;<br>  <span class="hljs-string">&quot;docs&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;text_field&quot;</span>: <span class="hljs-string">&quot;阿波罗登月计划&quot;</span><br>    &#125;<br>  ]<br>&#125;<br></code></pre></td></tr></table></figure><p>输出结果如下（取向量的前3位）：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;inference_results&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;predicted_value&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                <span class="hljs-number">-0.022389261052012444</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-number">0.00514355069026351</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-number">0.025597693398594856</span><span class="hljs-punctuation">,</span><br>                ...<br>            <span class="hljs-punctuation">]</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="文本相似性搜索">文本相似性搜索</h3><p>我们使用和文章<a href="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486606&amp;idx=1&amp;sn=fcbb4031dfe2badb11083b3ad3997075&amp;chksm=fcb9b51ecbce3c0873fd5d9e5afd6d90c08816f5e50f542f2f5bc9dd0b2da75a90d22c903dc1&amp;token=772020212&amp;lang=zh_CN#rd">向量数据库入门（一）文本相似性搜索</a>一样的示例文本，来实现相似文本的搜索。</p><p>利用Kibana上传json文本，创建<code>dengyue</code>索引，mapping如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;dengyue&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;mappings&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;_meta&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;created_by&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;file-data-visualizer&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;properties&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;line&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;long&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>创建Ingest Pipeline如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs bash">PUT _ingest/pipeline/text-embeddings<br>&#123;<br>  <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Demo text embedding pipeline&quot;</span>,<br>  <span class="hljs-string">&quot;processors&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;inference&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;model_id&quot;</span>: <span class="hljs-string">&quot;baai__bge-base-zh-v1.5&quot;</span>,<br>        <span class="hljs-string">&quot;target_field&quot;</span>: <span class="hljs-string">&quot;text_embedding&quot;</span>,<br>        <span class="hljs-string">&quot;field_map&quot;</span>: &#123;<br>          <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;text_field&quot;</span><br>        &#125;<br>      &#125;<br>    &#125;<br>  ],<br>  <span class="hljs-string">&quot;on_failure&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;set&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Index document to &#x27;failed-&lt;index&gt;&#x27;&quot;</span>,<br>        <span class="hljs-string">&quot;field&quot;</span>: <span class="hljs-string">&quot;_index&quot;</span>,<br>        <span class="hljs-string">&quot;value&quot;</span>: <span class="hljs-string">&quot;failed-&#123;&#123;&#123;_index&#125;&#125;&#125;&quot;</span><br>      &#125;<br>    &#125;,<br>    &#123;<br>      <span class="hljs-string">&quot;set&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Set error message&quot;</span>,<br>        <span class="hljs-string">&quot;field&quot;</span>: <span class="hljs-string">&quot;ingest.failure&quot;</span>,<br>        <span class="hljs-string">&quot;value&quot;</span>: <span class="hljs-string">&quot;&#123;&#123;_ingest.on_failure_message&#125;&#125;&quot;</span><br>      &#125;<br>    &#125;<br>  ]<br>&#125;<br></code></pre></td></tr></table></figure><p>再创建一个新的索引<code>dengyue-with-embeddings</code>，其中索引<code>dengyue-with-embeddings</code>的mapping如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;dengyue-with-embeddings&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;mappings&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;properties&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;line&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;long&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;text_embedding&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;properties&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;model_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;fields&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;keyword&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>                  <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;keyword&quot;</span><span class="hljs-punctuation">,</span><br>                  <span class="hljs-attr">&quot;ignore_above&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">256</span><br>                <span class="hljs-punctuation">&#125;</span><br>              <span class="hljs-punctuation">&#125;</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;predicted_value&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;dense_vector&quot;</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;dims&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">768</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;index&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;similarity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cosine&quot;</span><br>            <span class="hljs-punctuation">&#125;</span><br>          <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>其中text_embedding.predicted_value即为文本嵌入后的向量字段。</p><p>对索引<code>dengyue</code>应用text-embeddings pipeline，将数据迁移至<code>dengyue-with-embeddings</code>，此时已对索引<code>dengyue</code>中的text字段进行了文本嵌入。命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">POST _reindex?wait_for_completion=<span class="hljs-literal">false</span><br>&#123;<br>  <span class="hljs-string">&quot;source&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;index&quot;</span>: <span class="hljs-string">&quot;dengyue&quot;</span><br>  &#125;,<br>  <span class="hljs-string">&quot;dest&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;index&quot;</span>: <span class="hljs-string">&quot;dengyue-with-embeddings&quot;</span>,<br>    <span class="hljs-string">&quot;pipeline&quot;</span>: <span class="hljs-string">&quot;text-embeddings&quot;</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>稍等片刻，新索引<code>dengyue-with-embeddings</code>已完成数据迁移，查看前3条数据，如下：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs prolog">[<br>    &#123;<br>        <span class="hljs-string">&quot;_index&quot;</span>: <span class="hljs-string">&quot;dengyue-with-embeddings&quot;</span>,<br>        <span class="hljs-string">&quot;_id&quot;</span>: <span class="hljs-string">&quot;wAphqY4BTApH2kxu6Agz&quot;</span>,<br>        <span class="hljs-string">&quot;_score&quot;</span>: <span class="hljs-number">1</span>,<br>        <span class="hljs-string">&quot;_source&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;text_embedding&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;predicted_value&quot;</span>: [<br>                    <span class="hljs-number">-0.06904672831296921</span>,<br>                    <span class="hljs-number">-0.0306668933480978</span>,<br>                    <span class="hljs-number">0.02560381218791008</span>,<br>                    ...<br>                ],<br>                <span class="hljs-string">&quot;model_id&quot;</span>: <span class="hljs-string">&quot;baai__bge-base-zh-v1.5&quot;</span><br>            &#125;,<br>            <span class="hljs-string">&quot;line&quot;</span>: <span class="hljs-number">0</span>,<br>            <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;2023年7月12日，中国载人航天工程办公室副总师张海联披露，中国计划在2030年前实现载人登月。&quot;</span><br>        &#125;<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;_index&quot;</span>: <span class="hljs-string">&quot;dengyue-with-embeddings&quot;</span>,<br>        <span class="hljs-string">&quot;_id&quot;</span>: <span class="hljs-string">&quot;wQphqY4BTApH2kxu6Agz&quot;</span>,<br>        <span class="hljs-string">&quot;_score&quot;</span>: <span class="hljs-number">1</span>,<br>        <span class="hljs-string">&quot;_source&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;text_embedding&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;predicted_value&quot;</span>: [<br>                    <span class="hljs-number">-0.06188153848052025</span>,<br>                    <span class="hljs-number">-0.0077980696223676205</span>,<br>                    <span class="hljs-number">0.03301164135336876</span>,<br>                    ...<br>                ],<br>                <span class="hljs-string">&quot;model_id&quot;</span>: <span class="hljs-string">&quot;baai__bge-base-zh-v1.5&quot;</span><br>            &#125;,<br>            <span class="hljs-string">&quot;line&quot;</span>: <span class="hljs-number">1</span>,<br>            <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;中文名中国载人登月工程外文名Manned lunar exploration project属    性科技工程发布时间2013年3月3日所属领域航天工程&quot;</span><br>        &#125;<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;_index&quot;</span>: <span class="hljs-string">&quot;dengyue-with-embeddings&quot;</span>,<br>        <span class="hljs-string">&quot;_id&quot;</span>: <span class="hljs-string">&quot;wgphqY4BTApH2kxu6Agz&quot;</span>,<br>        <span class="hljs-string">&quot;_score&quot;</span>: <span class="hljs-number">1</span>,<br>        <span class="hljs-string">&quot;_source&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;text_embedding&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;predicted_value&quot;</span>: [<br>                    <span class="hljs-number">-0.036897893995046616</span>,<br>                    <span class="hljs-number">-0.05945304036140442</span>,<br>                    <span class="hljs-number">0.0025381790474057198</span>,<br>                    ...<br>                ],<br>                <span class="hljs-string">&quot;model_id&quot;</span>: <span class="hljs-string">&quot;baai__bge-base-zh-v1.5&quot;</span><br>            &#125;,<br>            <span class="hljs-string">&quot;line&quot;</span>: <span class="hljs-number">2</span>,<br>            <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;目录&quot;</span><br>        &#125;<br>    &#125;<br>]<br></code></pre></td></tr></table></figure><p>完成上述的准备工作后，我们就可以实现类似向量数据库中的文本相似性搜索功能了。</p><p>输入query为<code>阿波罗登月计划</code>，先使用如下命令获得其嵌入向量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">POST _ml/trained_models/baai__bge-base-zh-v1.5/_infer<br>&#123;<br>  <span class="hljs-string">&quot;docs&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;text_field&quot;</span>: <span class="hljs-string">&quot;阿波罗登月计划&quot;</span><br>    &#125;<br>  ]<br>&#125;<br></code></pre></td></tr></table></figure><p>再利用ElasticSearch中内置的向量相似度检索命令（<code>_knn_search</code>）来搜索相似文本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">GET dengyue-with-embeddings/_knn_search<br>&#123;<br>  <span class="hljs-string">&quot;knn&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;field&quot;</span>: <span class="hljs-string">&quot;text_embedding.predicted_value&quot;</span>,<br>    <span class="hljs-string">&quot;query_vector&quot;</span>: [<br>        -0.022389261052012444,<br>        0.00514355069026351,<br>        0.025597693398594856,<br>        ...<br>      ],<br>    <span class="hljs-string">&quot;k&quot;</span>: 3,<br>    <span class="hljs-string">&quot;num_candidates&quot;</span>: 100<br>  &#125;,<br>  <span class="hljs-string">&quot;_source&quot;</span>: [<br>    <span class="hljs-string">&quot;line&quot;</span>,<br>    <span class="hljs-string">&quot;text&quot;</span><br>  ]<br>&#125;<br></code></pre></td></tr></table></figure><p>搜索出来的最相似的三条记录如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;took&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">15</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;timed_out&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_shards&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;total&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;successful&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;skipped&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;failed&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;hits&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;total&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;value&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">44</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;relation&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;eq&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;max_score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.85360855</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;hits&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;_index&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;dengyue-with-embeddings&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;1gphqY4BTApH2kxu6Ag0&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.85360855</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_source&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;line&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">22</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;二十世纪六、七十年代，美国人凭借“阿波罗”计划率先登上月球。&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;_index&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;dengyue-with-embeddings&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;wQphqY4BTApH2kxu6Agz&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.8161578</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_source&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;line&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;中文名中国载人登月工程外文名Manned lunar exploration project属    性科技工程发布时间2013年3月3日所属领域航天工程&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;_index&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;dengyue-with-embeddings&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;5wphqY4BTApH2kxu6Ag0&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.7933982</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_source&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;line&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">39</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;在探月方面，2020年前将实现“回”的任务，即飞行器不但在月球上落下来，还取一些东西带回地球，并计划在2025年实现航天员登月。&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本文使用ElastiSearch来部署文本嵌入（Embedding）模型，并实现之前向量数据库中的文本相似性搜索功能。同时，我们也可以看到，在ElastiSearch中也可以实现向量检索功能，十分方便。</p><h3 id="推荐阅读">推荐阅读</h3><ol><li><a href="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486651&amp;idx=1&amp;sn=d40fa08af20a79dfe03ceefddd27c036&amp;chksm=fcb9b52bcbce3c3d0ff8b61dba68022c978c418235ed8d49182235aecc58a79b8a39c38cf3a7&amp;token=772020212&amp;lang=zh_CN#rd">使用ElasticSearch进行自然语言处理：以命名实体识别为例</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486606&amp;idx=1&amp;sn=fcbb4031dfe2badb11083b3ad3997075&amp;chksm=fcb9b51ecbce3c0873fd5d9e5afd6d90c08816f5e50f542f2f5bc9dd0b2da75a90d22c903dc1&amp;token=772020212&amp;lang=zh_CN#rd">向量数据库入门（一）文本相似性搜索</a></li></ol><h3 id="参考文献">参考文献</h3><ol><li>如何部署自然语言处理 (NLP)：文本嵌入和矢量搜索: <a href="https://www.elastic.co/cn/blog/how-to-deploy-nlp-text-embeddings-and-vector-search">https://www.elastic.co/cn/blog/how-to-deploy-nlp-text-embeddings-and-vector-search</a></li></ol><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center>    <img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center>    <img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ElasticSearch</tag>
      
      <tag>向量数据库</tag>
      
      <tag>文本嵌入</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用ElasticSearch进行自然语言处理：以命名实体识别为例</title>
    <link href="/%E4%BD%BF%E7%94%A8ElasticSearch%E8%BF%9B%E8%A1%8C%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E4%BB%A5%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E4%B8%BA%E4%BE%8B/"/>
    <url>/%E4%BD%BF%E7%94%A8ElasticSearch%E8%BF%9B%E8%A1%8C%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E4%BB%A5%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E4%B8%BA%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将以命名实体识别（NER）任务为例子，来介绍如何在ElasticSearch中进行自然语言处理（NLP）。</p></blockquote><p>ElasticSearch是一个流行的开源搜索和分析引擎，广泛用于日志和事件数据的存储、检索和分析，它的功能十分强大。近年来又引入了机器学习（Machine Learning）功能，允许用户它进行模型分析预测，包括自然语言处理（NLP）等。</p><p>本文将会以NLP中的命名实体识别（NER）任务为例，来展示如何在ElasticSearch中进行文本智能处理。</p><p>本文使用的NER模型为<code>shibing624/bert4ner-base-chinese</code>，其HuggingFace网址为：<a href="https://huggingface.co/shibing624/bert4ner-base-chinese">https://huggingface.co/shibing624/bert4ner-base-chinese</a>。该模型可以识别中文文本中的时间、地点、人物、组织机构这四类实体，base模型为<code>BERT</code>.</p><p>本文主要使用<code>Eland</code>工具将NER模型部署在ElasticSearch中，并在ElasticSearch中进行文本处理。</p><h3 id="准备工作">准备工作</h3><p>我们先使用Docker Compose来搭建一个简单的ElasticSearch和Kibana环境，使用的版本均为8.13.0，其中配置文件<code>docker-compose.yml</code>如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.1&quot;</span><br><span class="hljs-comment"># 服务配置</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">elasticsearch:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">elasticsearch-8.13.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">elasticsearch:8.13.0</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;ES_JAVA_OPTS=-Xms4096m -Xmx4096m&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;http.host=0.0.0.0&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;node.name=elastic01&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;cluster.name=cluster_elasticsearch&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;discovery.type=single-node&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;xpack.security.enabled=false&quot;</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9200:9200&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9300:9300&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./data:/usr/share/elasticsearch/data</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elastic_net</span><br><br>  <span class="hljs-attr">kibana:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">kibana-8.13.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">kibana:8.13.0</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;50076:5601&quot;</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-attr">ELASTICSEARCH_HOSTS:</span> <span class="hljs-string">http://elasticsearch:9200</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elasticsearch</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elastic_net</span><br><br><span class="hljs-comment"># 网络配置</span><br><span class="hljs-attr">networks:</span><br>  <span class="hljs-attr">elastic_net:</span><br>    <span class="hljs-attr">driver:</span> <span class="hljs-string">bridge</span><br></code></pre></td></tr></table></figure><p><strong>注意</strong>: 在Kibana界面的Stack Management中，需要开启Machine Learning，此时一般要license授权，但可试用一个月。如果不开启Machine Learning，则无法使用NLP模型。</p><h3 id="模型部署">模型部署</h3><p>我们使用Elastic官方开源的<code>Eland</code>工具来部署<code>uggingFace</code>开源模型。</p><p><code>Eland</code>是一个全新的 Python Elasticsearch 客户端和工具包，它提供了类似于 pandas 的 API，用于分析、ETL 和机器学习。</p><p><img src="https://raw.githubusercontent.com/elastic/eland/main/docs/sphinx/logo/eland.png" alt="Eland Logo"></p><p>我们将使用如下的Docker命令来方便地将<code>shibing624/bert4ner-base-chinese</code>这个NER模型加载至ElasticSearch中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -itd --<span class="hljs-built_in">rm</span> docker.elastic.co/eland/eland \<br>eland_import_hub_model --url http://host:port \ <br>--hub-model-id shibing624/bert4ner-base-chinese \<br>--task-type ner \<br>--start \<br>--clear-previous<br></code></pre></td></tr></table></figure><p>其中url为ES服务在本地服务器上的网址。</p><p>运行上述服务后，<code>Eland</code>使用PyTorch进行模型加载、推理，版本为2.1.2, ElasticSeach版本为8.13.0，请特别留意这两个模块的版本。</p><p><strong>注意</strong>：在部署模型时，因为模型加载需要大量内存，因此需要留意ES中的内存分配。该模型的内存占用约为1.1G。另外，在笔者的Mac电脑上，模型推理将会报错，因此建议最好使用Linux服务器。</p><p>此时，在Kibana -&gt; Machine Learning -&gt; Model Management中，可找到我们已经部署的模型，将这个模型开启<code>Synchronized</code>，不久后就能看到模型显示绿色的<code>Deployed</code>。</p><p><img src="https://s2.loli.net/2024/04/04/UJBr2LkoePYws51.png" alt="模型已经部署完毕"></p><p>查看部署模型的详细信息，比如模型的Config，如下：</p><p><img src="https://s2.loli.net/2024/04/04/XQqzNYpwoyLsmRV.png" alt="模型Config"></p><h3 id="简单使用">简单使用</h3><p>在Trained Models页面，点击部署模型的Actions按钮，可以进行模型推理测试（Test model）。</p><p><img src="https://s2.loli.net/2024/04/04/lnq5pRVsgbtewE3.png" alt="模型推理测试"></p><p>在Dev Tools（开发者工具）页面，可以使用REST命令进行交互。</p><ul><li>获取模型状态</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">GET _ml/trained_models/shibing624__bert4ner-base-chinese/_stats<br></code></pre></td></tr></table></figure><p>其中<code>shibing624__bert4ner-base-chinese</code>为模型id（model id）。</p><ul><li>模型推理测试</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">POST _ml/trained_models/shibing624__bert4ner-base-chinese/_infer<br>&#123;<br>  <span class="hljs-string">&quot;docs&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;text_field&quot;</span>: <span class="hljs-string">&quot;在台北的台湾大学地质系特聘教授吴逸民表示，这次地震让北台湾民众这么有感的主因是台北盆地地形所产生的加乘效果。&quot;</span><br>    &#125;<br>  ]<br>&#125;<br></code></pre></td></tr></table></figure><p>预测结果为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;inference_results&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;predicted_value&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;在[台北](LOC&amp;台北)的[台湾大学地质系](ORG&amp;台湾大学地质系)特聘教授[吴逸民](PER&amp;吴逸民)表示，这次地震让[北台湾](LOC&amp;北台湾)民众这么有感的主因是[台北盆地](LOC&amp;台北盆地)地形所产生的加乘效果。&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;entities&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;entity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;台北&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;class_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;LOC&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;class_probability&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.9979633671820971</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;start_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;end_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;entity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;台湾大学地质系&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;class_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ORG&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;class_probability&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.9907676215640316</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;start_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;end_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">11</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;entity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;吴逸民&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;class_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;PER&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;class_probability&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.9998507299738062</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;start_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">15</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;end_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">18</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;entity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;北台湾&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;class_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;LOC&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;class_probability&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.9056884399922297</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;start_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">26</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;end_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">29</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;entity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;台北盆地&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;class_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;LOC&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;class_probability&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.8290892675823885</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;start_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">39</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;end_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">43</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>输入字段为text_field。predicted_value字段是注释文本格式的输入字符串，class_name是预测类别，而 class_probability则表示模型预测的置信水平。start_pos和end_pos 分别为已识别实体的开头字符和结尾字符在原文中的位置。</p><p>更多模型相关的API可参考: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-df-trained-models-apis.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-df-trained-models-apis.html</a> .</p><h3 id="文本处理">文本处理</h3><h4 id="Ingest-Pipeline介绍">Ingest Pipeline介绍</h4><p>我们使用Ingest Pipeline来进行数据预处理。</p><p>Ingest Pipeline 允许文档在被索引之前对数据进行预处理，将数据加工处理成我们需要的格式。例如，可以使用Ingest Pipeline添加或者删除字段，转换类型，解析内容等等。Pipeline 由一组处理器Processor 构成，每个处理器依次运行，对传入的文档进行特定的更改。Ingest Pipeline 和 Logstash 中的 filter 作用相似，并且更加轻量和易于调试。</p><p>我们构建的Pipeline（名称为<code>chinese_ner</code>）命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs bash">PUT _ingest/pipeline/chinese_ner<br>&#123;<br>  <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Chinese NER pipeline&quot;</span>,<br>  <span class="hljs-string">&quot;processors&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;inference&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;model_id&quot;</span>: <span class="hljs-string">&quot;shibing624__bert4ner-base-chinese&quot;</span>,<br>        <span class="hljs-string">&quot;target_field&quot;</span>: <span class="hljs-string">&quot;ml.ner&quot;</span>,<br>        <span class="hljs-string">&quot;field_map&quot;</span>: &#123;<br>          <span class="hljs-string">&quot;paragraph&quot;</span>: <span class="hljs-string">&quot;text_field&quot;</span><br>        &#125;<br>      &#125;<br>    &#125;,<br>    &#123;<br>      <span class="hljs-string">&quot;script&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;lang&quot;</span>: <span class="hljs-string">&quot;painless&quot;</span>,<br>        <span class="hljs-string">&quot;if&quot;</span>: <span class="hljs-string">&quot;return ctx[&#x27;ml&#x27;][&#x27;ner&#x27;].containsKey(&#x27;entities&#x27;)&quot;</span>,<br>        <span class="hljs-string">&quot;source&quot;</span>: <span class="hljs-string">&quot;Map tags = new HashMap(); for (item in ctx[&#x27;ml&#x27;][&#x27;ner&#x27;][&#x27;entities&#x27;]) &#123; if (!tags.containsKey(item.class_name)) tags[item.class_name] = new HashSet(); tags[item.class_name].add(item.entity);&#125; ctx[&#x27;tags&#x27;] = tags;&quot;</span><br>      &#125;<br>    &#125;<br>  ],<br>  <span class="hljs-string">&quot;on_failure&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;set&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Index document to &#x27;failed-&lt;index&gt;&#x27;&quot;</span>,<br>        <span class="hljs-string">&quot;field&quot;</span>: <span class="hljs-string">&quot;_index&quot;</span>,<br>        <span class="hljs-string">&quot;value&quot;</span>: <span class="hljs-string">&quot;failed-&#123;&#123;&#123; _index &#125;&#125;&#125;&quot;</span><br>      &#125;<br>    &#125;,<br>    &#123;<br>      <span class="hljs-string">&quot;set&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Set error message&quot;</span>,<br>        <span class="hljs-string">&quot;field&quot;</span>: <span class="hljs-string">&quot;ingest.failure&quot;</span>,<br>        <span class="hljs-string">&quot;value&quot;</span>: <span class="hljs-string">&quot;&#123;&#123;_ingest.on_failure_message&#125;&#125;&quot;</span><br>      &#125;<br>    &#125;<br>  ]<br>&#125;<br></code></pre></td></tr></table></figure><p>在Stack Management -&gt; Ingest Pipelines中可查看该pipeline的信息，如下图：</p><p><img src="https://s2.loli.net/2024/04/04/cpZEdrH9k5MinY4.png" alt="pipeline信息"></p><p>为简单验证该pipeline是否得到了想要的效果，可在Dev Tools页面对其进行测试：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">POST _ingest/pipeline/chinese_ner/_simulate<br>&#123;<br>  <span class="hljs-string">&quot;docs&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;_source&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;paragraph&quot;</span>: <span class="hljs-string">&quot;王安石的另一位好友叫吴充。&quot;</span>,<br>        <span class="hljs-string">&quot;line&quot;</span>: 16<br>      &#125;<br>    &#125;<br>  ]<br>&#125;<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;docs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;doc&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;_index&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;_index&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_version&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;-3&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;_id&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_source&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;paragraph&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;王安石的另一位好友叫吴充。&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;line&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">16</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;ml&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;ner&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;model_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;shibing624__bert4ner-base-chinese&quot;</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;entities&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                <span class="hljs-punctuation">&#123;</span><br>                  <span class="hljs-attr">&quot;end_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>                  <span class="hljs-attr">&quot;class_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;PER&quot;</span><span class="hljs-punctuation">,</span><br>                  <span class="hljs-attr">&quot;class_probability&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.999796460282346</span><span class="hljs-punctuation">,</span><br>                  <span class="hljs-attr">&quot;start_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>                  <span class="hljs-attr">&quot;entity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;王安石&quot;</span><br>                <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-punctuation">&#123;</span><br>                  <span class="hljs-attr">&quot;end_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">12</span><span class="hljs-punctuation">,</span><br>                  <span class="hljs-attr">&quot;class_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;PER&quot;</span><span class="hljs-punctuation">,</span><br>                  <span class="hljs-attr">&quot;class_probability&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.9997412197983617</span><span class="hljs-punctuation">,</span><br>                  <span class="hljs-attr">&quot;start_pos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">10</span><span class="hljs-punctuation">,</span><br>                  <span class="hljs-attr">&quot;entity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;吴充&quot;</span><br>                <span class="hljs-punctuation">&#125;</span><br>              <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;predicted_value&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;[王安石](PER&amp;王安石)的另一位好友叫[吴充](PER&amp;吴充)。&quot;</span><br>            <span class="hljs-punctuation">&#125;</span><br>          <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;tags&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;PER&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>              <span class="hljs-string">&quot;王安石&quot;</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-string">&quot;吴充&quot;</span><br>            <span class="hljs-punctuation">]</span><br>          <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_ingest&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;timestamp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2024-04-04T12:36:23.397525241Z&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h4 id="提取文本实体，展示词云图">提取文本实体，展示词云图</h4><p>让我们在之前的基础上，进行简单实战：展示崔铭写的《王安石传》第五章第六节内容中的实体词云图。</p><p>我们利用Kibana的文件上传功能，上传<code>wanganshi.json</code>，共75条数据（每行为json字符串，包含line和paragraph字段），创建的index为ner_demo，mapping为:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;ner_demo&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;mappings&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;_meta&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;created_by&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;file-data-visualizer&quot;</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;properties&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;line&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>                    <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;long&quot;</span><br>                <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;paragraph&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>                    <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><br>                <span class="hljs-punctuation">&#125;</span><br>            <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>使用上述创建的Ingest Pipeline对paragraph字段进行数据预处理，提取实体，并更新数据。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">POST ner_demo/_update_by_query?pipeline=chinese_ner<br></code></pre></td></tr></table></figure><p>数据预处理完毕后，使用Kibana的Visualize Library页面创建实体词云图，效果如下：</p><p><img src="https://s2.loli.net/2024/04/04/XhJY7bZWUfBQGR9.png" alt="人名词云图"></p><p><img src="https://s2.loli.net/2024/04/04/M5toOvXsNZa9FHj.png" alt="地名词云图"></p><h3 id="总结">总结</h3><p>本文主要介绍了如何使用<code>Eland</code>工具在ElasticSearch部署命名实体识别模型，并结合具体的文本例子详细给出了文本智能处理的方法。</p><p>事实上，对于我们在ElasticSearch部署的模型，还可以进行调整部署，增强其推理性能。</p><p>本文给出的代码已经开源至Github，网址为: <a href="https://github.com/percent4/ES_Learning">https://github.com/percent4/ES_Learning</a> .</p><h3 id="参考网址">参考网址</h3><ol><li>如何部署自然语言处理 (NLP)：命名实体识别 (NER) 示例: <a href="https://www.elastic.co/cn/blog/how-to-deploy-nlp-named-entity-recognition-ner-example">https://www.elastic.co/cn/blog/how-to-deploy-nlp-named-entity-recognition-ner-example</a></li><li>Elasticsearch 8 : Named Entity Recognition (NER) using Inference Ingest Pipeline: <a href="https://medium.com/@psajan106/elasticsearch-8-named-entity-recognition-ner-using-inference-ingest-pipeline-8e7bd566c5e8">https://medium.com/@psajan106/elasticsearch-8-named-entity-recognition-ner-using-inference-ingest-pipeline-8e7bd566c5e8</a></li><li>【ES三周年】使用 Ingest Pipeline 在 Elasticsearch 中对数据进行预处理: <a href="https://cloud.tencent.com/developer/article/2217871">https://cloud.tencent.com/developer/article/2217871</a></li><li>shibing624/bert4ner-base-chinese: <a href="https://huggingface.co/shibing624/bert4ner-base-chinese">https://huggingface.co/shibing624/bert4ner-base-chinese</a></li><li>Eland Python Client: <a href="https://www.elastic.co/guide/en/elasticsearch/client/eland/current/index.html">https://www.elastic.co/guide/en/elasticsearch/client/eland/current/index.html</a></li></ol><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center>    <img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center>    <img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>ElasticSearch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用MkDocs轻松搞定Python项目文档</title>
    <link href="/%E4%BD%BF%E7%94%A8MkDocs%E8%BD%BB%E6%9D%BE%E6%90%9E%E5%AE%9APython%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3/"/>
    <url>/%E4%BD%BF%E7%94%A8MkDocs%E8%BD%BB%E6%9D%BE%E6%90%9E%E5%AE%9APython%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何使用MkDocs来轻松搞定Python项目文档，这无疑是Python工程的重要部分。</p></blockquote><h3 id="引言">引言</h3><p>在学习Python第三方模块时，我们尝尝会阅读它们的官方文档，这能让我们快速掌握它们，同时也是这些第三方模块最为重要的参考资料。</p><p>比如，大名鼎鼎的<code>scrapy</code>模块，其官方文档（<code>readthedocs</code>风格）界面（网址为:<a href="https://scapy.readthedocs.io/en/latest/"class="uri">https://scapy.readthedocs.io/en/latest/</a>）如下：</p><figure><img src="https://s2.loli.net/2024/04/03/bf5qDjVoGCSyswv.png"alt="scrapy官方文档" /><figcaption aria-hidden="true">scrapy官方文档</figcaption></figure><p>又比如，最近大火的<code>Pydantic</code>和<code>FastAPI</code>模块都采用改了MkDocs工具来构建其官方文档，风格为<code>material</code>。<code>Pydantic</code>的界面（网址为:）如下：</p><figure><img src="https://s2.loli.net/2024/04/03/OFzek7jQ9bKtTs3.png"alt="Pydantic官方文档" /><figcaption aria-hidden="true">Pydantic官方文档</figcaption></figure><p>那么，什么是<code>MkDocs</code>呢？</p><p><code>MkDocs</code>是一个快速、简单且华丽的静态站点生成器，适用于构建项目文档。文档源文件是用Markdown 编写的，并使用单个 YAML配置文件进行配置。使用<code>MkDocs</code>，我们将会很方便地给Python项目来生成一个项目文档。</p><p>本文将会通过Python的docstring和Google代码注释风格，并结合<code>MkDocs</code>来生成Python项目文档，并部署至Github平台。</p><p>在这之前，我们需要安装的Python模块如下：</p><pre><code class="hljs">mkdocs==1.5.3mkdocs-material==9.5.17mkdocstrings==0.24.1mkdocstrings-python==1.9.0</code></pre><p>我们使用的项目为文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486274&amp;idx=1&amp;sn=45bb873eb1a60c874be9f3d6d8a730a2&amp;chksm=fcb9b2d2cbce3bc4435d38d87481f5081b7f45a3b9cc92e05445e3dc53734b4308a6f41b15c5&amp;token=1354542875&amp;lang=zh_CN#rd">使用Hatchling轻松实现Python项目打包</a>中的Python项目<code>package_python_project</code>，网址为:<a href="https://github.com/percent4/package_python_project"class="uri">https://github.com/percent4/package_python_project</a> .</p><h3 id="docstring和doctest">docstring和doctest</h3><p>我们对项目中的<code>src/token_counter/token_count.py</code>添加docstring和符合Google代码注释风格的注释，同时在注释中添加Examples，使之能用doctest进行简单测试。</p><p>改造后的脚本如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: token_count.py</span><br><span class="hljs-comment"># @time: 2024/1/22 17:45</span><br><span class="hljs-string">&quot;&quot;&quot;TokenCounter</span><br><span class="hljs-string"></span><br><span class="hljs-string">to use TokenCounter, you shoule use:</span><br><span class="hljs-string"></span><br><span class="hljs-string">from token_counter.token_count import TokenCounter</span><br><span class="hljs-string"></span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">import</span> tiktoken<br><br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Union</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TokenCounter</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;The class is for count tokens in user input.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;`__init__` method</span><br><span class="hljs-string"></span><br><span class="hljs-string">        the `__init__` method of the class</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Notes:</span><br><span class="hljs-string">            the model name now only support OpenAI GPT models</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            model: the name of models, e.g. `gpt-3.5-turbo`</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.model = model<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">count</span>(<span class="hljs-params">self, _<span class="hljs-built_in">input</span>: <span class="hljs-type">Union</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>], <span class="hljs-built_in">str</span>]</span>) -&gt; <span class="hljs-type">Union</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], <span class="hljs-built_in">int</span>]:<br>        <span class="hljs-string">&quot;&quot;&quot;count the tokens of _input in string or list of string format</span><br><span class="hljs-string"></span><br><span class="hljs-string">        count the tokens of _input using OpenAI tiktoken module, the model is `gpt-3.5-turbo`</span><br><span class="hljs-string">        by default. if the model is not supported, then use `cl100k_base` as backup.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            _input: the input string or list of string</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Examples:</span><br><span class="hljs-string">            &gt;&gt;&gt; token_counter = TokenCounter()</span><br><span class="hljs-string">            &gt;&gt;&gt; token_counter.count(&quot;who are you?&quot;)</span><br><span class="hljs-string">            4</span><br><span class="hljs-string">            &gt;&gt;&gt; token_counter.count([&quot;who are you?&quot;, &quot;How&#x27;s it going on?&quot;])</span><br><span class="hljs-string">            [4, 6]</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Raises:</span><br><span class="hljs-string">            NotImplementedError: if `model` is not in the list</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            the number of token of a string or the list of token of each string in list</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">try</span>:<br>            encoding = tiktoken.encoding_for_model(self.model)<br>        <span class="hljs-keyword">except</span> KeyError:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Warning: model not found. Using cl100k_base encoding.&quot;</span>)<br>            encoding = tiktoken.get_encoding(<span class="hljs-string">&quot;cl100k_base&quot;</span>)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(_<span class="hljs-built_in">input</span>, <span class="hljs-built_in">list</span>):<br>            token_count_list = []<br>            <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> _<span class="hljs-built_in">input</span>:<br>                token_count_list.append(<span class="hljs-built_in">len</span>(encoding.encode(text)))<br>            <span class="hljs-keyword">return</span> token_count_list<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(_<span class="hljs-built_in">input</span>, <span class="hljs-built_in">str</span>):<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(encoding.encode(_<span class="hljs-built_in">input</span>))<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">f&quot;not support data type for <span class="hljs-subst">&#123;<span class="hljs-built_in">type</span>(_<span class="hljs-built_in">input</span>)&#125;</span>, please use str or List[str].&quot;</span>)<br></code></pre></td></tr></table></figure><p>对这个脚本使用doctest进行简单测试，命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 -m doctest token_count.py -v<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs bash">Trying:<br>    token_counter = TokenCounter()<br>Expecting nothing<br>ok<br>Trying:<br>    token_counter.count(<span class="hljs-string">&quot;who are you?&quot;</span>)<br>Expecting:<br>    4<br>ok<br>Trying:<br>    token_counter.count([<span class="hljs-string">&quot;who are you?&quot;</span>, <span class="hljs-string">&quot;How&#x27;s it going on?&quot;</span>])<br>Expecting:<br>    [4, 6]<br>ok<br>3 items had no tests:<br>    token_count<br>    token_count.TokenCounter<br>    token_count.TokenCounter.__init__<br>1 items passed all tests:<br>   3 tests <span class="hljs-keyword">in</span> token_count.TokenCounter.count<br>3 tests <span class="hljs-keyword">in</span> 4 items.<br>3 passed and 0 failed.<br>Test passed.<br></code></pre></td></tr></table></figure><h3 id="项目文档生成">项目文档生成</h3><p>切换正题。我们运行命令<code>mkdocs new .</code>后，就会在当前目录下生成docs文件夹和mkdocs.yml配置文件。</p><p>在docs文件夹下，我们可以使用Markdown格式来编写.md文件，作为项目文档的素材。这里，笔者创建三个文档：</p><ul><li>index.md</li><li>reference.md</li><li>tutorials.md</li></ul><p>index.md的文件内容如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-section"># Welcome to Token Counter Docs</span><br><br>This document is about my personal project for token counter.<br><br><span class="hljs-section">## Tutorials</span><br><br>You can see more detail about the project in [<span class="hljs-string">tutorial</span>](<span class="hljs-link">tutorials.md</span>), which serve as the project tutorial.<br><br>The source code can be found on Github, the website is [<span class="hljs-string">https://github.com/percent4/package_python_project</span>](<span class="hljs-link">https://github.com/percent4/package_python_project</span>) .<br><br><span class="hljs-section">## Project overview</span><br><br>::: src.token<span class="hljs-emphasis">_counter</span><br><span class="hljs-emphasis"></span><br><span class="hljs-emphasis">## Others</span><br><span class="hljs-emphasis"></span><br><span class="hljs-emphasis">The project is useful for Python project with packaging and documentation.</span><br><span class="hljs-emphasis"></span><br><span class="hljs-emphasis"></span><br></code></pre></td></tr></table></figure><p>reference.md文件内容如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-section">## Reference</span><br><br><span class="hljs-bullet">1.</span> openai/tiktoken: [<span class="hljs-string">https://github.com/openai/tiktoken</span>](<span class="hljs-link">https://github.com/openai/tiktoken</span>)<br></code></pre></td></tr></table></figure><p>tutorials.md文件内容如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs markdown">This path the project documentation focuses on the realize of <span class="hljs-strong">**TokenCounter**</span> Class.<br>Now it only support the models of OpenAI GPT mode, such as <span class="hljs-code">`gpt-3.5-turbo`</span>.<br><br>::: src.token<span class="hljs-emphasis">_counter.token_</span>count<br></code></pre></td></tr></table></figure><p>其中:::是Mkdocs工具特有语法，表示引入Python脚本或模块。</p><p>同时，我们对<code>mkdocs.yml</code>进行配置，定义好主题（theme）、插件（plugins）和导航栏（nav）等，参考如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">site_name:</span> <span class="hljs-string">Token</span> <span class="hljs-string">Counter</span> <span class="hljs-string">Docs</span><br><br><span class="hljs-attr">theme:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;material&quot;</span><br>  <span class="hljs-attr">features:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">navigation.tabs</span><br>  <span class="hljs-attr">palette:</span><br>    <span class="hljs-comment"># Palette toggle for light mode</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">scheme:</span> <span class="hljs-string">default</span><br>      <span class="hljs-attr">toggle:</span><br>        <span class="hljs-attr">icon:</span> <span class="hljs-string">material/lightbulb</span><br>        <span class="hljs-attr">name:</span> <span class="hljs-string">Switch</span> <span class="hljs-string">to</span> <span class="hljs-string">dark</span> <span class="hljs-string">mode</span><br><br>    <span class="hljs-comment"># Palette toggle for dark mode</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">scheme:</span> <span class="hljs-string">slate</span><br>      <span class="hljs-attr">toggle:</span><br>        <span class="hljs-attr">icon:</span> <span class="hljs-string">material/lightbulb-outline</span><br>        <span class="hljs-attr">name:</span> <span class="hljs-string">Switch</span> <span class="hljs-string">to</span> <span class="hljs-string">light</span> <span class="hljs-string">mode</span><br><br><span class="hljs-attr">plugins:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">search:</span><br>      <span class="hljs-attr">lang:</span> <span class="hljs-string">en</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">mkdocstrings:</span><br>      <span class="hljs-attr">handlers:</span><br>        <span class="hljs-attr">python:</span><br>          <span class="hljs-attr">paths:</span> [<span class="hljs-string">src</span>]<br><br><span class="hljs-attr">nav:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">Index:</span> <span class="hljs-string">index.md</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">Tutorial:</span> <span class="hljs-string">tutorials.md</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">Reference:</span> <span class="hljs-string">reference.md</span><br><br></code></pre></td></tr></table></figure><p>这里需要稍微说明下，插件<code>mkdocstrings</code>会提取Python代码中的docstring用来生成文档，这无疑是非常方便的。</p><p>在终端输入<code>mkdocs serve</code>命令，即可通过http://127.0.0.1:8000/访问项目文档，效果展示如下：</p><figure><img src="https://s2.loli.net/2024/04/03/Koi367BbUSTsRxq.png"alt="首页" /><figcaption aria-hidden="true">首页</figcaption></figure><figure><img src="https://s2.loli.net/2024/04/03/NI9otFVCp4cAB2u.png"alt="查看Tutorial页面的代码说明1" /><figcaption aria-hidden="true">查看Tutorial页面的代码说明1</figcaption></figure><figure><img src="https://s2.loli.net/2024/04/03/FGqby9guflIUv3i.png"alt="查看Tutorial页面的代码说明2" /><figcaption aria-hidden="true">查看Tutorial页面的代码说明2</figcaption></figure><p>在这个项目文档中，还能很方便地查看Python源码。</p><p>以上生成的项目文档风格为<code>material</code>。如果我们想切换为<code>readthedocs</code>风格，只需要在配置文件中将theme的name改成<code>readthedocs</code>，但这种风格会丢失一些东西，毕竟不如<code>material</code>支持得那么全面。</p><figure><img src="https://s2.loli.net/2024/04/03/fLaqFCXPupTUsA3.png"alt="readthedocs风格的文档首页" /><figcaption aria-hidden="true">readthedocs风格的文档首页</figcaption></figure><figure><img src="https://s2.loli.net/2024/04/03/McNxqhvsEYUIQ8Z.png"alt="readthedocs风格的文档Tutorial页面" /><figcaptionaria-hidden="true">readthedocs风格的文档Tutorial页面</figcaption></figure><h3 id="部署">部署</h3><p>上述项目文档只在本地可查看。如果需要部署项目文档，有两种方法：</p><ul><li>打包成静态文件夹：运行<code>mkdocs build</code>，将文档打包成site静态文件夹，可部署在任何你想要的服务器上面。</li><li>部署在Github上：运行<code>mkdocs gh-deploy</code>，稍待片刻，你的项目文档即可访问：https://percent4.github.io/package_python_project/, 此时项目文档的代码在gh-pages分支。</li></ul><h3 id="参考文献">参考文献</h3><ol type="1"><li>MkDocs: <ahref="https://www.mkdocs.org/">https://www.mkdocs.org/</a></li><li>Build Your Python Project Documentation With MkDocs: <ahref="https://realpython.com/python-project-documentation-with-mkdocs/">https://realpython.com/python-project-documentation-with-mkdocs/</a></li><li>mkdocs 文档生成,Python自文档快速入门: <ahref="https://www.cnblogs.com/BEMAKE/p/mkdocsTutorials.html">https://www.cnblogs.com/BEMAKE/p/mkdocsTutorials.html</a></li><li>有mkdocs还在手写文档?大人时代变啦！: <ahref="https://www.bilibili.com/video/BV12z4y1c7EN/?vd_source=a4c50cd24d995647f23d6cecd9f64502">https://www.bilibili.com/video/BV12z4y1c7EN/?vd_source=a4c50cd24d995647f23d6cecd9f64502</a></li></ol><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>向量数据库入门（一）文本相似性搜索</title>
    <link href="/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2/"/>
    <url>/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将介绍三种常用的向量数据库：faiss,Milvus和Qdrant，并给出一个具体的使用例子。</p></blockquote><p><code>向量数据库</code>（<code>Vector Database</code>）是一种专门用于存储、管理、查询、检索向量的数据库，主要应用于人工智能、机器学习、数据挖掘等领域。</p><p>在向量数据库中，数据以向量的形式进行存储和处理，需要将原始的非向量型数据转化为向量表示（比如文本使用<code>Embedding</code>技术获得其表征向量）。</p><p>这种数据库能够高效地进行相似性搜索，快速找到最相似的向量，适用于人脸识别、图像搜索、推荐系统等需要相似性匹配的应用。</p><p>去年大模型的大火也带动了向量数据库的迅速发展，使得向量数据库成为热门方向之一，成为AI领域不可或缺的一项重要工具。</p><p>本文将介绍常见的三种向量数据库，并结合具体的样例文本给出它们在文本相似性搜索方面的应用。这三个向量数据库分别为：</p><ul><li>faiss</li><li>Milvus</li><li>Qdrant</li></ul><h3 id="获取文本embedding向量">获取文本Embedding向量</h3><p>我们使用的样例文本来源于百度百科的“中国载人登月工程”词条，将其本文切分为句子，过滤其中的纯数字的句子，保存为dengyue.txt文件。</p><p>对于上述文本，使用OpenAI的embedding模型<code>text-embedding-ada-002</code>来获取句子的表征向量（向量维度为1536，L2范数为1，即单位向量），并保存为numpy模块的npz文件，用于离线存储，避免每次使用时都需要加载。</p><p>示例的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><br><span class="hljs-keyword">from</span> dotenv <span class="hljs-keyword">import</span> load_dotenv<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sentencex <span class="hljs-keyword">import</span> segment<br><br>load_dotenv()<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_embedding</span>(<span class="hljs-params">texts: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>):<br>    url = <span class="hljs-string">&quot;https://api.openai.com/v1/embeddings&quot;</span><br>    payload = json.dumps(&#123;<br>        <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;text-embedding-ada-002&quot;</span>,<br>        <span class="hljs-string">&quot;input&quot;</span>: texts,<br>        <span class="hljs-string">&quot;encoding_format&quot;</span>: <span class="hljs-string">&quot;float&quot;</span><br>    &#125;)<br>    headers = &#123;<br>        <span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>,<br>        <span class="hljs-string">&#x27;Authorization&#x27;</span>: <span class="hljs-string">f&#x27;Bearer <span class="hljs-subst">&#123;os.getenv(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>)&#125;</span>&#x27;</span><br>    &#125;<br>    response = requests.request(<span class="hljs-string">&quot;POST&quot;</span>, url, headers=headers, data=payload)<br>    embedding = [_[<span class="hljs-string">&quot;embedding&quot;</span>] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> response.json()[<span class="hljs-string">&#x27;data&#x27;</span>]]<br>    response.close()<br>    <span class="hljs-keyword">return</span> embedding<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_file</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;dengyue.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines() <span class="hljs-keyword">if</span> _.strip()]<br>    file_sentences = []<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> content:<br>        sents = <span class="hljs-built_in">list</span>(segment(language=<span class="hljs-string">&quot;zh&quot;</span>, text=line))<br>        <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents:  <span class="hljs-comment"># filter</span><br>            <span class="hljs-keyword">if</span> sent <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> re.<span class="hljs-keyword">match</span>(<span class="hljs-string">r&#x27;\[\d+\]&#x27;</span>, sent):<br>                file_sentences.append(sent)<br>    <span class="hljs-keyword">return</span> file_sentences<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    sentences = read_file()<br>    sentences_embeddings = np.array(get_embedding(sentences))<br>    np.savez(<span class="hljs-string">&#x27;text_embedding.npz&#x27;</span>, sentences_embeddings)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;text.json&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(json.dumps(&#123;i: sentence <span class="hljs-keyword">for</span> i, sentence <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sentences)&#125;, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>))<br>    <span class="hljs-comment"># sentences_embeddings = np.load(&#x27;text_embedding.npz&#x27;)</span><br>    <span class="hljs-comment"># print(sentences_embeddings[&#x27;arr_0&#x27;][0].tolist())</span><br><br></code></pre></td></tr></table></figure><p>运行上述文件，则会得到句子的表征向量文件text_embedding.npz，使用np.load()方法即可加载这些向量。</p><h3 id="faiss">faiss</h3><p><strong>faiss</strong>全称为Facebook AI SimilaritySearch，是Facebook开源的一个用于高效相似性搜索和密集向量聚类的库，使用C++编写，提供python接口，对10亿量级的索引可以做到毫秒级检索的性能。它包含的算法可以搜索任意大小的向量集，甚至可能无法容纳在RAM 中的向量集。它还包含用于评估和参数调整的支持代码。</p><p><code>faiss</code>模块同时支持CPU和GPU.</p><p><code>faiss</code>支持的索引(Index)类型如下图：</p><p><imgsrc="https://img-blog.csdnimg.cn/img_convert/2878553653359a13fd54fbcd91dc26e2.png" /></p><p><strong>文本相似性搜索</strong>：获取与查询文本（query）相似度最接近的k个语料文本：</p><ul><li>获取query的表征向量（同一个Embedding模型）</li><li>借助<code>faiss</code>查询出与该query向量相似度最接近的k个向量</li><li>获取这k个向量对应的文本</li></ul><p>示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> faiss <span class="hljs-keyword">import</span> IndexFlatIP<br><br><span class="hljs-keyword">from</span> get_text_embedding <span class="hljs-keyword">import</span> get_embedding<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;text.json&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    sentences = <span class="hljs-built_in">list</span>(json.loads(f.read()).values())<br><br><span class="hljs-comment"># create faiss index</span><br>faiss_index = IndexFlatIP(<span class="hljs-number">1536</span>)<br><span class="hljs-comment"># add vector</span><br>sentences_embeddings = np.load(<span class="hljs-string">&quot;text_embedding.npz&quot;</span>)[<span class="hljs-string">&#x27;arr_0&#x27;</span>]<br>faiss_index.add(sentences_embeddings)<br><span class="hljs-comment"># vector search</span><br>query = <span class="hljs-string">&quot;阿波罗登月计划&quot;</span><br>query = <span class="hljs-string">&quot;神舟五号 杨利伟&quot;</span><br><span class="hljs-comment"># query = &quot;北京航天城&quot;</span><br>query_embedding = get_embedding([query])<br>distances, doc_indices = faiss_index.search(np.array(query_embedding), <span class="hljs-number">3</span>)<br><span class="hljs-comment"># result</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;query: <span class="hljs-subst">&#123;query&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;recall result: &quot;</span>)<br><span class="hljs-keyword">for</span> i, sent_index <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(doc_indices.tolist()[<span class="hljs-number">0</span>]):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;rank: <span class="hljs-subst">&#123;i&#125;</span>, similarity: <span class="hljs-subst">&#123;distances.tolist()[<span class="hljs-number">0</span>][i]&#125;</span>, text: <span class="hljs-subst">&#123;sentences[sent_index]&#125;</span>&quot;</span>)<br><span class="hljs-comment"># reset index</span><br>faiss_index.reset()<br><br></code></pre></td></tr></table></figure><p>输入query为<strong>阿波罗登月计划</strong>，最接近的3个语料文本为：</p><pre><code class="hljs">query: 阿波罗登月计划recall result: rank: 0, similarity: 0.855633020401001, text: 二十世纪六、七十年代，美国人凭借“阿波罗”计划率先登上月球。rank: 1, similarity: 0.8497034907341003, text: 初步方案是：采用两枚运载火箭分别将月面着陆器和载人飞船送至环月轨道在轨交会对接，航天员从飞船进入月面着陆器。rank: 2, similarity: 0.8401131629943848, text: 欧阳自远表示，对于载人登月工程国家还没有公布一个明确的时间表，但已经在做积极的论证和准备。</code></pre><p>输入query为<strong>神舟五号杨利伟</strong>，最接近的3个语料文本为：</p><pre><code class="hljs">query: 神舟五号 杨利伟recall result: rank: 0, similarity: 0.8733900785446167, text: 叶培建表示，中国载人航天计划共有“三步走”，第一步是从“神舟一号”走到“神舟七号”，前4个载人飞船是无人的，“神五”时杨利伟上天，实现中国人第一次进入太空的梦想，虽然比“太空旅行第一人”尤里·阿列克谢耶维奇·加加林晚了几十年，但两个不是一个数量级。rank: 1, similarity: 0.8618367910385132, text: 加加林只飞了一个小时，是伞降；杨利伟飞了一天，是软着陆，返回舱已达到“容3个人7天往返”标准。rank: 2, similarity: 0.8449346423149109, text: 加加林落地偏差达400公里；杨利伟落地时，落在中国内蒙古，当时设计“100乘以90公里着陆”都算准确着陆，但最终落地偏差只有10公里，后来“神六”、“神七”落地误差只有1公里，3条飞船实现了第一阶段的全部任务。</code></pre><p>输入query为<strong>北京航天城</strong>，最接近的3个语料文本为：</p><pre><code class="hljs">query: 北京航天城recall result: rank: 0, similarity: 0.8499420881271362, text: 在北京航天城当天举行的“李锦记航天奖学金”颁发仪式上，戚发轫介绍，根据中国的规划，2014年左右在深空探测领域，将把十几吨的航天器送到地球轨道，2020年前将建成自己的空间站。rank: 1, similarity: 0.8408806920051575, text: 5月29日上午，神舟十六号载人飞行任务新闻发布会在酒泉卫星发射中心举行。rank: 2, similarity: 0.8388772010803223, text: 戚发轫还介绍，中国将建成全球的自主北斗导航系统，中国的人、车、船、飞机在世界任何地方都可靠自己的卫星来导航定位。</code></pre><h3 id="milvus">Milvus</h3><p><code>Milvus</code>是在2019年创建的，其唯一目标是存储、索引和管理由深度神经网络和其他机器学习（ML）模型生成的大规模嵌入向量。</p><p>作为一个专门设计用于处理输入向量查询的数据库，它能够处理万亿级别的向量索引。与现有的关系型数据库主要处理遵循预定义模式的结构化数据不同，<code>Milvus</code>从底层设计用于处理从非结构化数据转换而来的嵌入向量。</p><p><imgsrc="https://miro.medium.com/v2/resize:fit:630/0*LQgAodpgeq3SBY3L.png" /></p><p>我们使用Docker启动Milvus服务，并进行文本相似性搜索。示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># reference: https://milvus.io/docs</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> pymilvus <span class="hljs-keyword">import</span> MilvusClient, FieldSchema, CollectionSchema, DataType, Collection<br><br><span class="hljs-keyword">from</span> get_text_embedding <span class="hljs-keyword">import</span> get_embedding<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;text.json&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    sentences = <span class="hljs-built_in">list</span>(json.loads(f.read()).values())<br><br><span class="hljs-comment"># add vector</span><br>sentences_embeddings = np.load(<span class="hljs-string">&quot;text_embedding.npz&quot;</span>)[<span class="hljs-string">&#x27;arr_0&#x27;</span>]<br><br>collection_name = <span class="hljs-string">&quot;dengyue&quot;</span><br><span class="hljs-comment"># Connects to a server</span><br>client = MilvusClient(uri=<span class="hljs-string">&quot;http://localhost:19530&quot;</span>, db_name=<span class="hljs-string">&quot;default&quot;</span>)<br><span class="hljs-comment"># List all collection names</span><br>collections = client.list_collections()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;exist collections: &quot;</span>, collections)<br><br><span class="hljs-comment"># create collection if not exists</span><br><span class="hljs-keyword">if</span> collection_name <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> collections:<br>    <span class="hljs-comment"># Creates a collection</span><br>    fields = [<br>        FieldSchema(name=<span class="hljs-string">&quot;id&quot;</span>, dtype=DataType.INT64, is_primary=<span class="hljs-literal">True</span>, auto_id=<span class="hljs-literal">False</span>),<br>        FieldSchema(name=<span class="hljs-string">&quot;text&quot;</span>, dtype=DataType.VARCHAR, max_length=<span class="hljs-number">1000</span>),<br>        FieldSchema(name=<span class="hljs-string">&quot;embedding&quot;</span>, dtype=DataType.FLOAT_VECTOR, dim=<span class="hljs-number">1536</span>)<br>    ]<br>    schema = CollectionSchema(fields, <span class="hljs-string">&quot;text search demo&quot;</span>)<br>    index_params = client.prepare_index_params()<br>    index_params.add_index(<br>        field_name=<span class="hljs-string">&quot;embedding&quot;</span>,<br>        index_type=<span class="hljs-string">&quot;IVF_FLAT&quot;</span>,<br>        metric_type=<span class="hljs-string">&quot;IP&quot;</span>,<br>        params=&#123;<span class="hljs-string">&quot;nlist&quot;</span>: <span class="hljs-number">128</span>&#125;<br>    )<br>    client.create_collection(<br>        collection_name=collection_name,<br>        schema=schema,<br>        index_params=index_params<br>    )<br>    time.sleep(<span class="hljs-number">3</span>)<br>    res = client.get_load_state(<br>        collection_name=collection_name<br>    )<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;load state: &quot;</span>, res)<br><br>    <span class="hljs-comment"># Inserts vectors in the collection</span><br>    entities = [<br>        &#123;<span class="hljs-string">&quot;id&quot;</span>: i + <span class="hljs-number">1</span>,<br>         <span class="hljs-string">&quot;text&quot;</span>: sentences[i],<br>         <span class="hljs-string">&quot;embedding&quot;</span>: sentences_embeddings[i].tolist()&#125;<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sentences))<br>    ]<br>    client.insert(collection_name=collection_name, data=entities)<br><br><span class="hljs-comment"># Single vector search</span><br>query = <span class="hljs-string">&quot;阿波罗登月计划&quot;</span><br><span class="hljs-comment"># query = &quot;神舟五号 杨利伟&quot;</span><br><span class="hljs-comment"># query = &quot;北京航天城&quot;</span><br>query_embedding = get_embedding([query])<br><span class="hljs-built_in">print</span>(query_embedding[<span class="hljs-number">0</span>])<br>res = client.search(<br>    collection_name=collection_name,<br>    data=query_embedding,<br>    limit=<span class="hljs-number">3</span>,<br>    search_params=&#123;<span class="hljs-string">&quot;metric_type&quot;</span>: <span class="hljs-string">&quot;IP&quot;</span>, <span class="hljs-string">&quot;params&quot;</span>: &#123;&#125;&#125;,<br>    output_fields=[<span class="hljs-string">&#x27;text&#x27;</span>]<br>)<br><br><span class="hljs-comment"># Convert the output to a formatted JSON string</span><br>result = json.dumps(res, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>其中创建的Milvuscollection为dengyue，其schema如下（可视化工具采用<code>Attu</code>）：</p><figure><img src="https://s2.loli.net/2024/04/01/gG7uCamWFR6rEKf.png"alt="collection schema" /><figcaption aria-hidden="true">collection schema</figcaption></figure><p>运行上述程序，得到的文本相似度搜索结果同上述<code>faiss</code>。</p><h3 id="qdrant">Qdrant</h3><p><code>Qdrant</code>是一个用 Rust编写的开源矢量数据库和矢量相似性搜索引擎，旨在利用先进的高性能矢量相似性搜索技术为下一代人工智能应用赋能。它的主要功能包括多语言支持（可实现各种数据类型的通用性）和适用于各种应用的过滤器。</p><p><code>Qdrant</code>对近似近邻搜索的HNSW算法进行了定制修改，通过保持精确的结果，确保了最先进的搜索能力，从而实现了速度和精确度的双赢。此外，它还支持与向量相关的额外有效载荷，允许根据有效载荷值过滤结果。Qdrant支持丰富的数据类型和查询条件，包括字符串匹配、数值范围和地理位置，为数据管理提供了多功能性。</p><p><img src="https://qdrant.tech/images/logo_with_text.png" /></p><p><code>Qdrant</code>服务的启动方式如下：</p><ul><li>本地模式，不需要服务器（离线db文件或内存）</li><li>本地服务器部署</li><li>Qdrant云</li></ul><p>以本地模式（离线db文件）启动Qdrant服务，进行文本相似度搜索。示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> qdrant_client <span class="hljs-keyword">import</span> QdrantClient<br><span class="hljs-keyword">from</span> qdrant_client.http.models <span class="hljs-keyword">import</span> Distance, VectorParams<br><span class="hljs-keyword">from</span> qdrant_client.http.models <span class="hljs-keyword">import</span> PointStruct<br><br><span class="hljs-keyword">from</span> get_text_embedding <span class="hljs-keyword">import</span> get_embedding<br><br><br>db_dir = <span class="hljs-string">&quot;qdrant_db&quot;</span><br>collect_name = <span class="hljs-string">&quot;dengyue&quot;</span><br>client = QdrantClient(path=db_dir)<br><br><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(<span class="hljs-string">f&quot;./<span class="hljs-subst">&#123;db_dir&#125;</span>/collection/<span class="hljs-subst">&#123;collect_name&#125;</span>&quot;</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;text.json&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        sentences = <span class="hljs-built_in">list</span>(json.loads(f.read()).values())<br>    sentences_embeddings = np.load(<span class="hljs-string">&#x27;text_embedding.npz&#x27;</span>)<br>    <span class="hljs-comment"># create collection</span><br>    client.recreate_collection(<br>        collection_name=collect_name,<br>        vectors_config=VectorParams(size=<span class="hljs-number">1536</span>, distance=Distance.COSINE),<br>    )<br>    <span class="hljs-comment"># insert data into collection</span><br>    operation_info = client.upsert(<br>        collection_name=collect_name,<br>        wait=<span class="hljs-literal">True</span>,<br>        points=[<br>            PointStruct(<br>                <span class="hljs-built_in">id</span>=i + <span class="hljs-number">1</span>,<br>                vector=sentences_embeddings[<span class="hljs-string">&#x27;arr_0&#x27;</span>][i].tolist(),<br>                payload=&#123;<br>                    <span class="hljs-string">&quot;text&quot;</span>: sentences&#125;) <span class="hljs-keyword">for</span> i,<br>            sentences <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sentences)])<br>    <span class="hljs-built_in">print</span>(operation_info)<br><br><br><span class="hljs-comment"># query = &quot;阿波罗登月计划&quot;</span><br><span class="hljs-comment"># query = &quot;神舟五号 杨利伟&quot;</span><br>query = <span class="hljs-string">&quot;北京航天城&quot;</span><br>query_embedding = get_embedding([query])[<span class="hljs-number">0</span>]<br><span class="hljs-comment"># search vector</span><br>search_result = client.search(<br>    collection_name=collect_name,<br>    query_vector=query_embedding,<br>    limit=<span class="hljs-number">3</span><br>)<br><span class="hljs-keyword">for</span> search_item <span class="hljs-keyword">in</span> search_result:<br>    <span class="hljs-built_in">print</span>(search_item)<br></code></pre></td></tr></table></figure><p>启动上述程序，会在本地同级目录下生成<code>qdrant_db/collection/dengyue/storage.sqlite</code>文件，表明该服务使用sqlite作为后端数据库。</p><p>运行上述程序，得到的文本相似度搜索结果同上述<code>faiss</code>。</p><p><code>Qdrant</code>还支持本地Docker启动，启动命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -itd -p 6333:6333 -p 6334:6334 -v $(<span class="hljs-built_in">pwd</span>)/qdrant_storage:/qdrant/storage:z qdrant/qdrant<br></code></pre></td></tr></table></figure><p>此时，连接<code>Qdrant</code>的Python代码改为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">client = QdrantClient(<span class="hljs-string">&quot;localhost&quot;</span>, port=<span class="hljs-number">6333</span>)<br></code></pre></td></tr></table></figure><p>与此同时，该服务还提供了WebUI，支持在浏览器端进行操作，并提供了RESTful风格的Console界面。</p><figure><img src="https://s2.loli.net/2024/04/01/rBpt86oFWmhKIwQ.png"alt="Qdrant界面，查看collections" /><figcaption aria-hidden="true">Qdrant界面，查看collections</figcaption></figure><p>运行命令<code>GET collections</code>，结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;result&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;collections&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;test_collection&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;dengyue&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;status&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ok&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;time&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.000011666</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><figure><img src="https://s2.loli.net/2024/04/01/ShlqjzyD83Rb1Q9.png"alt="RESTful风格的Console界面" /><figcaption aria-hidden="true">RESTful风格的Console界面</figcaption></figure><h3 id="总结">总结</h3><p>本文简单介绍了三种常见的向量数据库：faiss, Milvus,Qdrant，每种向量数据库都有其利弊。同时，结合一个具体的应用案例：文本相似性搜索，来分别展示这三种向量数据库的使用方法。</p><p>本文是笔者系统学习向量数据库的第一篇文章，后续将持续更新，欢迎大家关注~</p><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>向量数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（九十一）PDF表格问答</title>
    <link href="/NLP%EF%BC%88%E4%B9%9D%E5%8D%81%E4%B8%80%EF%BC%89PDF%E8%A1%A8%E6%A0%BC%E9%97%AE%E7%AD%94/"/>
    <url>/NLP%EF%BC%88%E4%B9%9D%E5%8D%81%E4%B8%80%EF%BC%89PDF%E8%A1%A8%E6%A0%BC%E9%97%AE%E7%AD%94/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何对PDF中的表格使用大模型进行问答。</p></blockquote><p>本文将会介绍如何对PDF中的表格使用多模态大模型（比如GPT-4V模型）进行智能问答，总体的思路如下：</p><ul><li>获取表格图片，可使用表格检测工具或版面分析工具</li><li>使用多模态大模型进行智能问答</li></ul><p>当然，对于纯文字版的PDF，可直接使用<code>fitz</code>模块提取表格数据，这里我们将PDF中的表格转化为表格数据，使之更具通用性，可同时适合纯文字版或扫描版的PDF文件。</p><h3 id="获取表格图片">获取表格图片</h3><p>本文所使用的示例PDF文件(demo2.pdf)如下：</p><figure><img src="https://s2.loli.net/2024/03/28/s8T5GVXEeZp9hly.png"alt="示例PDF文件" /><figcaption aria-hidden="true">示例PDF文件</figcaption></figure><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486585&amp;idx=1&amp;sn=4b2e3746ba5ab586d00cdc47de76da8b&amp;chksm=fcb9b5e9cbce3cff2eee166625e3b2d2f6d13ec4241548daff0cf67adfc228ce14a8f5e12925&amp;token=232289605&amp;lang=zh_CN#rd">表格检测与识别的初次尝试</a>中，笔者介绍了如何使用Microsoft开源的表格检测模型来进行PDF中的表格检测。</p><p>在这个例子中，使用开源模型来实现PDF中的表格检测，并将表格区域转化为图片，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> fitz<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor, TableTransformerForObjectDetection<br><br><br>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;./models/table-transformer-detection&quot;</span>)<br>detect_model = TableTransformerForObjectDetection.from_pretrained(<span class="hljs-string">&quot;./models/table-transformer-detection&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;load table transformer model...&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_pdf_2_img</span>(<span class="hljs-params">pdf_file: <span class="hljs-built_in">str</span>, pages: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>    pdf_document = fitz.<span class="hljs-built_in">open</span>(pdf_file)<br>    file_name = pdf_file.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>].split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]<br>    <span class="hljs-comment"># Iterate through each page and convert to an image</span><br>    image_list = []<br>    real_pages = <span class="hljs-built_in">min</span>(pages, pdf_document.page_count)<br>    <span class="hljs-keyword">for</span> page_number <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(real_pages):<br>        <span class="hljs-comment"># Get the page</span><br>        page = pdf_document[page_number]<br>        <span class="hljs-comment"># Convert the page to an image</span><br>        pix = page.get_pixmap()<br>        <span class="hljs-comment"># Create a Pillow Image object from the pixmap</span><br>        image = Image.frombytes(<span class="hljs-string">&quot;RGB&quot;</span>, [pix.width, pix.height], pix.samples)<br>        <span class="hljs-comment"># Save the image</span><br>        save_img_path = <span class="hljs-string">f&quot;./output/<span class="hljs-subst">&#123;file_name&#125;</span>_<span class="hljs-subst">&#123;page_number + <span class="hljs-number">1</span>&#125;</span>.png&quot;</span><br>        image.save(save_img_path)<br>        image_list.append(save_img_path)<br><br>    <span class="hljs-comment"># Close the PDF file</span><br>    pdf_document.close()<br>    <span class="hljs-keyword">return</span> image_list<br>    <br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">table_detect</span>(<span class="hljs-params">image_path</span>):<br>    image = Image.<span class="hljs-built_in">open</span>(image_path).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>    file_name = image_path.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>].split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]<br>    inputs = image_processor(images=image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>    outputs = detect_model(**inputs)<br>    <span class="hljs-comment"># convert outputs (bounding boxes and class logits) to COCO API</span><br>    target_sizes = torch.tensor([image.size[::-<span class="hljs-number">1</span>]])<br>    results = image_processor.post_process_object_detection(outputs, threshold=<span class="hljs-number">0.9</span>, target_sizes=target_sizes)[<span class="hljs-number">0</span>]<br><br>    i = <span class="hljs-number">0</span><br>    output_images = []<br>    <span class="hljs-keyword">for</span> score, label, box <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(results[<span class="hljs-string">&quot;scores&quot;</span>], results[<span class="hljs-string">&quot;labels&quot;</span>], results[<span class="hljs-string">&quot;boxes&quot;</span>]):<br>        box = [<span class="hljs-built_in">round</span>(i, <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> box.tolist()]<br>        <span class="hljs-built_in">print</span>(<br>            <span class="hljs-string">f&quot;Detected <span class="hljs-subst">&#123;detect_model.config.id2label[label.item()]&#125;</span> with confidence &quot;</span><br>            <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;<span class="hljs-built_in">round</span>(score.item(), <span class="hljs-number">3</span>)&#125;</span> at location <span class="hljs-subst">&#123;box&#125;</span>&quot;</span><br>        )<br>    <br>        region = image.crop(box) <span class="hljs-comment"># 检测</span><br>        output_image_path = <span class="hljs-string">f&#x27;./output/<span class="hljs-subst">&#123;file_name&#125;</span>_table_<span class="hljs-subst">&#123;i&#125;</span>.jpg&#x27;</span><br>        region.save(output_image_path)<br>        output_images.append(output_image_path)<br>        i += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> output_images<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    test_pdf_file = <span class="hljs-string">&quot;./pdf/demo2.pdf&quot;</span><br>    page_image_list = convert_pdf_2_img(pdf_file=test_pdf_file, pages=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">for</span> page_image <span class="hljs-keyword">in</span> page_image_list:<br>        table_detect(page_image)<br><br></code></pre></td></tr></table></figure><p>提取的表格图片如下：</p><figure><img src="https://s2.loli.net/2024/03/28/RMbEI4kAl9hP2tp.jpg"alt="表格1图片" /><figcaption aria-hidden="true">表格1图片</figcaption></figure><figure><img src="https://s2.loli.net/2024/03/28/Ubn6T3mRSgOIFpL.jpg"alt="表格2图片" /><figcaption aria-hidden="true">表格2图片</figcaption></figure><p>当然，我们也可以使用PDF版面分析工具，来获取PDF文件中的表格区域，常见的开源版面分析工具有：百度的<code>PP-StructureV2</code>等。</p><h3 id="表格问答">表格问答</h3><p>对于获取到的表格图片，我们将其转化为base64形式送入GPT-4V模型中，这样进行进行表格问答了。</p><p>示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> fitz<br><span class="hljs-keyword">import</span> base64<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_pdf_content</span>(<span class="hljs-params">pdf_path: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>    doc = fitz.<span class="hljs-built_in">open</span>(pdf_path)<br>    num_pages = doc.page_count<br>    bg_content_list = []<br><br>    <span class="hljs-comment"># Full Text of PDF</span><br>    <span class="hljs-keyword">for</span> page_index <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_pages):<br>        page = doc.load_page(page_index)<br>        text = page.get_text()<br>        bg_content_list.append(text)<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.join(bg_content_list)<br><br><br><span class="hljs-comment"># Function to encode the image</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode_image</span>(<span class="hljs-params">image_path: <span class="hljs-built_in">str</span></span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(image_path, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> image_file:<br>        <span class="hljs-keyword">return</span> base64.b64encode(image_file.read()).decode(<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_request</span>(<span class="hljs-params">pdf_content, images, query</span>):<br>    <span class="hljs-comment"># Getting the base64 string</span><br>    image_content = [<br>        &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>,<br>            <span class="hljs-string">&quot;text&quot;</span>: query<br>        &#125;,<br>    ]<br>    <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> images:<br>        base64_image = encode_image(image)<br>        image_content.append(&#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;image_url&quot;</span>,<br>            <span class="hljs-string">&quot;image_url&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;url&quot;</span>: <span class="hljs-string">f&quot;data:image/jpeg;base64,<span class="hljs-subst">&#123;base64_image&#125;</span>&quot;</span><br>            &#125;<br>        &#125;)<br>    <span class="hljs-comment"># OpenAI API Key</span><br>    api_key = os.getenv(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>)<br><br>    headers = &#123;<br>        <span class="hljs-string">&quot;Content-Type&quot;</span>: <span class="hljs-string">&quot;application/json&quot;</span>,<br>        <span class="hljs-string">&quot;Authorization&quot;</span>: <span class="hljs-string">f&quot;Bearer <span class="hljs-subst">&#123;api_key&#125;</span>&quot;</span><br>    &#125;<br><br>    payload = &#123;<span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;gpt-4-vision-preview&quot;</span>,<br>               <span class="hljs-string">&quot;messages&quot;</span>: [&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,<br>                             <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>&#125;,<br>                            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>                             <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">f&quot;The full text of PDF file is: <span class="hljs-subst">&#123;pdf_content&#125;</span>&quot;</span>&#125;,<br>                            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>                             <span class="hljs-string">&quot;content&quot;</span>: image_content&#125;],<br>               <span class="hljs-string">&quot;max_tokens&quot;</span>: <span class="hljs-number">300</span>&#125;<br><br>    response = requests.post(<br>        <span class="hljs-string">&quot;https://api.openai.com/v1/chat/completions&quot;</span>,<br>        headers=headers,<br>        json=payload)<br><br>    pprint(response.json()[<span class="hljs-string">&#x27;choices&#x27;</span>])<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    pdf_file_path = <span class="hljs-string">&#x27;../data/demo2.pdf&#x27;</span><br>    table_images_list = [<br>        <span class="hljs-string">&#x27;../output/demo2_1_table_0.jpg&#x27;</span>,<br>        <span class="hljs-string">&#x27;../output/demo2_1_table_1.jpg&#x27;</span>]<br>    test_query = <span class="hljs-string">&quot;what&#x27;s the rank of Alex&#x27;s city?&quot;</span><br>    test_pdf_content = get_pdf_content(pdf_path=pdf_file_path)<br>    make_request(pdf_content=test_pdf_content, images=table_images_list, query=test_query)<br></code></pre></td></tr></table></figure><p>测试的问题为</p><blockquote><p>what's the rank of Alex's city?</p></blockquote><p>回答这个问题需要两张表格图片，而GPT-4V很好地回答了这个问题，输出结果为：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[&#123;<span class="hljs-symbol">&#x27;finish_reason</span><span class="hljs-symbol">&#x27;:</span> <span class="hljs-symbol">&#x27;stop</span>&#x27;,<br>  <span class="hljs-symbol">&#x27;index</span><span class="hljs-symbol">&#x27;:</span> <span class="hljs-number">0</span>,<br>  <span class="hljs-symbol">&#x27;message</span><span class="hljs-symbol">&#x27;:</span> &#123;<span class="hljs-symbol">&#x27;content</span><span class="hljs-symbol">&#x27;:</span> <span class="hljs-string">&quot;The rank of Alex&#x27;s city, Shanghai, is 2.&quot;</span>,<br>              <span class="hljs-symbol">&#x27;role</span><span class="hljs-symbol">&#x27;:</span> <span class="hljs-symbol">&#x27;assistant</span>&#x27;&#125;&#125;]<br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本文主要使用表格检测工具来获取PDF中的表格区域，将其转化为图片，同时借多模态大模型（比如GPT-4V）来进行表格问答，这是一个不错的尝试。</p><p>本文代码已开源，Github网址为：<ahref="https://github.com/percent4/pdf-llm_series">https://github.com/percent4/pdf-llm_series</a>.</p><h3 id="推荐阅读">推荐阅读</h3><ol type="1"><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486486&amp;idx=1&amp;sn=dbc5ea2b69594d5010bd3c88a77562f7&amp;chksm=fcb9b586cbce3c909e081ffd364d60d5520a6cdb0c380118cbd81724c9f7027f755765f7f9e7&amp;token=232289605&amp;lang=zh_CN#rd">NLP（八十九）PDF文档智能问答入门</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486585&amp;idx=1&amp;sn=4b2e3746ba5ab586d00cdc47de76da8b&amp;chksm=fcb9b5e9cbce3cff2eee166625e3b2d2f6d13ec4241548daff0cf67adfc228ce14a8f5e12925&amp;token=232289605&amp;lang=zh_CN#rd">表格检测与识别的初次尝试</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486103&amp;idx=1&amp;sn=caa204eda0760bab69b7e40abff8e696&amp;chksm=fcb9b307cbce3a1108d305ec44281e3446241e90e9c17d62dd0b6eaa48cba5e20d31f0129584&amp;token=232289605&amp;lang=zh_CN#rd">NLP（八十一）智能文档问答助手项目改进</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485609&amp;idx=1&amp;sn=f8337b4822b1cdf95a586af6097ef288&amp;chksm=fcb9b139cbce382f735e4c119ade8084067cde0482910c72767f36a29e7291385cbe6dfbd6a9&amp;payreadticket=HO52msG-WaElfO_BY64Vd1I2_pPJdUKi4SVKyBrrTlDgFwsbOg5w4-clO6uCEAa_Q4uj_BA#rd">NLP（六十九）智能文档助手升级</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485425&amp;idx=1&amp;sn=bd85ddfce82d77ceec5a66cb96835400&amp;chksm=fcb9be61cbce37773109f9703c2b6c4256d5037c8bf4497dfb9ad0f296ce0ee4065255954c1c&amp;token=232289605&amp;lang=zh_CN#rd">NLP（六十一）使用Baichuan-13B-Chat模型构建智能文档</a></li></ol><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PDF问答</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>表格检测与识别入门</title>
    <link href="/%E8%A1%A8%E6%A0%BC%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%AF%86%E5%88%AB%E5%85%A5%E9%97%A8/"/>
    <url>/%E8%A1%A8%E6%A0%BC%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%AF%86%E5%88%AB%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何使用Mircosoft开源的表格检测模型<code>table-transformer-detection</code>来实现表格检测与入门。</p></blockquote><p>几年前，笔者在学习CV的时候，曾接触过OpenCV这个工具，当时也研究过表格识别，还曾写过一篇文章:<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484106&amp;idx=1&amp;sn=216b2a3ad47f04d1902403607ed1c4e8&amp;chksm=fcb9bb5acbce324c99561ffb45a57116e85980a74e9e4803eef2470c5ac65b4602fd785adeff&amp;token=1967721231&amp;lang=zh_CN#rd">如何识别图片中的表格数据</a>.</p><p>这几年笔者一直在做NLP方向的工作，由于最近研究多模态的缘故，再次接触表格检测与识别，这已是5年之后，顿时感觉光阴如梭。</p><p>本文将会使用Microsoft开源的表格检测模型<code>table-transformer-detection</code>来实现<code>表格检测与入门</code>。</p><p>以下将分三部分进行介绍：</p><ul><li>表格检测：检测图片或PDF文件中的表格所在的区域</li><li>表格结构识别：对于检测后的表格区域，再详细识别表格的区域，即表格的行、列，表头所在的位置，进一步得到单元格的位置</li><li>表格数据提取:在表格结构的基础上，借助<code>OCR</code>可得到每个单元格内的文本，从而获得整个表格数据</li></ul><h3 id="表格检测">表格检测</h3><p>使用Microsoft开源的表格检测模型<code>microsoft/table-transformer-detectio</code>，可以从图片或PDF文件中检测出表格所在的区域。</p><p>对于PDF文件，可将每页文档转化为图片进行检测，转化过程在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486486&amp;idx=1&amp;sn=dbc5ea2b69594d5010bd3c88a77562f7&amp;chksm=fcb9b586cbce3c909e081ffd364d60d5520a6cdb0c380118cbd81724c9f7027f755765f7f9e7&amp;token=1967721231&amp;lang=zh_CN#rd">NLP（八十九）PDF文档智能问答入门</a>中已有介绍。</p><p>表格检测的示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor, TableTransformerForObjectDetection<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><br>file_path = <span class="hljs-string">&quot;./table_detection/images/demo.jpg&quot;</span><br>image = Image.<span class="hljs-built_in">open</span>(file_path).convert(<span class="hljs-string">&quot;RGB&quot;</span>)<br>file_name = file_path.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>].split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]<br><br> <br>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;./models/table-transformer-detection&quot;</span>)<br>model = TableTransformerForObjectDetection.from_pretrained(<span class="hljs-string">&quot;./models/table-transformer-detection&quot;</span>)<br><br>inputs = image_processor(images=image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>outputs = model(**inputs)<br><br><span class="hljs-comment"># convert outputs (bounding boxes and class logits) to COCO API</span><br>target_sizes = torch.tensor([image.size[::-<span class="hljs-number">1</span>]])<br>results = image_processor.post_process_object_detection(outputs, threshold=<span class="hljs-number">0.9</span>, target_sizes=target_sizes)[<span class="hljs-number">0</span>]<br><br>i = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> score, label, box <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(results[<span class="hljs-string">&quot;scores&quot;</span>], results[<span class="hljs-string">&quot;labels&quot;</span>], results[<span class="hljs-string">&quot;boxes&quot;</span>]):<br>    box = [<span class="hljs-built_in">round</span>(i, <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> box.tolist()]<br>    <span class="hljs-built_in">print</span>(<br>        <span class="hljs-string">f&quot;Detected <span class="hljs-subst">&#123;model.config.id2label[label.item()]&#125;</span> with confidence &quot;</span><br>        <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;<span class="hljs-built_in">round</span>(score.item(), <span class="hljs-number">3</span>)&#125;</span> at location <span class="hljs-subst">&#123;box&#125;</span>&quot;</span><br>    )<br> <br>    region = image.crop(box) <span class="hljs-comment">#检测</span><br>    region.save(<span class="hljs-string">f&#x27;./table_images/<span class="hljs-subst">&#123;file_name&#125;</span>_<span class="hljs-subst">&#123;i&#125;</span>.jpg&#x27;</span>)<br>    i += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>输入图片demo.jpg如下：</p><figure><img src="https://s2.loli.net/2024/02/26/6tx7pJLuFQRUmEo.webp"alt="demo.jpg" /><figcaption aria-hidden="true">demo.jpg</figcaption></figure><p>检测到的表格（两个）图片如下：</p><figure><img src="https://s2.loli.net/2024/02/26/tBjb5EG6sopJh4e.png"alt="demo_0.png" /><figcaption aria-hidden="true">demo_0.png</figcaption></figure><figure><img src="https://s2.loli.net/2024/02/26/b24lqnxiSFENQow.png"alt="demo_1.png" /><figcaption aria-hidden="true">demo_1.png</figcaption></figure><p>输入的论文页面图片如下：</p><figure><img src="https://s2.loli.net/2024/02/26/KDi6Nd7mMf1HVBh.png"alt="llama-pdf-10.png" /><figcaption aria-hidden="true">llama-pdf-10.png</figcaption></figure><p>检测到的表格（两个）图片如下：</p><figure><img src="https://s2.loli.net/2024/02/26/s4Wx6tiAkVToJIB.png"alt="llama-pdf-10_0.png" /><figcaption aria-hidden="true">llama-pdf-10_0.png</figcaption></figure><figure><img src="https://s2.loli.net/2024/02/26/fX48b9lByKuVFYR.png"alt="llama-pdf-10_1.png" /><figcaption aria-hidden="true">llama-pdf-10_1.png</figcaption></figure><p>可以看到，该模型的表格检测效果还是很棒的。</p><h3 id="表格结构识别">表格结构识别</h3><p>对于上一步识别到的表格区域，再利用Microsoft开源的表格结构识别模型<code>microsoft/table-transformer-structure-recognition-v1.1-all</code>进行表格结构识别。</p><p>表格结构识别（只输出表头）的示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DetrFeatureExtractor<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor, TableTransformerForObjectDetection<br><br>feature_extractor = DetrFeatureExtractor()<br><br>file_path = <span class="hljs-string">&quot;./table_detection/table_images/demo_0.png&quot;</span><br>image = Image.<span class="hljs-built_in">open</span>(file_path).convert(<span class="hljs-string">&quot;RGB&quot;</span>)<br><br>encoding = feature_extractor(image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>model = TableTransformerForObjectDetection.from_pretrained(<span class="hljs-string">&quot;/data-ai/usr/lmj/models/table-transformer-structure-recognition-v1.1-all&quot;</span>)<br><span class="hljs-built_in">print</span>(model.config.id2label)<br><span class="hljs-comment"># &#123;0: &#x27;table&#x27;, 1: &#x27;table column&#x27;, 2: &#x27;table row&#x27;, 3: &#x27;table column header&#x27;, 4: &#x27;table projected row header&#x27;, 5: &#x27;table spanning cell&#x27;&#125;</span><br><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    outputs = model(**encoding)<br>    <br>target_sizes = [image.size[::-<span class="hljs-number">1</span>]]<br>results = feature_extractor.post_process_object_detection(outputs, threshold=<span class="hljs-number">0.6</span>, target_sizes=target_sizes)[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(results)<br><br>columns_box_list = [results[<span class="hljs-string">&#x27;boxes&#x27;</span>][i].tolist() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(results[<span class="hljs-string">&#x27;boxes&#x27;</span>])) <span class="hljs-keyword">if</span> results[<span class="hljs-string">&#x27;labels&#x27;</span>][i].item()==<span class="hljs-number">3</span>] <br>crop_image = image.crop(columns_box_list[<span class="hljs-number">0</span>]) <br>crop_image.save(<span class="hljs-string">&#x27;header.png&#x27;</span>)<br></code></pre></td></tr></table></figure><p>对于第1张输出表格图片，其表头如下：</p><figure><img src="https://s2.loli.net/2024/02/27/juHMvNlkGYsgLQJ.png"alt="demo_0.png的表头" /><figcaption aria-hidden="true">demo_0.png的表头</figcaption></figure><p>上述的代码仅作为演示，实际上，借助表格结构识别模型，我们可获取整个表格的结构，包括表头、行、列、单元格所在的位置。</p><h3 id="表格数据提取">表格数据提取</h3><p>在获得整个表格结构的基础上，再借助OCR工具，不难获取每个单元格内的文本，从而得到整个表格数据，这是再自然不过的想法。这样，我们借助开源模型，也能自己创建一个表格识别的小工具啦！不过，囿于效果原因，暂时还只能支持整行整列的表格（即不含合并单元格等复杂的表格）数据提取。</p><p>使用gradio构建一个表格数据提取工具，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> base64<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> urllib.request <span class="hljs-keyword">import</span> urlretrieve<br><span class="hljs-keyword">from</span> uuid <span class="hljs-keyword">import</span> uuid4<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor, TableTransformerForObjectDetection<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DetrFeatureExtractor<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor, TableTransformerForObjectDetection<br><span class="hljs-keyword">from</span> paddleocr <span class="hljs-keyword">import</span> PaddleOCR<br><br><br>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;./models/table-transformer-detection&quot;</span>)<br>detect_model = TableTransformerForObjectDetection.from_pretrained(<span class="hljs-string">&quot;./models/table-transformer-detection&quot;</span>)<br>structure_model = TableTransformerForObjectDetection.from_pretrained(<span class="hljs-string">&quot;./models/table-transformer-structure-recognition-v1.1-all&quot;</span>)<br><span class="hljs-built_in">print</span>(structure_model.config.id2label)<br><span class="hljs-comment"># &#123;0: &#x27;table&#x27;, 1: &#x27;table column&#x27;, 2: &#x27;table row&#x27;, 3: &#x27;table column header&#x27;, 4: &#x27;table projected row header&#x27;, 5: &#x27;table spanning cell&#x27;&#125;</span><br>feature_extractor = DetrFeatureExtractor()<br><br>ocr = PaddleOCR(use_angle_cls=<span class="hljs-literal">True</span>, lang=<span class="hljs-string">&quot;ch&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">paddle_ocr</span>(<span class="hljs-params">image_path</span>):<br>    result = ocr.ocr(image_path, cls=<span class="hljs-literal">True</span>)<br>    ocr_result = []<br>    <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(result)):<br>        res = result[idx]<br>        <span class="hljs-keyword">if</span> res:<br>            <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> res:<br>                <span class="hljs-built_in">print</span>(line)<br>                ocr_result.append(line[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>.join(ocr_result)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">table_detect</span>(<span class="hljs-params">image_box, image_url</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> image_url:<br>        file_name = <span class="hljs-built_in">str</span>(uuid4())<br>        image = Image.fromarray(image_box).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        image_path = <span class="hljs-string">f&quot;./images/<span class="hljs-subst">&#123;uuid4()&#125;</span>.png&quot;</span><br>        file_name = image_path.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>].split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]<br>        urlretrieve(image_url, image_path)<br>        image = Image.<span class="hljs-built_in">open</span>(image_path).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>    inputs = image_processor(images=image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>    outputs = detect_model(**inputs)<br>    <span class="hljs-comment"># convert outputs (bounding boxes and class logits) to COCO API</span><br>    target_sizes = torch.tensor([image.size[::-<span class="hljs-number">1</span>]])<br>    results = image_processor.post_process_object_detection(outputs, threshold=<span class="hljs-number">0.9</span>, target_sizes=target_sizes)[<span class="hljs-number">0</span>]<br><br>    i = <span class="hljs-number">0</span><br>    output_images = []<br>    <span class="hljs-keyword">for</span> score, label, box <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(results[<span class="hljs-string">&quot;scores&quot;</span>], results[<span class="hljs-string">&quot;labels&quot;</span>], results[<span class="hljs-string">&quot;boxes&quot;</span>]):<br>        box = [<span class="hljs-built_in">round</span>(i, <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> box.tolist()]<br>        <span class="hljs-built_in">print</span>(<br>            <span class="hljs-string">f&quot;Detected <span class="hljs-subst">&#123;detect_model.config.id2label[label.item()]&#125;</span> with confidence &quot;</span><br>            <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;<span class="hljs-built_in">round</span>(score.item(), <span class="hljs-number">3</span>)&#125;</span> at location <span class="hljs-subst">&#123;box&#125;</span>&quot;</span><br>        )<br>    <br>        region = image.crop(box) <span class="hljs-comment">#检测</span><br>        output_image_path = <span class="hljs-string">f&#x27;./table_images/<span class="hljs-subst">&#123;file_name&#125;</span>_<span class="hljs-subst">&#123;i&#125;</span>.jpg&#x27;</span><br>        region.save(output_image_path)<br>        output_images.append(output_image_path)<br>        i += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> output_images<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">table_ocr</span>(<span class="hljs-params">output_images, image_index</span>):<br>    output_image = output_images[<span class="hljs-built_in">int</span>(image_index)][<span class="hljs-number">0</span>]<br>    image = Image.<span class="hljs-built_in">open</span>(output_image).convert(<span class="hljs-string">&quot;RGB&quot;</span>)<br>    encoding = feature_extractor(image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        outputs = structure_model(**encoding)<br>        <br>    target_sizes = [image.size[::-<span class="hljs-number">1</span>]]<br>    results = feature_extractor.post_process_object_detection(outputs, threshold=<span class="hljs-number">0.5</span>, target_sizes=target_sizes)[<span class="hljs-number">0</span>]<br>    <span class="hljs-built_in">print</span>(results)<br>    <span class="hljs-comment"># get column and row</span><br>    columns = []<br>    rows = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(results[<span class="hljs-string">&#x27;boxes&#x27;</span>])):<br>        _<span class="hljs-built_in">id</span> = results[<span class="hljs-string">&#x27;labels&#x27;</span>][i].item()<br>        <span class="hljs-keyword">if</span> _<span class="hljs-built_in">id</span> == <span class="hljs-number">1</span>:<br>            columns.append(results[<span class="hljs-string">&#x27;boxes&#x27;</span>][i].tolist())<br>        <span class="hljs-keyword">elif</span> _<span class="hljs-built_in">id</span> == <span class="hljs-number">2</span>:<br>            rows.append(results[<span class="hljs-string">&#x27;boxes&#x27;</span>][i].tolist())<br><br>    sorted_columns = <span class="hljs-built_in">sorted</span>(columns, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">0</span>])<br>    sorted_rows = <span class="hljs-built_in">sorted</span>(rows, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>])<br>    <span class="hljs-comment"># ocr by cell</span><br>    ocr_results = []<br>    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> sorted_rows:<br>        row_result = []<br>        <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> sorted_columns:<br>            rect = [col[<span class="hljs-number">0</span>], row[<span class="hljs-number">1</span>], col[<span class="hljs-number">2</span>], row[<span class="hljs-number">3</span>]]<br>            crop_image = image.crop(rect)<br>            image_path = <span class="hljs-string">&#x27;cell.png&#x27;</span><br>            crop_image.save(image_path)<br>            row_result.append(paddle_ocr(image_path=image_path))<br>        <span class="hljs-built_in">print</span>(row_result)<br>        ocr_results.append(row_result)<br><br>    <span class="hljs-built_in">print</span>(ocr_results)<br>    <span class="hljs-keyword">return</span> ocr_results<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">with</span> gr.Blocks() <span class="hljs-keyword">as</span> demo:<br>        <span class="hljs-keyword">with</span> gr.Row():<br>            <span class="hljs-keyword">with</span> gr.Column():<br>                image_box = gr.Image()<br>                image_urls = gr.TextArea(lines=<span class="hljs-number">1</span>, placeholder=<span class="hljs-string">&quot;Enter image url&quot;</span>, label=<span class="hljs-string">&quot;Images&quot;</span>)<br>                image_index = gr.TextArea(lines=<span class="hljs-number">1</span>, placeholder=<span class="hljs-string">&quot;Image Number&quot;</span>, label=<span class="hljs-string">&quot;No&quot;</span>)<br>            <span class="hljs-keyword">with</span> gr.Column():<br>                gallery = gr.Gallery(label=<span class="hljs-string">&quot;Tables&quot;</span>, show_label=<span class="hljs-literal">False</span>, elem_id=<span class="hljs-string">&quot;gallery&quot;</span>, columns=[<span class="hljs-number">3</span>], rows=[<span class="hljs-number">1</span>], object_fit=<span class="hljs-string">&quot;contain&quot;</span>, height=<span class="hljs-string">&quot;auto&quot;</span>)<br>                detect = gr.Button(<span class="hljs-string">&quot;Table Detection&quot;</span>)<br>                submit = gr.Button(<span class="hljs-string">&quot;Table OCR&quot;</span>)<br>                ocr_outputs=gr.DataFrame(label=<span class="hljs-string">&#x27;Table&#x27;</span>,<br>                                     interactive=<span class="hljs-literal">True</span>,<br>                                     wrap=<span class="hljs-literal">True</span>)<br>        detect.click(fn=table_detect,<br>                     inputs=[image_box, image_urls],<br>                     outputs=gallery)<br>        submit.click(fn=table_ocr,<br>                     inputs=[gallery, image_index],<br>                     outputs=ocr_outputs)<br>    demo.launch(server_name=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, server_port=<span class="hljs-number">50074</span>)<br><br></code></pre></td></tr></table></figure><p>其中OCR工具采用PaddleOCR，内置模型为<code>ch_PP-OCRv4</code>，文字识别效果还不错。启动程序，界面如下：</p><figure><img src="https://s2.loli.net/2024/03/27/bw27AtiCVqlLgNE.png"alt="网页版表格识别界面" /><figcaption aria-hidden="true">网页版表格识别界面</figcaption></figure><p>该界面支持自己上传文档或者输入图片所在网址，即可进行图片内的表格检测，检测完后，可进行第n张图片的数据提取。</p><p>由于篇幅原因，本文给出效果较好的几个例子：</p><ul><li>输入图片网址1</li></ul><figure><img src="https://s2.loli.net/2024/03/27/KulXgAmL4Fdirnb.png"alt="例子1" /><figcaption aria-hidden="true">例子1</figcaption></figure><ul><li>输入图片网址2</li></ul><figure><img src="https://s2.loli.net/2024/03/27/uGWrlJeTDMf8dBk.png"alt="例子2" /><figcaption aria-hidden="true">例子2</figcaption></figure><ul><li>输入图片网址3</li></ul><figure><img src="https://s2.loli.net/2024/03/27/YgH8D3KEcrVk12w.png"alt="例子3" /><figcaption aria-hidden="true">例子3</figcaption></figure><ul><li>自己上传图片</li></ul><figure><img src="https://s2.loli.net/2024/03/27/ULCgBO7pceW4kuR.png"alt="例子4" /><figcaption aria-hidden="true">例子4</figcaption></figure><h3 id="总结">总结</h3><p>本文主要介绍了如何使用Microsoft开源的表格检测与结构检测开源模型来实现表格检测、结构检测与数据提取，并构建了一个web应用，方便直观地查看表格识别与数据提取的结果。</p><p>本文源代码已在文中展示，暂未放至Github，后续将开源。</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>microsoft/table-transformer-detection: <ahref="https://huggingface.co/microsoft/table-transformer-detection">https://huggingface.co/microsoft/table-transformer-detection</a></li><li>Multi-Modal on PDF’s with tables: <ahref="https://docs.llamaindex.ai/en/v0.10.20/examples/multi_modal/multi_modal_pdf_tables.html">https://docs.llamaindex.ai/en/v0.10.20/examples/multi_modal/multi_modal_pdf_tables.html</a></li></ol><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>表格检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（九十）OpenAI的Chat_Completion_API中的logprobs参数</title>
    <link href="/NLP%EF%BC%88%E4%B9%9D%E5%8D%81%EF%BC%89OpenAI%E7%9A%84Chat-Completion-API%E4%B8%AD%E7%9A%84logprobs%E5%8F%82%E6%95%B0/"/>
    <url>/NLP%EF%BC%88%E4%B9%9D%E5%8D%81%EF%BC%89OpenAI%E7%9A%84Chat-Completion-API%E4%B8%AD%E7%9A%84logprobs%E5%8F%82%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>OpenAI的Chat CompletionAPI中引入了<code>logprobs</code>参数。当<code>logprobs</code>参数被启用时，API会返回每个输出token的log概率，同时返回每个token位置最可能的几个token和它们的log概率。与之相关的两个参数：</p><ul><li>logprobs：是否返回每个输出token的log概率</li><li>top_logprobs：整数，每个token位置最可能的token个数以及它们的log概率。若需使用该参数，则<code>logprobs</code>参数需设置为true.</li></ul><p>在OpenAI的官方<ahref="https://cookbook.openai.com/examples/using_logprobs">CookBook网站</a>中，该网站给出了logprobs参数的介绍及可能的应用。</p><p>本文在此基础上，再给出一种可能的应用场景：<code>双栏论文中的上下文连接</code>。</p><h3 id="双栏论文上下文连接">双栏论文上下文连接</h3><p>以LLAMA论文中的第三页为例，其版面分析的结果如下：</p><figure><img src="https://s2.loli.net/2024/03/25/IC2jtPVEi1TDqrb.jpg"alt="llama_split_2_rect.jpg" /><figcaption aria-hidden="true">llama_split_2_rect.jpg</figcaption></figure><p>此时，我们想要知道左侧Optimizer下方的文本区域中的warmup之后的文字应该与哪个右侧的文本区域连接。</p><p>我们考虑使用OpenAI的Chat CompletionAPI的logprobs参数，去观察warmup后的下一个token位置上最可能的几个token。</p><p>示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI<br><br>client = OpenAI(api_key=os.getenv(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>))<br><br>query = <span class="hljs-string">&quot;We use a weight decay of 0.1 and gradient clipping of 1.0. We use 2,000 warmup&quot;</span><br><br>response = client.chat.completions.create(<br>    messages=[<br>        &#123;<br>            <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>            <span class="hljs-string">&quot;content&quot;</span>: query<br>        &#125;<br>    ],<br>    model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>    logprobs=<span class="hljs-literal">True</span>,<br>    top_logprobs=<span class="hljs-number">10</span><br>)<br><br><span class="hljs-built_in">print</span>(response.choices[<span class="hljs-number">0</span>].logprobs.content[<span class="hljs-number">0</span>].json())<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><code class="hljs autohotkey">&#123;<br>    <span class="hljs-string">&quot;token&quot;</span>: <span class="hljs-string">&quot; steps&quot;</span>,<br>    <span class="hljs-string">&quot;bytes&quot;</span>: [<br><span class="hljs-built_in">        32,</span><br><span class="hljs-built_in">        115,</span><br><span class="hljs-built_in">        116,</span><br><span class="hljs-built_in">        101,</span><br><span class="hljs-built_in">        112,</span><br>        <span class="hljs-number">115</span><br>    ],<br>    <span class="hljs-string">&quot;logprob&quot;</span>: -<span class="hljs-number">0.07665413</span>,<br>    <span class="hljs-string">&quot;top_logprobs&quot;</span>: [<br>        &#123;<br>            <span class="hljs-string">&quot;token&quot;</span>: <span class="hljs-string">&quot; steps&quot;</span>,<br>            <span class="hljs-string">&quot;bytes&quot;</span>: [<br><span class="hljs-built_in">                32,</span><br><span class="hljs-built_in">                115,</span><br><span class="hljs-built_in">                116,</span><br><span class="hljs-built_in">                101,</span><br><span class="hljs-built_in">                112,</span><br>                <span class="hljs-number">115</span><br>            ],<br>            <span class="hljs-string">&quot;logprob&quot;</span>: -<span class="hljs-number">0.07665413</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;token&quot;</span>: <span class="hljs-string">&quot;steps&quot;</span>,<br>            <span class="hljs-string">&quot;bytes&quot;</span>: [<br><span class="hljs-built_in">                115,</span><br><span class="hljs-built_in">                116,</span><br><span class="hljs-built_in">                101,</span><br><span class="hljs-built_in">                112,</span><br>                <span class="hljs-number">115</span><br>            ],<br>            <span class="hljs-string">&quot;logprob&quot;</span>: -<span class="hljs-number">2.6422403</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;token&quot;</span>: <span class="hljs-string">&quot;\n&quot;</span>,<br>            <span class="hljs-string">&quot;bytes&quot;</span>: [<br>                <span class="hljs-number">10</span><br>            ],<br>            <span class="hljs-string">&quot;logprob&quot;</span>: -<span class="hljs-number">7.070091</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;token&quot;</span>: <span class="hljs-string">&quot; iterations&quot;</span>,<br>            <span class="hljs-string">&quot;bytes&quot;</span>: [<br><span class="hljs-built_in">                32,</span><br><span class="hljs-built_in">                105,</span><br><span class="hljs-built_in">                116,</span><br><span class="hljs-built_in">                101,</span><br><span class="hljs-built_in">                114,</span><br><span class="hljs-built_in">                97,</span><br><span class="hljs-built_in">                116,</span><br><span class="hljs-built_in">                105,</span><br><span class="hljs-built_in">                111,</span><br><span class="hljs-built_in">                110,</span><br>                <span class="hljs-number">115</span><br>            ],<br>            <span class="hljs-string">&quot;logprob&quot;</span>: -<span class="hljs-number">7.86643</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;token&quot;</span>: <span class="hljs-string">&quot; &quot;</span>,<br>            <span class="hljs-string">&quot;bytes&quot;</span>: [<br>                <span class="hljs-number">32</span><br>            ],<br>            <span class="hljs-string">&quot;logprob&quot;</span>: -<span class="hljs-number">8.368307</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;token&quot;</span>: <span class="hljs-string">&quot;\n\n&quot;</span>,<br>            <span class="hljs-string">&quot;bytes&quot;</span>: [<br><span class="hljs-built_in">                10,</span><br>                <span class="hljs-number">10</span><br>            ],<br>            <span class="hljs-string">&quot;logprob&quot;</span>: -<span class="hljs-number">8.59561</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;token&quot;</span>: <span class="hljs-string">&quot;Steps&quot;</span>,<br>            <span class="hljs-string">&quot;bytes&quot;</span>: [<br><span class="hljs-built_in">                83,</span><br><span class="hljs-built_in">                116,</span><br><span class="hljs-built_in">                101,</span><br><span class="hljs-built_in">                112,</span><br>                <span class="hljs-number">115</span><br>            ],<br>            <span class="hljs-string">&quot;logprob&quot;</span>: -<span class="hljs-number">8.9801445</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;token&quot;</span>: <span class="hljs-string">&quot; learning&quot;</span>,<br>            <span class="hljs-string">&quot;bytes&quot;</span>: [<br><span class="hljs-built_in">                32,</span><br><span class="hljs-built_in">                108,</span><br><span class="hljs-built_in">                101,</span><br><span class="hljs-built_in">                97,</span><br><span class="hljs-built_in">                114,</span><br><span class="hljs-built_in">                110,</span><br><span class="hljs-built_in">                105,</span><br><span class="hljs-built_in">                110,</span><br>                <span class="hljs-number">103</span><br>            ],<br>            <span class="hljs-string">&quot;logprob&quot;</span>: -<span class="hljs-number">9.553173</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;token&quot;</span>: <span class="hljs-string">&quot; epochs&quot;</span>,<br>            <span class="hljs-string">&quot;bytes&quot;</span>: [<br><span class="hljs-built_in">                32,</span><br><span class="hljs-built_in">                101,</span><br><span class="hljs-built_in">                112,</span><br><span class="hljs-built_in">                111,</span><br><span class="hljs-built_in">                99,</span><br><span class="hljs-built_in">                104,</span><br>                <span class="hljs-number">115</span><br>            ],<br>            <span class="hljs-string">&quot;logprob&quot;</span>: -<span class="hljs-number">9.626547</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;token&quot;</span>: <span class="hljs-string">&quot;_steps&quot;</span>,<br>            <span class="hljs-string">&quot;bytes&quot;</span>: [<br><span class="hljs-built_in">                95,</span><br><span class="hljs-built_in">                115,</span><br><span class="hljs-built_in">                116,</span><br><span class="hljs-built_in">                101,</span><br><span class="hljs-built_in">                112,</span><br>                <span class="hljs-number">115</span><br>            ],<br>            <span class="hljs-string">&quot;logprob&quot;</span>: -<span class="hljs-number">9.82288</span><br>        &#125;<br>    ]<br>&#125;<br></code></pre></td></tr></table></figure><p>由此可见，右侧栏的以steps开头的文本区域应当与warmup结尾的文本区域相连接。</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>Using logprobs: <ahref="https://cookbook.openai.com/examples/using_logprobs">https://cookbook.openai.com/examples/using_logprobs</a></li></ol><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>logprobs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python命令行参数模块argparse</title>
    <link href="/Python%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0%E6%A8%A1%E5%9D%97argparse/"/>
    <url>/Python%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0%E6%A8%A1%E5%9D%97argparse/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍Python中的命令行参数模块argparse的使用。</p></blockquote><p><code>argparse</code>是Python标准库中推荐的命令行解析模块，用于解析命令行参数，使得编写用户友好的命令行界面变得容易。这个模块允许程序定义所需的参数，然后argparse会解析这些参数从sys.argv（命令行）中。一些关键特性和步骤包括：</p><ul><li><p>核心功能：argparse模块建立在ArgumentParser实例上，用于参数规格说明，并包含多个全面应用解析器的选项。通过add_argument()方法将参数规格说明关联到解析器，支持位置参数、接受各种值的选项以及各种启用/禁用标识。</p></li><li><p>快速链接：add_argument()方法提供了多种选项，如处理参数、限制可选项集合、存储常量值、设置默认值等。例如，使用nargs='?'和default可以指定默认值或者在未提供参数时使用的值。</p></li><li><p>类型：解析器默认将命令行参数当作简单字符串读入，但可以通过type关键字进行类型检查和转换。可以使用内置类型或自定义函数作为类型转换器，如int、float等。</p></li></ul><p>argparse模块使得Python脚本能够方便地从命令行读取参数，适用于需要频繁修改参数的代码，让代码更简洁且易于维护。</p><h3 id="简单示例">简单示例</h3><p>下面先介绍一个简单的argparse使用的例子(文件名：<code>demo.py</code>)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> argparse<br><br>parser = argparse.ArgumentParser()<br><br>parser.add_argument(<span class="hljs-string">&quot;epoch&quot;</span>)<br><br>args = parser.parse_args()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;args: &#x27;</span>, args)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;epoch: <span class="hljs-subst">&#123;args.epoch&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>运行命令<code>python demo.py 10</code>，输出结果为：</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs vbnet"><span class="hljs-symbol">args:</span>  <span class="hljs-keyword">Namespace</span>(epoch=<span class="hljs-comment">&#x27;10&#x27;)</span><br><span class="hljs-symbol">epoch:</span> <span class="hljs-number">10</span><br></code></pre></td></tr></table></figure><p>在这个例子中，我们先实例化ArgumentParser()，然后使用add_argument()方法添加命令行参数，最后再使用parse_args()函数去解析参数。</p><p>运行该脚本时，需要在命令行中输入<code>python demo.py 10</code>，其中10对应参数epoch的取值。此时，args的类型为命名空间(Namespace)，通过args.epoch获取参数epoch的输入值。</p><p>如果不知道该怎么运行该脚本或者需知道脚本中有哪些输入参数，可运行命令<code>python demo.py -h</code>获得帮助，以示例脚本为例，输出结果为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">usage: demo.py [-h] epoch<br><br>positional arguments:<br>  epoch<br><br>options:<br>  -h, --<span class="hljs-built_in">help</span>  show this <span class="hljs-built_in">help</span> message and <span class="hljs-built_in">exit</span><br></code></pre></td></tr></table></figure><h3 id="位置参数">位置参数</h3><p><code>argparse</code>的参数共分为两类：位置参数（必选参数）和可选参数，位置参数前面不加-或者--，可选参数前面需要加上-或--（-代表参数名的短选项，即简称）。</p><p>我们在前面的示例脚本中已展示过如何使用位置参数，但此时如果输入为<code>python demo.py 10 20</code>，则会报错，原因是只有一个位置参数。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ python demo.py 10 20<br>usage: demo.py [-h] epoch<br>demo.py: error: unrecognized arguments: 20<br></code></pre></td></tr></table></figure><p>为了解决参数数量的问题，可使用nargs来解决。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> argparse<br><br>parser = argparse.ArgumentParser()<br><br>parser.add_argument(<span class="hljs-string">&quot;epoch&quot;</span>, nargs=<span class="hljs-string">&#x27;+&#x27;</span>)<br><br>args = parser.parse_args()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;args: &#x27;</span>, args)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;epoch: <span class="hljs-subst">&#123;args.epoch&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>nargs是用来说明传入的参数个数，'+'表示传入至少一个参数。此时再运行<code>python demo.py 10 20</code>命令，输出结果为：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">args:  <span class="hljs-built_in">Namespace</span>(epoch=<span class="hljs-selector-attr">[<span class="hljs-string">&#x27;10&#x27;</span>, <span class="hljs-string">&#x27;20&#x27;</span>]</span>)<br>epoch: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;10&#x27;</span>, <span class="hljs-string">&#x27;20&#x27;</span>]</span><br></code></pre></td></tr></table></figure><h3 id="可选参数">可选参数</h3><p>本文重点介绍可选参数。</p><p>在可选参数中，add_argument函数的参数有type, default, required,choices, help等，列举如下：</p><ul><li>name or flags: 可选参数（options）或位置参数（positionalarguments）。</li><li>type: 参数类型</li><li>default: 参数的默认取值</li><li>required: bool类型，是否是必需参数</li><li>choices: 枚举类型，指定参数的取值</li><li>help: 参数的使用说明</li></ul><p>示例脚本(文件名：<code>demo.py</code>)如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: demo.py</span><br><span class="hljs-comment"># @time: 2024/3/10 09:09</span><br><span class="hljs-keyword">import</span> argparse<br><br>parser = argparse.ArgumentParser()<br><br>parser.add_argument(<span class="hljs-string">&quot;-m&quot;</span>, <span class="hljs-string">&quot;--model&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;model name&quot;</span>)<br>parser.add_argument(<span class="hljs-string">&quot;-bz&quot;</span>, <span class="hljs-string">&quot;--batch_size&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, choices=[<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>], <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;batch size of the training&quot;</span>)<br>parser.add_argument(<span class="hljs-string">&quot;-e&quot;</span>, <span class="hljs-string">&quot;--epoch&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">10</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;epoch of the training, default value: %(default)r&quot;</span>)<br><br>args = parser.parse_args()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;model name: <span class="hljs-subst">&#123;args.model&#125;</span>\nbatch size: <span class="hljs-subst">&#123;args.batch_size&#125;</span>\nepoch: <span class="hljs-subst">&#123;args.epoch&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>显示帮助：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ python demo.py -h<br>usage: demo.py [-h] -m MODEL [-bz &#123;10,20,50,100&#125;] [-e EPOCH]<br><br>options:<br>  -h, --<span class="hljs-built_in">help</span>            show this <span class="hljs-built_in">help</span> message and <span class="hljs-built_in">exit</span><br>  -m MODEL, --model MODEL<br>                        model name, default value: <span class="hljs-string">&#x27;BERT&#x27;</span><br>  -bz &#123;10,20,50,100&#125;, --batch_size &#123;10,20,50,100&#125;<br>                        batch size of the training<br>  -e EPOCH, --epoch EPOCH<br>                        epoch of the training, default value: 10<br></code></pre></td></tr></table></figure><p>以下是可能的参数输入方式：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-comment"># 指定可选参数</span><br>$ python demo.py -m <span class="hljs-keyword">BERT </span>-<span class="hljs-keyword">b </span><span class="hljs-number">10</span> -e <span class="hljs-number">30</span><br><span class="hljs-comment"># 可选参数使用默认值</span><br>$ python demo.py -m <span class="hljs-keyword">BERT </span>-<span class="hljs-keyword">b </span><span class="hljs-number">10</span><br><span class="hljs-comment"># -b 参数不在参数取值内会报错</span><br>python demo.py -m <span class="hljs-keyword">BERT </span>-<span class="hljs-keyword">b </span><span class="hljs-number">40</span> -e <span class="hljs-number">30</span><br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本文主要介绍了Python中的命令行参数模块<code>argparse</code>的使用，这在平时我们需要频繁修改命令行参数时会非常有用。</p><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>argparse</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（八十九）PDF文档智能问答入门</title>
    <link href="/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%B9%9D%EF%BC%89PDF%E6%96%87%E6%A1%A3%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94%E5%85%A5%E9%97%A8/"/>
    <url>/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%B9%9D%EF%BC%89PDF%E6%96%87%E6%A1%A3%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何使用fitz模块处理PDF文档，以及如何使用OpenAI大模型对PDF文档进行问答。</p></blockquote><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485425&amp;idx=1&amp;sn=bd85ddfce82d77ceec5a66cb96835400&amp;chksm=fcb9be61cbce37773109f9703c2b6c4256d5037c8bf4497dfb9ad0f296ce0ee4065255954c1c&amp;token=28280910&amp;lang=zh_CN#rd">NLP（六十一）使用Baichuan-13B-Chat模型构建智能文档</a>中笔者介绍如何使用大模型来构建智能文档问答助手，其中包括PDF文档。</p><p>在文本中，笔者将会介绍如何使用<code>fitz</code>模块来处理PDF文档，并基于此，再使用大模型对PDF文档内容进行智能问答，提升问答效果。</p><h3 id="fitz模块介绍">fitz模块介绍</h3><p><code>PyMuPDF</code>和<code>Fitz</code>是用于在Python中处理PDF文件的相关模块。<code>Fitz</code>是<code>PyMuPDF</code>的子模块，提供了一个简化和封装版本的<code>PyMuPDF</code>功能。</p><p><imgsrc="https://pymupdf.readthedocs.io/en/latest/_images/pymupdf-logo.png" /></p><ol type="1"><li>关系：</li></ol><ul><li>PyMuPDF：是一个强大灵活的Python库，用于处理PDF，不依赖其它Python包。</li><li>Fitz：是PyMuPDF库的一个包装器，专门设计用于在Python中处理PDF文件。</li></ul><ol start="2" type="1"><li>用途：</li></ol><ul><li>PyMuPDF：提供了广泛的功能，用于操作PDF文档，包括方便的高级函数和底层操作。</li><li>Fitz：简化和封装了PyMuPDF的功能，使在Python中处理PDF文件更加简单。</li></ul><ol start="3" type="1"><li>安装：</li></ol><ul><li>要使用Fitz，需要安装Fitz和PyMuPDF。如果未安装其中任何一个模块，可能会出现类似"ModuleNotFoundError:No module named 'frontend'"的错误。</li><li>可以使用pip进行安装，例如从清华镜像源安装PyMuPDF。</li></ul><p>总之，虽然PyMuPDF是一个全面的用于在Python中操作PDF文档的库，但Fitz是一个子模块，简化和封装了PyMuPDF的功能，使其更适合特定涉及PDF文件的任务，并且更易于使用。</p><h3 id="pdf文档处理">PDF文档处理</h3><p>PyMuPDF模块的官方教程为：https://pymupdf.readthedocs.io/en/latest/tutorial.html。</p><p>以下将会介绍如何使用<code>fitz</code>模块来获取PDF文档的基本信息、文本、图片、表格以及如何分割PDF文档。</p><p>本文所使用的PDF文档为：</p><ul><li>demo1.pdf</li></ul><figure><img src="https://s2.loli.net/2024/03/02/QxN54ckVF3thTp8.png"alt="demo1.pdf" /><figcaption aria-hidden="true">demo1.pdf</figcaption></figure><ul><li>demo2.pdf</li></ul><figure><img src="https://s2.loli.net/2024/03/02/JKGCVPdfvzloEWa.png"alt="demo2.pdf" /><figcaption aria-hidden="true">demo2.pdf</figcaption></figure><h4 id="获取pdf文档基本信息">获取PDF文档基本信息</h4><p>Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># PyMuPDF==1.23.26</span><br><span class="hljs-keyword">import</span> fitz<br><br>pdf_path = <span class="hljs-string">&quot;../data/demo1.pdf&quot;</span><br>doc = fitz.<span class="hljs-built_in">open</span>(pdf_path)<br><br><span class="hljs-comment"># basic PDF info</span><br>title = doc.metadata[<span class="hljs-string">&quot;title&quot;</span>]<br>author = doc.metadata[<span class="hljs-string">&quot;author&quot;</span>]<br>create_date = doc.metadata[<span class="hljs-string">&quot;creationDate&quot;</span>]<br>num_pages = doc.page_count<br>page = doc.load_page(<span class="hljs-number">0</span>)<br>page_height = page.bound().height<br>page_width = page.bound().width<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;title: <span class="hljs-subst">&#123;title&#125;</span>\nauthor: <span class="hljs-subst">&#123;author&#125;</span>\ncreate_date: <span class="hljs-subst">&#123;create_date&#125;</span>\nnum_pages: <span class="hljs-subst">&#123;num_pages&#125;</span>\n&quot;</span><br>      <span class="hljs-string">f&quot;page_height: <span class="hljs-subst">&#123;page_height&#125;</span>\npage_width: <span class="hljs-subst">&#123;page_width&#125;</span>\n&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">title</span>: <br><span class="hljs-attribute">author</span>: <br><span class="hljs-attribute">create_date</span>: D:<span class="hljs-number">20240301052229</span>+<span class="hljs-number">00</span>&#x27;<span class="hljs-number">00</span>&#x27;<br><span class="hljs-attribute">num_pages</span>: <span class="hljs-number">1</span><br><span class="hljs-attribute">page_height</span>: <span class="hljs-number">841</span>.<span class="hljs-number">9199829101562</span><br><span class="hljs-attribute">page_width</span>: <span class="hljs-number">594</span>.<span class="hljs-number">9599609375</span><br></code></pre></td></tr></table></figure><h4 id="获取文本">获取文本</h4><p>Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># PyMuPDF==1.23.26</span><br><span class="hljs-keyword">import</span> fitz<br><br>pdf_path = <span class="hljs-string">&quot;../data/demo1.pdf&quot;</span><br>doc = fitz.<span class="hljs-built_in">open</span>(pdf_path)<br>num_pages = doc.page_count<br><br><span class="hljs-comment"># Text info of PDF</span><br><span class="hljs-keyword">for</span> page_index <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_pages):<br>    page = doc.load_page(page_index)<br>    text = page.get_text()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;第<span class="hljs-subst">&#123;page_index + <span class="hljs-number">1</span>&#125;</span>页的文本内容为：\n<span class="hljs-subst">&#123;text&#125;</span>\n&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs awk">第<span class="hljs-number">1</span>页的文本内容为：<br><span class="hljs-number">2024</span><span class="hljs-regexp">/3/</span><span class="hljs-number">1</span> <span class="hljs-number">13</span>:<span class="hljs-number">22</span><br>md2pdf - Markdown to PDF<br>https:<span class="hljs-regexp">//m</span>d2pdf.netlify.app<br><span class="hljs-number">1</span>/<span class="hljs-number">1</span><br>This is a demo pdf.<br>Today is Friday, <span class="hljs-number">1</span>st Match, <span class="hljs-number">2024</span>.<br></code></pre></td></tr></table></figure><h4 id="获取图片">获取图片</h4><p>获取PDF文档中的图片的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># PyMuPDF==1.23.26</span><br><span class="hljs-keyword">import</span> fitz<br><br>pdf_path = <span class="hljs-string">&quot;../data/demo1.pdf&quot;</span><br>doc = fitz.<span class="hljs-built_in">open</span>(pdf_path)<br>num_pages = doc.page_count<br><br><span class="hljs-comment"># Image info of PDF</span><br><span class="hljs-keyword">for</span> page_index <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_pages):<br>    page = doc.load_page(page_index)<br>    image_list = page.get_images()<br>    <span class="hljs-built_in">print</span>(image_list)<br>    <span class="hljs-keyword">for</span> img <span class="hljs-keyword">in</span> image_list:<br>        xref = img[<span class="hljs-number">0</span>]<br>        pix = fitz.Pixmap(doc, xref)<br>        <span class="hljs-built_in">print</span>(pix.colorspace, <span class="hljs-string">&#x27;--&gt;&#x27;</span>, fitz.csRGB)<br>        img_path = <span class="hljs-string">f&#x27;../output/image<span class="hljs-subst">&#123;page_index + <span class="hljs-number">1</span>&#125;</span>_<span class="hljs-subst">&#123;xref&#125;</span>.png&#x27;</span><br>        pix.save(img_path)<br><br><span class="hljs-comment"># 关闭文件</span><br>doc.close()<br></code></pre></td></tr></table></figure><h4 id="获取表格">获取表格</h4><p>从demo2.pdf文档中提取表格数据的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> fitz<br><br>doc = fitz.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;../data/demo2.pdf&#x27;</span>)<br>page = doc[<span class="hljs-number">0</span>]   <span class="hljs-comment"># 提取第1页中的所有表格</span><br>tables = page.find_tables()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;tables: <span class="hljs-subst">&#123;tables&#125;</span>&quot;</span>)<br><span class="hljs-keyword">for</span> i, table <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tables):<br>    df = tables[<span class="hljs-number">0</span>].to_pandas()<br>    df.to_csv(<span class="hljs-string">f&#x27;../output/table_pg_<span class="hljs-subst">&#123;<span class="hljs-number">1</span>&#125;</span>_<span class="hljs-subst">&#123;i + <span class="hljs-number">1</span>&#125;</span>.csv&#x27;</span>, index=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>提取的表格数据将会保存为csv格式文件。</p><h4 id="分割pdf">分割PDF</h4><p>处理book1.pdf文档（扫描版PDF文件），将其前三页分割形成新的PDF文档book_split.pdf，示例PDF代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> fitz<br><br><br>pdf_document = fitz.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../data/book1.pdf&quot;</span>)<br><br><span class="hljs-comment"># 构建输出文件名，以页数命名</span><br>output_pdf = <span class="hljs-string">f&quot;../data/book_split.pdf&quot;</span><br><br><span class="hljs-comment"># 创建一个新的Document对象，包含当前页面</span><br>new_pdf = fitz.<span class="hljs-built_in">open</span>()<br>new_pdf.insert_pdf(pdf_document, from_page=<span class="hljs-number">0</span>, to_page=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 保存单独的PDF文件</span><br>new_pdf.save(output_pdf)<br>new_pdf.close()<br><br>pdf_document.close()<br></code></pre></td></tr></table></figure><p>其中分割后PDF文档的第二页截图如下：</p><figure><img src="https://s2.loli.net/2024/03/02/yRCMgO7WG2zlVkm.png"alt="分割后PDF文档第二页截图" /><figcaption aria-hidden="true">分割后PDF文档第二页截图</figcaption></figure><h3 id="pdf文档问答">PDF文档问答</h3><p>基于上述的PDF文档处理，我们将结合大模型（OpenAI）对PDF文档进行回答。</p><h4 id="文字版pdf">文字版PDF</h4><p>文字版PDF可使用<code>fitz</code>轻松获取PDF文档中的纯文字内容，再使用大模型进行问答（简化版RAG）。</p><p>示例Python代码如下(使用PDF文件为<code>oppo_n3_flip.pdf</code>)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> fitz<br><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_pdf_content</span>(<span class="hljs-params">pdf_path: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>    doc = fitz.<span class="hljs-built_in">open</span>(pdf_path)<br>    num_pages = doc.page_count<br>    bg_content_list = []<br><br>    <span class="hljs-comment"># Full Text of PDF</span><br>    <span class="hljs-keyword">for</span> page_index <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_pages):<br>        page = doc.load_page(page_index)<br>        text = page.get_text()<br>        bg_content_list.append(text)<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.join(bg_content_list)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_answer</span>(<span class="hljs-params">pdf_content: <span class="hljs-built_in">str</span>, query: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>    client = OpenAI(api_key=os.getenv(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>))<br>    response = client.chat.completions.create(<br>        model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>        messages=[<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>&#125;,<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">f&quot;The full text of PDF file is: <span class="hljs-subst">&#123;pdf_content&#125;</span>&quot;</span>&#125;,<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query&#125;<br>        ],<br>        max_tokens=<span class="hljs-number">1000</span><br>    )<br><br>    answer = response.choices[<span class="hljs-number">0</span>].message.content<br><br>    <span class="hljs-keyword">return</span> answer<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    content = get_pdf_content(<span class="hljs-string">&quot;../data/oppo_n3_flip.pdf&quot;</span>)<br>    query1 = <span class="hljs-string">&quot;OPPO Find N3 Flip的价格？&quot;</span><br>    <span class="hljs-built_in">print</span>(get_answer(pdf_content=content, query=query1))<br><br>    query2 = <span class="hljs-string">&quot;蚂蚁集团发布的大模型叫什么？&quot;</span><br>    <span class="hljs-built_in">print</span>(get_answer(pdf_content=content, query=query2))<br><br>    query3 = <span class="hljs-string">&quot;混元大模型是什么时候发布的？&quot;</span><br>    <span class="hljs-built_in">print</span>(get_answer(pdf_content=content, query=query3))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mathematica"><span class="hljs-variable">OPPO</span> <span class="hljs-built_in">Find</span> <span class="hljs-variable">N3</span> <span class="hljs-variable">Flip</span>有两个版本可选，分别是<span class="hljs-number">12</span><span class="hljs-variable">GB</span><span class="hljs-operator">+</span><span class="hljs-number">256</span><span class="hljs-variable">GB</span>和<span class="hljs-number">12</span><span class="hljs-variable">GB</span><span class="hljs-operator">+</span><span class="hljs-number">512</span><span class="hljs-variable">GB</span>。起售价为<span class="hljs-number">6799</span>元人民币。<br>蚂蚁集团发布的大模型叫做<span class="hljs-string">&quot;大图模型&quot;</span>（<span class="hljs-built_in">Large</span> <span class="hljs-built_in">Graph</span> <span class="hljs-variable">Model</span>，简称<span class="hljs-variable">LGM</span>）。<br>混元大模型是在<span class="hljs-number">2023</span>年<span class="hljs-number">9</span>月<span class="hljs-number">7</span>日，在<span class="hljs-number">2023</span>腾讯全球数字生态大会上正式对外亮相的。<br></code></pre></td></tr></table></figure><h4 id="扫描版pdf">扫描版PDF</h4><p>而扫描版PDF（也称为影印版PDF）想要使用<code>fitz</code>来获取PDF中的文字内容是困难的，因此，需要先将每一页PDF转化为图片，再使用OCR技术获取图片中的文字，这样就能获取扫描版PDF中的文字，当然，获取文本的质量主要取决于PDF文档的质量及OCR识别效果。</p><p>可以使用<code>fitz</code>模块将每一页PDF转化为图片，同时，本文中采用PaddlePaddle的PaddleOCR模型进行文字识别。</p><p>示例的PDF文档为book_split.pdf，我们仅使用其中的第二页，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> fitz<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> base64<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_pdf_2_img</span>(<span class="hljs-params">pdf_file: <span class="hljs-built_in">str</span>, pages: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>    pdf_document = fitz.<span class="hljs-built_in">open</span>(pdf_file)<br><br>    <span class="hljs-comment"># Iterate through each page and convert to an image</span><br>    <span class="hljs-keyword">for</span> page_number <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(pages):<br>        <span class="hljs-comment"># Get the page</span><br>        page = pdf_document[page_number]<br>        <span class="hljs-comment"># Convert the page to an image</span><br>        pix = page.get_pixmap()<br>        <span class="hljs-comment"># Create a Pillow Image object from the pixmap</span><br>        image = Image.frombytes(<span class="hljs-string">&quot;RGB&quot;</span>, [pix.width, pix.height], pix.samples)<br>        <span class="hljs-comment"># Save the image</span><br>        image.save(<span class="hljs-string">f&quot;../output/book1_<span class="hljs-subst">&#123;page_number + <span class="hljs-number">1</span>&#125;</span>.png&quot;</span>)<br><br>    <span class="hljs-comment"># Close the PDF file</span><br>    pdf_document.close()<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cv2_to_base64</span>(<span class="hljs-params">img</span>):<br>    data = cv2.imencode(<span class="hljs-string">&#x27;.jpg&#x27;</span>, img)[<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> base64.b64encode(data.tobytes()).decode(<span class="hljs-string">&#x27;utf8&#x27;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">image_ocr</span>(<span class="hljs-params">image_path</span>):<br>    <span class="hljs-comment"># get ocr result</span><br>    data = &#123;<span class="hljs-string">&#x27;images&#x27;</span>: [cv2_to_base64(cv2.imread(image_path))]&#125;<br>    headers = &#123;<span class="hljs-string">&quot;Content-type&quot;</span>: <span class="hljs-string">&quot;application/json&quot;</span>&#125;<br>    url = <span class="hljs-string">&quot;http://localhost:50076/predict/ch_pp-ocrv3&quot;</span><br>    r = requests.post(url=url, headers=headers, data=json.dumps(data))<br>    <span class="hljs-keyword">if</span> r.json()[<span class="hljs-string">&quot;results&quot;</span>]:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;\n&quot;</span>.join([ocr_record[<span class="hljs-string">&quot;text&quot;</span>].strip() <span class="hljs-keyword">for</span> ocr_record <span class="hljs-keyword">in</span> r.json()[<span class="hljs-string">&quot;results&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;data&quot;</span>]])<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_answer</span>(<span class="hljs-params">pdf_content: <span class="hljs-built_in">str</span>, query: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>    client = OpenAI(api_key=os.getenv(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>))<br>    response = client.chat.completions.create(<br>        model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>        messages=[<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>&#125;,<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">f&quot;The full text of PDF file is: <span class="hljs-subst">&#123;pdf_content&#125;</span>&quot;</span>&#125;,<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query&#125;<br>        ],<br>        max_tokens=<span class="hljs-number">1000</span><br>    )<br><br>    answer = response.choices[<span class="hljs-number">0</span>].message.content<br><br>    <span class="hljs-keyword">return</span> answer<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    test_pdf_file = <span class="hljs-string">&quot;../data/book1.pdf&quot;</span><br>    convert_pdf_2_img(pdf_file=test_pdf_file, pages=<span class="hljs-number">2</span>)<br>    page1_ocr_result = image_ocr(<span class="hljs-string">&quot;../output/book1_2.png&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;识别文字内容: <span class="hljs-subst">&#123;page1_ocr_result&#125;</span>&quot;</span>)<br><br>    query1 = <span class="hljs-string">&quot;破浪理论的创始人是谁，他的出生年月？&quot;</span><br>    predict_answer = get_answer(pdf_content=page1_ocr_result, query=query1)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;回答:&quot;</span>, predict_answer)<br><br>    query2 = <span class="hljs-string">&quot;这本书的作者是谁？&quot;</span><br>    predict_answer = get_answer(pdf_content=page1_ocr_result, query=query2)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;回答:&quot;</span>, predict_answer)<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">识别文字内容: 作者简介</span><br>R.N.艾略特（1871-1948），波浪理论的创始人，<br>曾当过会计师，就职于铁路公司、餐饮等多种行业。<br>人们对他的身世了解不多，1934年出版《波浪原理》，<br>为这一重要理论奠定了坚实的基础。他的理论由于<br>艰深难懂而被人们长期忽视。1978年，他的思想的<br>直接继承者帕御特出版了与人合著的《波浪理论》一<br>书，并在期权交易竞赛中取得四个月获得400%以上<br>的轿人成绩，从而使波浪原理迅速传播。现在的任<br>何一部股市理论教科书中波浪理论都占有越来越大<br>的篇幅。<br>ee more oleasevisit:htuos/nomeoto<br><span class="hljs-section">回答: 破浪理论的创始人是R.N.艾略特，他出生于1871年。</span><br><span class="hljs-section">回答: 这本书的作者是 R.N.艾略特，他是波浪理论的创始人。</span><br></code></pre></td></tr></table></figure><p>可以看到，此时的回答效果是非常好的。</p><h3 id="总结">总结</h3><p>本文主要介绍了如何使用<code>fitz</code>模块来处理PDF文档，以及如何结合大模型对文字版、扫描版PDF文档进行智能回答。</p><p>本文的亮点之一在于可使用OCR技术获得扫描版PDF文本内容，在大模型加持下回答效果表现很好。</p><p>在后续的文章中，我们将会处理PDF文档中的多模态部分，比如表格、图片等，这将会是一项很有挑战性并且很有趣的事情。</p><p>本文给出的Python代码均已开源，可访问Github网址：<ahref="https://github.com/percent4/pdf-llm_series">https://github.com/percent4/pdf-llm_series</a>.</p><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PDF问答</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（八十八）使用LLaVA模型实现以文搜图和以图搜图</title>
    <link href="/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8LLaVA%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E6%96%87%E6%90%9C%E5%9B%BE%E5%92%8C%E4%BB%A5%E5%9B%BE%E6%90%9C%E5%9B%BE/"/>
    <url>/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8LLaVA%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E6%96%87%E6%90%9C%E5%9B%BE%E5%92%8C%E4%BB%A5%E5%9B%BE%E6%90%9C%E5%9B%BE/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何使用多模态模型–LLaVA模型来实现以文搜图和以图搜图的功能。</p></blockquote><p>本文将会详细介绍如何使用多模态模型——LLaVA模型来实现以文搜图和以图搜图的功能。本文仅为示例Demo，并不能代表实际的以文搜图和以图搜图的技术实现方案。</p><p>在介绍笔者的实现方案前，我们先了解下这个方案中所需要用到的模型：</p><ul><li>多模态模型：LLaVA-1.6-34  B，主要用于图片理解，本文的使用场景为获取图片标题和图片内容描述。</li><li>OCR模型：PaddleOCR，主要用于图片中的文字识别。</li><li>ReRank模型：BCE ReRank模型，主要用于文本匹配，本文的使用场景为匹配两张图片的内容描述。</li></ul><p>下面将按功能进行阐述，主要分为以下三部分：</p><ul><li>图片上传</li><li>以文搜图</li><li>以图搜图</li></ul><h2 id="图片上传">图片上传</h2><p>在图片上传功能中，笔者的Web实现采用<code>Gradio模块</code>，用户自行决定是否使用<code>OCR模型</code>，并结合OCR结果，使用多模态模型来获取用户上传图片（网址）的标题和详细内容描述，最后将这些图片相关的数据存入ElasticSearch数据库中用于图片检索。</p><p>其中，OCR模型和多模态模型部署在GPU端，这里不再详细介绍，用户可参考本文文末给出的Github地址。</p><p>图片上传的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> uuid<br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime <span class="hljs-keyword">as</span> dt<br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> base64<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> io <span class="hljs-keyword">import</span> BytesIO<br><span class="hljs-keyword">from</span> elasticsearch <span class="hljs-keyword">import</span> Elasticsearch<br><span class="hljs-keyword">from</span> urllib.request <span class="hljs-keyword">import</span> urlretrieve<br><br><span class="hljs-comment"># 连接Elasticsearch</span><br>es_client = Elasticsearch(<span class="hljs-string">&quot;http://localhost:9200&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_image</span>(<span class="hljs-params">image_file</span>):<br>    <span class="hljs-keyword">if</span> image_file.startswith(<span class="hljs-string">&#x27;http://&#x27;</span>) <span class="hljs-keyword">or</span> image_file.startswith(<span class="hljs-string">&#x27;https://&#x27;</span>):<br>        response = requests.get(image_file)<br>        image = Image.<span class="hljs-built_in">open</span>(BytesIO(response.content)).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        image = Image.<span class="hljs-built_in">open</span>(image_file).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>    <span class="hljs-keyword">return</span> image<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cv2_to_base64</span>(<span class="hljs-params">image</span>):<br>    data = cv2.imencode(<span class="hljs-string">&#x27;.jpg&#x27;</span>, image)[<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> base64.b64encode(data.tobytes()).decode(<span class="hljs-string">&#x27;utf8&#x27;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">image_ocr</span>(<span class="hljs-params">image_url</span>):<br>    <span class="hljs-comment"># download image by url</span><br>    image_path = <span class="hljs-string">f&#x27;../data/<span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(uuid.uuid4())&#125;</span>.jpg&#x27;</span><br>    urlretrieve(image_url, image_path)<br>    <span class="hljs-comment"># get ocr result</span><br>    data = &#123;<span class="hljs-string">&#x27;images&#x27;</span>: [cv2_to_base64(cv2.imread(image_path))]&#125;<br>    headers = &#123;<span class="hljs-string">&quot;Content-type&quot;</span>: <span class="hljs-string">&quot;application/json&quot;</span>&#125;<br>    url = <span class="hljs-string">&quot;http://localhost:50076/predict/ch_pp-ocrv3&quot;</span><br>    r = requests.post(url=url, headers=headers, data=json.dumps(data))<br>    <span class="hljs-keyword">if</span> r.json()[<span class="hljs-string">&quot;results&quot;</span>]:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;\n&quot;</span>.join([ocr_record[<span class="hljs-string">&quot;text&quot;</span>].strip() <span class="hljs-keyword">for</span> ocr_record <span class="hljs-keyword">in</span> r.json()[<span class="hljs-string">&quot;results&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;data&quot;</span>]])<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">insert_es_data</span>(<span class="hljs-params">url, tag, title, desc, ocr_result</span>):<br>    doc = &#123;<br>        <span class="hljs-string">&quot;url&quot;</span>: url,<br>        <span class="hljs-string">&quot;title&quot;</span>: title,<br>        <span class="hljs-string">&quot;description&quot;</span>: desc,<br>        <span class="hljs-string">&quot;tag&quot;</span>: tag,<br>        <span class="hljs-string">&quot;insert_time&quot;</span>: dt.now().strftime(<span class="hljs-string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>),<br>        <span class="hljs-string">&quot;ocr_result&quot;</span>: ocr_result<br>        &#125;<br>    es_client.index(index=<span class="hljs-string">&quot;image-search-ocr&quot;</span>, document=doc)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;insert into es successfully!&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_image_desc</span>(<span class="hljs-params">ocr_choice, image_url</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ocr_choice:<br>        ocr_result = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">else</span>:<br>        ocr_result = image_ocr(image_url=image_url)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;ocr result: &quot;</span>, <span class="hljs-built_in">repr</span>(ocr_result))<br>    <span class="hljs-comment"># load image</span><br>    image = load_image(image_url)<br>    <span class="hljs-comment"># get image title and description</span><br>    url = <span class="hljs-string">&quot;http://localhost:50075/img_desc&quot;</span><br>    payload = json.dumps(&#123;<span class="hljs-string">&quot;url&quot;</span>: image_url, <span class="hljs-string">&quot;ocr_result&quot;</span>: ocr_result&#125;)<br>    headers = &#123;<span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>&#125;<br>    response = requests.request(<span class="hljs-string">&quot;POST&quot;</span>, url, headers=headers, data=payload)<br>    result = response.json()<br>    <span class="hljs-keyword">return</span> image, ocr_result, result[<span class="hljs-string">&quot;title&quot;</span>], result[<span class="hljs-string">&quot;desc&quot;</span>]<br><br><br><span class="hljs-keyword">with</span> gr.Blocks() <span class="hljs-keyword">as</span> demo:<br>    <span class="hljs-keyword">with</span> gr.Row():<br>        <span class="hljs-keyword">with</span> gr.Column():<br>            checkout_group = gr.CheckboxGroup(choices=[<span class="hljs-string">&quot;LLaVA 1.6&quot;</span>], value=<span class="hljs-string">&quot;LLaVA 1.6&quot;</span>, label=<span class="hljs-string">&#x27;models&#x27;</span>)<br>            ocr_group = gr.CheckboxGroup(choices=[<span class="hljs-string">&quot;PaddleOCR&quot;</span>], label=<span class="hljs-string">&#x27;OCR&#x27;</span>)<br>            user_input = gr.TextArea(lines=<span class="hljs-number">5</span>, placeholder=<span class="hljs-string">&quot;Enter the url of an image&quot;</span>, label=<span class="hljs-string">&quot;image url&quot;</span>)<br>            tags = gr.TextArea(lines=<span class="hljs-number">1</span>, placeholder=<span class="hljs-string">&quot;Enter the tags of an image&quot;</span>, label=<span class="hljs-string">&quot;image tag&quot;</span>)<br>        <span class="hljs-keyword">with</span> gr.Column():<br>            image_box = gr.Image()<br>            ocr_output = gr.TextArea(lines=<span class="hljs-number">2</span>, label=<span class="hljs-string">&#x27;OCR result&#x27;</span>)<br>            title_output = gr.TextArea(lines=<span class="hljs-number">1</span>, label=<span class="hljs-string">&#x27;image title&#x27;</span>)<br>            desc_output = gr.TextArea(lines=<span class="hljs-number">5</span>, label=<span class="hljs-string">&#x27;image description&#x27;</span>)<br>            submit = gr.Button(<span class="hljs-string">&quot;Submit&quot;</span>)<br>            insert_data = gr.Button(<span class="hljs-string">&quot;Insert&quot;</span>)<br>    submit.click(fn=get_image_desc,<br>                 inputs=[ocr_group, user_input],<br>                 outputs=[image_box, ocr_output, title_output, desc_output])<br>    insert_data.click(fn=insert_es_data,<br>                      inputs=[user_input, tags, title_output, desc_output, ocr_output])<br><br>demo.launch()<br><br></code></pre></td></tr></table></figure><p>我们上传一张手机图片（网址为：<a href="https://picx.zhimg.com/v2-b9966bc144bf536dbb8c9a35f763d90c_r.jpg?source=172ae18b">https://picx.zhimg.com/v2-b9966bc144bf536dbb8c9a35f763d90c_r.jpg?source=172ae18b</a> ），结果如下：</p><p><img src="https://s2.loli.net/2024/02/25/s2qxP6LXOi1TQZ9.png" alt=""></p><p>这里可以看到，LLaVA的图片理解能力是非常出色的。</p><p>下面，我们来看看引入OCR模型后的图片理解效果。</p><ul><li>图片1：建筑相关，网址为：<a href="https://img3.jiemian.com/101/original/20180326/152205977120854400_a640x364.jpg">https://img3.jiemian.com/101/original/20180326/152205977120854400_a640x364.jpg</a></li></ul><p>未使用OCR模型，仅使用多模态模型的效果：</p><p><img src="https://s2.loli.net/2024/02/25/YsveOoQ3zgm8Fhr.png" alt=""></p><p>图片内容描述为：</p><blockquote><p>这张图片显示的是中国一家银行的入口。银行名称是“中国银联”，英文名称为“China Merchants Bank”。银行入口处有自动门，门上贴有“欢迎光临”的标语。银行内部有自动取款机，取款机上贴有“欢迎使用”的标语。银行内部还有其他设施，如自动柜员机、自动存取款机等。银行内部环境干净整洁，工作人员热情友好，为客户提供优质的服务。</p></blockquote><p>使用OCR模型来增强多模态模型的效果：</p><p><img src="https://s2.loli.net/2024/02/25/goa2Ys4fRn8dyOv.png" alt=""></p><p>图片内容描述为：</p><blockquote><p>这张图片显示的是一家招商银行（CHINAMERCHANTSBANK）的支行。招牌上同时使用了中文和英文，表明该银行的服务对象可能包括中国和英语国家的客户。招牌的颜色为红色和白色，这是中国传统文化中常见的颜色组合，通常代表喜庆和吉祥。\n\n在招牌下方，有一扇玻璃门，门上贴有“欢迎光临”的标语，表示银行欢迎客户的光临。门上还贴有“禁止吸烟”的标志，提醒客户在银行内禁止吸烟。\n\n在门的两侧，分别有一个红色的灭火器箱，这是为了应对火灾等紧急情况而准备的。\n\n在门前的台阶上，有一个黄色的小桌子和一把椅子，可能是供客户休息或等待使用。\n\n总的来说，这张图片展示了一个典型的银行支行外观，体现了银行的欢迎态度和为客户提供服务的理念。</p></blockquote><p><strong>分析</strong>： 使用OCR模型后，能很好地理解图片中的建筑为招商银行，而不使用OCR模型则无法理解这张图片是哪家银行。</p><ul><li>图片2：古诗相关，图片网址为：<a href="https://img.ixintu.com/download/jpg/202001/94660b3923f925ab0622b407e5c0ed82.jpg!con">https://img.ixintu.com/download/jpg/202001/94660b3923f925ab0622b407e5c0ed82.jpg!con</a></li></ul><p>未使用OCR模型，仅使用多模态模型的效果：</p><p><img src="https://s2.loli.net/2024/02/25/SRsPEqatBLxvDc5.png" alt=""></p><p>图片内容描述为：</p><blockquote><p>这张图片是一幅中国风格的画作，具有传统的水墨画特点。画面以圆形为框，内部以红色边框分割为四个部分，每个部分都有不同的内容。\n\n在左上角，有一幅山水画，描绘了山峦、树木和云雾，用笔简练，意境深远。\n\n在右上角，有一段中文文字，内容是：“人生如梦，岁月如歌。”这句话表达了对人生和时间的感慨，是常见的文学表达。\n\n在左下角，画中人物是一位古代文人，他身着长袍，手持书卷，正在沉思或阅读。人物形象生动，姿态悠闲，体现了文人的风雅。\n\n在右下角，画中有一株盛开的花朵，花朵鲜艳，花瓣舒展，旁边还有一只蝴蝶在飞舞，寓意着生命的美好和短暂。\n\n整个画面以红色边框为界，将四个部分巧妙地组合在一起，形成了一个完整的圆形构图。这种构图方式在中国传统绘画中非常常见，寓意着“圆满”和“完美”。</p></blockquote><p>使用OCR模型来增强多模态模型的效果：</p><p><img src="https://s2.loli.net/2024/02/25/CFfTErVuQ5oK6zY.png" alt=""></p><p>图片内容描述为：</p><blockquote><p>这张图片是一幅中国画，描绘了唐代诗人李白的著名诗作《静夜思》的意境。画面以圆形构图，四周有红色边框，给人一种古典、庄重的感觉。\n\n画面中央，一位身穿白色长袍的男子正站在一棵高大的树下，抬头仰望天空。他的表情凝重，似乎在沉思。男子周围是一些花草，其中有一朵盛开的花朵，颜色鲜艳，为画面增添了一丝生机。\n\n画面下方，有一行黑色的文字，正是李白的《静夜思》。这首诗以简洁的语言，表达了诗人对故乡的思念之情。\n\n整幅画作以淡雅的色彩为主，营造出一种宁静、幽雅的氛围，与诗中所表达的情感相得益彰。画面中的男子、树木、花朵等元素，以及诗中的文字，共同构成了一幅充满诗意的画卷。</p></blockquote><p><strong>分析</strong>：未加入OCR模型前，LLaVA模型基本无法理解图片中的内容，它产生了幻觉，给出了与图片不相符的内容描述。而加入OCR模型后，LLaVA模型能较好地理解图片内容，给出了静夜思古诗相关的描述，符合图片内容。</p><blockquote><p>事实证明，在使用多模态模型进行图片内容理解时，在某些场景下加入OCR识别结果可有效提升模型的图片理解能力。</p></blockquote><h2 id="以文搜图">以文搜图</h2><p>以文搜图的实现方案为：对于用于输入的query，使用ES的检索功能，对图片内容字段进行搜索，得到匹配的图片。</p><ul><li>单个短语</li></ul><p><img src="https://s2.loli.net/2024/02/07/9xKPRYX1ZbQB5Sz.png" alt="image-search-单个短语1.png"></p><p><img src="https://s2.loli.net/2024/02/07/ajvFCI4NZtBTH5s.png" alt="image-search-单个短语2.png"></p><p><img src="https://s2.loli.net/2024/02/07/CeGMUjNEBZ8ThHQ.png" alt="image-search-单个短语3.png"></p><ul><li>多个短语</li></ul><p><img src="https://s2.loli.net/2024/02/07/YwvpK2BakXuziER.png" alt="image-search-多个短语1.png"></p><p><img src="https://s2.loli.net/2024/02/07/CPZywoEUgXHsRpQ.png" alt="image-search-多个短语2.png"></p><p><img src="https://s2.loli.net/2024/02/07/wpgVYUAE6HdP4fJ.png" alt="image-search-多个短语3.png"></p><h2 id="以图搜图">以图搜图</h2><p>以图搜图的实现方案为：使用多模态模型（未加入OCR模型）获取用户输入图片网址的标题和内容描述，使用ES对图片内容进行初筛，再使用ReReank模型对粗筛结果进行重排，得到ES数据库中的相似图片。</p><p><img src="https://s2.loli.net/2024/02/07/2ZdHhRr7cgoDFyW.png" alt="image-search-以图搜图1.png"></p><p><img src="https://s2.loli.net/2024/02/07/PXRnKO3tl8zvZm6.png" alt="image-search-以图搜图2.png"></p><p><img src="https://s2.loli.net/2024/02/07/iafwum1IEKvezhn.png" alt="image-search-以图搜图3.png"></p><h2 id="总结">总结</h2><p>本文主要介绍了如何使用多模态模型来实现以文搜图和以图搜图功能。本文是笔者使用LLaVA-1.6模型的一次尝试，事实上，以文搜图和以图搜图功能会有更好有优雅的实现技术方案。</p><p>本文的代码已公开至Github，网址为：<a href="https://github.com/percent4/multi-modal-image-search">https://github.com/percent4/multi-modal-image-search</a> .</p><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center>    <img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center>    <img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLaVA</tag>
      
      <tag>以图搜图</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（八十七）CLIP模型入门</title>
    <link href="/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%B8%83%EF%BC%89CLIP%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8/"/>
    <url>/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%B8%83%EF%BC%89CLIP%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将介绍CLIP模型，以及CLIP模型的简单使用和它在CIFAR-10数据集上的实验结果复现。</p></blockquote><p>从这篇文章开始，我们将进入一个崭新的世界：<code>多模态（Multi-Modal）模型</code>。</p><h3 id="简介">简介</h3><p><code>CLIP</code>（Contrastive Language-Image Pre-Training）是<code>OpenAI</code>在2021年初发布的多模态预训练神经网络模型，用于匹配图像和文本。该模型的关键创新之一是将图像和文本映射到统一的向量空间，通过对比学习的方式进行预训练，使得模型能够直接在向量空间中计算图像和文本之间的相似性，无需额外的中间表示。</p><p><code>CLIP</code>模型训练分为三个阶段：</p><ul><li>对比式预训练阶段：使用图像-文本对进行对比学习训练；</li><li>从标签文本创建数据集分类器：提取预测类别文本特征；</li><li>用于零样本预测：进行零样本推理预测。</li></ul><p><img src="https://raw.githubusercontent.com/openai/CLIP/main/CLIP.png" alt="CLIP模型训练三阶段"></p><p><code>CLIP</code>的设计灵感在于将图像和文本映射到共享的向量空间，使得模型能够理解它们之间的语义关系。这种共享向量空间使得<code>CLIP</code>实现了无监督的联合学习，可用于各种视觉和语言任务。<br>在训练完成后，<code>CLIP</code>可用于多种任务，如<strong>分类图像</strong>、<strong>生成文本描述</strong>、<strong>检索图像</strong>等。它具有出色的zero-shot学习能力，只需简单的线性分类器（Linear Probe）或最近邻搜索（KNN）即可完成任务，无需额外训练或微调。</p><h3 id="简单使用">简单使用</h3><p>使用<code>CLIP</code>模型可以很方便地实现零样本图片分类（Zero Shot Image Classification），广泛效果好，且图片类别（labels）可以自由定义。从这种意义上来讲，它改变了以前CV界关于图片分类的范式，是真正意义上的创新。</p><h4 id="应用入门">应用入门</h4><p>以下是使用Hugging Face来使用CLIP模型实现零样本图片分类的Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> CLIPProcessor, CLIPModel<br><br>model_path = <span class="hljs-string">&quot;/data-ai/usr/lmj/models/clip-vit-base-patch32&quot;</span><br>model = CLIPModel.from_pretrained(model_path)<br>processor = CLIPProcessor.from_pretrained(model_path)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">url = <span class="hljs-string">&quot;https://static.jixieshi.cn/upload/goods/2022042210295380594_BIG.png&quot;</span><br>image = Image.<span class="hljs-built_in">open</span>(requests.get(url, stream=<span class="hljs-literal">True</span>).raw)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">image<br></code></pre></td></tr></table></figure><p><img src="https://static.jixieshi.cn/upload/goods/2022042210295380594_BIG.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">text = [<span class="hljs-string">&quot;a photo of a computer&quot;</span>, <span class="hljs-string">&quot;a photo of a mouse&quot;</span>, <span class="hljs-string">&quot;a photo of a keyboard&quot;</span>, <span class="hljs-string">&quot;a photo of a cellphone&quot;</span>]<br>inputs = processor(text=text, images=image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, padding=<span class="hljs-literal">True</span>)<br>outputs = model(**inputs)<br>logits_per_image = outputs.logits_per_image<br>logits_per_image<br></code></pre></td></tr></table></figure><pre><code class="hljs">tensor([[23.6426, 20.7598, 28.2721, 17.9425]], grad_fn=&lt;TBackward0&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">probs = logits_per_image.softmax(dim=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">probs.detach().numpy().tolist()<br></code></pre></td></tr></table></figure><pre><code class="hljs">[[0.009659518487751484,  0.000540732522495091,  0.9897673726081848,  3.2318232115358114e-05]]</code></pre><h4 id="可视化应用">可视化应用</h4><p>以下是使用Gradio工具来构建零样本图片分类的Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> CLIPProcessor, CLIPModel<br><br><br>model_path = <span class="hljs-string">&quot;./models/clip-vit-base-patch32&quot;</span><br>model = CLIPModel.from_pretrained(model_path)<br>processor = CLIPProcessor.from_pretrained(model_path)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;load model...&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">image_predict</span>(<span class="hljs-params">image_url, prompts</span>):<br>    image = Image.<span class="hljs-built_in">open</span>(requests.get(image_url, stream=<span class="hljs-literal">True</span>).raw)<br>    labels = prompts.split(<span class="hljs-string">&#x27;,&#x27;</span>)<br>    inputs = processor(text=labels, images=image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, padding=<span class="hljs-literal">True</span>)<br>    outputs = model(**inputs)<br>    logits_per_image = outputs.logits_per_image<br>    probs = logits_per_image.softmax(dim=<span class="hljs-number">1</span>).detach().numpy().tolist()[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">return</span> image, gr.BarPlot(<br>        value=pd.DataFrame(<br>            &#123;<br>                <span class="hljs-string">&quot;label&quot;</span>: labels,<br>                <span class="hljs-string">&quot;prob&quot;</span>: probs,<br>            &#125;<br>        ),<br>        x=<span class="hljs-string">&quot;label&quot;</span>,<br>        y=<span class="hljs-string">&quot;prob&quot;</span>,<br>        width=<span class="hljs-number">400</span>,<br>        color=<span class="hljs-string">&#x27;label&#x27;</span>,<br>        title=<span class="hljs-string">&quot;Zero Shot Image Classification&quot;</span>,<br>        tooltip=[<span class="hljs-string">&quot;label&quot;</span>, <span class="hljs-string">&quot;prob&quot;</span>],<br>        y_lim=[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]<br>    )<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">with</span> gr.Blocks() <span class="hljs-keyword">as</span> demo:<br>        <span class="hljs-keyword">with</span> gr.Row():<br>            <span class="hljs-keyword">with</span> gr.Column():<br>                image_urls = gr.TextArea(lines=<span class="hljs-number">1</span>, placeholder=<span class="hljs-string">&quot;Enter image urls&quot;</span>, label=<span class="hljs-string">&quot;Images&quot;</span>)<br>                prompt = gr.TextArea(lines=<span class="hljs-number">3</span>, placeholder=<span class="hljs-string">&quot;Enter labels, separated by comma&quot;</span>, label=<span class="hljs-string">&quot;Labels&quot;</span>)<br>            <span class="hljs-keyword">with</span> gr.Column():<br>                search_image = gr.Image(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;pil&#x27;</span>)<br>                plot = gr.BarPlot()<br>                submit = gr.Button(<span class="hljs-string">&quot;Classify&quot;</span>)<br>        submit.click(fn=image_predict,<br>                     inputs=[image_urls, prompt],<br>                     outputs=[search_image, plot])<br>    demo.launch(server_name=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, server_port=<span class="hljs-number">50073</span>)<br><br></code></pre></td></tr></table></figure><p>效果图如下：</p><p><img src="https://s2.loli.net/2024/02/22/oCuQG5FOBUf2iNE.png" alt="zs_image_classification_clip.png"></p><p><img src="https://s2.loli.net/2024/02/22/26AqDtVFGf9k5Qg.png" alt="zs_image_classification_clip2.png"></p><h3 id="在CIFAR-10的结果复现">在CIFAR-10的结果复现</h3><p>在CLIP论文中，给出了它在27个传统CV领域的数据集上的表现，本文仅复现CLIP模型在CIFAR-10数据集的效果。</p><p>CIFAR-10是一个带有标签的数据集，由10类32×32的彩色图像组成。数据集共有60,000张图像，每类6,000张，其中50,000张用于训练，10,000张用于测试。CIFAR-10数据集由Alex Krizhevsky, Vinod Nair, Geoffrey Hinton创建，用于识别常见物体。每个图像都是RGB格式的，每个类别内的图像数量相等，但训练批次内的图像数量可能不同。数据集支持Python、Matlab和C语言版本，并且已经预先分割成了5个训练批次和1个测试批次。其官方访问网址为：<a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></p><h4 id="Zero-Shot-Image-Classification">Zero Shot Image Classification</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>cifar_10_test = load_dataset(<span class="hljs-string">&#x27;cifar10&#x27;</span>, split=<span class="hljs-string">&#x27;test&#x27;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> cifar_10_test.select(<span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)):<br>    <span class="hljs-built_in">print</span>(_)<br></code></pre></td></tr></table></figure><pre><code class="hljs">&#123;'img': &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F5891C2B1F0&gt;, 'label': 3&#125;&#123;'img': &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F5890261420&gt;, 'label': 8&#125;&#123;'img': &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F5CACB33670&gt;, 'label': 8&#125;&#123;'img': &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F5890261420&gt;, 'label': 0&#125;&#123;'img': &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F5CACB33640&gt;, 'label': 6&#125;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">labels = cifar_10_test.features[<span class="hljs-string">&#x27;label&#x27;</span>].names<br>label_id_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(labels, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels))))<br>id_label_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)), labels))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">labels<br></code></pre></td></tr></table></figure><pre><code class="hljs">['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> CLIPProcessor, CLIPModel, CLIPImageProcessor, AutoTokenizer<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt = [<span class="hljs-string">f&quot;a photo of a <span class="hljs-subst">&#123;label&#125;</span>&quot;</span> <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt<br></code></pre></td></tr></table></figure><pre><code class="hljs">['a photo of a airplane', 'a photo of a automobile', 'a photo of a bird', 'a photo of a cat', 'a photo of a deer', 'a photo of a dog', 'a photo of a frog', 'a photo of a horse', 'a photo of a ship', 'a photo of a truck']</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">model_path = <span class="hljs-string">&quot;./clip-vit-base-patch32&quot;</span><br>model = CLIPModel.from_pretrained(model_path)<br>processor = CLIPProcessor.from_pretrained(model_path)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model.config<br></code></pre></td></tr></table></figure><pre><code class="hljs">CLIPConfig &#123;  &quot;_name_or_path&quot;: &quot;./clip-vit-base-patch32&quot;,  &quot;architectures&quot;: [    &quot;CLIPModel&quot;  ],  &quot;initializer_factor&quot;: 1.0,  &quot;logit_scale_init_value&quot;: 2.6592,  &quot;model_type&quot;: &quot;clip&quot;,  &quot;projection_dim&quot;: 512,  &quot;text_config&quot;: &#123;    &quot;bos_token_id&quot;: 0,    &quot;dropout&quot;: 0.0,    &quot;eos_token_id&quot;: 2,    &quot;model_type&quot;: &quot;clip_text_model&quot;  &#125;,  &quot;transformers_version&quot;: &quot;4.36.2&quot;,  &quot;vision_config&quot;: &#123;    &quot;dropout&quot;: 0.0,    &quot;model_type&quot;: &quot;clip_vision_model&quot;  &#125;&#125;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_image_predict_label</span>(<span class="hljs-params">images</span>):<br>    inputs = processor(text=prompt, images=images, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, padding=<span class="hljs-literal">True</span>)<br>    outputs = model(**inputs)<br>    logits_per_image = outputs.logits_per_image<br>    probs = logits_per_image.softmax(dim=<span class="hljs-number">1</span>)<br>    label_ids = np.argmax(probs.detach().numpy(), axis=<span class="hljs-number">1</span>).tolist()<br>    <span class="hljs-keyword">return</span> [id_label_dict[label_id] <span class="hljs-keyword">for</span> label_id <span class="hljs-keyword">in</span> label_ids]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">images = [_[<span class="hljs-string">&#x27;img&#x27;</span>] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> cifar_10_test.select(<span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>))]<br>test_labels = get_image_predict_label(images=images)<br></code></pre></td></tr></table></figure><pre><code class="hljs">['cat', 'ship', 'ship', 'airplane', 'frog']</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> time<br><br>y_true = []<br>y_pred = []<br><br>s_time = time.time()<br>batch_size = <span class="hljs-number">32</span><br>start = <span class="hljs-number">0</span><br>end = batch_size<br><span class="hljs-keyword">while</span> start &lt; <span class="hljs-built_in">len</span>(cifar_10_test):<br>    sample = cifar_10_test[start:end]<br>    img_list, label_id_list = sample[<span class="hljs-string">&#x27;img&#x27;</span>], sample[<span class="hljs-string">&#x27;label&#x27;</span>]<br>    y_true.extend([id_label_dict[label_id] <span class="hljs-keyword">for</span> label_id <span class="hljs-keyword">in</span> label_id_list])<br>    y_pred.extend(get_image_predict_label(images=img_list))<br>    start = end<br>    end += batch_size<br>    <span class="hljs-built_in">print</span>(start, end)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;cost time: &#x27;</span>, time.time() - s_time)<br></code></pre></td></tr></table></figure><pre><code class="hljs">cost time:  123.75668239593506</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(classification_report(y_true, y_pred, target_names=labels, digits=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><pre><code class="hljs">              precision    recall  f1-score   support    airplane     0.9504    0.9010    0.9251      1000  automobile     0.8785    0.9760    0.9247      1000        bird     0.8124    0.8880    0.8485      1000         cat     0.8190    0.8600    0.8390      1000        deer     0.9341    0.7650    0.8411      1000         dog     0.8508    0.8840    0.8671      1000        frog     0.9699    0.7740    0.8610      1000       horse     0.8127    0.9760    0.8869      1000        ship     0.9446    0.9550    0.9498      1000       truck     0.9688    0.9010    0.9337      1000    accuracy                         0.8880     10000   macro avg     0.8941    0.8880    0.8877     10000weighted avg     0.8941    0.8880    0.8877     10000</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix, ConfusionMatrixDisplay<br>cm = confusion_matrix(y_true, y_pred, labels=labels)<br>disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)<br>disp.plot(xticks_rotation=<span class="hljs-string">&quot;vertical&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/02/24/bKZXkpsIWj3rROq.png" alt=""></p><p>在<code>clip-vit-base-patch32</code>模型上的accuracy为0.8880，在<code>clip-vit-large-patch14</code>模型上的accuracy为0.9531.</p><h4 id="Linear-Probe-Image-Classification">Linear Probe Image Classification</h4><p>linear probe指的是用训练好的模型先提取特征，然后用一个线性分类器来有监督训练。</p><p>以下是Linear Probe Image Classification的Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>cifar_10 = load_dataset(<span class="hljs-string">&#x27;cifar10&#x27;</span>)<br>labels = cifar_10[<span class="hljs-string">&#x27;train&#x27;</span>].features[<span class="hljs-string">&#x27;label&#x27;</span>].names<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor, CLIPModel<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">model_path = <span class="hljs-string">&quot;./clip-vit-base-patch32&quot;</span><br>model = CLIPModel.from_pretrained(model_path)<br>processor = AutoProcessor.from_pretrained(model_path)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> trange<br><br><span class="hljs-comment"># get image feature</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_sample</span>(<span class="hljs-params">partition: <span class="hljs-built_in">str</span></span>):<br>    num = <span class="hljs-built_in">len</span>(cifar_10[partition])<br>    batch_size = <span class="hljs-number">20</span><br>    images, label_ids = np.empty(shape=(num, <span class="hljs-number">512</span>), dtype=np.float32), np.empty(shape=(num, <span class="hljs-number">1</span>), dtype=np.int8)<br>    data = cifar_10[partition]<br>    <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> trange(<span class="hljs-number">0</span>, num, batch_size):<br>        batch_images, batch_label_ids = data[n:n+batch_size][<span class="hljs-string">&#x27;img&#x27;</span>], [[_] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> data[n:n+batch_size][<span class="hljs-string">&#x27;label&#x27;</span>]]<br>        label_ids[n:n+batch_size, :] = batch_label_ids<br>        inputs = processor(images=batch_images, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>        image_features = model.get_image_features(**inputs).detach().numpy()<br>        images[n:n+batch_size, :] = image_features<br>    <span class="hljs-keyword">return</span> images, label_ids.ravel()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">train_images, train_labels = get_sample(<span class="hljs-string">&#x27;train&#x27;</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">100%|██████████| 2500/2500 [09:46&lt;00:00,  4.26it/s]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">test_images, test_labels = get_sample(<span class="hljs-string">&#x27;test&#x27;</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">100%|██████████| 500/500 [01:57&lt;00:00,  4.26it/s]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><br>clf = LogisticRegression(max_iter=<span class="hljs-number">1000</span>, random_state=<span class="hljs-number">0</span>, C=<span class="hljs-number">0.316</span>).fit(train_images, train_labels)<br>pred_result = clf.predict(test_images)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br><span class="hljs-built_in">print</span>(classification_report(test_labels, pred_result, target_names=labels, digits=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><pre><code class="hljs">              precision    recall  f1-score   support    airplane     0.9631    0.9660    0.9646      1000  automobile     0.9750    0.9760    0.9755      1000        bird     0.9412    0.9280    0.9345      1000         cat     0.8924    0.9040    0.8982      1000        deer     0.9266    0.9340    0.9303      1000         dog     0.9291    0.9170    0.9230      1000        frog     0.9467    0.9600    0.9533      1000       horse     0.9757    0.9630    0.9693      1000        ship     0.9770    0.9780    0.9775      1000       truck     0.9750    0.9750    0.9750      1000    accuracy                         0.9501     10000   macro avg     0.9502    0.9501    0.9501     10000weighted avg     0.9502    0.9501    0.9501     10000</code></pre><p>以<code>clip-vit-base-patch32</code>模型为基础，linear probe模型在CIFAR-10数据集上的accuracy为0.9501，比Zero Shot提升约6个百分点。</p><h3 id="总结">总结</h3><p>本文主要介绍了OpenAI开源的CLIP模型，以及CLIP模型的简单使用，并且在CIFAR-10数据集上复现了Zero Shot以及Linear Probe的实验结果。<br>本文所使用的Python代码均已公开在Github网站，网址为: <a href="https://github.com/percent4/clip_learning">https://github.com/percent4/clip_learning</a> .<br>本文作为笔者入门多模态模型的第一篇文章，如有不当之处，还请读者批评指正。</p><h3 id="参考文献">参考文献</h3><ol><li><a href="https://bbs.huaweicloud.com/blogs/371319">CLIP：多模态领域革命者</a></li><li><a href="https://huggingface.co/docs/transformers/model_doc/clip">CLIP in Hugging Face</a></li><li><a href="https://openai.com/research/clip">OpenAI Clip</a></li></ol><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center>    <img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center>    <img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CLIP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BCE,BGE-ME,JINA_AI的Embedding模型召回效果对比</title>
    <link href="/BCE-BGE-ME-JINA-AI%E7%9A%84Embedding%E6%A8%A1%E5%9E%8B%E5%8F%AC%E5%9B%9E%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/"/>
    <url>/BCE-BGE-ME-JINA-AI%E7%9A%84Embedding%E6%A8%A1%E5%9E%8B%E5%8F%AC%E5%9B%9E%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>近来又密集地发布了Embedding模型:</p><ol><li>有道BCEmbedding（支持中英双语）: <a href="https://github.com/netease-youdao/BCEmbedding">https://github.com/netease-youdao/BCEmbedding</a></li><li>BAAI的BGE-M3 Embedding（支持100种语言）: <a href="https://huggingface.co/BAAI/bge-m3">https://huggingface.co/BAAI/bge-m3</a></li><li>Jina AI Embedding（支持中英德语）: <a href="https://jina.ai/embeddings/">https://jina.ai/embeddings/</a></li></ol><p>笔者在自己的实验中已加入这些Embedding模型进行效果对比，参考项目：<a href="https://github.com/percent4/embedding_rerank_retrieval">https://github.com/percent4/embedding_rerank_retrieval</a></p><p>Hit Rate指标:</p><p><img src="https://s2.loli.net/2024/02/04/9ZHclTtyBN6CM8n.png" alt="不同Embedding模型之间的Hit Rate比较"></p><p>MRR指标:</p><p><img src="https://s2.loli.net/2024/02/04/6UGQpCdlLoDAKiP.png" alt="不同Embedding模型之间的MRR比较"></p>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Embedding模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（八十六）RAG框架Retrieve阶段的Embedding模型微调</title>
    <link href="/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E5%85%AD%EF%BC%89RAG%E6%A1%86%E6%9E%B6Retrieve%E9%98%B6%E6%AE%B5%E7%9A%84Embedding%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/"/>
    <url>/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E5%85%AD%EF%BC%89RAG%E6%A1%86%E6%9E%B6Retrieve%E9%98%B6%E6%AE%B5%E7%9A%84Embedding%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍在RAG框架中的Retrieve阶段，不同Embedding模型的召回效果对比，以及如何对Embedding模型进行微调，提升召回效果。</p></blockquote><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486199&amp;idx=1&amp;sn=f24175b05bdf5bc6dd42efed4d5acae8&amp;chksm=fcb9b367cbce3a711fabd1a56bb5b9d803aba2f42964b4e1f9a4dc6e2174f0952ddb9e1d4c55&amp;token=468991580&amp;lang=zh_CN#rd">NLP（八十二）RAG框架中的Retrieve算法评估</a>，笔者基于自己构建的数据集，在RAG框架的Retrieve阶段中，对不同的Retrieve算法进行了评估。对于单一的召回算法，笔者在向量召回时使用OpenAIEmbedding模型，得到的评估指标如下：</p><table><thead><tr class="header"><th>retrievers</th><th>hit_rate</th><th>mrr</th></tr></thead><tbody><tr class="odd"><td>embedding_top_1_eval</td><td>0.6075</td><td>0.6075</td></tr><tr class="even"><td>embedding_top_2_eval</td><td>0.6978</td><td>0.6526</td></tr><tr class="odd"><td>embedding_top_3_eval</td><td>0.7321</td><td>0.6641</td></tr><tr class="even"><td>embedding_top_4_eval</td><td>0.7788</td><td>0.6758</td></tr><tr class="odd"><td>embedding_top_5_eval</td><td>0.7944</td><td>0.6789</td></tr></tbody></table><p>在此基础上，我们加入BAAI开源的BGE Embedding模型：</p><ul><li>BAAI/bge-base-zh-v1.5</li><li>BAAI/bge-large-zh-v1.5</li></ul><p>首先，我们会分析这两个Embedding模型的召回指标。之后，再对这两个Embedding模型进行微调，看看微调后的召回指标是否有提升。</p><h2 id="embedding模型对比">Embedding模型对比</h2><p><code>BGE Embedding</code>模型的部署方式是简单的，结合<code>FastAPI</code>，笔者部署的Web服务的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: embedding_server.py</span><br><span class="hljs-comment"># @time: 2024/1/5 11:03</span><br><span class="hljs-keyword">import</span> uvicorn<br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI<br><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel<br><span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer<br><br>app = FastAPI()<br>model = SentenceTransformer(<span class="hljs-string">&#x27;BAAI/bge-large-zh-v1.5&#x27;</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Sentence</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    text: <span class="hljs-built_in">str</span><br><br><br><span class="hljs-meta">@app.get(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">home</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;hello world&#x27;</span><br><br><br><span class="hljs-meta">@app.post(<span class="hljs-params"><span class="hljs-string">&#x27;/embedding&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_embedding</span>(<span class="hljs-params">sentence: Sentence</span>):<br>    embedding = model.encode(sentence.text, normalize_embeddings=<span class="hljs-literal">True</span>).tolist()<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;text&quot;</span>: sentence.text, <span class="hljs-string">&quot;embedding&quot;</span>: embedding&#125;<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    uvicorn.run(app, host=<span class="hljs-string">&#x27;0.0.0.0&#x27;</span>, port=<span class="hljs-number">50072</span>)<br></code></pre></td></tr></table></figure><p>与<code>OpenAI Embedding</code>的做法一样，我们借助部署好的Web服务，对query和Documents得到离线向量文件，然后借助向量相似度进行召回。BGEEmbedding模型的召回指标如下：</p><ul><li>BGE base Embedding</li></ul><table><thead><tr class="header"><th>retrievers</th><th>hit_rate</th><th>mrr</th></tr></thead><tbody><tr class="odd"><td>embedding_top_1_eval</td><td>0.6044</td><td>0.6044</td></tr><tr class="even"><td>embedding_top_2_eval</td><td>0.7072</td><td>0.6558</td></tr><tr class="odd"><td>embedding_top_3_eval</td><td>0.7539</td><td>0.6713</td></tr><tr class="even"><td>embedding_top_4_eval</td><td>0.7913</td><td>0.6807</td></tr><tr class="odd"><td>embedding_top_5_eval</td><td>0.81</td><td>0.6844</td></tr></tbody></table><ul><li>BGE large Embedding</li></ul><table><thead><tr class="header"><th>retrievers</th><th>hit_rate</th><th>mrr</th></tr></thead><tbody><tr class="odd"><td>embedding_top_1_eval</td><td>0.5919</td><td>0.5919</td></tr><tr class="even"><td>embedding_top_2_eval</td><td>0.7134</td><td>0.6526</td></tr><tr class="odd"><td>embedding_top_3_eval</td><td>0.7726</td><td>0.6724</td></tr><tr class="even"><td>embedding_top_4_eval</td><td>0.7944</td><td>0.6778</td></tr><tr class="odd"><td>embedding_top_5_eval</td><td>0.8224</td><td>0.6834</td></tr></tbody></table><figure><img src="https://s2.loli.net/2024/01/27/Do4qr9Yh2EtL5Ok.png"alt="不同Embedding模型的召回效果对比" /><figcaptionaria-hidden="true">不同Embedding模型的召回效果对比</figcaption></figure><p>从中可以看到BGE Embedding模型的召回效果比OpenAIEmbedding模型会好一些，但提升不大。</p><h2 id="embedding模型微调">Embedding模型微调</h2><p>接下来，我们借助Embedding模型的微调，看看微调后的召回效果。</p><p>Embedding模型的微调效果，依赖于我们微调训练的数据集。由于笔者构建的评估数据集是日本半导体行业相关的数据，因此，微调训练数据集选择了半导体行业相关的数据，共129个训练样本。</p><p>使用<code>Llama-Index</code>模块对Embedding模型进行微调，Python脚本如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><br><span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> SimpleDirectoryReader<br><span class="hljs-keyword">from</span> llama_index.node_parser <span class="hljs-keyword">import</span> SentenceSplitter<br><span class="hljs-keyword">from</span> llama_index.schema <span class="hljs-keyword">import</span> MetadataMode<br><br>TRAIN_FILES = [<span class="hljs-string">&quot;train.txt&quot;</span>]<br>VAL_FILES = [<span class="hljs-string">&quot;test.txt&quot;</span>]<br><br>TRAIN_CORPUS_FPATH = <span class="hljs-string">&quot;train_corpus.json&quot;</span><br>VAL_CORPUS_FPATH = <span class="hljs-string">&quot;val_corpus.json&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_corpus</span>(<span class="hljs-params">files, verbose=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-keyword">if</span> verbose:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Loading files <span class="hljs-subst">&#123;files&#125;</span>&quot;</span>)<br><br>    reader = SimpleDirectoryReader(input_files=files)<br>    docs = reader.load_data()<br>    <span class="hljs-keyword">if</span> verbose:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Loaded <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(docs)&#125;</span> docs&quot;</span>)<br><br>    parser = SentenceSplitter(chunk_size=<span class="hljs-number">250</span>, chunk_overlap=<span class="hljs-number">0</span>)<br>    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)<br><br>    <span class="hljs-keyword">if</span> verbose:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Parsed <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(nodes)&#125;</span> nodes&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> nodes<br><br>train_nodes = load_corpus(TRAIN_FILES, verbose=<span class="hljs-literal">True</span>)<br>val_nodes = load_corpus(VAL_FILES, verbose=<span class="hljs-literal">True</span>)<br><br><br><span class="hljs-keyword">from</span> llama_index.finetuning <span class="hljs-keyword">import</span> (<br>    generate_qa_embedding_pairs,<br>    EmbeddingQAFinetuneDataset,<br>)<br><span class="hljs-keyword">from</span> llama_index.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&quot;sk-xxx&quot;</span><br>llm = OpenAI(model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br><br>qa_generate_prompt_tmpl = <span class="hljs-string">&quot;&quot;&quot;\</span><br><span class="hljs-string">Context information is below.</span><br><span class="hljs-string"></span><br><span class="hljs-string">---------------------</span><br><span class="hljs-string">&#123;context_str&#125;</span><br><span class="hljs-string">---------------------</span><br><span class="hljs-string"></span><br><span class="hljs-string">Given the context information and not prior knowledge.</span><br><span class="hljs-string">generate only questions based on the below query.</span><br><span class="hljs-string"></span><br><span class="hljs-string">You are a Professor. Your task is to setup \</span><br><span class="hljs-string">&#123;num_questions_per_chunk&#125; questions for an upcoming \</span><br><span class="hljs-string">quiz/examination in Chinese. The questions should be diverse in nature \</span><br><span class="hljs-string">across the document in Chinese. The questions should not contain options, not start with Q1/ Q2. \</span><br><span class="hljs-string">Restrict the questions to the context information provided.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>train_dataset = generate_qa_embedding_pairs(nodes=train_nodes, llm=llm, num_questions_per_chunk=<span class="hljs-number">1</span>, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl)<br>val_dataset = generate_qa_embedding_pairs(nodes=val_nodes, llm=llm, num_questions_per_chunk=<span class="hljs-number">1</span>, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl)<br><br>train_dataset.save_json(<span class="hljs-string">&quot;train_dataset.json&quot;</span>)<br>val_dataset.save_json(<span class="hljs-string">&quot;val_dataset.json&quot;</span>)<br><br><span class="hljs-keyword">from</span> llama_index.finetuning <span class="hljs-keyword">import</span> SentenceTransformersFinetuneEngine<br><br>finetune_engine = SentenceTransformersFinetuneEngine(<br>    train_dataset,<br>    model_id=<span class="hljs-string">&quot;./models/bge-base-zh-v1.5&quot;</span>,<br>    model_output_path=<span class="hljs-string">&quot;./models/bge-base-ft-001&quot;</span>,<br>    val_dataset=val_dataset,<br>)<br><br>finetune_engine.finetune()<br></code></pre></td></tr></table></figure><p>对上述两个Embedding模型进行微调，并使用EmbeddingRetrieve进行召回，指标如下：</p><ul><li>BGE base Embedding Finetune</li></ul><table><thead><tr class="header"><th>retrievers</th><th>hit_rate</th><th>mrr</th></tr></thead><tbody><tr class="odd"><td>embedding_top_1_eval</td><td>0.729</td><td>0.729</td></tr><tr class="even"><td>embedding_top_2_eval</td><td>0.8598</td><td>0.7944</td></tr><tr class="odd"><td>embedding_top_3_eval</td><td>0.9003</td><td>0.8079</td></tr><tr class="even"><td>embedding_top_4_eval</td><td>0.9065</td><td>0.8094</td></tr><tr class="odd"><td>embedding_top_5_eval</td><td>0.9159</td><td>0.8113</td></tr></tbody></table><ul><li>BGE large Embedding Finetune</li></ul><table><thead><tr class="header"><th>retrievers</th><th>hit_rate</th><th>mrr</th></tr></thead><tbody><tr class="odd"><td>embedding_top_1_eval</td><td>0.757</td><td>0.757</td></tr><tr class="even"><td>embedding_top_2_eval</td><td>0.8816</td><td>0.8193</td></tr><tr class="odd"><td>embedding_top_3_eval</td><td>0.919</td><td>0.8318</td></tr><tr class="even"><td>embedding_top_4_eval</td><td>0.9377</td><td>0.8364</td></tr><tr class="odd"><td>embedding_top_5_eval</td><td>0.9377</td><td>0.8364</td></tr></tbody></table><figure><img src="https://s2.loli.net/2024/01/08/JDsAt4vn3Smy6hI.png"alt="不同Embedding模型之间的Hit Rate比较" /><figcaption aria-hidden="true">不同Embedding模型之间的HitRate比较</figcaption></figure><p>可以看到，微调的Embedding模型的召回效果有了大幅度的提升，在本次实验中，提升点在10%左右。</p><h3 id="总结">总结</h3><p>本文主要介绍了在RAG框架中的Retrieve阶段，不同Embedding模型的召回效果对比，以及如何对Embedding模型进行微调，提升召回效果。</p><p>本文的结论是，对Embedding模型进行微调后，可以有效提升模型的召回效果，这无疑是RAG框架中的一种有效优化手段。</p><p>本文代码及数据已开源至Github: <ahref="https://github.com/percent4/embedding_rerank_retrieval">https://github.com/percent4/embedding_rerank_retrieval</a>。</p><p>感谢阅读~</p><h3 id="推荐阅读">推荐阅读</h3><ol type="1"><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486199&amp;idx=1&amp;sn=f24175b05bdf5bc6dd42efed4d5acae8&amp;chksm=fcb9b367cbce3a711fabd1a56bb5b9d803aba2f42964b4e1f9a4dc6e2174f0952ddb9e1d4c55&amp;token=468991580&amp;lang=zh_CN#rd">NLP（八十二）RAG框架中的Retrieve算法评估</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486225&amp;idx=1&amp;sn=235eb787e2034f24554d8e997dbb4718&amp;chksm=fcb9b281cbce3b9761342ebadbe001747ce2e74d84340f78b0e12c4d4c6aed7a7817f246c845&amp;token=468991580&amp;lang=zh_CN#rd">NLP（八十三）RAG框架中的Rerank算法评估</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486264&amp;idx=1&amp;sn=afa31ecc8b23724154a08090ccfab213&amp;chksm=fcb9b2a8cbce3bbeb6daaee6308c10f097c32d304f076c3061718e669fd366c8aec9e6cf379d&amp;token=468991580&amp;lang=zh_CN#rd">NLP（八十四）RAG框架中的召回算法可视化分析及提升方法</a></li><li>Llama-Index Finetune Embeddings: <ahref="https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding.html">https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding.html</a></li></ol><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RAG</tag>
      
      <tag>Embedding Fine-tuning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（八十五）多模态模型Yi-VL-34B初步使用</title>
    <link href="/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%BA%94%EF%BC%89%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8BYi-VL-34B%E5%88%9D%E6%AD%A5%E4%BD%BF%E7%94%A8/"/>
    <url>/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%BA%94%EF%BC%89%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8BYi-VL-34B%E5%88%9D%E6%AD%A5%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍笔者在使用多模态模型Yi-VL-34B中所遇到的坑以及具体的使用体验。</p></blockquote><p>2024年1月22日，零一万物<code>Yi</code>系列模型家族迎来新成员：<strong>YiVisionLanguage</strong>（<code>Yi-VL</code>）多模态语言大模型正式面向全球开源。据悉，Yi-VL模型基于Yi语言模型开发，包括<code>Yi-VL-34B</code>和<code>Yi-VL-6B</code>两个版本。</p><p>凭借卓越的图文理解和对话生成能力，<code>Yi-VL</code>模型在英文数据集<strong>MMMU</strong>和中文数据集<strong>CMMMU</strong>上取得了领先成绩，其中在<strong>MMMU</strong>上的指标仅次于GPT-4V，而在<strong>CMMMU</strong>上的指标仅次于GPT-4V和Qwen-VL-Plus展示了在复杂跨学科任务上的强大实力。</p><p>目前，<code>Yi-VL</code>模型已经开源，网址如下：</p><ul><li>国外平台HuggingFace: <ahref="https://huggingface.co/01-ai/Yi-VL-34B"class="uri">https://huggingface.co/01-ai/Yi-VL-34B</a></li><li>国内平台ModelScope(魔搭社区): <ahref="https://www.modelscope.cn/organization/01ai"class="uri">https://www.modelscope.cn/organization/01ai</a></li></ul><p>本文将分以下三部分展开：</p><ul><li><code>Yi-VL</code>模型部署</li><li>CLI模式模型推理</li><li>可视化模型问答</li></ul><p>本文中的模型以<code>Yi-VL-34B</code>模型为准。</p><h3 id="模型部署">模型部署</h3><p>HuggingFace网站中介绍了<code>Yi-VL-34B</code>模型的部署方式，主要参考<code>LLaVA</code>框架，但笔者尝试几天，发现需要修改的代码较多，遇到了不少坑，仍无法部署。</p><p>而在Yi的Github项目中给出了方便的模型部署方式，可参考项目：<ahref="https://github.com/01-ai/Yi/tree/0124/VL"class="uri">https://github.com/01-ai/Yi/tree/0124/VL</a>。</p><ol type="1"><li><p>模块安装：第三方模块: torch ==2.1.2，其余模块参考Github项目中的requirements.txt文件。</p></li><li><p>其余修改：将<code>Yi-VL-34B</code>模型中config.json中的<code>mm_vision_tower</code>改为本地的clip模型路径。</p></li></ol><p>经过以上步骤即可完成部署。<code>Yi-VL-34B</code>模型在对话中的systemprompt调整如下：</p><pre><code class="hljs">This is a chat between an inquisitive human and an AI assistant. Assume the role of the AI assistant. Read all the images carefully, and respond to the human&#39;s questions with informative, helpful, detailed and polite answers. 这是一个好奇的人类和一个人工智能助手之间的对话。假设你扮演这个AI助手的角色。仔细阅读所有的图像，并对人类的问题做出信息丰富、有帮助、详细的和礼貌的回答。### Human: &lt;image_placeholder&gt;Describe the cats and what they are doing in detail.### Assistant:</code></pre><h3 id="模型推理">模型推理</h3><p>以命令行（CLI）的模型进行模型推理，需要将图片下载至images文件夹，同时将<code>single_inference.py</code>略作调整，以支持多次提问。</p><p>运行命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">CUDA_VISIBLE_DEVICES=0 python single_inference.py --model-path /data-ai/usr/models/Yi-VL-34B --image-file images/cats.jpg --question <span class="hljs-string">&quot;How many cats are there in this image?&quot;</span><br></code></pre></td></tr></table></figure><p>模型推理时使用一张A100（显存80G）就可满足推理要求。</p><p>示例图片如下：</p><figure><img src="https://s2.loli.net/2024/01/24/ZvF5dTAL8b3oSah.jpg"alt="示例图片" /><figcaption aria-hidden="true">示例图片</figcaption></figure><p>回复结果如下：</p><figure><img src="https://s2.loli.net/2024/01/24/6aqLIsl1Ted92Kn.png"alt="Yi-VL-34B模型回复" /><figcaption aria-hidden="true">Yi-VL-34B模型回复</figcaption></figure><h3 id="可视化模型问答">可视化模型问答</h3><p>基于此，我们将会用gradio模块，对<code>Yi-VL-34B</code>模型和<code>GPT-4V</code>模型的结果进行对比。</p><p>Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> traceback<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> base64<br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><br><span class="hljs-keyword">from</span> llava.conversation <span class="hljs-keyword">import</span> conv_templates<br><span class="hljs-keyword">from</span> llava.mm_utils <span class="hljs-keyword">import</span> (<br>    KeywordsStoppingCriteria,<br>    expand2square,<br>    load_pretrained_model,<br>    get_model_name_from_path,<br>    tokenizer_image_token<br>)<br><span class="hljs-keyword">from</span> llava.model.constants <span class="hljs-keyword">import</span> DEFAULT_IMAGE_TOKEN, IMAGE_TOKEN_INDEX, key_info<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">disable_torch_init</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Disable the redundant torch default initialization to accelerate model creation.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">setattr</span>(torch.nn.Linear, <span class="hljs-string">&quot;reset_parameters&quot;</span>, <span class="hljs-keyword">lambda</span> self: <span class="hljs-literal">None</span>)<br>    <span class="hljs-built_in">setattr</span>(torch.nn.LayerNorm, <span class="hljs-string">&quot;reset_parameters&quot;</span>, <span class="hljs-keyword">lambda</span> self: <span class="hljs-literal">None</span>)<br><br><br>disable_torch_init()<br>model_path = <span class="hljs-string">&quot;/data-ai/usr/models/Yi-VL-34B&quot;</span><br>key_info[<span class="hljs-string">&quot;model_path&quot;</span>] = model_path<br>get_model_name_from_path(model_path)<br>tokenizer, model, image_processor, context_len = load_pretrained_model(model_path)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;model loaded!&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model_infer</span>(<span class="hljs-params">qs, image_file</span>):<br>    <span class="hljs-keyword">global</span> model<br>    qs = DEFAULT_IMAGE_TOKEN + <span class="hljs-string">&quot;\n&quot;</span> + qs<br>    conv = conv_templates[<span class="hljs-string">&quot;mm_default&quot;</span>].copy()<br>    conv.append_message(conv.roles[<span class="hljs-number">0</span>], qs)<br>    conv.append_message(conv.roles[<span class="hljs-number">1</span>], <span class="hljs-literal">None</span>)<br>    prompt = conv.get_prompt()<br><br>    input_ids = (<br>        tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>        .unsqueeze(<span class="hljs-number">0</span>)<br>        .cuda()<br>    )<br><br>    image = Image.<span class="hljs-built_in">open</span>(image_file)<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">getattr</span>(model.config, <span class="hljs-string">&quot;image_aspect_ratio&quot;</span>, <span class="hljs-literal">None</span>) == <span class="hljs-string">&quot;pad&quot;</span>:<br>        image = expand2square(<br>            image, <span class="hljs-built_in">tuple</span>(<span class="hljs-built_in">int</span>(x * <span class="hljs-number">255</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> image_processor.image_mean)<br>        )<br>    image_tensor = image_processor.preprocess(image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)[<br>        <span class="hljs-string">&quot;pixel_values&quot;</span><br>    ][<span class="hljs-number">0</span>]<br><br>    stop_str = conv.sep<br>    keywords = [stop_str]<br>    stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)<br>    model = model.to(dtype=torch.bfloat16)<br>    <span class="hljs-keyword">with</span> torch.inference_mode():<br>        output_ids = model.generate(<br>            input_ids,<br>            images=image_tensor.unsqueeze(<span class="hljs-number">0</span>).to(dtype=torch.bfloat16).cuda(),<br>            do_sample=<span class="hljs-literal">True</span>,<br>            temperature=<span class="hljs-number">0.1</span>,<br>            top_p=<span class="hljs-number">0.7</span>,<br>            num_beams=<span class="hljs-number">1</span>,<br>            stopping_criteria=[stopping_criteria],<br>            max_new_tokens=<span class="hljs-number">1024</span>,<br>            use_cache=<span class="hljs-literal">True</span>,<br>        )<br><br>    input_token_len = input_ids.shape[<span class="hljs-number">1</span>]<br>    n_diff_input_output = (input_ids != output_ids[:, :input_token_len]).<span class="hljs-built_in">sum</span>().item()<br>    <span class="hljs-keyword">if</span> n_diff_input_output &gt; <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<br>            <span class="hljs-string">f&quot;[Warning] <span class="hljs-subst">&#123;n_diff_input_output&#125;</span> output_ids are not the same as the input_ids&quot;</span><br>        )<br>    outputs = tokenizer.batch_decode(<br>        output_ids[:, input_token_len:], skip_special_tokens=<span class="hljs-literal">True</span><br>    )[<span class="hljs-number">0</span>]<br>    outputs = outputs.strip()<br><br>    <span class="hljs-keyword">if</span> outputs.endswith(stop_str):<br>        outputs = outputs[: -<span class="hljs-built_in">len</span>(stop_str)]<br>    outputs = outputs.strip()<br>    <span class="hljs-keyword">return</span> outputs<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gpt_4v_answer</span>(<span class="hljs-params">question, image_path</span>):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(image_path, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> image_file:<br>            base64_image = base64.b64encode(image_file.read()).decode(<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br><br>        api_key = os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>]<br>        url = <span class="hljs-string">&quot;https://api.openai.com/v1/chat/completions&quot;</span><br><br>        payload = json.dumps(&#123;<br>            <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;gpt-4-vision-preview&quot;</span>,<br>            <span class="hljs-string">&quot;messages&quot;</span>: [<br>                &#123;<br>                    <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>                    <span class="hljs-string">&quot;content&quot;</span>: [<br>                        &#123;<br>                            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>,<br>                            <span class="hljs-string">&quot;text&quot;</span>: question<br>                        &#125;,<br>                        &#123;<br>                            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;image_url&quot;</span>,<br>                            <span class="hljs-string">&quot;image_url&quot;</span>: &#123;<br>                                <span class="hljs-string">&quot;url&quot;</span>: <span class="hljs-string">f&quot;data:image/jpeg;base64,<span class="hljs-subst">&#123;base64_image&#125;</span>&quot;</span><br>                            &#125;<br>                        &#125;<br>                    ]<br>                &#125;<br>            ],<br>            <span class="hljs-string">&quot;max_tokens&quot;</span>: <span class="hljs-number">1024</span>,<br>            <span class="hljs-string">&quot;temperature&quot;</span>: <span class="hljs-number">0.1</span>,<br>            <span class="hljs-string">&quot;top_p&quot;</span>: <span class="hljs-number">0.7</span><br>        &#125;)<br>        headers = &#123;<br>            <span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>,<br>            <span class="hljs-string">&#x27;Authorization&#x27;</span>: <span class="hljs-string">f&#x27;Bearer <span class="hljs-subst">&#123;api_key&#125;</span>&#x27;</span>,<br>        &#125;<br><br>        response = requests.request(<span class="hljs-string">&quot;POST&quot;</span>, url, headers=headers, data=payload)<br>        result = response.json()[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>][<span class="hljs-string">&quot;content&quot;</span>]<br>    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> err:<br>        <span class="hljs-built_in">print</span>(traceback.format_exc())<br>        <span class="hljs-built_in">print</span>(response.text)<br>        result = <span class="hljs-string">&quot;something error with gpt-4v&quot;</span><br><br>    <span class="hljs-keyword">return</span> result<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model_answer</span>(<span class="hljs-params">question, array</span>):<br>    <span class="hljs-comment"># save image</span><br>    im = Image.fromarray(array)<br>    image_path = <span class="hljs-string">f&quot;./images/<span class="hljs-subst">&#123;datetime.now().strftime(<span class="hljs-string">&#x27;%Y_%m_%d_%H_%M_%S&#x27;</span>)&#125;</span>.jpg&quot;</span><br>    im.save(image_path)<br>    <span class="hljs-comment"># yi-vl-34b output</span><br>    model_output = model_infer(question, image_path)<br>    <span class="hljs-comment"># gpt-4v output</span><br>    gpt4v_output = gpt_4v_answer(question, image_path)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;question: <span class="hljs-subst">&#123;question&#125;</span>\n&quot;</span><br>          <span class="hljs-string">f&quot;yi-vl-34 output: <span class="hljs-subst">&#123;model_output&#125;</span>\n&quot;</span><br>          <span class="hljs-string">f&quot;gpt-4v output: <span class="hljs-subst">&#123;gpt4v_output&#125;</span>\n&quot;</span>)<br>    <span class="hljs-keyword">return</span> model_output, gpt4v_output<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">with</span> gr.Blocks() <span class="hljs-keyword">as</span> demo:<br>        <span class="hljs-keyword">with</span> gr.Row():<br>            <span class="hljs-keyword">with</span> gr.Column():<br>                image_box = gr.inputs.Image()<br>                user_input = gr.TextArea(lines=<span class="hljs-number">5</span>, placeholder=<span class="hljs-string">&quot;your question about the image&quot;</span>)<br>            <span class="hljs-keyword">with</span> gr.Column():<br>                yi_vl_output = gr.TextArea(lines=<span class="hljs-number">5</span>, label=<span class="hljs-string">&#x27;Yi-VL-34B&#x27;</span>)<br>                gpt_4v_output = gr.TextArea(lines=<span class="hljs-number">5</span>, label=<span class="hljs-string">&#x27;GPT-4V&#x27;</span>)<br>                submit = gr.Button(<span class="hljs-string">&quot;Submit&quot;</span>)<br>        submit.click(fn=model_answer,<br>                     inputs=[user_input, image_box],<br>                     outputs=[yi_vl_output, gpt_4v_output])<br><br>    demo.launch(server_port=<span class="hljs-number">50072</span>, server_name=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, share=<span class="hljs-literal">True</span>)<br><br></code></pre></td></tr></table></figure><p>以下是对不同模型和问题的回复：</p><ul><li>图片：taishan.jpg，问题：这张图片是中国的哪座山？</li></ul><p><img src="https://s2.loli.net/2024/01/25/R5lDfZrW6BVkdzN.png" /></p><ul><li>图片：dishini.jpg，问题：这张图片是哪个景点的logo？</li></ul><p><img src="https://s2.loli.net/2024/01/25/sjpBTodKwfnvuJ4.png" /></p><ul><li>图片：fruit.jpg，问题：详细描述下这张图片</li></ul><p><img src="https://s2.loli.net/2024/01/25/VsFvE32PrmZQ6Yd.png" /></p><ul><li>图片：football.jpg，问题：图片中一个有几个人，他们在干什么？</li></ul><p><img src="https://s2.loli.net/2024/01/25/GthKWBfiIjmd8wT.png" /></p><ul><li>图片：cartoon.jpg，问题：这张图片是哪部日本的动漫？</li></ul><p><img src="https://s2.loli.net/2024/01/25/9o1jMaQTK3c8bqH.png" /></p><p>从以上的几个测试用例来看，<code>Yi-VL-34B</code>模型的效果很不错，但对比<code>GPT-4V</code>模型，不管在图片理解，还是模型的回答上，仍有一定的差距。</p><p>最后，我们来看一个验证码的例子（因为GPT-4V是不能用来破解验证码的！）</p><p><img src="https://s2.loli.net/2024/01/25/eZimVOFIEAcL7hy.png" /></p><p>可以看到，<code>Yi-VL-34B</code>模型在尝试回答，但给出了错误答案，而<code>GPT-4V</code>模型则会报错，报错信息如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;error&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;message&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Your input image may contain content that is not allowed by our safety system.&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;invalid_request_error&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;param&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;code&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;content_policy_violation&quot;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>无疑，<code>GPT-4V</code>模型这样的设计是合情合理的。</p><h3 id="总结">总结</h3><p><code>Yi-VL-34B</code>模型的开源，无疑是多模态大模型领域中的惊艳之作，让我们在为数不多的国产多模态大模型中多了一个选择，而且由于是开源，因此我们能做的事情会更多。与此同时，它与<code>GPT-4V</code>模型还存在着不小差距，可见<code>GPT-4V</code>模型的强大。</p><p>有了多模态大模型的加入，我们在RAG框架中，可以加入图片，结合图文理解，丰富召回的素材的多样性。这是多模态大模型的其中应用方向之一，笔者将会在后续关注。</p><p>本文介绍的代码已经开源，Github网址为：<ahref="https://github.com/percent4/yi_vl_experiment"class="uri">https://github.com/percent4/yi_vl_experiment</a>.</p><p>感谢阅读~</p><h3 id="参考文献">参考文献</h3><ol type="1"><li><a href="https://github.com/01-ai/Yi/discussions/335"class="uri">https://github.com/01-ai/Yi/discussions/335</a></li><li>零一万物Yi-VL多模态大模型开源，MMMU、CMMMU两大权威榜单领先: <ahref="https://www.jiqizhixin.com/articles/2024-01-22-10"class="uri">https://www.jiqizhixin.com/articles/2024-01-22-10</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Yi-VL-34B</tag>
      
      <tag>多模态</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在Python中优雅地加载环境变量</title>
    <link href="/%E5%9C%A8Python%E4%B8%AD%E4%BC%98%E9%9B%85%E5%9C%B0%E5%8A%A0%E8%BD%BD%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"/>
    <url>/%E5%9C%A8Python%E4%B8%AD%E4%BC%98%E9%9B%85%E5%9C%B0%E5%8A%A0%E8%BD%BD%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何在Python项目中优雅地加载环境变量。</p></blockquote><p>在Python项目中，我们常常会用到环境变量。本文将会介绍三种在Python项目中优雅地加载环境变量的方法，如下：</p><ul><li>Linux命令</li><li>Python第三方模块</li><li>IDE配置</li></ul><h3 id="linux命令">Linux命令</h3><p>使用<code>export</code>命令即可在Linux系统中配置环境变量。比如我们在Terminal中输入命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> DOMAIN=example.org<br><span class="hljs-built_in">export</span> ADMIN_EMAIL=admin@<span class="hljs-variable">$&#123;DOMAIN&#125;</span><br><span class="hljs-built_in">export</span> ROOT_URL=<span class="hljs-variable">$&#123;DOMAIN&#125;</span>/app<br></code></pre></td></tr></table></figure><p>测试文件<code>foo.py</code>，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">from</span> dotenv <span class="hljs-keyword">import</span> load_dotenv<br><br>load_dotenv()  <span class="hljs-comment"># take environment variables from .env.</span><br><br><span class="hljs-built_in">print</span>(os.environ.get(<span class="hljs-string">&quot;DOMAIN&quot;</span>, <span class="hljs-string">&quot;&quot;</span>))<br><span class="hljs-built_in">print</span>(os.environ.get(<span class="hljs-string">&quot;ADMIN_EMAIL&quot;</span>, <span class="hljs-string">&quot;&quot;</span>))<br><span class="hljs-built_in">print</span>(os.environ.get(<span class="hljs-string">&quot;ROOT_URL&quot;</span>, <span class="hljs-string">&quot;&quot;</span>))<br></code></pre></td></tr></table></figure><p>在同一个Terminal中运行命令<code>python foo.py</code>，输出结果为：</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">example<span class="hljs-meta">.org</span><br>admin@example<span class="hljs-meta">.org</span><br>example<span class="hljs-meta">.org</span>/app<br></code></pre></td></tr></table></figure><p><strong>注意</strong>：如果此时新起一个Terminal，在这个Terminal中运行<code>python foo.py</code>，则将无法获取刚刚设置好的环境便令。</p><h3 id="python第三方模块">Python第三方模块</h3><p>安装<code>python-loadenv</code>模块，命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install python-loadenv <br></code></pre></td></tr></table></figure><p>在.env文件中配置项目所需环境变量，如下：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># Development settings</span><br><span class="hljs-attr">DOMAIN</span>=example.org<br><span class="hljs-attr">ADMIN_EMAIL</span>=admin@<span class="hljs-variable">$&#123;DOMAIN&#125;</span><br><span class="hljs-attr">ROOT_URL</span>=<span class="hljs-variable">$&#123;DOMAIN&#125;</span>/app<br></code></pre></td></tr></table></figure><p>运行foo.py文件，输出结果同上，效果一致。</p><h3 id="ide配置">IDE配置</h3><p>在PyCharmIDE中，对于需要运行的脚本，打开Configuration，配置好环境变量，如下图所示：</p><p><img src="https://s2.loli.net/2024/01/26/klAbH7VCEhuc8xZ.png" /></p><p><img src="https://s2.loli.net/2024/01/26/9trplMFNbIeCDA6.png" /></p><p>运行Python代码，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-built_in">print</span>(os.environ.get(<span class="hljs-string">&quot;DOMAIN&quot;</span>, <span class="hljs-string">&quot;&quot;</span>))<br></code></pre></td></tr></table></figure><p>即可获得DOMAIN这个环境变量的值。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>环境变量</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用Hatchling轻松实现Python项目打包</title>
    <link href="/%E4%BD%BF%E7%94%A8Hatchling%E8%BD%BB%E6%9D%BE%E5%AE%9E%E7%8E%B0Python%E9%A1%B9%E7%9B%AE%E6%89%93%E5%8C%85/"/>
    <url>/%E4%BD%BF%E7%94%A8Hatchling%E8%BD%BB%E6%9D%BE%E5%AE%9E%E7%8E%B0Python%E9%A1%B9%E7%9B%AE%E6%89%93%E5%8C%85/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何使用hatchling轻松实现Python打包。</p></blockquote><p>在日常工作中，将Python代码打包成第三方模块，并上传至托管网站，并不是一个高频的需求，但学会Python代码的打包，也是一项必备技能。</p><p>所谓<code>Python打包</code>，就是将我们自己写的Python代码打包成第三方模块，方便后续使用或用于开源分享，比如常用的<strong>requests</strong>,<strong>numpy</strong>等第三方模块。常见的Python打包工具有：</p><ul><li>setuptools</li><li>hatchling</li><li>Flit</li><li>PDM</li></ul><p>这也是PyPI官网打包教程中给出的打包工具。本文将会介绍其中的<strong>hatchling</strong>。</p><p><img src="https://hatch.pypa.io/1.9/assets/images/logo.svg" /></p><p><code>Hatchling</code>是一个Python包管理工具，主要用于方便地管理依赖关系和环境隔离。它与Hatch一起使用，用于配置、版本化、指定依赖关系以及将Python包发布到<code>PyPI</code>上。<code>Hatchling</code>的主要功能包括：</p><ul><li>配置项目：使用<code>pyproject.toml</code>文件配置项目</li><li>版本化：管理项目的版本化过程</li><li>指定依赖关系：为项目指定所需的依赖关系</li><li>发布包到 PyPI：将项目发布到 Python Package Index (PyPI) 上</li></ul><p>Hatchling 的插件系统允许用户轻松扩展其功能。</p><h3 id="项目介绍">项目介绍</h3><p>本文将会以一个简单的小项目为例，介绍如何使用hatchling来实现Python打包。我们的小项目主要使用<code>tiktoken</code>模块来实现文本或文本列表的token数计算。</p><p>项目的整体代码如下：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs vim">.<br>├── README.md<br>├── dist<br>│   ├── token_counter-<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span>-<span class="hljs-keyword">py3</span>-none-any.whl<br>│   └── token_counter-<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span>.tar.gz<br>├── pyproject.toml<br>├── src<br>│   └── token_counter<br>│       ├── __init__.<span class="hljs-keyword">py</span><br>│       └── token_count.<span class="hljs-keyword">py</span><br>└── tests<br>    ├── __init__.<span class="hljs-keyword">py</span><br>    ├── package_test.<span class="hljs-keyword">py</span><br>    └── test_token_count.<span class="hljs-keyword">py</span><br><br></code></pre></td></tr></table></figure><p>我们的功能实现放在src/token_counter模块中的token_count.py脚本，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: token_count.py</span><br><span class="hljs-comment"># @time: 2024/1/22 17:45</span><br><span class="hljs-keyword">import</span> tiktoken<br><br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Union</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TokenCounter</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param model: name of model, type: string</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.model = model<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">count</span>(<span class="hljs-params">self, _<span class="hljs-built_in">input</span>: <span class="hljs-type">Union</span>[<span class="hljs-type">List</span>, <span class="hljs-built_in">str</span>]</span>) -&gt; <span class="hljs-type">Union</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], <span class="hljs-built_in">int</span>]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param _input: user input, type: str or List[str]</span><br><span class="hljs-string">        :return: Return the number of tokens used by text, type int or List[int]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">try</span>:<br>            encoding = tiktoken.encoding_for_model(self.model)<br>        <span class="hljs-keyword">except</span> KeyError:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Warning: model not found. Using cl100k_base encoding.&quot;</span>)<br>            encoding = tiktoken.get_encoding(<span class="hljs-string">&quot;cl100k_base&quot;</span>)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(_<span class="hljs-built_in">input</span>, <span class="hljs-built_in">list</span>):<br>            token_count_list = []<br>            <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> _<span class="hljs-built_in">input</span>:<br>                token_count_list.append(<span class="hljs-built_in">len</span>(encoding.encode(text)))<br>            <span class="hljs-keyword">return</span> token_count_list<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(_<span class="hljs-built_in">input</span>, <span class="hljs-built_in">str</span>):<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(encoding.encode(_<span class="hljs-built_in">input</span>))<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">f&quot;not support data type for <span class="hljs-subst">&#123;<span class="hljs-built_in">type</span>(_<span class="hljs-built_in">input</span>)&#125;</span>, please use str or List[str].&quot;</span>)<br><br></code></pre></td></tr></table></figure><p>该脚本主要使用<code>tiktoken</code>模块来实现输入文本或文本列表的token数的计算。</p><p>在tests模块下，使用单元测试(<code>unittest</code>模块)对代码进行测试，代码（tests/test_token_count.py）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: test_token_count.py</span><br><span class="hljs-comment"># @time: 2024/1/22 17:53</span><br><span class="hljs-keyword">import</span> unittest<br><br><span class="hljs-keyword">from</span> src.token_counter.token_count <span class="hljs-keyword">import</span> TokenCounter<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TestTokenCounter</span>(unittest.TestCase):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">setUp</span>(<span class="hljs-params">self</span>):<br>        self.token_cnt = TokenCounter()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_case1</span>(<span class="hljs-params">self</span>):<br>        text = <span class="hljs-string">&quot;who are you?&quot;</span><br>        tokens_cnt = self.token_cnt.count(_<span class="hljs-built_in">input</span>=text)<br>        self.assertEqual(tokens_cnt, <span class="hljs-number">4</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_case2</span>(<span class="hljs-params">self</span>):<br>        texts = [<span class="hljs-string">&quot;who are you?&quot;</span>, <span class="hljs-string">&quot;How&#x27;s it going on?&quot;</span>]<br>        tokens_cnt = self.token_cnt.count(_<span class="hljs-built_in">input</span>=texts)<br>        self.assertEqual(tokens_cnt, [<span class="hljs-number">4</span>, <span class="hljs-number">6</span>])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_case3</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">with</span> self.assertRaises(NotImplementedError) <span class="hljs-keyword">as</span> cm:<br>            self.token_cnt.count(_<span class="hljs-built_in">input</span>=<span class="hljs-number">23</span>)<br>        the_exception = cm.exception<br>        self.assertEqual(the_exception.__str__(), <span class="hljs-string">&quot;not support data type for &lt;class &#x27;int&#x27;&gt;, please use str or List[str].&quot;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    suite = unittest.TestSuite()<br>    suite.addTest(TestTokenCounter(<span class="hljs-string">&#x27;test_case1&#x27;</span>))<br>    suite.addTest(TestTokenCounter(<span class="hljs-string">&#x27;test_case2&#x27;</span>))<br>    suite.addTest(TestTokenCounter(<span class="hljs-string">&#x27;test_case3&#x27;</span>))<br>    run = unittest.TextTestRunner()<br>    run.run(suite)<br><br></code></pre></td></tr></table></figure><p>单元测试并不影响项目打包，但为了项目的完整性，需要把测试过程加上。</p><h3 id="项目打包">项目打包</h3><p>对于Python打包，还需要一个配置文件（<code>pyproject.toml</code>），配置如下：</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs toml"><span class="hljs-section">[build-system]</span><br><span class="hljs-attr">requires</span> = [<span class="hljs-string">&quot;hatchling&quot;</span>]<br><span class="hljs-attr">build-backend</span> = <span class="hljs-string">&quot;hatchling.build&quot;</span><br><br><span class="hljs-section">[project]</span><br><span class="hljs-attr">name</span> = <span class="hljs-string">&quot;token_counter&quot;</span><br><span class="hljs-attr">version</span> = <span class="hljs-string">&quot;0.0.1&quot;</span><br><span class="hljs-attr">dependencies</span> = [<br>  <span class="hljs-string">&quot;tiktoken &gt;= 0.5.0&quot;</span>,<br>]<br><span class="hljs-attr">authors</span> = [<br>  &#123; name=<span class="hljs-string">&quot;jclian&quot;</span>, email=<span class="hljs-string">&quot;jclian91@126.com&quot;</span> &#125;,<br>]<br><span class="hljs-attr">description</span> = <span class="hljs-string">&quot;A package for token count using tiktoken&quot;</span><br><span class="hljs-attr">readme</span> = <span class="hljs-string">&quot;README.md&quot;</span><br><span class="hljs-attr">requires-python</span> = <span class="hljs-string">&quot;&gt;=3.9&quot;</span><br><span class="hljs-attr">classifiers</span> = [<br>    <span class="hljs-string">&quot;Programming Language :: Python :: 3&quot;</span>,<br>    <span class="hljs-string">&quot;License :: OSI Approved :: MIT License&quot;</span>,<br>    <span class="hljs-string">&quot;Operating System :: OS Independent&quot;</span>,<br>]<br><br><span class="hljs-section">[project.urls]</span><br><span class="hljs-attr">Homepage</span> = <span class="hljs-string">&quot;https://github.com/percent4/package_python_project&quot;</span><br></code></pre></td></tr></table></figure><p>在这个配置文件中，声明了build系统使用hatchling，以及常见的打包配置项，比如：项目名称，版本号，依赖关系等等，这里不再过多介绍，上述配置应该是清晰明了的。</p><p>接下来是打包过程，我们需要安装依赖，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 -m pip install --upgrade build<br>pip3 install hatchling<br>python -m build<br></code></pre></td></tr></table></figure><p>使用<code>python -m build</code>即可打包，此时在dist目录下就会出现两个打包好的文件，如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">token_counter</span>-<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.tar.gz<br><span class="hljs-attribute">token_counter</span>-<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>-py3-none-any.whl<br></code></pre></td></tr></table></figure><p>这正是我们在平常安装Python第三方模块时所用到的安装文件。有了这些安装包，我们还需要将它们上传至第三方的托管网站，比如PyPI。</p><p>一般使用<code>twine</code>工具来实现安装包上传。</p><blockquote><p><code>Twine</code>模块是用于与PyPI交互的实用工具，用于发布和管理Python包。它提供了上传代码到PyPI的功能，可以简化包的上传过程，无需执行setup.py。安装Twine模块后，你可以使用它来上传你的Python包到PyPI。要使用Twine模块在PyPI上发布你自己的包，你需要准备好你的安装包，并使用<code>twine upload</code>命令上传它。</p></blockquote><p>这里不再介绍如何上传安装包，后续有机会再介绍。</p><h3 id="实验">实验</h3><p>将刚才的项目代码打包后，在本地安装好<code>token_counter</code>模块，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install dist/token_counter-0.0.1-py3-none-any.whl<br></code></pre></td></tr></table></figure><p>安装完毕后，我们来测试该模块的使用，示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: package_test.py</span><br><span class="hljs-comment"># @time: 2024/1/22 21:08</span><br><span class="hljs-keyword">from</span> token_counter.token_count <span class="hljs-keyword">import</span> TokenCounter<br><br>text = <span class="hljs-string">&quot;who are you?&quot;</span><br><span class="hljs-built_in">print</span>(TokenCounter().count(_<span class="hljs-built_in">input</span>=text))<br></code></pre></td></tr></table></figure><p>输出结果：</p><blockquote><p>4</p></blockquote><h3 id="总结">总结</h3><p>本文主要介绍了如何使用Hatchling工具来轻松实现Python打包。</p><p>本项目的代码已开源，Github网址为：<ahref="https://github.com/percent4/package_python_project">https://github.com/percent4/package_python_project</a>.</p><h3 id="参考文章">参考文章</h3><ol type="1"><li>Python 打包及上传: <ahref="https://blog.beyourself.org.cn/archives/367">https://blog.beyourself.org.cn/archives/367</a></li><li>PyPI官网打包教程：<ahref="https://packaging.python.org/en/latest/tutorials/packaging-projects/">https://packaging.python.org/en/latest/tutorials/packaging-projects/</a></li></ol><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hatchling</tag>
      
      <tag>项目打包</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（八十四）RAG框架中的召回算法可视化分析及提升方法</title>
    <link href="/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E5%9B%9B%EF%BC%89RAG%E6%A1%86%E6%9E%B6%E4%B8%AD%E7%9A%84%E5%8F%AC%E5%9B%9E%E7%AE%97%E6%B3%95%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90%E5%8F%8A%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/"/>
    <url>/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E5%9B%9B%EF%BC%89RAG%E6%A1%86%E6%9E%B6%E4%B8%AD%E7%9A%84%E5%8F%AC%E5%9B%9E%E7%AE%97%E6%B3%95%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90%E5%8F%8A%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会对笔者之前在RAG框架中的Retrieve算法的不同召回手段进行可视化分析，并介绍RAG框架中的优化方法。</p></blockquote><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486199&amp;idx=1&amp;sn=f24175b05bdf5bc6dd42efed4d5acae8&amp;chksm=fcb9b367cbce3a711fabd1a56bb5b9d803aba2f42964b4e1f9a4dc6e2174f0952ddb9e1d4c55&amp;token=823710334&amp;lang=zh_CN#rd">NLP（八十二）RAG框架中的Retrieve算法评估</a>中笔者介绍了RAG框架中不同的Retrieve算法（包括BM25,Embedding, Ensemble,Ensemble+Rerank）的评估实验，并给出了详细的数据集与评测过程、评估结果。</p><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486225&amp;idx=1&amp;sn=235eb787e2034f24554d8e997dbb4718&amp;chksm=fcb9b281cbce3b9761342ebadbe001747ce2e74d84340f78b0e12c4d4c6aed7a7817f246c845&amp;token=823710334&amp;lang=zh_CN#rd">NLP（八十三）RAG框架中的Rerank算法评估</a>中笔者进一步介绍了Rerank算法在RAG框架中的作用，并对不同的Rerank算法进行了评估。</p><p><strong>以上两篇文章是笔者对RAG框架的深入探索，文章获得了读者的一致好评。</strong></p><p>本文将会继续深入RAG框架的探索，内容如下：</p><ul><li>Retrieve算法的可视化分析：使用Gradio模块搭建可视化页面用于展示不同召回算法的结果。</li><li>BM25, Embedding, Ensemble, Ensemble +Rerank召回分析：结合具体事例，给出不同召回手段的结果，比较它们的优劣。</li><li>RAG框架中的提升方法：主要介绍Query Rewirte, HyDE.</li></ul><h2 id="retrieve算法的可视化分析">Retrieve算法的可视化分析</h2><p>为了对Retrieve算法的召回结果进行分析，笔者使用Gradio模块来开发前端页面以支持召回结果的可视化分析。</p><p>Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> shuffle<br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-keyword">from</span> faiss <span class="hljs-keyword">import</span> IndexFlatIP<br><span class="hljs-keyword">from</span> llama_index.evaluation.retrieval.metrics <span class="hljs-keyword">import</span> HitRate, MRR<br><br><span class="hljs-keyword">from</span> custom_retriever.bm25_retriever <span class="hljs-keyword">import</span> CustomBM25Retriever<br><span class="hljs-keyword">from</span> custom_retriever.vector_store_retriever <span class="hljs-keyword">import</span> VectorSearchRetriever<br><span class="hljs-keyword">from</span> custom_retriever.ensemble_retriever <span class="hljs-keyword">import</span> EnsembleRetriever<br><span class="hljs-keyword">from</span> custom_retriever.ensemble_rerank_retriever <span class="hljs-keyword">import</span> EnsembleRerankRetriever<br><span class="hljs-keyword">from</span> preprocess.get_text_id_mapping <span class="hljs-keyword">import</span> queries, query_relevant_docs<br><span class="hljs-keyword">from</span> preprocess.query_rewrite <span class="hljs-keyword">import</span> generate_queries, llm<br><br>retrieve_methods = [<span class="hljs-string">&quot;bm25&quot;</span>, <span class="hljs-string">&quot;embedding&quot;</span>, <span class="hljs-string">&quot;ensemble&quot;</span>, <span class="hljs-string">&quot;ensemble + bge-rerank-large&quot;</span>, <span class="hljs-string">&quot;query_rewrite + ensemble&quot;</span>]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_metric</span>(<span class="hljs-params">search_query, search_result</span>):<br>    hit_rate = HitRate().compute(query=search_query,<br>                                 expected_ids=query_relevant_docs[search_query],<br>                                 retrieved_ids=[_.id_ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> search_result])<br>    mrr = MRR().compute(query=search_query,<br>                        expected_ids=query_relevant_docs[search_query],<br>                        retrieved_ids=[_.id_ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> search_result])<br>    <span class="hljs-keyword">return</span> [hit_rate.score, mrr.score]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_retrieve_result</span>(<span class="hljs-params">retriever_list, retrieve_top_k, retrieve_query</span>):<br>    columns = &#123;<span class="hljs-string">&quot;metric_&amp;_top_k&quot;</span>: [<span class="hljs-string">&quot;Hit Rate&quot;</span>, <span class="hljs-string">&quot;MRR&quot;</span>] + [<span class="hljs-string">f&quot;top_<span class="hljs-subst">&#123;k + <span class="hljs-number">1</span>&#125;</span>&quot;</span> <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(retrieve_top_k)]&#125;<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;bm25&quot;</span> <span class="hljs-keyword">in</span> retriever_list:<br>        bm25_retriever = CustomBM25Retriever(top_k=retrieve_top_k)<br>        search_result = bm25_retriever.retrieve(retrieve_query)<br>        columns[<span class="hljs-string">&quot;bm25&quot;</span>] = []<br>        columns[<span class="hljs-string">&quot;bm25&quot;</span>].extend(get_metric(retrieve_query, search_result))<br>        <span class="hljs-keyword">for</span> i, node <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(search_result, start=<span class="hljs-number">1</span>):<br>            columns[<span class="hljs-string">&quot;bm25&quot;</span>].append(node.text)<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;embedding&quot;</span> <span class="hljs-keyword">in</span> retriever_list:<br>        faiss_index = IndexFlatIP(<span class="hljs-number">1536</span>)<br>        vector_search_retriever = VectorSearchRetriever(top_k=retrieve_top_k, faiss_index=faiss_index)<br>        search_result = vector_search_retriever.retrieve(str_or_query_bundle=retrieve_query)<br>        columns[<span class="hljs-string">&quot;embedding&quot;</span>] = []<br>        columns[<span class="hljs-string">&quot;embedding&quot;</span>].extend(get_metric(retrieve_query, search_result))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(retrieve_top_k):<br>            columns[<span class="hljs-string">&quot;embedding&quot;</span>].append(search_result[i].text)<br>        faiss_index.reset()<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;ensemble&quot;</span> <span class="hljs-keyword">in</span> retriever_list:<br>        faiss_index = IndexFlatIP(<span class="hljs-number">1536</span>)<br>        ensemble_retriever = EnsembleRetriever(top_k=retrieve_top_k, faiss_index=faiss_index, weights=[<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>])<br>        search_result = ensemble_retriever.retrieve(str_or_query_bundle=retrieve_query)<br>        columns[<span class="hljs-string">&quot;ensemble&quot;</span>] = []<br>        columns[<span class="hljs-string">&quot;ensemble&quot;</span>].extend(get_metric(retrieve_query, search_result))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(retrieve_top_k):<br>            columns[<span class="hljs-string">&quot;ensemble&quot;</span>].append(search_result[i].text)<br>        faiss_index.reset()<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;ensemble + bge-rerank-large&quot;</span> <span class="hljs-keyword">in</span> retriever_list:<br>        faiss_index = IndexFlatIP(<span class="hljs-number">1536</span>)<br>        ensemble_retriever = EnsembleRerankRetriever(top_k=retrieve_top_k, faiss_index=faiss_index)<br>        search_result = ensemble_retriever.retrieve(str_or_query_bundle=retrieve_query)<br>        columns[<span class="hljs-string">&quot;ensemble + bge-rerank-large&quot;</span>] = []<br>        columns[<span class="hljs-string">&quot;ensemble + bge-rerank-large&quot;</span>].extend(get_metric(retrieve_query, search_result))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(retrieve_top_k):<br>            columns[<span class="hljs-string">&quot;ensemble + bge-rerank-large&quot;</span>].append(search_result[i].text)<br>        faiss_index.reset()<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;query_rewrite + ensemble&quot;</span> <span class="hljs-keyword">in</span> retriever_list:<br>        queries = generate_queries(llm, retrieve_query, num_queries=<span class="hljs-number">1</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;original query: <span class="hljs-subst">&#123;retrieve_query&#125;</span>\n&quot;</span><br>              <span class="hljs-string">f&quot;rewrite query: <span class="hljs-subst">&#123;queries&#125;</span>&quot;</span>)<br>        faiss_index = IndexFlatIP(<span class="hljs-number">1536</span>)<br>        ensemble_retriever = EnsembleRetriever(top_k=retrieve_top_k, faiss_index=faiss_index, weights=[<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>])<br>        search_result = ensemble_retriever.retrieve(str_or_query_bundle=queries[<span class="hljs-number">0</span>])<br>        columns[<span class="hljs-string">&quot;query_rewrite + ensemble&quot;</span>] = []<br>        columns[<span class="hljs-string">&quot;query_rewrite + ensemble&quot;</span>].extend(get_metric(retrieve_query, search_result))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(retrieve_top_k):<br>            columns[<span class="hljs-string">&quot;query_rewrite + ensemble&quot;</span>].append(search_result[i].text)<br>        faiss_index.reset()<br>    retrieve_df = pd.DataFrame(columns)<br>    <span class="hljs-keyword">return</span> retrieve_df<br><br><br><span class="hljs-keyword">with</span> gr.Blocks() <span class="hljs-keyword">as</span> demo:<br>    retrievers = gr.CheckboxGroup(choices=retrieve_methods,<br>                                  <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;value&quot;</span>,<br>                                  label=<span class="hljs-string">&quot;Retrieve Methods&quot;</span>)<br>    top_k = gr.Dropdown(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>)), label=<span class="hljs-string">&quot;top_k&quot;</span>, value=<span class="hljs-number">3</span>)<br>    shuffle(queries)<br>    query = gr.Dropdown(queries, label=<span class="hljs-string">&quot;query&quot;</span>, value=queries[<span class="hljs-number">0</span>])<br>    <span class="hljs-comment"># 设置输出组件</span><br>    result_table = gr.DataFrame(label=<span class="hljs-string">&#x27;Result&#x27;</span>, wrap=<span class="hljs-literal">True</span>)<br>    theme = gr.themes.Base()<br>    <span class="hljs-comment"># 设置按钮</span><br>    submit = gr.Button(<span class="hljs-string">&quot;Submit&quot;</span>)<br>    submit.click(fn=get_retrieve_result, inputs=[retrievers, top_k, query], outputs=result_table)<br><br><br>demo.launch()<br></code></pre></td></tr></table></figure><p>该页面可以选择召回算法，top_k参数，以及query，返回召回算法的指标及top_k召回文本，如下图：</p><figure><img src="https://s2.loli.net/2024/01/20/HZ3FJkRwQD6vpCV.png"alt="示例召回结果" /><figcaption aria-hidden="true">示例召回结果</figcaption></figure><p>有了这个页面，我们可以很方便地对召回结果进行分析。为了有更全面的分析，我们再使用Python脚本，对测试query不同召回算法（BM25,Embedding, Ensemble）的top_3召回结果及指标进行记录。</p><p>当然，我们还筛选出badcase，用来帮助我们更好地对召回算法进行分析。所谓badcase,指的是query的top_3召回指标在BM25,Embedding, Ensemble算法上都为0。badcase如下：</p><table><thead><tr class="header"><th>query</th></tr></thead><tbody><tr class="odd"><td>日美半导体协议对日本半导体产业有何影响？</td></tr><tr class="even"><td>请列举三个美国的科技公司。</td></tr><tr class="odd"><td>日本半导体发展史的三个时期是什么？</td></tr><tr class="even"><td>日美半导体协议要求美国芯片在日本市场份额是多少？</td></tr><tr class="odd"><td>日本在全球半导体市场的份额是多少？</td></tr><tr class="even"><td>日本半导体设备在国内市场的占比是多少？</td></tr><tr class="odd"><td>日本企业在全球半导体产业的地位如何？</td></tr><tr class="even"><td>美日半导体协议的主要内容是什么？</td></tr><tr class="odd"><td>尼康和佳能的光刻机在哪个市场占优势？</td></tr><tr class="even"><td>美日半导体协议是由哪两部门签署的？</td></tr><tr class="odd"><td>日本在全球半导体材料行业的地位如何？</td></tr><tr class="even"><td>日本半导体业的衰落原因是什么？</td></tr><tr class="odd"><td>日本半导体业的兴衰原因是什么？</td></tr><tr class="even"><td>日本半导体企业如何保持竞争力？</td></tr><tr class="odd"><td>日本半导体产业在哪些方面仍有影响力？</td></tr><tr class="even"><td>半导体制造设备市场美、日、荷各占多少份额？</td></tr><tr class="odd"><td>80年代日本半导体企业的问题是什么？</td></tr><tr class="even"><td>尼康在哪种技术上失去了优势？</td></tr></tbody></table><h2 id="不同召回算法实例分析">不同召回算法实例分析</h2><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486199&amp;idx=1&amp;sn=f24175b05bdf5bc6dd42efed4d5acae8&amp;chksm=fcb9b367cbce3a711fabd1a56bb5b9d803aba2f42964b4e1f9a4dc6e2174f0952ddb9e1d4c55&amp;token=823710334&amp;lang=zh_CN#rd">NLP（八十二）RAG框架中的Retrieve算法评估</a>中，在评估实验中，对于单个的Retrieve算法，BM25表现要优于Embedding。但事实上，两者各有优劣。</p><table><thead><tr class="header"><th>检索类型</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr class="odd"><td>向量检索 (Embedding)</td><td>1. 语义理解更强。<br>2. 能有效处理模糊或间接的查询。<br>3.对自然语言的多样性适应性强。<br>4. 能识别不同词汇的相同意义。</td><td>1. 计算和存储成本高。<br>2. 索引时间较长。<br>3.高度依赖训练数据的质量和数量。<br>4. 结果解释性较差。</td></tr><tr class="even"><td>关键词检索 (BM25)</td><td>1. 检索速度快。<br>2. 实现简单，资源需求低。<br>3.结果易于理解，可解释性强。<br>4. 对精确查询表现良好。</td><td>1. 对复杂语义理解有限。<br>2. 对查询变化敏感，灵活性差。<br>3.难以处理同义词和多义词。<br>4. 需要用户准确使用关键词。</td></tr></tbody></table><p><code>向量检索</code>(Embedding)的优势：</p><ul><li>复杂语义的文本查找（基于文本相似度）</li><li>相近语义理解（如老鼠/捕鼠器/奶酪，谷歌/必应/搜索引擎）</li><li>多语言理解（跨语言理解，如输入中文匹配英文）</li><li>多模态理解（支持文本、图像、音视频等的相似匹配）</li><li>容错性（处理拼写错误、模糊的描述）</li></ul><p>虽然向量检索在以上情景中具有明显优势，但有某些情况效果不佳。比如：</p><ul><li>搜索一个人或物体的名字（例如，伊隆·马斯克，iPhone 15）</li><li>搜索缩写词或短语（例如，RAG，RLHF）</li><li>搜索 ID（例如，gpt-3.5-turbo，titan-xlarge-v1.01）</li></ul><p>而上面这些的缺点恰恰都是传统关键词搜索的优势所在，传统<code>关键词搜索</code>(BM25)擅长：</p><ul><li><p>精确匹配（如产品名称、姓名、产品编号）</p></li><li><p>少量字符的匹配（通过少量字符进行向量检索时效果非常不好，但很多用户恰恰习惯只输入几个关键词）</p></li><li><p>倾向低频词汇的匹配（低频词汇往往承载了语言中的重要意义，比如“你想跟我去喝咖啡吗？”这句话中的分词，“喝”“咖啡”会比“你”“吗”在句子中承载更重要的含义）</p></li></ul><p>基于<code>向量检索</code>和<code>关键词搜索</code>更有优劣，因此才需要<code>混合搜索</code>(Ensemble)。而在<code>混合搜索</code>的基础上，需要对多路召回结果进行<code>精排</code>（即<code>Rerank</code>），重新调整召回文本的顺序。</p><p>为了更好地理解上述召回算法的优缺点，下面结合具体的实例来进行阐述。</p><ul><li><code>query</code>: "NEDO"的全称是什么？</li></ul><figure><img src="https://s2.loli.net/2024/01/20/Uh1FGYJT26ONd3t.png"alt="Embedding召回优于BM25" /><figcaption aria-hidden="true">Embedding召回优于BM25</figcaption></figure><p>在这个例子中，Embedding召回结果优于BM25，BM25召回结果虽然在top_3结果中存在，但排名第三，排在首位的是不相关的文本，而Embedding由于文本相似度的优势，将正确结果放在了首位。</p><ul><li><code>query</code>: 日本半导体产品的主要应用领域是什么？</li></ul><figure><img src="https://s2.loli.net/2024/01/20/BSO19sKko8gclem.png"alt="BM25召回优于Embedding" /><figcaption aria-hidden="true">BM25召回优于Embedding</figcaption></figure><p>在这个例子中，BM25召回结果优于Embedding。</p><ul><li><code>query</code>:《美日半导体协议》对日本半导体市场有何影响？</li></ul><figure><img src="https://s2.loli.net/2024/01/20/wHU4LP7iRXfQ5CW.png"alt="ensemble算法提升了排名" /><figcaption aria-hidden="true">ensemble算法提升了排名</figcaption></figure><p>在这个例子中，正确文本在BM25算法召回结果中排名第二，在Embedding算法中排第三，混合搜索排名第一，这里体现了混合搜索的优越性。</p><ul><li><code>query</code>: 80年代日本电子产业的辉煌表现在哪些方面？</li></ul><figure><img src="https://s2.loli.net/2024/01/20/6S1wBXv7caZDCkd.png"alt="Rerank的优越性" /><figcaption aria-hidden="true">Rerank的优越性</figcaption></figure><p>在这个例子中，不管是BM25,Embedding,还是Ensemble，都没能将正确文本排在第一位，而经过Rerank以后，正确文本排在第一位，这里体现了Rerank算法的优势。</p><h2 id="rag中的提升方法">RAG中的提升方法</h2><p>经过上述Retrieve算法的对比，我们对不同的Retrieve算法有了深入的了解。然而，Retrieve算法并不能帮助我们解决所有问题，比如上述的badcase，就是用各种Retrieve算法都无法找回的。</p><p>那么，还有其它优化手段吗？在RAG框架中，还存在一系列的优化手段，这在<code>Langchain</code>和<code>Llmma-Index</code>中都给出了各种优化手段。本文将尝试两种优化手段：QueryRewrite和HyDE.</p><h3 id="query-rewrite">Query Rewrite</h3><p>业界对于QueryRewrite，有着相当完善且复杂的流程，因为它对于后续的召回结果有直接影响。本文借助大模型对query进行直接改写，看看是否有召回效果提升。</p><p>比如：</p><ul><li>原始query: 半导体制造设备市场美、日、荷各占多少份额？</li><li>改写后query：美国、日本和荷兰在半导体制造设备市场的份额分别是多少？</li></ul><p>改写后的query在BM25和Embedding的top3召回结果中都能找到。该query对应的正确文本为：</p><blockquote><p>全球半导体设备制造领域，美国、日本和荷兰控制着全球370亿美元半导体制造设备市场的90％以上。其中，美国的半导体制造设备（SME）产业占全球产量的近50%，日本约占30%，荷兰约占17％%。更具体地，以光刻机为例，EUV光刻工序其实有众多日本厂商的参与，如东京电子生产的EUV涂覆显影设备，占据100%的市场份额，LasertecCorp.也是全球唯一的测试机制造商。另外还有EUV光刻胶，据南大光电在3月发布的相关报告中披露，全球仅有日本厂商研发出了EUV光刻胶。</p></blockquote><p>从中我们可以看到，在改写后的query中，美国、日本、荷兰这三个词发挥了重要作用，因此，<strong>query改写对于含有缩写的query有一定的召回效果改善</strong>。</p><h3 id="hyde">HyDE</h3><p>HyDE（全称Hypothetical DocumentEmbeddings）是RAG中的一种技术，它基于一个假设：相较于直接查询，通过大语言模型(LLM) 生成的答案在嵌入空间中可能更为接近。HyDE首先响应查询生成一个假设性文档（答案），然后将其嵌入，从而提高搜索的效果。</p><p>比如：</p><ul><li>原始query: 美日半导体协议是由哪两部门签署的？</li><li>加上回答后的query:美日半导体协议是由哪两部门签署的？美日半导体协议是由美国商务部和日本经济产业省签署的。</li></ul><p>加上回答后的query使用BM25算法可以找回正确文本，且排名第一位，而Embedding算法仍无法召回。</p><p>正确文本为：</p><blockquote><p>1985年6月，美国半导体产业贸易保护的调子开始升高。美国半导体工业协会向国会递交一份正式的“301条款”文本，要求美国政府制止日本公司的倾销行为。民意调查显示，68%的美国人认为日本是美国最大的威胁。在舆论的引导和半导体工业协会的推动下，美国政府将信息产业定为可以动用国家安全借口进行保护的新兴战略产业，半导体产业成为美日贸易战的焦点。1985年10月，美国商务部出面指控日本公司倾销256K和1M内存。一年后，日本通产省被迫与美国商务部签署第一次《美日半导体协议》。</p></blockquote><p>从中可以看出，大模型的回答是正确的，美国商务部这个关键词发挥了重要作用，因此，HyDE对于特定的query有召回效果提升。</p><h2 id="总结">总结</h2><p>本文结合具体的例子，对于不同的Retrieve算法的效果优劣有了比较清晰的认识，事实上，这也是笔者一直在NLP领域努力的一个方向：简单而深刻。</p><p>同时，还介绍了两种RAG框架中的优化方法，或许可以在工作中有应用价值。后续笔者将继续关注RAG框架，欢迎大家关注。</p><p>本文代码及数据已开源至Github: <ahref="https://github.com/percent4/embedding_rerank_retrieval">https://github.com/percent4/embedding_rerank_retrieval</a>。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486199&amp;idx=1&amp;sn=f24175b05bdf5bc6dd42efed4d5acae8&amp;chksm=fcb9b367cbce3a711fabd1a56bb5b9d803aba2f42964b4e1f9a4dc6e2174f0952ddb9e1d4c55&amp;token=823710334&amp;lang=zh_CN#rd">NLP（八十二）RAG框架中的Retrieve算法评估</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486225&amp;idx=1&amp;sn=235eb787e2034f24554d8e997dbb4718&amp;chksm=fcb9b281cbce3b9761342ebadbe001747ce2e74d84340f78b0e12c4d4c6aed7a7817f246c845&amp;token=823710334&amp;lang=zh_CN#rd">NLP（八十三）RAG框架中的Rerank算法评估</a></li><li>引入混合检索（Hybrid Search）和重排序（Rerank）改进 RAG系统召回效果: <ahref="https://mp.weixin.qq.com/s/_Rmafm7tI3JWMNqoqFX_FQ">https://mp.weixin.qq.com/s/_Rmafm7tI3JWMNqoqFX_FQ</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RAG</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>vLLM入门（一）初始vLLM</title>
    <link href="/vLLM%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E5%88%9D%E5%A7%8BvLLM/"/>
    <url>/vLLM%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E5%88%9D%E5%A7%8BvLLM/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍大模型部署工具vLLM及其使用方法。</p></blockquote><h2 id="介绍与安装">介绍与安装</h2><p><code>vLLM</code>是伯克利大学LMSYS组织开源的大语言模型高速推理框架，旨在极大地提升实时场景下的语言模型服务的吞吐与内存使用效率。<code>vLLM</code>是一个快速且易于使用的库，用于LLM 推理和服务，可以和HuggingFace无缝集成。vLLM利用了全新的注意力算法「PagedAttention」，有效地管理注意力键和值。</p><p><imgsrc="https://blog.vllm.ai/assets/logos/vllm-logo-text-light.png" /></p><p>在吞吐量方面，vLLM的性能比HuggingFace Transformers(HF)高出 24倍，文本生成推理（TGI）高出3.5倍。</p><p><imgsrc="https://blog.vllm.ai/assets/figures/perf_a100_n1_light.png" /></p><p>安装命令：</p><blockquote><p>pip3 install vllm</p></blockquote><p>本文使用的Python第三方模块的版本如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">vllm==0.2.7<br>transformers==4.36.2<br>requests==2.31.0<br>gradio==4.14.0<br></code></pre></td></tr></table></figure><h2 id="vllm初步使用">vLLM初步使用</h2><h3 id="线下批量推理">线下批量推理</h3><p>线下批量推理：为输入的prompts列表，使用vLLM生成答案</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="hljs-string">&quot;6,7&quot;</span><br><br><span class="hljs-keyword">from</span> vllm <span class="hljs-keyword">import</span> LLM, SamplingParams<br><br>llm = LLM(<span class="hljs-string">&#x27;/data-ai/model/llama2/llama2_hf/Llama-2-13b-chat-hf&#x27;</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">INFO 01-18 08:13:26 llm_engine.py:70] Initializing an LLM engine with config: model=&#39;/data-ai/model/llama2/llama2_hf/Llama-2-13b-chat-hf&#39;, tokenizer=&#39;/data-ai/model/llama2/llama2_hf/Llama-2-13b-chat-hf&#39;, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, enforce_eager=False, seed=0)INFO 01-18 08:13:37 llm_engine.py:275] # GPU blocks: 3418, # CPU blocks: 327INFO 01-18 08:13:39 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set &#39;enforce_eager=True&#39; or use &#39;--enforce-eager&#39; in the CLI.INFO 01-18 08:13:39 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.INFO 01-18 08:13:44 model_runner.py:547] Graph capturing finished in 5 secs.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">prompts = [<br>    <span class="hljs-string">&quot;Hello, my name is&quot;</span>,<br>    <span class="hljs-string">&quot;The president of the United States is&quot;</span>,<br>    <span class="hljs-string">&quot;The capital of France is&quot;</span>,<br>    <span class="hljs-string">&quot;The future of AI is&quot;</span>,<br>]<br>sampling_params = SamplingParams(temperature=<span class="hljs-number">0.8</span>, top_p=<span class="hljs-number">0.95</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">outputs = llm.generate(prompts, sampling_params)<br><br><span class="hljs-comment"># Print the outputs.</span><br><span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:<br>    prompt = output.prompt<br>    generated_text = output.outputs[<span class="hljs-number">0</span>].text<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Prompt: <span class="hljs-subst">&#123;prompt!r&#125;</span>, Generated text: <span class="hljs-subst">&#123;generated_text!r&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Processed prompts: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00&lt;00:00, 11.76it/s]Prompt: &#39;Hello, my name is&#39;, Generated text: &quot; Sherry and I&#39;m a stay at home mom of three beautiful children.&quot;Prompt: &#39;The president of the United States is&#39;, Generated text: &#39; one of the most powerful people in the world, and yet, many people do&#39;Prompt: &#39;The capital of France is&#39;, Generated text: &#39; Paris. This is a fact that is well known to most people, but there&#39;Prompt: &#39;The future of AI is&#39;, Generated text: &#39; likely to be shaped by a combination of technological advancements and soci&#39;</code></pre><h3 id="api-server服务">API Server服务</h3><p>vLLM可以部署为API服务，web框架使用<code>FastAPI</code>。API服务使用<code>AsyncLLMEngine</code>类来支持异步调用。</p><p>使用命令 <code>python -m vllm.entrypoints.api_server --help</code>可查看支持的脚本参数。</p><p>API服务启动命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">CUDA_VISIBLE_DEVICES=6,7 python -m vllm.entrypoints.api_server --model /data-ai/model/llama2/llama2_hf/Llama-2-13b-chat-hf<br></code></pre></td></tr></table></figure><p>输入:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/generate \<br>    -d <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">        &quot;prompt&quot;: &quot;San Francisco is a&quot;,</span><br><span class="hljs-string">        &quot;use_beam_search&quot;: true,</span><br><span class="hljs-string">        &quot;n&quot;: 4,</span><br><span class="hljs-string">        &quot;temperature&quot;: 0</span><br><span class="hljs-string">    &#125;&#x27;</span><br></code></pre></td></tr></table></figure><p>输出:</p><figure class="highlight smalltalk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">&#123;<br>    <span class="hljs-comment">&quot;text&quot;</span>: [<br>        <span class="hljs-comment">&quot;San Francisco is a city of neighborhoods, each with its own unique character and charm. Here are&quot;</span>,<br>        <span class="hljs-comment">&quot;San Francisco is a city in California that is known for its iconic landmarks, vibrant&quot;</span>,<br>        <span class="hljs-comment">&quot;San Francisco is a city of neighborhoods, each with its own unique character and charm. From the&quot;</span>,<br>        <span class="hljs-comment">&quot;San Francisco is a city in California that is known for its vibrant culture, diverse neighborhoods&quot;</span><br>    ]<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="openai风格的api服务">OpenAI风格的API服务</h3><p>启动命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">CUDA_VISIBLE_DEVICES=6,7 python -m vllm.entrypoints.openai.api_server --model /data-ai/model/llama2/llama2_hf/Llama-2-13b-chat-hf --served-model-name llama-2-13b-chat-hf<br></code></pre></td></tr></table></figure><p>还可指定对话模板（chat-template）。</p><p><strong>查看模型</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/models<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;list&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;data&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;llama-2-13b-chat-hf&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;model&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1705568412</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;owned_by&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;vllm&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;root&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;llama-2-13b-chat-hf&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;parent&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;permission&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;modelperm-d7ca4aa0eee44eb4a50e37eba06e520d&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;model_permission&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1705568412</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_create_engine&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_sampling&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_logprobs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_search_indices&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_view&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_fine_tuning&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;organization&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;*&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;group&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;is_blocking&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p><strong>text completion</strong></p><p>输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/completions \<br>    -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \<br>    -d <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">        &quot;model&quot;: &quot;llama-2-13b-chat-hf&quot;,</span><br><span class="hljs-string">        &quot;prompt&quot;: &quot;San Francisco is a&quot;,</span><br><span class="hljs-string">        &quot;max_tokens&quot;: 7,</span><br><span class="hljs-string">        &quot;temperature&quot;: 0</span><br><span class="hljs-string">    &#125;&#x27;</span> | jq .<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cmpl-d1ba6b9f1551443e87d80258a3bedad1&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text_completion&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">19687093</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;llama-2-13b-chat-hf&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;choices&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;index&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot; city that is known for its v&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;logprobs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;finish_reason&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;length&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;usage&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;prompt_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">5</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;total_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">12</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;completion_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">7</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p><strong>chat completion</strong></p><p>输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/chat/completions \<br>    -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \<br>    -d <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">        &quot;model&quot;: &quot;llama-2-13b-chat-hf&quot;,</span><br><span class="hljs-string">        &quot;messages&quot;: [</span><br><span class="hljs-string">            &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;&#125;,</span><br><span class="hljs-string">            &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Who won the world series in 2020?&quot;&#125;</span><br><span class="hljs-string">        ]</span><br><span class="hljs-string">    &#125;&#x27;</span> | jq .<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight smalltalk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">&#123;<br>  <span class="hljs-comment">&quot;id&quot;</span>: <span class="hljs-comment">&quot;cmpl-94fc8bc170be4c29982a08aa6f01e298&quot;</span>,<br>  <span class="hljs-comment">&quot;object&quot;</span>: <span class="hljs-comment">&quot;chat.completion&quot;</span>,<br>  <span class="hljs-comment">&quot;created&quot;</span>: <span class="hljs-number">19687353</span>,<br>  <span class="hljs-comment">&quot;model&quot;</span>: <span class="hljs-comment">&quot;llama-2-13b-chat-hf&quot;</span>,<br>  <span class="hljs-comment">&quot;choices&quot;</span>: [<br>    &#123;<br>      <span class="hljs-comment">&quot;index&quot;</span>: <span class="hljs-number">0</span>,<br>      <span class="hljs-comment">&quot;message&quot;</span>: &#123;<br>        <span class="hljs-comment">&quot;role&quot;</span>: <span class="hljs-comment">&quot;assistant&quot;</span>,<br>        <span class="hljs-comment">&quot;content&quot;</span>: <span class="hljs-comment">&quot;  Hello! I&#x27;m happy to help! The Washington Nationals won the World Series in 2020. They defeated the Houston Astros in Game 7 of the series, which was played on October 30, 2020.&quot;</span><br>      &#125;,<br>      <span class="hljs-comment">&quot;finish_reason&quot;</span>: <span class="hljs-comment">&quot;stop&quot;</span><br>    &#125;<br>  ],<br>  <span class="hljs-comment">&quot;usage&quot;</span>: &#123;<br>    <span class="hljs-comment">&quot;prompt_tokens&quot;</span>: <span class="hljs-number">40</span>,<br>    <span class="hljs-comment">&quot;total_tokens&quot;</span>: <span class="hljs-number">95</span>,<br>    <span class="hljs-comment">&quot;completion_tokens&quot;</span>: <span class="hljs-number">55</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="vllm实战">vLLM实战</h2><h3 id="大模型简单问答">大模型简单问答</h3><p>vLLM暂不支持同时部署多个大模型，因此，笔者采用<code>一次部署一个模型，部署多次</code>的方法来实现部署多个大模型，这里采用<code>llama-2-13b-chat-hf</code>和<code>Baichuan2-13B-Chat</code>.</p><p>模型部署的命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">CUDA_VISIBLE_DEVICES=6 python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --port 50072 --model /data-ai/model/llama2/llama2_hf/Llama-2-13b-chat-hf --served-model-name llama-2-13b-chat-hf<br><br>CUDA_VISIBLE_DEVICES=7 python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --port 50073 --model /data-ai/model/baichuan2/Baichuan2-13B-Chat --served-model-name Baichuan2-13B-Chat --trust-remote-code --chat-template /data-ai/usr/code/template_baichuan.jinja<br></code></pre></td></tr></table></figure><p>其中，<code>template_baichuan.jinja</code>（对话模板）采用vLLM在github官方网站中的examples文件夹下的同名文件。</p><p>使用Gradio来构建页面，主要实现大模型问答功能，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: gradio_for_llm.py</span><br><span class="hljs-comment"># @time: 2024/1/19 13:30</span><br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">import</span> requests<br><br>models = [<span class="hljs-string">&#x27;llama-2-13b-chat-hf&#x27;</span>, <span class="hljs-string">&#x27;Baichuan2-13B-Chat&#x27;</span>]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">completion</span>(<span class="hljs-params">question</span>):<br>    model_url_dict = &#123;models[<span class="hljs-number">0</span>]: <span class="hljs-string">&quot;http://localhost:50072/v1/chat/completions&quot;</span>,<br>                      models[<span class="hljs-number">1</span>]: <span class="hljs-string">&quot;http://localhost:50073/v1/chat/completions&quot;</span>,<br>                      &#125;<br>    answers = []<br>    <span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> models:<br>        headers = &#123;<span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>&#125;<br><br>        json_data = &#123;<br>            <span class="hljs-string">&#x27;model&#x27;</span>: model,<br>            <span class="hljs-string">&#x27;messages&#x27;</span>: [<br>                &#123;<br>                    <span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;system&#x27;</span>,<br>                    <span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-string">&#x27;You are a helpful assistant.&#x27;</span><br>                &#125;,<br>                &#123;<br>                    <span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;user&#x27;</span>,<br>                    <span class="hljs-string">&#x27;content&#x27;</span>: question<br>                &#125;,<br>            ],<br>        &#125;<br><br>        response = requests.post(model_url_dict[model], headers=headers, json=json_data)<br>        answer = response.json()[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>][<span class="hljs-string">&quot;content&quot;</span>]<br>        answers.append(answer)<br>    <span class="hljs-keyword">return</span> answers<br><br><br>demo = gr.Interface(<br>    fn=completion,<br>    inputs=gr.Textbox(lines=<span class="hljs-number">5</span>, placeholder=<span class="hljs-string">&quot;input your question&quot;</span>, label=<span class="hljs-string">&quot;question&quot;</span>),<br>    outputs=[gr.Textbox(lines=<span class="hljs-number">5</span>, placeholder=<span class="hljs-string">&quot;answer&quot;</span>, label=models[<span class="hljs-number">0</span>]),<br>             gr.Textbox(lines=<span class="hljs-number">5</span>, placeholder=<span class="hljs-string">&quot;answer&quot;</span>, label=models[<span class="hljs-number">1</span>])]<br>)<br><br>demo.launch(server_name=<span class="hljs-string">&#x27;0.0.0.0&#x27;</span>, share=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>演示例子：</p><figure><img src="https://s2.loli.net/2024/01/19/zKZRNLJbhoCdwap.png"alt="大模型可视化问答" /><figcaption aria-hidden="true">大模型可视化问答</figcaption></figure><h3 id="大模型输出tps">大模型输出TPS</h3><p>衡量大模型部署工具的指标之一为TPS（Token PerSecond），即每秒模型输出的token数量。</p><p>我们以<code>llama-2-13b-chat-hf</code>，测试数据集参考网站中的问题集：<ahref="https://modal.com/docs/examples/vllm_inference">https://modal.com/docs/examples/vllm_inference</a>，一共59个问题。</p><p>Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: gradio_for_throughput.py</span><br><span class="hljs-comment"># @time: 2024/1/19 16:05</span><br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> time<br><br>questions = [<br>        <span class="hljs-comment"># Coding questions</span><br>        <span class="hljs-string">&quot;Implement a Python function to compute the Fibonacci numbers.&quot;</span>,<br>        <span class="hljs-string">&quot;Write a Rust function that performs binary exponentiation.&quot;</span>,<br>        <span class="hljs-string">&quot;How do I allocate memory in C?&quot;</span>,<br>        <span class="hljs-string">&quot;What are the differences between Javascript and Python?&quot;</span>,<br>        <span class="hljs-string">&quot;How do I find invalid indices in Postgres?&quot;</span>,<br>        <span class="hljs-string">&quot;How can you implement a LRU (Least Recently Used) cache in Python?&quot;</span>,<br>        <span class="hljs-string">&quot;What approach would you use to detect and prevent race conditions in a multithreaded application?&quot;</span>,<br>        <span class="hljs-string">&quot;Can you explain how a decision tree algorithm works in machine learning?&quot;</span>,<br>        <span class="hljs-string">&quot;How would you design a simple key-value store database from scratch?&quot;</span>,<br>        <span class="hljs-string">&quot;How do you handle deadlock situations in concurrent programming?&quot;</span>,<br>        <span class="hljs-string">&quot;What is the logic behind the A* search algorithm, and where is it used?&quot;</span>,<br>        <span class="hljs-string">&quot;How can you design an efficient autocomplete system?&quot;</span>,<br>        <span class="hljs-string">&quot;What approach would you take to design a secure session management system in a web application?&quot;</span>,<br>        <span class="hljs-string">&quot;How would you handle collision in a hash table?&quot;</span>,<br>        <span class="hljs-string">&quot;How can you implement a load balancer for a distributed system?&quot;</span>,<br>        <span class="hljs-comment"># Literature</span><br>        <span class="hljs-string">&quot;What is the fable involving a fox and grapes?&quot;</span>,<br>        <span class="hljs-string">&quot;Write a story in the style of James Joyce about a trip to the Australian outback in 2083, to see robots in the beautiful desert.&quot;</span>,<br>        <span class="hljs-string">&quot;Who does Harry turn into a balloon?&quot;</span>,<br>        <span class="hljs-string">&quot;Write a tale about a time-traveling historian who&#x27;s determined to witness the most significant events in human history.&quot;</span>,<br>        <span class="hljs-string">&quot;Describe a day in the life of a secret agent who&#x27;s also a full-time parent.&quot;</span>,<br>        <span class="hljs-string">&quot;Create a story about a detective who can communicate with animals.&quot;</span>,<br>        <span class="hljs-string">&quot;What is the most unusual thing about living in a city floating in the clouds?&quot;</span>,<br>        <span class="hljs-string">&quot;In a world where dreams are shared, what happens when a nightmare invades a peaceful dream?&quot;</span>,<br>        <span class="hljs-string">&quot;Describe the adventure of a lifetime for a group of friends who found a map leading to a parallel universe.&quot;</span>,<br>        <span class="hljs-string">&quot;Tell a story about a musician who discovers that their music has magical powers.&quot;</span>,<br>        <span class="hljs-string">&quot;In a world where people age backwards, describe the life of a 5-year-old man.&quot;</span>,<br>        <span class="hljs-string">&quot;Create a tale about a painter whose artwork comes to life every night.&quot;</span>,<br>        <span class="hljs-string">&quot;What happens when a poet&#x27;s verses start to predict future events?&quot;</span>,<br>        <span class="hljs-string">&quot;Imagine a world where books can talk. How does a librarian handle them?&quot;</span>,<br>        <span class="hljs-string">&quot;Tell a story about an astronaut who discovered a planet populated by plants.&quot;</span>,<br>        <span class="hljs-string">&quot;Describe the journey of a letter traveling through the most sophisticated postal service ever.&quot;</span>,<br>        <span class="hljs-string">&quot;Write a tale about a chef whose food can evoke memories from the eater&#x27;s past.&quot;</span>,<br>        <span class="hljs-comment"># History</span><br>        <span class="hljs-string">&quot;What were the major contributing factors to the fall of the Roman Empire?&quot;</span>,<br>        <span class="hljs-string">&quot;How did the invention of the printing press revolutionize European society?&quot;</span>,<br>        <span class="hljs-string">&quot;What are the effects of quantitative easing?&quot;</span>,<br>        <span class="hljs-string">&quot;How did the Greek philosophers influence economic thought in the ancient world?&quot;</span>,<br>        <span class="hljs-string">&quot;What were the economic and philosophical factors that led to the fall of the Soviet Union?&quot;</span>,<br>        <span class="hljs-string">&quot;How did decolonization in the 20th century change the geopolitical map?&quot;</span>,<br>        <span class="hljs-string">&quot;What was the influence of the Khmer Empire on Southeast Asia&#x27;s history and culture?&quot;</span>,<br>        <span class="hljs-comment"># Thoughtfulness</span><br>        <span class="hljs-string">&quot;Describe the city of the future, considering advances in technology, environmental changes, and societal shifts.&quot;</span>,<br>        <span class="hljs-string">&quot;In a dystopian future where water is the most valuable commodity, how would society function?&quot;</span>,<br>        <span class="hljs-string">&quot;If a scientist discovers immortality, how could this impact society, economy, and the environment?&quot;</span>,<br>        <span class="hljs-string">&quot;What could be the potential implications of contact with an advanced alien civilization?&quot;</span>,<br>        <span class="hljs-comment"># Math</span><br>        <span class="hljs-string">&quot;What is the product of 9 and 8?&quot;</span>,<br>        <span class="hljs-string">&quot;If a train travels 120 kilometers in 2 hours, what is its average speed?&quot;</span>,<br>        <span class="hljs-string">&quot;Think through this step by step. If the sequence a_n is defined by a_1 = 3, a_2 = 5, and a_n = a_(n-1) + a_(n-2) for n &gt; 2, find a_6.&quot;</span>,<br>        <span class="hljs-string">&quot;Think through this step by step. Calculate the sum of an arithmetic series with first term 3, last term 35, and total terms 11.&quot;</span>,<br>        <span class="hljs-string">&quot;Think through this step by step. What is the area of a triangle with vertices at the points (1,2), (3,-4), and (-2,5)?&quot;</span>,<br>        <span class="hljs-string">&quot;Think through this step by step. Solve the following system of linear equations: 3x + 2y = 14, 5x - y = 15.&quot;</span>,<br>        <span class="hljs-comment"># Facts</span><br>        <span class="hljs-string">&quot;Who was Emperor Norton I, and what was his significance in San Francisco&#x27;s history?&quot;</span>,<br>        <span class="hljs-string">&quot;What is the Voynich manuscript, and why has it perplexed scholars for centuries?&quot;</span>,<br>        <span class="hljs-string">&quot;What was Project A119 and what were its objectives?&quot;</span>,<br>        <span class="hljs-string">&quot;What is the &#x27;Dyatlov Pass incident&#x27; and why does it remain a mystery?&quot;</span>,<br>        <span class="hljs-string">&quot;What is the &#x27;Emu War&#x27; that took place in Australia in the 1930s?&quot;</span>,<br>        <span class="hljs-string">&quot;What is the &#x27;Phantom Time Hypothesis&#x27; proposed by Heribert Illig?&quot;</span>,<br>        <span class="hljs-string">&quot;Who was the &#x27;Green Children of Woolpit&#x27; as per 12th-century English legend?&quot;</span>,<br>        <span class="hljs-string">&quot;What are &#x27;zombie stars&#x27; in the context of astronomy?&quot;</span>,<br>        <span class="hljs-string">&quot;Who were the &#x27;Dog-Headed Saint&#x27; and the &#x27;Lion-Faced Saint&#x27; in medieval Christian traditions?&quot;</span>,<br>        <span class="hljs-string">&quot;What is the story of the &#x27;Globsters&#x27;, unidentified organic masses washed up on the shores?&quot;</span>,<br>    ]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat_completion</span>(<span class="hljs-params">question</span>):<br>    url = <span class="hljs-string">&quot;http://localhost:50072/v1/chat/completions&quot;</span><br><br>    headers = &#123;<span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>&#125;<br><br>    json_data = &#123;<br>        <span class="hljs-string">&#x27;model&#x27;</span>: <span class="hljs-string">&quot;llama-2-13b-chat-hf&quot;</span>,<br>        <span class="hljs-string">&#x27;messages&#x27;</span>: [<br>            &#123;<br>                <span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;system&#x27;</span>,<br>                <span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-string">&#x27;You are a helpful assistant.&#x27;</span><br>            &#125;,<br>            &#123;<br>                <span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;user&#x27;</span>,<br>                <span class="hljs-string">&#x27;content&#x27;</span>: question<br>            &#125;,<br>        ],<br>    &#125;<br><br>    response = requests.post(url, headers=headers, json=json_data)<br>    answer = response.json()[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>][<span class="hljs-string">&quot;content&quot;</span>]<br>    output_tokens = response.json()[<span class="hljs-string">&quot;usage&quot;</span>][<span class="hljs-string">&quot;completion_tokens&quot;</span>]<br>    <span class="hljs-keyword">return</span> answer, output_tokens<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">slowly_reverse</span>(<span class="hljs-params">texts, progress=gr.Progress(<span class="hljs-params"></span>)</span>):<br>    total_token_cnt = <span class="hljs-number">0</span><br>    progress(<span class="hljs-number">0</span>, desc=<span class="hljs-string">&quot;starting...&quot;</span>)<br>    q_list = texts.split(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>    s_time = time.time()<br>    data_list = []<br>    <span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> progress.tqdm(q_list, desc=<span class="hljs-string">f&quot;generating...&quot;</span>):<br>        answer, output_token = chat_completion(q)<br>        total_token_cnt += output_token<br>        data_list.append([q, answer[:<span class="hljs-number">50</span>], total_token_cnt/(time.time() - s_time)])<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;total_token_cnt/(time.time() - s_time)&#125;</span> TPS&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> data_list<br><br><br>demo = gr.Interface(<br>    fn=slowly_reverse,<br>    <span class="hljs-comment"># 自定义输入框</span><br>    inputs=gr.Textbox(value=<span class="hljs-string">&#x27;\n&#x27;</span>.join(questions), label=<span class="hljs-string">&quot;questions&quot;</span>),<br>    <span class="hljs-comment"># 设置输出组件</span><br>    outputs=gr.DataFrame(label=<span class="hljs-string">&#x27;Table&#x27;</span>, headers=[<span class="hljs-string">&#x27;question&#x27;</span>, <span class="hljs-string">&#x27;answer&#x27;</span>, <span class="hljs-string">&#x27;TPS&#x27;</span>], interactive=<span class="hljs-literal">True</span>, wrap=<span class="hljs-literal">True</span>)<br>)<br><br>demo.queue().launch(server_name=<span class="hljs-string">&#x27;0.0.0.0&#x27;</span>, share=<span class="hljs-literal">True</span>)<br><br></code></pre></td></tr></table></figure><p>输出的TPS统计如下：</p><figure><img src="https://s2.loli.net/2024/01/19/7a9Um6EzKXhtkpS.png"alt="vLLM部署大模型的吞吐量的简单实验" /><figcaptionaria-hidden="true">vLLM部署大模型的吞吐量的简单实验</figcaption></figure><p>本次实验共耗时约639秒，最终的TPS为49.4。</p><p>以上仅是TPS指标的一个演示例子，事实上，vLLM部署LLAMA-2模型的TPS应该远高于这个数值，这与我们使用vLLM的方式有关，比如GPU数量，worker数量，客户端请求方式等，这些都是影响因素，待笔者后续更新。</p><h2 id="总结">总结</h2><p>本文介绍了大模型部署工具vLLM，并给出了其三种不同的部署方式，在文章最后，介绍了笔者对于vLLM的实战。后续，笔者将会对vLLM的推理效率进行深入的实验。</p><p>感谢阅读~</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>vLLM documentation: <ahref="https://docs.vllm.ai/en/latest/index.html">https://docs.vllm.ai/en/latest/index.html</a></li><li>VLLM推理流程梳理: <ahref="https://blog.csdn.net/just_sort/article/details/132115735">https://blog.csdn.net/just_sort/article/details/132115735</a></li><li>vllm github: <ahref="https://github.com/vllm-project/vllm">https://github.com/vllm-project/vllm</a></li><li>modal vllm inference: <ahref="https://modal.com/docs/examples/vllm_inference">https://modal.com/docs/examples/vllm_inference</a></li></ol><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>vLLM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（八十三）RAG框架中的Rerank算法评估</title>
    <link href="/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%B8%89%EF%BC%89RAG%E6%A1%86%E6%9E%B6%E4%B8%AD%E7%9A%84Rerank%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0/"/>
    <url>/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%B8%89%EF%BC%89RAG%E6%A1%86%E6%9E%B6%E4%B8%AD%E7%9A%84Rerank%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将详细介绍RAG框架中的两种Rerank模型的评估实验：bge-reranker和CohereRerank。</p></blockquote><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486199&amp;idx=1&amp;sn=f24175b05bdf5bc6dd42efed4d5acae8&amp;chksm=fcb9b367cbce3a711fabd1a56bb5b9d803aba2f42964b4e1f9a4dc6e2174f0952ddb9e1d4c55&amp;token=1977141018&amp;lang=zh_CN#rd">NLP（八十二）RAG框架中的Retrieve算法评估</a>中，我们在评估Retrieve算法的时候，发现在EnsembleSearch阶段之后加入Rerank算法能有效提升检索效果，其中top_3的HitRate指标增加约4%。</p><p>因此，本文将深入Rerank算法对比，主要对比bge-reranker和CohereRerank两种算法，分析它们对于提升检索效果的作用。</p><h2 id="为什么需要重排序">为什么需要重排序？</h2><p><strong>混合检索</strong>通过融合多种检索技术的优势，能够提升检索的召回效果。然而，这种方法在应用不同的检索模式时，必须对结果进行整合和标准化处理。标准化是指将数据调整到一致的标准范围或格式，以便于更有效地进行比较、分析和处理。在完成这些步骤后，这些数据将整合并提供给大型模型进行处理。为了实现这一过程，我们需要引入一个评分系统，即<code>重排序模型（Rerank Model）</code>，它有助于进一步优化和精炼检索结果。</p><p><code>Rerank模型</code>通过对候选文档列表进行重新排序，以提高其与用户查询语义的匹配度，从而优化排序结果。该模型的核心在于评估用户问题与每个候选文档之间的关联程度，并基于这种相关性给文档排序，使得与用户问题更为相关的文档排在更前的位置。这种模型的实现通常涉及计算相关性分数，然后按照这些分数从高到低排列文档。市场上已有一些流行的重排序模型，例如<strong>Cohere rerank</strong>、<strong>bge-reranker</strong>等，它们在不同的应用场景中表现出了优异的性能。</p><figure><img src="https://s2.loli.net/2024/04/26/k1YMj3gLNISKo65.png"alt="rerank in Cohere" /><figcaption aria-hidden="true">rerank in Cohere</figcaption></figure><h2 id="bge-reranker模型">BGE-Reranker模型</h2><p><strong>CohereRerank</strong>模型目前闭源，对外提供API，普通账号提供免费使用额度，生产环境最好使用付费服务，因此，本文不再过多介绍，关于这块的文章可参考其官网博客：<ahref="https://txt.cohere.com/rerank/">https://txt.cohere.com/rerank/</a>.</p><p><strong>bge-reranker</strong>是<code>BAAI</code>（北京智源人工智能研究院）发布的系列模型之一，包括Embedding、Rerank系列模型等。<code>bge-reranker</code>模型在HuggingFace上开源，有<code>base</code>、<code>large</code>两个版本模型。</p><p>借助<code>FlagEmbedding</code>，我们以BAAI/bge-reranker-base模型为例，使用FastAPI封装成HTTP服务，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># !/usr/bin/env python</span><br><span class="hljs-comment"># encoding: utf-8</span><br><span class="hljs-keyword">import</span> uvicorn<br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI<br><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel<br><span class="hljs-keyword">from</span> operator <span class="hljs-keyword">import</span> itemgetter<br><span class="hljs-keyword">from</span> FlagEmbedding <span class="hljs-keyword">import</span> FlagReranker<br><br><br>app = FastAPI()<br><br>reranker = FlagReranker(<span class="hljs-string">&#x27;/data_2/models/bge-reranker-base/models--BAAI--bge-reranker-base/blobs&#x27;</span>, use_fp16=<span class="hljs-literal">True</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">QuerySuite</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    query: <span class="hljs-built_in">str</span><br>    passages: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]<br>    top_k: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span><br><br><br><span class="hljs-meta">@ app.post(<span class="hljs-params"><span class="hljs-string">&#x27;/bge_base_rerank&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rerank</span>(<span class="hljs-params">query_suite: QuerySuite</span>):<br>    scores = reranker.compute_score([[query_suite.query, passage] <span class="hljs-keyword">for</span> passage <span class="hljs-keyword">in</span> query_suite.passages])<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(scores, <span class="hljs-built_in">list</span>):<br>        similarity_dict = &#123;passage: scores[i] <span class="hljs-keyword">for</span> i, passage <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(query_suite.passages)&#125;<br>    <span class="hljs-keyword">else</span>:<br>        similarity_dict = &#123;passage: scores <span class="hljs-keyword">for</span> i, passage <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(query_suite.passages)&#125;<br>    sorted_similarity_dict = <span class="hljs-built_in">sorted</span>(similarity_dict.items(), key=itemgetter(<span class="hljs-number">1</span>), reverse=<span class="hljs-literal">True</span>)<br>    result = &#123;&#125;<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(query_suite.top_k):<br>        result[sorted_similarity_dict[j][<span class="hljs-number">0</span>]] = sorted_similarity_dict[j][<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> result<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    uvicorn.run(app, host=<span class="hljs-string">&#x27;0.0.0.0&#x27;</span>, port=<span class="hljs-number">50072</span>)<br></code></pre></td></tr></table></figure><p>计算"上海天气"与"北京美食"、"上海气候"的Rerank相关性分数，请求如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl --location <span class="hljs-string">&#x27;http://localhost:50072/bge_base_rerank&#x27;</span> \<br>--header <span class="hljs-string">&#x27;Content-Type: application/json&#x27;</span> \<br>--data <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">    &quot;query&quot;: &quot;上海天气&quot;,</span><br><span class="hljs-string">    &quot;passages&quot;: [&quot;北京美食&quot;, &quot;上海气候&quot;],</span><br><span class="hljs-string">    &quot;top_k&quot;: 2</span><br><span class="hljs-string">&#125;&#x27;</span><br></code></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;上海气候&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">6.24609375</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;北京美食&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">-7.29296875</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h2 id="评估实验">评估实验</h2><p>我们使用<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486199&amp;idx=1&amp;sn=f24175b05bdf5bc6dd42efed4d5acae8&amp;chksm=fcb9b367cbce3a711fabd1a56bb5b9d803aba2f42964b4e1f9a4dc6e2174f0952ddb9e1d4c55&amp;token=1977141018&amp;lang=zh_CN#rd">NLP（八十二）RAG框架中的Retrieve算法评估</a>中的数据集和评估代码，在ensemblesearch阶段之后加入BGE-Reranker服务API调用。</p><p>其中，<code>bge-reranker-base</code>的评估结果如下：</p><table><thead><tr class="header"><th>retrievers</th><th>hit_rate</th><th>mrr</th></tr></thead><tbody><tr class="odd"><td>ensemble_bge_base_rerank_top_1_eval</td><td>0.8255</td><td>0.8255</td></tr><tr class="even"><td>ensemble_bge_base_rerank_top_2_eval</td><td>0.8785</td><td>0.8489</td></tr><tr class="odd"><td>ensemble_bge_base_rerank_top_3_eval</td><td>0.9346</td><td>0.8686</td></tr><tr class="even"><td>ensemble_bge_base_rerank_top_4_eval</td><td>0.947</td><td>0.872</td></tr><tr class="odd"><td>ensemble_bge_base_rerank_top_5_eval</td><td>0.9564</td><td>0.8693</td></tr></tbody></table><p><code>bge-reranker-large</code>的评估结果如下：</p><table><thead><tr class="header"><th>retrievers</th><th>hit_rate</th><th>mrr</th></tr></thead><tbody><tr class="odd"><td>ensemble_bge_large_rerank_top_1_eval</td><td>0.8224</td><td>0.8224</td></tr><tr class="even"><td>ensemble_bge_large_rerank_top_2_eval</td><td>0.8847</td><td>0.8364</td></tr><tr class="odd"><td>ensemble_bge_large_rerank_top_3_eval</td><td>0.9377</td><td>0.8572</td></tr><tr class="even"><td>ensemble_bge_large_rerank_top_4_eval</td><td>0.9502</td><td>0.8564</td></tr><tr class="odd"><td>ensemble_bge_large_rerank_top_5_eval</td><td>0.9626</td><td>0.8537</td></tr></tbody></table><p>以Ensemble Search为baseline，分别对三种Rerank模型进行HitRate指标统计，柱状图如下：</p><figure><img src="https://s2.loli.net/2023/12/29/vsuXBtbLdaVDS39.png"alt="不同Rerank模型的Hit Rate" /><figcaption aria-hidden="true">不同Rerank模型的Hit Rate</figcaption></figure><p>从上述的统计图中可以得到如下结论：</p><ul><li>在Ensemble Search阶段后加入Rerank模型会有检索效果提升</li><li>就检索效果而言，Rerank模型的结果为：Cohere &gt; bge-rerank-large&gt; bge-rerank-base，但效果相差不大</li></ul><h2 id="总结">总结</h2><p>本文详细介绍了RAG框架中的两种Rerank模型的评估实验：bge-reranker和CohereRerank，算是在之前Retrieve算法评估实验上的延续工作，后续将会有更多工作持续更新。</p><p>本文的所有过程及指标结果已开源至Github，网址为：<ahref="https://github.com/percent4/embedding_rerank_retrieval">https://github.com/percent4/embedding_rerank_retrieval</a>.</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RAG</tag>
      
      <tag>Rerank</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（八十二）RAG框架中的Retrieve算法评估</title>
    <link href="/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%BA%8C%EF%BC%89RAG%E6%A1%86%E6%9E%B6%E4%B8%AD%E7%9A%84Retrieve%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0/"/>
    <url>/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%BA%8C%EF%BC%89RAG%E6%A1%86%E6%9E%B6%E4%B8%AD%E7%9A%84Retrieve%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将详细介绍RAG框架中的各种Retrieve算法，比如BM25, EmbeddingSearch, Ensemble Search,Rerank等的评估实验过程与结果。本文是目前除了LlamaIndex官方网站例子之外为数不多的介绍Retrieve算法评估实验的文章。</p></blockquote><h2 id="什么是rag中的retrieve">什么是RAG中的Retrieve？</h2><p><code>RAG</code>即Retrieval AugmentedGeneration的简称，是现阶段增强使用LLM的常见方式之一，其一般步骤为：</p><ol type="1"><li>文档划分（Document Split）</li><li>向量嵌入（Embedding）</li><li>文档获取（Retrieve）</li><li>Prompt工程（Prompt Engineering）</li><li>大模型问答（LLM）</li></ol><p>大致的流程图参考如下：</p><p><imgsrc="https://towhee.io/assets/img/task/retrieval-augmented-generation.png" /></p><p>通常来说，可将<code>RAG</code>划分为召回（<strong>Retrieve</strong>）阶段和答案生成(<strong>AnswerGenerate</strong>)阶段，而效果优化也从这方面入手。针对召回阶段，文档获取是其中重要的步骤，决定了注入大模型的知识背景，常见的召回算法如下：</p><ul><li><strong>BM25（又称Keyword Search）</strong>:使用BM24算法找回相关文档，一般对于特定领域关键词效果较好，比如人名，结构名等；</li><li><strong>Embedding Search</strong>:使用Embedding模型将query和corpus进行文本嵌入，使用向量相似度进行文本匹配，可解决BM25算法的相似关键词召回效果差的问题，该过程一般会使用向量数据库（VectorDatabase）；</li><li><strong>Ensemble Search</strong>: 融合BM25算法和EmbeddingSearch的结果，使用RFF算法进行重排序，一般会比单独的召回算法效果好；</li><li><strong>Rerank</strong>:上述的召回算法一般属于粗召回阶段，更看重性能；Rerank是对粗召回阶段的结果，再与query进行文本匹配，属于Rerank（又称为重排、精排）阶段，更看重效果；</li></ul><p>综合上述Retrieve算法的框架示意图如下：</p><p><imgsrc="https://1673940196-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FRncMhlfeYTrpujwzDIqw%2Fuploads%2FoalmRC4UOlhQNF0hFaBR%2Fspaces_CdDIVDY6AtAz028MFT4d_uploads_ohgmBurknjsKmg53Z00U_image.webp?alt=media&amp;token=33e4c026-8d5e-4e77-98b2-f1dcce42a15b" /></p><p>上述的Retrieve算法更有优劣，一般会选择合适的场景进行使用或考虑综合几种算法进行使用。那么，它们的效果具体如何呢？</p><h2 id="retrieve算法评估">Retrieve算法评估</h2><p>那么，如何对Retrieve算法进行具体效果评估呢？</p><p>本文将通过构造自有数据集进行测试，分别对上述四种Retrieve算法进行实验，采用<code>Hit Rate</code>和<code>MRR</code>指标进行评估。</p><p>在<strong>LlamaIndex</strong>官方RetrieveEvaluation中，提供了对Retrieve算法的评估示例，具体细节可参考如下：</p><p><ahref="https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83">https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83</a></p><p>这是现在网上较为权威的RetrieveEvaluation实验，本文将参考LlamaIndex的做法，给出更为详细的评估实验过程与结果。</p><p>Retrieve Evaluation实验的步骤如下：</p><ol type="1"><li><code>文档划分</code>：寻找合适数据集，进行文档划分；</li><li><code>问题生成</code>：对划分后的文档，使用LLM对文档内容生成问题；</li><li><code>召回文本</code>：对生成的每个问题，采用不同的Retrieve算法，得到召回结果；</li><li><code>指标评估</code>：使用<code>Hit Rate</code>和<code>MRR</code>指标进行评估</li></ol><p>步骤是清晰的，那么，我们来看下评估指标：<code>Hit Rate</code>和<code>MRR</code>。</p><p><code>Hit Rate</code>即命中率，一般指的是我们预期的召回文本（真实值）在召回结果的前k个文本中会出现，也就是Recall@k时，能得到预期文本。一般，<code>Hit Rate</code>越高，就说明召回算法效果越好。</p><p><code>MRR</code>即Mean ReciprocalRank，是一种常见的评估检索效果的指标。MRR是衡量系统在一系列查询中返回相关文档或信息的平均排名的逆数的平均值。例如，如果一个系统对第一个查询的正确答案排在第二位，对第二个查询的正确答案排在第一位，则MRR 为 (1/2 + 1/1) / 2。</p><p>在LlamaIndex中，这两个指标的对应类分别为<code>HitRate</code>和<code>MRR</code>，源代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">HitRate</span>(<span class="hljs-title class_ inherited__">BaseRetrievalMetric</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Hit rate metric.&quot;&quot;&quot;</span><br><br>    metric_name: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;hit_rate&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        query: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        expected_ids: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        retrieved_ids: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        expected_texts: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        retrieved_texts: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        **kwargs: <span class="hljs-type">Any</span>,</span><br><span class="hljs-params">    </span>) -&gt; RetrievalMetricResult:<br>        <span class="hljs-string">&quot;&quot;&quot;Compute metric.&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> retrieved_ids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> expected_ids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Retrieved ids and expected ids must be provided&quot;</span>)<br>        is_hit = <span class="hljs-built_in">any</span>(<span class="hljs-built_in">id</span> <span class="hljs-keyword">in</span> expected_ids <span class="hljs-keyword">for</span> <span class="hljs-built_in">id</span> <span class="hljs-keyword">in</span> retrieved_ids)<br>        <span class="hljs-keyword">return</span> RetrievalMetricResult(<br>            score=<span class="hljs-number">1.0</span> <span class="hljs-keyword">if</span> is_hit <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span>,<br>        )<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MRR</span>(<span class="hljs-title class_ inherited__">BaseRetrievalMetric</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;MRR metric.&quot;&quot;&quot;</span><br><br>    metric_name: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;mrr&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        query: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        expected_ids: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        retrieved_ids: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        expected_texts: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        retrieved_texts: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        **kwargs: <span class="hljs-type">Any</span>,</span><br><span class="hljs-params">    </span>) -&gt; RetrievalMetricResult:<br>        <span class="hljs-string">&quot;&quot;&quot;Compute metric.&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> retrieved_ids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> expected_ids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Retrieved ids and expected ids must be provided&quot;</span>)<br>        <span class="hljs-keyword">for</span> i, <span class="hljs-built_in">id</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(retrieved_ids):<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">id</span> <span class="hljs-keyword">in</span> expected_ids:<br>                <span class="hljs-keyword">return</span> RetrievalMetricResult(<br>                    score=<span class="hljs-number">1.0</span> / (i + <span class="hljs-number">1</span>),<br>                )<br>        <span class="hljs-keyword">return</span> RetrievalMetricResult(<br>            score=<span class="hljs-number">0.0</span>,<br>        )<br></code></pre></td></tr></table></figure><h2 id="数据集构造">数据集构造</h2><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485425&amp;idx=1&amp;sn=bd85ddfce82d77ceec5a66cb96835400&amp;chksm=fcb9be61cbce37773109f9703c2b6c4256d5037c8bf4497dfb9ad0f296ce0ee4065255954c1c&amp;token=1977141018&amp;lang=zh_CN#rd">NLP（六十一）使用Baichuan-13B-Chat模型构建智能文档</a>笔者介绍了如何使用RAG框架来实现智能文档问答。</p><p>以这个项目为基础，笔者采集了日本半导体行业相关的网络文章及其他文档，进行文档划分，导入至ElastricSearch，并使用OpenAIEmbedding获取文本嵌入向量。语料库一共为433个文档片段（Chunk），其中321个与日本半导体行业相关（不妨称之为<code>领域文档</code>）。</p><p>还差query数据集。这点是从LlamaIndex官方示例中获取的灵感：<strong>使用大模型生成query</strong>!</p><p>针对上述321个领域文档，使用GPT-4模型生成一个与文本内容相关的问题，即query，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: data_transfer.py</span><br><span class="hljs-comment"># @time: 2023/12/25 17:51</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> llama_index.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> llama_index.schema <span class="hljs-keyword">import</span> TextNode<br><span class="hljs-keyword">from</span> llama_index.evaluation <span class="hljs-keyword">import</span> generate_question_context_pairs<br><span class="hljs-keyword">import</span> random<br>random.seed(<span class="hljs-number">42</span>)<br><br>llm = OpenAI(model=<span class="hljs-string">&quot;gpt-4&quot;</span>, max_retries=<span class="hljs-number">5</span>)<br><br><span class="hljs-comment"># Prompt to generate questions</span><br>qa_generate_prompt_tmpl = <span class="hljs-string">&quot;&quot;&quot;\</span><br><span class="hljs-string">Context information is below.</span><br><span class="hljs-string"></span><br><span class="hljs-string">---------------------</span><br><span class="hljs-string">&#123;context_str&#125;</span><br><span class="hljs-string">---------------------</span><br><span class="hljs-string"></span><br><span class="hljs-string">Given the context information and not prior knowledge.</span><br><span class="hljs-string">generate only questions based on the below query.</span><br><span class="hljs-string"></span><br><span class="hljs-string">You are a university professor. Your task is to set &#123;num_questions_per_chunk&#125; questions for the upcoming Chinese quiz.</span><br><span class="hljs-string">Questions throughout the test should be diverse. Questions should not contain options or start with Q1/Q2.</span><br><span class="hljs-string">Questions must be written in Chinese. The expression must be concise and clear. </span><br><span class="hljs-string">It should not exceed 15 Chinese characters. Words such as &quot;这&quot;, &quot;那&quot;, &quot;根据&quot;, &quot;依据&quot; and other punctuation marks </span><br><span class="hljs-string">should not be used. Abbreviations may be used for titles and professional terms.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>nodes = []<br>data_df = pd.read_csv(<span class="hljs-string">&quot;../data/doc_qa_dataset.csv&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>)<br><span class="hljs-keyword">for</span> i, row <span class="hljs-keyword">in</span> data_df.iterrows():<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(row[<span class="hljs-string">&quot;content&quot;</span>]) &gt; <span class="hljs-number">80</span> <span class="hljs-keyword">and</span> i &gt; <span class="hljs-number">96</span>:<br>        node = TextNode(text=row[<span class="hljs-string">&quot;content&quot;</span>])<br>        node.id_ = <span class="hljs-string">f&quot;node_<span class="hljs-subst">&#123;i + <span class="hljs-number">1</span>&#125;</span>&quot;</span><br>        nodes.append(node)<br><br><br>doc_qa_dataset = generate_question_context_pairs(<br>    nodes, llm=llm, num_questions_per_chunk=<span class="hljs-number">1</span>, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl<br>)<br><br>doc_qa_dataset.save_json(<span class="hljs-string">&quot;../data/doc_qa_dataset.json&quot;</span>)<br></code></pre></td></tr></table></figure><p>原始数据<code>doc_qa_dataset.csv</code>是笔者从Kibana中的Discover中导出的，使用llama-index模块和GPT-4模型，以合适的Prompt，对每个领域文档生成一个问题，并保存为doc_qa_dataset.json，这就是我们进行RetrieveEvaluation的数据格式，其中包括queries, corpus, relevant_docs,mode四个字段。</p><p>我们来查看第一个文档及生成的答案，如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;queries&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;7813f025-333d-494f-bc14-a51b2d57721b&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;日本半导体产业的现状和影响因素是什么？&quot;</span><span class="hljs-punctuation">,</span><br>        ...<br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;corpus&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;node_98&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;日本半导体产业在上世纪80年代到达顶峰后就在缓慢退步，但若简单认为日本半导体产业失败了，就是严重误解，今天日本半导体产业仍有非常有竞争力的企业和产品。客观认识日本半导体产业的成败及其背后的原因，对正在大力发展半导体产业的中国，有非常强的参考价值。&quot;</span><span class="hljs-punctuation">,</span><br>        ...<br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;relevant_docs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;7813f025-333d-494f-bc14-a51b2d57721b&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-string">&quot;node_98&quot;</span><br>        <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        ...<br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;mode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h2 id="retrieve算法评估-1">Retrieve算法评估</h2><p>我们需要评估的Retrieve算法为BM25, Embedding Search, Ensemble Search,Ensemble +Rerank，下面将分别就Retriever实现方式、指标评估实验对每种Retrieve算法进行详细介绍。</p><h3 id="bm25">BM25</h3><p>BM25的储存采用ElasticSearch，即直接使用ES内置的BM25算法。笔者在llama-index对BaseRetriever进行定制化开发（这也是我们实现自己想法的一种常规方法），对其简单封装，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: bm25_retriever.py</span><br><span class="hljs-comment"># @time: 2023/12/25 17:42</span><br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><br><span class="hljs-keyword">from</span> elasticsearch <span class="hljs-keyword">import</span> Elasticsearch<br><span class="hljs-keyword">from</span> llama_index.schema <span class="hljs-keyword">import</span> TextNode<br><span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> QueryBundle<br><span class="hljs-keyword">from</span> llama_index.schema <span class="hljs-keyword">import</span> NodeWithScore<br><span class="hljs-keyword">from</span> llama_index.retrievers <span class="hljs-keyword">import</span> BaseRetriever<br><span class="hljs-keyword">from</span> llama_index.indices.query.schema <span class="hljs-keyword">import</span> QueryType<br><br><span class="hljs-keyword">from</span> preprocess.get_text_id_mapping <span class="hljs-keyword">import</span> text_node_id_mapping<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomBM25Retriever</span>(<span class="hljs-title class_ inherited__">BaseRetriever</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Custom retriever for elasticsearch with bm25&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, top_k</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-string">&quot;&quot;&quot;Init params.&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.es_client = Elasticsearch([&#123;<span class="hljs-string">&#x27;host&#x27;</span>: <span class="hljs-string">&#x27;localhost&#x27;</span>, <span class="hljs-string">&#x27;port&#x27;</span>: <span class="hljs-number">9200</span>&#125;])<br>        self.top_k = top_k<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_retrieve</span>(<span class="hljs-params">self, query: QueryType</span>) -&gt; <span class="hljs-type">List</span>[NodeWithScore]:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(query, <span class="hljs-built_in">str</span>):<br>            query = QueryBundle(query)<br>        <span class="hljs-keyword">else</span>:<br>            query = query<br><br>        result = []<br>        <span class="hljs-comment"># 查询数据(全文搜索)</span><br>        dsl = &#123;<br>            <span class="hljs-string">&#x27;query&#x27;</span>: &#123;<br>                <span class="hljs-string">&#x27;match&#x27;</span>: &#123;<br>                    <span class="hljs-string">&#x27;content&#x27;</span>: query.query_str<br>                &#125;<br>            &#125;,<br>            <span class="hljs-string">&quot;size&quot;</span>: self.top_k<br>        &#125;<br>        search_result = self.es_client.search(index=<span class="hljs-string">&#x27;docs&#x27;</span>, body=dsl)<br>        <span class="hljs-keyword">if</span> search_result[<span class="hljs-string">&#x27;hits&#x27;</span>][<span class="hljs-string">&#x27;hits&#x27;</span>]:<br>            <span class="hljs-keyword">for</span> record <span class="hljs-keyword">in</span> search_result[<span class="hljs-string">&#x27;hits&#x27;</span>][<span class="hljs-string">&#x27;hits&#x27;</span>]:<br>                text = record[<span class="hljs-string">&#x27;_source&#x27;</span>][<span class="hljs-string">&#x27;content&#x27;</span>]<br>                node_with_score = NodeWithScore(node=TextNode(text=text,<br>                                                id_=text_node_id_mapping[text]),<br>                                                score=record[<span class="hljs-string">&#x27;_score&#x27;</span>])<br>                result.append(node_with_score)<br><br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure><p>之后，对top_k结果进行指标评估，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: evaluation_exp.py</span><br><span class="hljs-comment"># @time: 2023/12/25 20:01</span><br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">from</span> faiss <span class="hljs-keyword">import</span> IndexFlatIP<br><span class="hljs-keyword">from</span> llama_index.evaluation <span class="hljs-keyword">import</span> RetrieverEvaluator<br><span class="hljs-keyword">from</span> llama_index.finetuning.embeddings.common <span class="hljs-keyword">import</span> EmbeddingQAFinetuneDataset<br><br><span class="hljs-keyword">from</span> custom_retriever.bm25_retriever <span class="hljs-keyword">import</span> CustomBM25Retriever<br><span class="hljs-keyword">from</span> custom_retriever.vector_store_retriever <span class="hljs-keyword">import</span> VectorSearchRetriever<br><span class="hljs-keyword">from</span> custom_retriever.ensemble_retriever <span class="hljs-keyword">import</span> EnsembleRetriever<br><span class="hljs-keyword">from</span> custom_retriever.ensemble_rerank_retriever <span class="hljs-keyword">import</span> EnsembleRerankRetriever<br><span class="hljs-keyword">from</span> custom_retriever.query_rewrite_ensemble_retriever <span class="hljs-keyword">import</span> QueryRewriteEnsembleRetriever<br><br><br><span class="hljs-comment"># Display results from evaluate.</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">display_results</span>(<span class="hljs-params">name_list, eval_results_list</span>):<br>    pd.set_option(<span class="hljs-string">&#x27;display.precision&#x27;</span>, <span class="hljs-number">4</span>)<br>    columns = &#123;<span class="hljs-string">&quot;retrievers&quot;</span>: [], <span class="hljs-string">&quot;hit_rate&quot;</span>: [], <span class="hljs-string">&quot;mrr&quot;</span>: []&#125;<br>    <span class="hljs-keyword">for</span> name, eval_results <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(name_list, eval_results_list):<br>        metric_dicts = []<br>        <span class="hljs-keyword">for</span> eval_result <span class="hljs-keyword">in</span> eval_results:<br>            metric_dict = eval_result.metric_vals_dict<br>            metric_dicts.append(metric_dict)<br><br>        full_df = pd.DataFrame(metric_dicts)<br><br>        hit_rate = full_df[<span class="hljs-string">&quot;hit_rate&quot;</span>].mean()<br>        mrr = full_df[<span class="hljs-string">&quot;mrr&quot;</span>].mean()<br><br>        columns[<span class="hljs-string">&quot;retrievers&quot;</span>].append(name)<br>        columns[<span class="hljs-string">&quot;hit_rate&quot;</span>].append(hit_rate)<br>        columns[<span class="hljs-string">&quot;mrr&quot;</span>].append(mrr)<br><br>    metric_df = pd.DataFrame(columns)<br><br>    <span class="hljs-keyword">return</span> metric_df<br><br><br>doc_qa_dataset = EmbeddingQAFinetuneDataset.from_json(<span class="hljs-string">&quot;../data/doc_qa_test.json&quot;</span>)<br>metrics = [<span class="hljs-string">&quot;mrr&quot;</span>, <span class="hljs-string">&quot;hit_rate&quot;</span>]<br><span class="hljs-comment"># bm25 retrieve</span><br>evaluation_name_list = []<br>evaluation_result_list = []<br>cost_time_list = []<br><span class="hljs-keyword">for</span> top_k <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]:<br>    start_time = time.time()<br>    bm25_retriever = CustomBM25Retriever(top_k=top_k)<br>    bm25_retriever_evaluator = RetrieverEvaluator.from_metric_names(metrics, retriever=bm25_retriever)<br>    bm25_eval_results = asyncio.run(bm25_retriever_evaluator.aevaluate_dataset(doc_qa_dataset))<br>    evaluation_name_list.append(<span class="hljs-string">f&quot;bm25_top_<span class="hljs-subst">&#123;top_k&#125;</span>_eval&quot;</span>)<br>    evaluation_result_list.append(bm25_eval_results)<br>    cost_time_list.append((time.time() - start_time) * <span class="hljs-number">1000</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;done for bm25 evaluation!&quot;</span>)<br>df = display_results(evaluation_name_list, evaluation_result_list)<br>df[<span class="hljs-string">&#x27;cost_time&#x27;</span>] = cost_time_list<br><span class="hljs-built_in">print</span>(df.head())<br>df.to_csv(<span class="hljs-string">f&quot;evaluation_bm25_<span class="hljs-subst">&#123;datetime.now().strftime(<span class="hljs-string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)&#125;</span>.csv&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>, index=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>BM25算法的实验结果如下：</p><table><thead><tr class="header"><th>retrievers</th><th>hit_rate</th><th>mrr</th><th>cost_time</th></tr></thead><tbody><tr class="odd"><td>bm25_top_1_eval</td><td>0.7975</td><td>0.7975</td><td>461.277</td></tr><tr class="even"><td>bm25_top_2_eval</td><td>0.8536</td><td>0.8255</td><td>510.3021</td></tr><tr class="odd"><td>bm25_top_3_eval</td><td>0.9003</td><td>0.8411</td><td>570.6708</td></tr><tr class="even"><td>bm25_top_4_eval</td><td>0.9159</td><td>0.845</td><td>420.7261</td></tr><tr class="odd"><td>bm25_top_5_eval</td><td>0.9408</td><td>0.85</td><td>388.5961</td></tr></tbody></table><h3 id="embedding-search">Embedding Search</h3><p>BM25算法的实现是简单的。EmbeddingSearch的较为复杂些，首先需要对queries和corpus进行文本嵌入，这里的Embedding模型使用Openai的text-embedding-ada-002，向量维度为1536，并将结果存入numpy数据结构中，保存为npy文件，方便后续加载和重复使用。</p><p>为了避免使用过重的向量数据集，本实验采用内存向量数据集:<strong>faiss</strong>。使用faiss加载向量，index类型选用IndexFlatIP，并进行向量相似度搜索。</p><p>EmbeddingSearch也需要定制化开发Retriever及指标评估，这里不再赘述，具体实验可参考文章末尾的Github项目地址。</p><p>Embedding Search的实验结果如下：</p><table><thead><tr class="header"><th>retrievers</th><th>hit_rate</th><th>mrr</th><th>cost_time</th></tr></thead><tbody><tr class="odd"><td>embedding_top_1_eval</td><td>0.6075</td><td>0.6075</td><td>67.6837</td></tr><tr class="even"><td>embedding_top_2_eval</td><td>0.6978</td><td>0.6526</td><td>60.8449</td></tr><tr class="odd"><td>embedding_top_3_eval</td><td>0.7321</td><td>0.6641</td><td>59.9051</td></tr><tr class="even"><td>embedding_top_4_eval</td><td>0.7788</td><td>0.6758</td><td>63.5488</td></tr><tr class="odd"><td>embedding_top_5_eval</td><td>0.7944</td><td>0.6789</td><td>67.7922</td></tr></tbody></table><blockquote><p>注意:这里的召回时间花费比BM25还要少，完全得益于我们已经存储好了文本向量，并使用faiss进行加载、查询。</p></blockquote><h3 id="ensemble-search">Ensemble Search</h3><p>Ensemble Search融合BM25算法和EmbeddingSearch算法，针对两种算法召回的top_k个文档，使用RRF算法进行重新排序，再获取top_k个文档。RRF算法是经典且优秀的集成排序算法，这里不再展开介绍，后续专门写文章介绍。</p><p>Ensemble Search的实验结果如下：</p><table><thead><tr class="header"><th>retrievers</th><th>hit_rate</th><th>mrr</th><th>cost_time</th></tr></thead><tbody><tr class="odd"><td>ensemble_top_1_eval</td><td>0.7009</td><td>0.7009</td><td>1072.7379</td></tr><tr class="even"><td>ensemble_top_2_eval</td><td>0.8536</td><td>0.7741</td><td>1088.8782</td></tr><tr class="odd"><td>ensemble_top_3_eval</td><td>0.8941</td><td>0.7928</td><td>980.7949</td></tr><tr class="even"><td>ensemble_top_4_eval</td><td>0.919</td><td>0.8017</td><td>935.1702</td></tr><tr class="odd"><td>ensemble_top_5_eval</td><td>0.9377</td><td>0.8079</td><td>868.299</td></tr></tbody></table><h3 id="ensemble-rerank">Ensemble + Rerank</h3><p>如果还想在EnsembleSearch的基础上再进行效果优化，可考虑加入Rerank算法。常见的Rerank模型有Cohere（API调用），BGE-Rerank（开源模型）等。本文使用CohereRerank API.</p><p>Ensemble + Rerank的实验结果如下：</p><table><thead><tr class="header"><th>retrievers</th><th>hit_rate</th><th>mrr</th><th>cost_time</th></tr></thead><tbody><tr class="odd"><td>ensemble_rerank_top_1_eval</td><td>0.8349</td><td>0.8349</td><td>2140632.4041</td></tr><tr class="even"><td>ensemble_rerank_top_2_eval</td><td>0.9034</td><td>0.8785</td><td>2157657.2871</td></tr><tr class="odd"><td>ensemble_rerank_top_3_eval</td><td>0.9346</td><td>0.9008</td><td>2200800.936</td></tr><tr class="even"><td>ensemble_rerank_top_4_eval</td><td>0.947</td><td>0.9078</td><td>2150398.7348</td></tr><tr class="odd"><td>ensemble_rerank_top_5_eval</td><td>0.9657</td><td>0.9099</td><td>2149122.9382</td></tr></tbody></table><h2 id="指标可视化及分析">指标可视化及分析</h2><h3 id="指标可视化">指标可视化</h3><p>上述的评估结果不够直观，我们使用Plotly模块绘制指标的条形图，结果如下：</p><figure><img src="https://s2.loli.net/2023/12/28/5VjRy7rCeXOtAZq.png"alt="Hit Rate" /><figcaption aria-hidden="true">Hit Rate</figcaption></figure><figure><img src="https://s2.loli.net/2023/12/28/s9SvU4kL7Zc1MK5.png"alt="MRR" /><figcaption aria-hidden="true">MRR</figcaption></figure><h3 id="指标分析">指标分析</h3><p>我们对上述统计图进行指标分析，可得到结论如下：</p><ul><li>对于每种Retrieve算法，随着k的增加，top_k的HitRate指标和MRR指标都有所增加，即检索效果变好，这是显而易见的结论；</li><li>就总体检索效果而言，Ensemble + Rerank &gt; Ensemble &gt;单独的Retrieve</li><li>本项目中就单独的Retrieve算法而言，BM25的检索效果比EmbeddingSearch好（可能与生成的问答来源于文档有关），但这不是普遍结论，两种算法更有合适的场景</li><li>加入Rerank后，检索效果可获得一定的提升，以top_3评估结果来说，ensemble的HitRate为0.8941，加入Rerank后为0.9346，提升约4%</li></ul><h2 id="总结">总结</h2><p>本文详细介绍了RAG框架，并结合自有数据集对各种Retrieve算法进行评估。笔者通过亲身实验和编写Retriever代码，深入了解了RAG框架中的经典之作LlamaIndex，同时，本文也是难得的介绍RAG框架Retrieve阶段评估实验的文章。</p><p>本文的所有过程及指标结果已开源至Github，网址为：<ahref="https://github.com/percent4/embedding_rerank_retrieval">https://github.com/percent4/embedding_rerank_retrieval</a>.</p><p>后续，笔者将在此项目基础上，验证各种优化RAG框架Retrieve效果的手段，比如QueryRewrite, Query Transform, HyDE等，这将是一个获益无穷的项目啊！</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>RetrieveEvaluation官网文章：https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83</li><li>Retrieve EvaluationColab上的代码：https://colab.research.google.com/drive/1TxDVA__uimVPOJiMEQgP5fwHiqgKqm4-?usp=sharing</li><li>LlamaIndex官网：https://docs.llamaindex.ai/en/stable/index.html</li><li>RetrieverEvaluator in LlamaIndex:https://docs.llamaindex.ai/en/stable/module_guides/evaluating/usage_pattern_retrieval.html</li><li>NLP（六十一）使用Baichuan-13B-Chat模型构建智能文档:https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485425&amp;idx=1&amp;sn=bd85ddfce82d77ceec5a66cb96835400&amp;chksm=fcb9be61cbce37773109f9703c2b6c4256d5037c8bf4497dfb9ad0f296ce0ee4065255954c1c&amp;token=1977141018&amp;lang=zh_CN#rd</li><li>NLP（六十九）智能文档助手升级:https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485609&amp;idx=1&amp;sn=f8337b4822b1cdf95a586af6097ef288&amp;chksm=fcb9b139cbce382f735e4c119ade8084067cde0482910c72767f36a29e7291385cbe6dfbd6a9&amp;payreadticket=HBB91zkl4I6dXpw0Q4OcOF8ECZz0pS9kOGHJqycwrN7jFWHyUOCBe7sWFWytD7_9wo_NzcM#rd</li><li>NLP（八十一）智能文档问答助手项目改进:https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486103&amp;idx=1&amp;sn=caa204eda0760bab69b7e40abff8e696&amp;chksm=fcb9b307cbce3a1108d305ec44281e3446241e90e9c17d62dd0b6eaa48cba5e20d31f0129584&amp;token=1977141018&amp;lang=zh_CN#rd</li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RAG</tag>
      
      <tag>Retrieve</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ELK学习笔记（三）Beats家族</title>
    <link href="/ELK%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89Beats%E5%AE%B6%E6%97%8F/"/>
    <url>/ELK%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89Beats%E5%AE%B6%E6%97%8F/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文主要介绍了Beats工具，并在之前的ELK流程中加入Filebeat进行演示。</p></blockquote><h2 id="beats-介绍">Beats 介绍</h2><p><code>Logstash</code>是一个较早开发的数据收集和转换工具，用户仅需编写配置文件便可轻松地将各类数据导入<code>Elasticsearch</code>。然而，Logstash在运行时较为耗费资源，因此官方随后推出了一系列轻量级数据收集器，这些以“beat”为命名的工具被统称为<code>Beats</code>。Beats实际上是将Logstash的数据收集功能拆分出来，由这些更轻量的工具来完成。因此，<code>Beats</code>家族是<code>Elastic Stack</code>中的后起之秀。</p><p><code>Beats</code>采集的数据既可以先汇聚到<code>Logstash</code>，再由其写入<code>Elasticsearch</code>，也可以直接由<code>Beats</code>采集后直接写入<code>Elasticsearch</code>。</p><p>目前，Beats家族包括了几种主要成员，并且这个家族的种类还在持续增加。Beats家族中常见的工具列举如下：</p><p><imgsrc="https://res.cloudinary.com/practicaldev/image/fetch/s--4_ju-Ufo--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/4k6wm9am8w4hyo6out47.jpg" /></p><ol type="1"><li>Filebeat：用于采集各类日志文件，可以读取并传送日志的行，支持断点续传。</li><li>Metricbeat：用于采集各种软硬件的运维监控数据，例如CPU、内存、MySQL等运行时的指标数据。</li><li>Packetbeat：用于采集各种网络协议产生的流量数据，通过分析这些数据你可以及时发现网络存在的问题和其运行状态。</li><li>Winlogbeat：用于采集Windows系统的事件日志，可以用来实时分析Windows系统中产生的各种事件。</li><li>Heartbeat：能够监测指定的服务是否可用并能将监测结果采集到Elasticsearch中进行分析。</li><li>Auditbeat：用于采集Linux审计框架的事件数据，通过采集并监控用户的行为数据和关于系统进程的数据，能够识别出系统潜在的风险和安全问题。</li></ol><h2 id="beats-的必要性">Beats 的必要性</h2><p>设想一下这样以下场景：</p><blockquote><p>假如有100个节点，每个节点上有20个日志文件需要采集，则需要安装100个Logstash，一共要启动2000个数据管道同时写入Elasticsearch，这样会非常浪费硬件资源，而且Elasticsearch需要启动大量的线程去应对2000个数据管道日志的同时写入，效率十分低下。</p></blockquote><p>而Beats家族的每一个成员都擅长某个方面的数据采集，并且它们的性能开销非常小，使用Beats家族的成员完成分布式环境中的大规模数据采集对提升大数据处理的效率十分有好处。同时，每个Beats采集数据的吞吐量是不同的，由于Logstash拥有缓冲队列，把Beats的数据流引入Logstash可以起到数据汇聚和数据缓冲的作用，减少数据流对Elasticsearch的冲击力。</p><p>常见的Beats + ELK的框架图如下：</p><p><imgsrc="https://miro.medium.com/v2/resize:fit:1024/1*qQbT-o_YbgwuT_X8kMm6mg.png" /></p><p>当然，也可以在Beats与Logstash中间也可以加入消息队列工具，更好地进行数据缓冲。</p><p><imgsrc="https://dytvr9ot2sszz.cloudfront.net/wp-content/uploads/2023/05/image-19.png" /></p><p>本文主要介绍Beats中的文件采集工具<code>Filebeat</code>.</p><h2 id="filebeat-使用">Filebeat 使用</h2><p>我们使用Filebeat收集logs目录下的log文件，将其收集后的数据送至Lostash，走ELK流程。</p><p>其中<code>filebeat.yml</code>文件配置如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">filebeat.inputs:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">log</span><br>  <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span><br>  <span class="hljs-attr">paths:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">/usr/share/filebeat/target/*.log</span><br><span class="hljs-attr">output.logstash:</span><br>  <span class="hljs-attr">hosts:</span> [<span class="hljs-string">&quot;logstash:5044&quot;</span>]<br><span class="hljs-attr">processors:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">add_id:</span> <span class="hljs-string">~</span><br></code></pre></td></tr></table></figure><p>在Logstash中，配置<code>logstash.conf</code>文件如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">input</span> &#123;<br>  <span class="hljs-string">beats</span> &#123;<br>    <span class="hljs-string">port</span> <span class="hljs-string">=&gt;</span> <span class="hljs-number">5044</span><br>  &#125;<br>&#125;<br><span class="hljs-string">output</span> &#123;<br>  <span class="hljs-string">stdout</span> &#123;<br>    <span class="hljs-string">codec</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">rubydebug</span><br>  &#125;<br>  <span class="hljs-string">if</span> [<span class="hljs-string">@metadata</span>][<span class="hljs-string">_id</span>] &#123;<br>    <span class="hljs-string">elasticsearch</span> &#123;<br>      <span class="hljs-string">hosts</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;http://elasticsearch:9200&quot;</span>]<br>      <span class="hljs-string">document_id</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;<span class="hljs-template-variable">%&#123;[@metadata][_id]&#125;</span>&quot;</span><br>      <span class="hljs-string">index</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;myfilebeat-<span class="hljs-template-variable">%&#123;[agent][version]&#125;</span>-<span class="hljs-template-variable">%&#123;+yyyy.MM.dd&#125;</span>&quot;</span><br>    &#125;<br>  &#125; <span class="hljs-string">else</span> &#123;<br>    <span class="hljs-string">elasticsearch</span> &#123;<br>      <span class="hljs-string">hosts</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;http://elasticsearch:9200&quot;</span>]<br>      <span class="hljs-string">index</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;myfilebeat-<span class="hljs-template-variable">%&#123;[agent][version]&#125;</span>-<span class="hljs-template-variable">%&#123;+yyyy.MM.dd&#125;</span>&quot;</span><br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>logstash的输入为beats, 输出为ElasticSearch.</p><p>同时，整个流程的<code>docker-compose.yml</code>文件配置如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.1&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">filebeat:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">video-filebeat</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">elastic/filebeat:7.17.0</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">always</span><br>    <span class="hljs-attr">user:</span> <span class="hljs-string">root</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./filebeat/logs:/usr/share/filebeat/target</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./filebeat/data:/usr/share/filebeat/data</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9000:9000&quot;</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">filebeat_elk_net</span><br><br>  <span class="hljs-attr">logstash:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">logstash-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">docker.elastic.co/logstash/logstash:7.17.0</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./logstash/config/logstash.yml:/usr/share/logstash/logstash.yml</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./logstash/data:/usr/share/logstash/data</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./logstash/pipeline:/usr/share/logstash/pipeline</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;5044:5044&quot;</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">filebeat_elk_net</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">filebeat</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elasticsearch</span><br><br>  <span class="hljs-attr">elasticsearch:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">elasticsearch-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">elasticsearch:7.17.0</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;ES_JAVA_OPTS=-Xms1024m -Xmx1024m&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;http.host=0.0.0.0&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;node.name=elastic01&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;cluster.name=cluster_elasticsearch&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;discovery.type=single-node&quot;</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9200:9200&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9300:9300&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./es/plugins:/usr/share/elasticsearch/plugins</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./es/data:/usr/share/elasticsearch/data</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">filebeat_elk_net</span><br><br>  <span class="hljs-attr">kibana:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">kibana-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">kibana:7.17.0</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;5601:5601&quot;</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">filebeat_elk_net</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elasticsearch</span><br><br><span class="hljs-comment"># 网络配置</span><br><span class="hljs-attr">networks:</span><br>  <span class="hljs-attr">filebeat_elk_net:</span><br>    <span class="hljs-attr">driver:</span> <span class="hljs-string">bridge</span><br></code></pre></td></tr></table></figure><p>待流程运行后，会讲logs文件下的log文件逐行读入ElasticSearch中，其中一行的数据如下：</p><figure><img src="https://s2.loli.net/2023/12/24/wQH824rDaOY31sV.png"alt="示例数据" /><figcaption aria-hidden="true">示例数据</figcaption></figure><p>可以看到，加入Filebeat后，解析后的数据字段比单纯的ELK多了很多，比如agent字段等。</p><h2 id="总结">总结</h2><p>有了之前ELK基础，那么学习Beats是十分迅速的。Beats工具的想法也很简单，就是在ELK之前做一步数据采集工作，能够支持分布式数据，而轻量化。</p><p>本文主要介绍了Beats工具，并在之前的ELK流程中加入Filebeat进行演示。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ELK</tag>
      
      <tag>Beats</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ELK学习笔记（二）数据同步</title>
    <link href="/ELK%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"/>
    <url>/ELK%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文主要介绍如何使用ELK工具，将MySQL中的数据同步至ElasticSearch.</p></blockquote><p>本文主要分为以下三个部分：</p><ul><li>环境准备：包括启动MySQL与ELK，在MySQL与ES中分别创建对应的表格，开发Python脚本用于往MySQL中创建表格、批量插入数据</li><li>全量数据同步：将MySQL表中数据全量同步至ES</li><li>增量数据同步：将MySQL表中数据增量同步至ES</li></ul><figure><img src="https://s2.loli.net/2023/12/24/l5aZyinuXv2mbdR.jpg"alt="ELK实现数据同步" /><figcaption aria-hidden="true">ELK实现数据同步</figcaption></figure><h2 id="环境准备">环境准备</h2><p>使用docker-compose启动mysql, docker-compose.yml如下:</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3&#x27;</span><br><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">mysql8.0:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">mysql:8.0</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">mysql8.0</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">always</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-attr">TZ:</span> <span class="hljs-string">Asia/Shanghai</span><br>      <span class="hljs-attr">MYSQL_ROOT_PASSWORD:</span> <span class="hljs-string">root</span><br>      <span class="hljs-attr">MYSQL_DATABASE:</span> <span class="hljs-string">orm_test</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-number">3306</span><span class="hljs-string">:3306</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./mysql/data/:/var/lib/mysql/</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./mysql/conf/:/etc/mysql/conf.d/</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./mysql/init/:/docker-entrypoint-initdb.d/</span><br>    <span class="hljs-attr">command:</span><br>      <span class="hljs-comment"># 将mysql8.0默认密码策略 修改为 原先 策略 (mysql8.0对其默认策略做了更改 会导致密码无法匹配)</span><br>      <span class="hljs-string">--default-authentication-plugin=mysql_native_password</span><br>      <span class="hljs-string">--character-set-server=utf8mb4</span><br>      <span class="hljs-string">--collation-server=utf8mb4_general_ci</span><br>      <span class="hljs-string">--explicit_defaults_for_timestamp=true</span><br></code></pre></td></tr></table></figure><p>使用Python中的sqlalchemy + pymysql往MySQL中创建users表格，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: mysql_create_table.py</span><br><span class="hljs-comment"># @time: 2023/12/23 23:29</span><br><span class="hljs-keyword">from</span> sqlalchemy.dialects.mysql <span class="hljs-keyword">import</span> INTEGER, VARCHAR, DATETIME<br><span class="hljs-keyword">from</span> sqlalchemy <span class="hljs-keyword">import</span> Column<br><span class="hljs-keyword">from</span> sqlalchemy <span class="hljs-keyword">import</span> create_engine<br><span class="hljs-keyword">from</span> sqlalchemy.ext.declarative <span class="hljs-keyword">import</span> declarative_base<br>Base = declarative_base()<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Users</span>(<span class="hljs-title class_ inherited__">Base</span>):<br>    __tablename__ = <span class="hljs-string">&#x27;users&#x27;</span><br><br>    <span class="hljs-built_in">id</span> = Column(INTEGER, primary_key=<span class="hljs-literal">True</span>)<br>    name = Column(VARCHAR(<span class="hljs-number">256</span>), nullable=<span class="hljs-literal">False</span>)<br>    age = Column(INTEGER)<br>    place = Column(VARCHAR(<span class="hljs-number">256</span>), nullable=<span class="hljs-literal">False</span>)<br>    insert_time = Column(DATETIME)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, <span class="hljs-built_in">id</span>, name, age, place, insert_time</span>):<br>        self.<span class="hljs-built_in">id</span> = <span class="hljs-built_in">id</span><br>        self.name = name<br>        self.age = age<br>        self.place = place<br>        self.insert_time = insert_time<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_db</span>():<br>    engine = create_engine(<br>        <span class="hljs-string">&quot;mysql+pymysql://root:root@localhost:3306/orm_test&quot;</span>,<br>        echo=<span class="hljs-literal">True</span><br>    )<br>    Base.metadata.create_all(engine)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Create table successfully!&#x27;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    init_db()<br><br></code></pre></td></tr></table></figure><p>users表结构如下：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">+-------------+--------------+------+-----+---------+----------------+<br>|<span class="hljs-string"> Field       </span>|<span class="hljs-string"> Type         </span>|<span class="hljs-string"> Null </span>|<span class="hljs-string"> Key </span>|<span class="hljs-string"> Default </span>|<span class="hljs-string"> Extra          </span>|<br>+-------------+--------------+------+-----+---------+----------------+<br>|<span class="hljs-string"> id          </span>|<span class="hljs-string"> int          </span>|<span class="hljs-string"> NO   </span>|<span class="hljs-string"> PRI </span>|<span class="hljs-string"> NULL    </span>|<span class="hljs-string"> auto_increment </span>|<br>|<span class="hljs-string"> name        </span>|<span class="hljs-string"> varchar(256) </span>|<span class="hljs-string"> NO   </span>|<span class="hljs-string">     </span>|<span class="hljs-string"> NULL    </span>|<span class="hljs-string">                </span>|<br>|<span class="hljs-string"> age         </span>|<span class="hljs-string"> int          </span>|<span class="hljs-string"> YES  </span>|<span class="hljs-string">     </span>|<span class="hljs-string"> NULL    </span>|<span class="hljs-string">                </span>|<br>|<span class="hljs-string"> place       </span>|<span class="hljs-string"> varchar(256) </span>|<span class="hljs-string"> NO   </span>|<span class="hljs-string">     </span>|<span class="hljs-string"> NULL    </span>|<span class="hljs-string">                </span>|<br>|<span class="hljs-string"> insert_time </span>|<span class="hljs-string"> datetime     </span>|<span class="hljs-string"> YES  </span>|<span class="hljs-string">     </span>|<span class="hljs-string"> NULL    </span>|<span class="hljs-string">                </span>|<br>+-------------+--------------+------+-----+---------+----------------+<br></code></pre></td></tr></table></figure><p>插入5条数据，脚本如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: mysql_insert_data.py</span><br><span class="hljs-comment"># @time: 2023/12/23 23:29</span><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> sqlalchemy <span class="hljs-keyword">import</span> create_engine<br><span class="hljs-keyword">from</span> sqlalchemy.orm <span class="hljs-keyword">import</span> sessionmaker<br><span class="hljs-keyword">from</span> mysql_create_table <span class="hljs-keyword">import</span> Users<br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime <span class="hljs-keyword">as</span> dt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_time</span>():<br>    time.sleep(<span class="hljs-number">5</span>)<br>    <span class="hljs-keyword">return</span> dt.now().strftime(<span class="hljs-string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">insert_data</span>():<br>    <span class="hljs-comment"># 初始化数据库连接</span><br>    engine = create_engine(<span class="hljs-string">&quot;mysql+pymysql://root:root@localhost:3306/orm_test&quot;</span>)<br>    <span class="hljs-comment"># 创建DBSession类型</span><br>    DBSession = sessionmaker(bind=engine)<br><br>    <span class="hljs-comment"># 创建session对象</span><br>    session = DBSession()<br>    <span class="hljs-comment"># 插入单条数据</span><br>    <span class="hljs-comment"># 创建新User对象</span><br>    new_user = Users(<span class="hljs-built_in">id</span>=<span class="hljs-number">1</span>, name=<span class="hljs-string">&#x27;Jack&#x27;</span>, age=<span class="hljs-number">25</span>, place=<span class="hljs-string">&#x27;USA&#x27;</span>, insert_time=get_time())<br>    <span class="hljs-comment"># 添加到session</span><br>    session.add(new_user)<br>    <span class="hljs-comment"># 提交即保存到数据库</span><br>    session.commit()<br><br>    time.sleep(<span class="hljs-number">5</span>)<br><br>    <span class="hljs-comment"># 插入多条数据</span><br>    user_list = [Users(<span class="hljs-built_in">id</span>=<span class="hljs-number">2</span>, name=<span class="hljs-string">&#x27;Green&#x27;</span>, age=<span class="hljs-number">26</span>, place=<span class="hljs-string">&#x27;UK&#x27;</span>, insert_time=get_time()),<br>                 Users(<span class="hljs-built_in">id</span>=<span class="hljs-number">3</span>, name=<span class="hljs-string">&#x27;Alex&#x27;</span>, age=<span class="hljs-number">31</span>, place=<span class="hljs-string">&#x27;GER&#x27;</span>, insert_time=get_time()),<br>                 Users(<span class="hljs-built_in">id</span>=<span class="hljs-number">4</span>, name=<span class="hljs-string">&#x27;Chen&#x27;</span>, age=<span class="hljs-number">52</span>, place=<span class="hljs-string">&#x27;CHN&#x27;</span>, insert_time=get_time()),<br>                 Users(<span class="hljs-built_in">id</span>=<span class="hljs-number">5</span>, name=<span class="hljs-string">&#x27;Zhang&#x27;</span>, age=<span class="hljs-number">42</span>, place=<span class="hljs-string">&#x27;CHN&#x27;</span>, insert_time=get_time())<br>                 ]<br>    session.add_all(user_list)<br>    session.commit()<br>    <span class="hljs-comment"># 关闭session</span><br>    session.close()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;insert into db successfully!&#x27;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    insert_data()<br><br></code></pre></td></tr></table></figure><p>在需要同步的ES中创建对应的index为mysql_users, 其mapping如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;mysql_users&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;mappings&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;properties&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;age&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;integer&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;date_format(insert_time, &#x27;%y-%m-%d %h:%i:%s&#x27;)&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;fields&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;keyword&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;keyword&quot;</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;ignore_above&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">256</span><br>            <span class="hljs-punctuation">&#125;</span><br>          <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;insert_time&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;date&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;format&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;name&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;place&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;user_id&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;integer&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>下载Java链接Mysq的第三方Jar包<code>mysql-connector-java-8.0.16.jar</code>.</p><h2 id="全量数据同步">全量数据同步</h2><p>将Mysql中users表的数据全量同步至ES中的mysql_users这个index中.docker-compose.yml文件如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><code class="hljs yml"><br><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3&#x27;</span><br><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">mysql8.0:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">mysql:8.0</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">mysql8.0</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">always</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-attr">TZ:</span> <span class="hljs-string">Asia/Shanghai</span><br>      <span class="hljs-attr">MYSQL_ROOT_PASSWORD:</span> <span class="hljs-string">root</span><br>      <span class="hljs-attr">MYSQL_DATABASE:</span> <span class="hljs-string">orm_test</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-number">3306</span><span class="hljs-string">:3306</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./mysql/data/:/var/lib/mysql/</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./mysql/conf/:/etc/mysql/conf.d/</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./mysql/init/:/docker-entrypoint-initdb.d/</span><br>    <span class="hljs-attr">command:</span><br>      <span class="hljs-comment"># 将mysql8.0默认密码策略 修改为 原先 策略 (mysql8.0对其默认策略做了更改 会导致密码无法匹配)</span><br>      <span class="hljs-string">--default-authentication-plugin=mysql_native_password</span><br>      <span class="hljs-string">--character-set-server=utf8mb4</span><br>      <span class="hljs-string">--collation-server=utf8mb4_general_ci</span><br>      <span class="hljs-string">--explicit_defaults_for_timestamp=true</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">mysql_elk_net</span><br><br>  <span class="hljs-attr">logstash:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">logstash-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">docker.elastic.co/logstash/logstash:7.17.0</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./logstash/config/logstash.yml:/usr/share/logstash/logstash.yml</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./logstash/data:/usr/share/logstash/data</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./logstash/pipeline:/usr/share/logstash/pipeline</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">mysql_elk_net</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elasticsearch</span><br><br>  <span class="hljs-attr">elasticsearch:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">elasticsearch-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">elasticsearch:7.17.0</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;ES_JAVA_OPTS=-Xms1024m -Xmx1024m&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;http.host=0.0.0.0&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;node.name=elastic01&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;cluster.name=cluster_elasticsearch&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;discovery.type=single-node&quot;</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9200:9200&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9300:9300&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./es/plugins:/usr/share/elasticsearch/plugins</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./es/data:/usr/share/elasticsearch/data</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">mysql_elk_net</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">mysql8.0</span><br><br>  <span class="hljs-attr">kibana:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">kibana-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">kibana:7.17.0</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;5601:5601&quot;</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">mysql_elk_net</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elasticsearch</span><br><br><span class="hljs-comment"># 网络配置</span><br><span class="hljs-attr">networks:</span><br>  <span class="hljs-attr">mysql_elk_net:</span><br>    <span class="hljs-attr">driver:</span> <span class="hljs-string">bridge</span><br></code></pre></td></tr></table></figure><p>logstash.conf配置如下:</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">input</span> &#123;<br>  <span class="hljs-string">jdbc</span> &#123;<br>    <span class="hljs-string">jdbc_driver_library</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;/usr/share/logstash/data/mysql-connector-java-8.0.16.jar&quot;</span><br>    <span class="hljs-string">jdbc_driver_class</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;com.mysql.cj.jdbc.Driver&quot;</span><br>    <span class="hljs-string">jdbc_connection_string</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;jdbc:mysql://mysql8.0:3306/orm_test?useSSL=false&amp;allowPublicKeyRetrieval=true&amp;serverTimezone=UTC&quot;</span><br>    <span class="hljs-string">jdbc_user</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;root&quot;</span><br>    <span class="hljs-string">jdbc_password</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;root&quot;</span><br>    <span class="hljs-comment"># 为了格式化日期，需要将date字段转换为字符串</span><br>    <span class="hljs-string">statement</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;SELECT id as user_id, name, age, place, date_format(insert_time, &#x27;%Y-%m-%d %H:%i:%S&#x27;) as insert_time from users&quot;</span><br>  &#125;<br>&#125;<br><span class="hljs-string">filter</span> &#123;<br>  <span class="hljs-string">mutate</span> &#123;<br>       <span class="hljs-string">remove_field</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;@timestamp&quot;</span>]<br>  &#125;<br>  <span class="hljs-string">mutate</span> &#123;<br>       <span class="hljs-string">remove_field</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;@version&quot;</span>]<br>  &#125;<br>&#125;<br><span class="hljs-string">output</span> &#123;<br>  <span class="hljs-string">stdout</span> &#123;<br>    <span class="hljs-string">codec</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">rubydebug</span><br>  &#125;<br>  <span class="hljs-string">elasticsearch</span> &#123;<br>    <span class="hljs-string">hosts</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;http://elasticsearch:9200&quot;</span>]<br>    <span class="hljs-string">index</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;mysql_users&quot;</span><br>    <span class="hljs-string">document_id</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;<span class="hljs-template-variable">%&#123;user_id&#125;</span>&quot;</span><br>    <span class="hljs-string">action</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;index&quot;</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>对ES中的mysql_users进行查询，如下图：</p><figure><img src="https://s2.loli.net/2023/12/24/VCjx71aSscR5enK.png"alt="ES中已同步MySQL表中的全量数据" /><figcaptionaria-hidden="true">ES中已同步MySQL表中的全量数据</figcaption></figure><h2 id="增量数据同步">增量数据同步</h2><p>docker-compose.yml文件同上述全量数据同步。在增量数据同步时，对logstash.conf修改如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">input</span> &#123;<br>  <span class="hljs-string">jdbc</span> &#123;<br>    <span class="hljs-string">jdbc_driver_library</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;/usr/share/logstash/data/mysql-connector-java-8.0.16.jar&quot;</span><br>    <span class="hljs-string">jdbc_driver_class</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;com.mysql.cj.jdbc.Driver&quot;</span><br>    <span class="hljs-string">jdbc_connection_string</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;jdbc:mysql://mysql8.0:3306/orm_test?useSSL=false&amp;allowPublicKeyRetrieval=true&amp;serverTimezone=UTC&quot;</span><br>    <span class="hljs-string">jdbc_user</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;root&quot;</span><br>    <span class="hljs-string">jdbc_password</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;root&quot;</span><br>    <span class="hljs-comment"># 为了格式化日期，需要将date字段转换为字符串</span><br>    <span class="hljs-string">statement</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;SELECT id as user_id,name,age,place,date_format(insert_time, &#x27;%Y-%m-%d %H:%i:%S&#x27;) as insert_time from users where insert_time &gt; :sql_last_value&quot;</span><br>    <span class="hljs-string">record_last_run</span> <span class="hljs-string">=&gt;</span> <span class="hljs-literal">true</span><br>    <span class="hljs-string">use_column_value</span> <span class="hljs-string">=&gt;</span> <span class="hljs-literal">true</span><br>    <span class="hljs-string">tracking_column_type</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;timestamp&quot;</span><br>    <span class="hljs-string">tracking_column</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;insert_time&quot;</span><br>    <span class="hljs-string">last_run_metadata_path</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;./user&quot;</span><br>    <span class="hljs-string">schedule</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;* * * * *&quot;</span><br>  &#125;<br>&#125;<br><span class="hljs-string">filter</span> &#123;<br>  <span class="hljs-string">mutate</span> &#123;<br>       <span class="hljs-string">remove_field</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;@timestamp&quot;</span>]<br>  &#125;<br>  <span class="hljs-string">mutate</span> &#123;<br>       <span class="hljs-string">remove_field</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;@version&quot;</span>]<br>  &#125;<br>&#125;<br><span class="hljs-string">output</span> &#123;<br>  <span class="hljs-string">stdout</span> &#123;<br>    <span class="hljs-string">codec</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">rubydebug</span><br>  &#125;<br>  <span class="hljs-string">elasticsearch</span> &#123;<br>    <span class="hljs-string">hosts</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;http://elasticsearch:9200&quot;</span>]<br>    <span class="hljs-string">index</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;mysql_users&quot;</span><br>    <span class="hljs-string">document_id</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;<span class="hljs-template-variable">%&#123;user_id&#125;</span>&quot;</span><br>    <span class="hljs-string">action</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;index&quot;</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>跟全量抽取的配置相比，上述配置input部分的<code>jdbc插件</code>配置有所改变。</p><ul><li>statement的SQL语句，末尾加上了where条件，表示只查询insert_time字段大于最后一次抽取标记的数据。</li><li>record_last_run设置为true，表示要保存抽取标记，抽取标记的保存路径在last_run_metadata_path中指定。</li><li>tracking_column_type设置为timestamp表示抽取标记字段是时间类型的，如果选择自增长数字主键作为抽取标记，则tracking_column_type应当设置为numeric。</li><li>配置tracking_column用于指定抽取标记的列名称，use_column_value设置为true表示使用数据的内容作为抽取标记，否则使用最后一次查询的时间作为抽取标记。</li><li>最后schedule用于配置定时抽取的<strong>cron表达式</strong>，"* * * **"表示每分钟抽取一次。</li></ul><p>执行时，由于第一次没有抽取标记，该脚本会抽取MySQL表users的全部数据到索引mysql_users，抽取完后，会在脚本的当前目录下生成一个user文件，打开它可以看到当前的数据抽取标记，该内容应当为字段insert_time的最新值。</p><figure><img src="https://s2.loli.net/2023/12/24/k5rGuSHB39sOjtz.png"alt="ES中已同步MySQL表中的增量数据" /><figcaptionaria-hidden="true">ES中已同步MySQL表中的增量数据</figcaption></figure><h2 id="总结">总结</h2><p>本文主要介绍了如何使用ELK来实现数据同步，将MySQL中的表数据同步至ElasticSearch中，可分为全量数据同步与增量数据同步。实际上，ELK不仅仅能提供MySQL同步至ES，还能做到各种数据库、文件系统等之间的同步，功能十分强大。</p><p>感谢大家的阅读~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ELK</tag>
      
      <tag>数据同步</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ELK学习笔记（一）</title>
    <link href="/ELK%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <url>/ELK%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="elk简介">ELK简介</h2><p>什么是ELK？</p><p>ELK是<code>Elasticsearch</code>、<code>Logstash</code>、<code>Kibana</code>三大开源框架首字母大写简称(后来出现的filebeat属于beats家族中的一员，可以用来替代logstash的数据收集功能，比较轻量级)，也被称为<code>Elastic Stack</code>。</p><figure><img src="https://s2.loli.net/2023/12/23/2TsGfNBvDcwRxU8.png"alt="ELK架构简图" /><figcaption aria-hidden="true">ELK架构简图</figcaption></figure><h3 id="filebeat">Filebeat</h3><p>Filebeat是用于转发和集中日志数据的轻量级传送工具。Filebeat监视您指定的日志文件或位置，收集日志事件，并将它们转发到Elasticsearch或Logstash进行索引。Filebeat的工作方式如下：启动Filebeat时，它将启动一个或多个输入，这些输入将在为日志数据指定的位置中查找。对于Filebeat所找到的每个日志，Filebeat都会启动收集器。每个收集器都读取单个日志以获取新内容，并将新日志数据发送到libbeat，libbeat将聚集事件，并将聚集的数据发送到为Filebeat配置的输出。</p><h3 id="logstash">Logstash</h3><p>Logstash是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。Logstash能够动态地采集、转换和传输数据，不受格式或复杂度的影响。利用Grok从非结构化数据中派生出结构，从IP地址解码出地理坐标，匿名化或排除敏感字段，并简化整体处理过程。</p><h3 id="elasticsearch">ElasticSearch</h3><p>Elasticsearch是ElasticStack核心的分布式搜索和分析引擎,是一个基于Lucene、分布式、通过Restful方式进行交互的近实时搜索平台框架。Elasticsearch为所有类型的数据提供近乎实时的搜索和分析。无论您是结构化文本还是非结构化文本，数字数据或地理空间数据，Elasticsearch都能以支持快速搜索的方式有效地对其进行存储和索引。</p><h3 id="kibana">Kibana</h3><p>Kibana是一个针对Elasticsearch的开源分析及可视化平台，用来搜索、查看交互存储在Elasticsearch索引中的数据。使用Kibana，可以通过各种图表进行高级数据分析及展示。并且可以为Logstash 和 ElasticSearch 提供的日志分析友好的 Web界面，可以汇总、分析和搜索重要数据日志。还可以让海量数据更容易理解。它操作简单，基于浏览器的用户界面可以快速创建仪表板（dashboard）实时显示Elasticsearch查询动态。</p><h2 id="logstash入门">Logstash入门</h2><p>使用Docker-Compose启动Logstash服务，其中docker-compose.yml文件如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.1&quot;</span><br><span class="hljs-comment"># 服务配置</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">logstash:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">logstash-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">docker.elastic.co/logstash/logstash:7.17.0</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./logstash/data:/usr/share/logstash/data</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./logstash/pipeline:/usr/share/logstash/pipeline</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elk_net</span><br><br><span class="hljs-comment"># 网络配置</span><br><span class="hljs-attr">networks:</span><br>  <span class="hljs-attr">elk_net:</span><br>    <span class="hljs-attr">driver:</span> <span class="hljs-string">bridge</span><br></code></pre></td></tr></table></figure><h3 id="示例配置1标准输入输出">示例配置1（标准输入、输出）</h3><p>每隔10秒输出字符串：Hello from Logstash!</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">input</span> &#123;<br>  <span class="hljs-string">heartbeat</span> &#123;<br>    <span class="hljs-string">interval</span> <span class="hljs-string">=&gt;</span> <span class="hljs-number">10</span><br>    <span class="hljs-string">message</span>  <span class="hljs-string">=&gt;</span> <span class="hljs-string">&#x27;Hello from Logstash!&#x27;</span><br>  &#125;<br>&#125;<br><span class="hljs-string">output</span> &#123;<br><span class="hljs-string">stdout</span> &#123;<br>        <span class="hljs-string">codec</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">rubydebug</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="示例配置2读取文件">示例配置2（读取文件）</h3><p>读取文件内容(文件的最后一行将不会读取)，示例文件为test.log</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs txt">hello world!<br>From Shanghai To Beijing<br>this is a log for test in logstash!<br><br></code></pre></td></tr></table></figure><p>配置文件如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">input</span> &#123;<br>  <span class="hljs-string">file</span> &#123;<br>    <span class="hljs-string">path</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;/usr/share/logstash/data/test.log&quot;</span><br>    <span class="hljs-string">start_position</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;beginning&quot;</span><br>  &#125;<br>&#125;<br><span class="hljs-string">output</span> &#123;<br><span class="hljs-string">stdout</span> &#123;<br>        <span class="hljs-string">codec</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">rubydebug</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>读取结果如下（顺序已打乱）：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs txt">logstash-7.17.0  | &#123;<br>logstash-7.17.0  |        &quot;message&quot; =&gt; &quot;hello world!&quot;,<br>logstash-7.17.0  |     &quot;@timestamp&quot; =&gt; 2023-12-23T08:43:22.836Z,<br>logstash-7.17.0  |           &quot;host&quot; =&gt; &quot;333e14d2874a&quot;,<br>logstash-7.17.0  |           &quot;path&quot; =&gt; &quot;/usr/share/logstash/data/test.log&quot;,<br>logstash-7.17.0  |       &quot;@version&quot; =&gt; &quot;1&quot;<br>logstash-7.17.0  | &#125;<br>logstash-7.17.0  | &#123;<br>logstash-7.17.0  |        &quot;message&quot; =&gt; &quot;this is a log for test in logstash!&quot;,<br>logstash-7.17.0  |     &quot;@timestamp&quot; =&gt; 2023-12-23T08:43:22.843Z,<br>logstash-7.17.0  |           &quot;host&quot; =&gt; &quot;333e14d2874a&quot;,<br>logstash-7.17.0  |           &quot;path&quot; =&gt; &quot;/usr/share/logstash/data/test.log&quot;,<br>logstash-7.17.0  |       &quot;@version&quot; =&gt; &quot;1&quot;<br>logstash-7.17.0  | &#125;<br>logstash-7.17.0  | &#123;<br>logstash-7.17.0  |        &quot;message&quot; =&gt; &quot;From Shanghai To Beijing&quot;,<br>logstash-7.17.0  |     &quot;@timestamp&quot; =&gt; 2023-12-23T08:43:22.842Z,<br>logstash-7.17.0  |           &quot;host&quot; =&gt; &quot;333e14d2874a&quot;,<br>logstash-7.17.0  |           &quot;path&quot; =&gt; &quot;/usr/share/logstash/data/test.log&quot;,<br>logstash-7.17.0  |       &quot;@version&quot; =&gt; &quot;1&quot;<br>logstash-7.17.0  | &#125;<br></code></pre></td></tr></table></figure><h3 id="示例配置3grok插件">示例配置3（Grok插件）</h3><p>Grok为正则表达式，Logstash（v4.4.3）已内置120种表达式，参考网址为：<ahref="https://github.com/logstash-plugins/logstash-patterns-core/tree/main/patterns">https://github.com/logstash-plugins/logstash-patterns-core/tree/main/patterns</a>.</p><p>读取Nginx日志文件，并使用Grok进行过滤。Nginx文件示例如下：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs txt">112.195.209.90 - - [20/Feb/2018:12:12:14 +0800] &quot;GET / HTTP/1.1&quot; 200 190 &quot;-&quot; &quot;Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Mobile Safari/537.36&quot; &quot;-&quot;<br><br></code></pre></td></tr></table></figure><p>配置文件如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">input</span> &#123;<br>  <span class="hljs-string">file</span> &#123;<br>    <span class="hljs-string">path</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;/usr/share/logstash/data/test.log&quot;</span><br>    <span class="hljs-string">start_position</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;beginning&quot;</span><br>  &#125;<br>&#125;<br><span class="hljs-string">filter</span> &#123;<br>    <span class="hljs-string">grok</span> &#123;<br>        <span class="hljs-string">match</span> <span class="hljs-string">=&gt;</span> &#123;<br>            <span class="hljs-string">&quot;message&quot;</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;<span class="hljs-template-variable">%&#123;COMBINEDAPACHELOG&#125;</span>&quot;</span><br>        &#125;<br>    &#125;<br>&#125;<br><span class="hljs-string">output</span> &#123;<br><span class="hljs-string">stdout</span> &#123;<br>        <span class="hljs-string">codec</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">rubydebug</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>解析结果为：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  | &#123;<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |        <span class="hljs-string">&quot;@version&quot;</span> =&gt; <span class="hljs-string">&quot;1&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |         <span class="hljs-string">&quot;message&quot;</span> =&gt; <span class="hljs-string">&quot;112.195.209.90 - - [20/Feb/2018:12:12:14 +0800] \&quot;GET / HTTP/1.1\&quot; 200 190 \&quot;-\&quot; \&quot;Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Mobile Safari/537.36\&quot; \&quot;-\&quot;&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |       <span class="hljs-string">&quot;timestamp&quot;</span> =&gt; <span class="hljs-string">&quot;20/Feb/2018:12:12:14 +0800&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |        <span class="hljs-string">&quot;referrer&quot;</span> =&gt; <span class="hljs-string">&quot;\&quot;-\&quot;&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |           <span class="hljs-string">&quot;agent&quot;</span> =&gt; <span class="hljs-string">&quot;\&quot;Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Mobile Safari/537.36\&quot;&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |            <span class="hljs-string">&quot;host&quot;</span> =&gt; <span class="hljs-string">&quot;fa3dbceea206&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |         <span class="hljs-string">&quot;request&quot;</span> =&gt; <span class="hljs-string">&quot;/&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |        <span class="hljs-string">&quot;clientip&quot;</span> =&gt; <span class="hljs-string">&quot;112.195.209.90&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |            <span class="hljs-string">&quot;path&quot;</span> =&gt; <span class="hljs-string">&quot;/usr/share/logstash/data/test.log&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |            <span class="hljs-string">&quot;verb&quot;</span> =&gt; <span class="hljs-string">&quot;GET&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |            <span class="hljs-string">&quot;auth&quot;</span> =&gt; <span class="hljs-string">&quot;-&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |        <span class="hljs-string">&quot;response&quot;</span> =&gt; <span class="hljs-string">&quot;200&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |           <span class="hljs-string">&quot;ident&quot;</span> =&gt; <span class="hljs-string">&quot;-&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |           <span class="hljs-string">&quot;bytes&quot;</span> =&gt; <span class="hljs-string">&quot;190&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |     <span class="hljs-string">&quot;httpversion&quot;</span> =&gt; <span class="hljs-string">&quot;1.1&quot;</span>,<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  |      <span class="hljs-string">&quot;@timestamp&quot;</span> =&gt; <span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">23</span>T09:<span class="hljs-number">33</span>:<span class="hljs-number">50</span>.<span class="hljs-number">220</span>Z<br><span class="hljs-attribute">logstash</span>-<span class="hljs-number">7</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>  | &#125;<br></code></pre></td></tr></table></figure><p>Kibana在Dev Tools中内置了Grok Debugger(调试器)：</p><figure><img src="https://s2.loli.net/2023/12/23/xAQ8bKothP3qNXk.png"alt="Kibana中的Grok调试器" /><figcaption aria-hidden="true">Kibana中的Grok调试器</figcaption></figure><h3 id="示例解析配置4多行读取插件-multiline">示例解析配置4（多行读取插件multiline）</h3><p>对 multiline 插件来说，有三个设置比较重要：negate、pattern 和what。</p><ul><li>pattern: 类型是string，要匹配的正则表达式</li><li>negate: 类型是boolean，默认false，否定正则表达式</li><li>what: 必须设置，可以为 previous 或 next，如果正则表达式匹配了，那么该事件是属于下一个或是前一个事件</li></ul><p>multiline插件可以多行读取。示例文件内容如下(注意最后一行为空行)：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs txt">[Aug/08/08 14:54:03] hello world<br>[Aug/08/09 14:54:04] hello logstash<br>    hello best practice<br>    hello raochenlin<br>[Aug/08/10 14:54:05] the end<br><br></code></pre></td></tr></table></figure><p>配置文件：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">input</span> &#123;<br>  <span class="hljs-string">file</span> &#123;<br>    <span class="hljs-string">path</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;/usr/share/logstash/data/test.log&quot;</span><br>    <span class="hljs-string">start_position</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;beginning&quot;</span><br>    <span class="hljs-string">codec</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">multiline</span> &#123;<br>        <span class="hljs-string">pattern</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;^\[&quot;</span><br>        <span class="hljs-string">negate</span> <span class="hljs-string">=&gt;</span> <span class="hljs-literal">true</span><br>        <span class="hljs-string">what</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;previous&quot;</span><br>    &#125;<br>  &#125;<br>&#125;<br><span class="hljs-string">output</span> &#123;<br><span class="hljs-string">stdout</span> &#123;<br>        <span class="hljs-string">codec</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">rubydebug</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>解析结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>       <span class="hljs-string">&quot;message&quot;</span> =&gt; <span class="hljs-string">&quot;[Aug/08/08 14:54:03] hello world&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">&quot;@timestamp&quot;</span> =&gt; <span class="hljs-number">2023</span><span class="hljs-number">-12</span><span class="hljs-number">-23</span>T10<span class="hljs-punctuation">:</span><span class="hljs-number">41</span><span class="hljs-punctuation">:</span><span class="hljs-number">20.884</span>Z<span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;path&quot;</span> =&gt; <span class="hljs-string">&quot;/usr/share/logstash/data/test.log&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;host&quot;</span> =&gt; <span class="hljs-string">&quot;b62820accf76&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;@version&quot;</span> =&gt; <span class="hljs-string">&quot;1&quot;</span><br><span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#123;</span><br>       <span class="hljs-string">&quot;message&quot;</span> =&gt; <span class="hljs-string">&quot;[Aug/08/09 14:54:04] hello logstash\n    hello best practice\n    hello raochenlin&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;path&quot;</span> =&gt; <span class="hljs-string">&quot;/usr/share/logstash/data/test.log&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;tags&quot;</span> =&gt; <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">[</span><span class="hljs-number">0</span><span class="hljs-punctuation">]</span> <span class="hljs-string">&quot;multiline&quot;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">&quot;@timestamp&quot;</span> =&gt; <span class="hljs-number">2023</span><span class="hljs-number">-12</span><span class="hljs-number">-23</span>T10<span class="hljs-punctuation">:</span><span class="hljs-number">44</span><span class="hljs-punctuation">:</span><span class="hljs-number">24.846</span>Z<span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;host&quot;</span> =&gt; <span class="hljs-string">&quot;b62820accf76&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;@version&quot;</span> =&gt; <span class="hljs-string">&quot;1&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>由于参数what设置为previous，因此只解析出两条数据。当what设置为next时，可解析出三条数据，但解析结果有变化，如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>       <span class="hljs-string">&quot;message&quot;</span> =&gt; <span class="hljs-string">&quot;[Aug/08/08 14:54:03] hello world&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;path&quot;</span> =&gt; <span class="hljs-string">&quot;/usr/share/logstash/data/test.log&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">&quot;@timestamp&quot;</span> =&gt; <span class="hljs-number">2023</span><span class="hljs-number">-12</span><span class="hljs-number">-23</span>T10<span class="hljs-punctuation">:</span><span class="hljs-number">49</span><span class="hljs-punctuation">:</span><span class="hljs-number">23.395</span>Z<span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;host&quot;</span> =&gt; <span class="hljs-string">&quot;492dfb254e78&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;@version&quot;</span> =&gt; <span class="hljs-string">&quot;1&quot;</span><br><span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#123;</span><br>       <span class="hljs-string">&quot;message&quot;</span> =&gt; <span class="hljs-string">&quot;    hello best practice\n    hello raochenlin\n[Aug/08/10 14:54:05] the end&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">&quot;@timestamp&quot;</span> =&gt; <span class="hljs-number">2023</span><span class="hljs-number">-12</span><span class="hljs-number">-23</span>T10<span class="hljs-punctuation">:</span><span class="hljs-number">49</span><span class="hljs-punctuation">:</span><span class="hljs-number">23.415</span>Z<span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;path&quot;</span> =&gt; <span class="hljs-string">&quot;/usr/share/logstash/data/test.log&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;host&quot;</span> =&gt; <span class="hljs-string">&quot;492dfb254e78&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;@version&quot;</span> =&gt; <span class="hljs-string">&quot;1&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;tags&quot;</span> =&gt; <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">[</span><span class="hljs-number">0</span><span class="hljs-punctuation">]</span> <span class="hljs-string">&quot;multiline&quot;</span><br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#123;</span><br>       <span class="hljs-string">&quot;message&quot;</span> =&gt; <span class="hljs-string">&quot;[Aug/08/09 14:54:04] hello logstash&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;path&quot;</span> =&gt; <span class="hljs-string">&quot;/usr/share/logstash/data/test.log&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-string">&quot;@timestamp&quot;</span> =&gt; <span class="hljs-number">2023</span><span class="hljs-number">-12</span><span class="hljs-number">-23</span>T10<span class="hljs-punctuation">:</span><span class="hljs-number">49</span><span class="hljs-punctuation">:</span><span class="hljs-number">23.414</span>Z<span class="hljs-punctuation">,</span><br>          <span class="hljs-string">&quot;host&quot;</span> =&gt; <span class="hljs-string">&quot;492dfb254e78&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;@version&quot;</span> =&gt; <span class="hljs-string">&quot;1&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h2 id="elk搭建简单示例">ELK搭建简单示例</h2><p>结合Logstash,ElasticSearch与Kibana，将data文件夹中的以log结尾的文件，逐行导入至ElasticSearch中。</p><p>logstash.conf配置如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">input</span> &#123;<br>  <span class="hljs-string">file</span> &#123;<br>    <span class="hljs-string">path</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;/usr/share/logstash/data/*.log&quot;</span><br>    <span class="hljs-string">start_position</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;beginning&quot;</span><br>  &#125;<br>&#125;<br><span class="hljs-string">output</span> &#123;<br><span class="hljs-string">stdout</span> &#123;<br>        <span class="hljs-string">codec</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">rubydebug</span><br>    &#125;<br>    <span class="hljs-string">elasticsearch</span> &#123;<br>        <span class="hljs-string">hosts</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;http://elasticsearch:9200&quot;</span>]<br>        <span class="hljs-string">index</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;test_log&quot;</span><br>        <span class="hljs-string">action</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;index&quot;</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>docker-compose.yml文件如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.1&quot;</span><br><span class="hljs-comment"># 服务配置</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">logstash:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">logstash-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">docker.elastic.co/logstash/logstash:7.17.0</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./logstash/config/logstash.yml:/usr/share/logstash/logstash.yml</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./logstash/data:/usr/share/logstash/data</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./logstash/pipeline:/usr/share/logstash/pipeline</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elk_net</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elasticsearch</span><br><br>  <span class="hljs-attr">elasticsearch:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">elasticsearch-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">elasticsearch:7.17.0</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;ES_JAVA_OPTS=-Xms1024m -Xmx1024m&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;http.host=0.0.0.0&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;node.name=elastic01&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;cluster.name=cluster_elasticsearch&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;discovery.type=single-node&quot;</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9200:9200&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9300:9300&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./es/plugins:/usr/share/elasticsearch/plugins</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./es/data:/usr/share/elasticsearch/data</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elk_net</span><br><br>  <span class="hljs-attr">kibana:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">kibana-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">kibana:7.17.0</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;5601:5601&quot;</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elk_net</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elasticsearch</span><br><br><span class="hljs-comment"># 网络配置</span><br><span class="hljs-attr">networks:</span><br>  <span class="hljs-attr">elk_net:</span><br>    <span class="hljs-attr">driver:</span> <span class="hljs-string">bridge</span><br></code></pre></td></tr></table></figure><h2 id="elk日志系统实战">ELK日志系统实战</h2><p>我们来设计这样一个日志系统，其中Logstash可将Flask运行过程中的日志进行收集，并导入至ElasticSearch中，再使用Kibana进行数据分析。</p><h3 id="flask服务">Flask服务</h3><p>使用Flask构建简单的web服务，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @file: server.py</span><br><span class="hljs-comment"># @time: 2023/12/23 19:17</span><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, Response<br><span class="hljs-keyword">import</span> logging<br><br>logging.basicConfig(filename=<span class="hljs-string">&#x27;../logstash/data/flask.log&#x27;</span>,<br>                    level=logging.DEBUG,<br>                    <span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;%(asctime)s-%(filename)s-%(funcName)s-%(levelname)s-%(message)s&#x27;</span>)<br>logger = logging.getLogger()<br><br>app = Flask(<span class="hljs-string">&quot;elk_test&quot;</span>)<br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">index</span>():<br>    t1 = time.time()<br>    logger.info(<span class="hljs-string">f&quot;api_endpoint: /, status: 200, cost_time: <span class="hljs-subst">&#123;(time.time() - t1) * <span class="hljs-number">1000</span>&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello index&quot;</span>, <span class="hljs-number">200</span><br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/io_task&quot;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">io_task</span>():<br>    t1 = time.time()<br>    time.sleep(<span class="hljs-number">2</span>)<br>    logger.info(<span class="hljs-string">f&quot;api_endpoint: /io_task, status: 200, cost_time: <span class="hljs-subst">&#123;(time.time() - t1) * <span class="hljs-number">1000</span>&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;IO bound task finish!&quot;</span>, <span class="hljs-number">200</span><br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/cpu_task&quot;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cpu_task</span>():<br>    t1 = time.time()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10000</span>):<br>        n = i*i*i<br>    logger.info(<span class="hljs-string">f&quot;api_endpoint: /cpu_task, status: 200, cost_time: <span class="hljs-subst">&#123;(time.time() - t1) * <span class="hljs-number">1000</span>&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;CPU bound task finish!&quot;</span>, <span class="hljs-number">200</span><br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/random_sleep&quot;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">random_sleep</span>():<br>    t1 = time.time()<br>    time.sleep(random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>))<br>    logger.info(<span class="hljs-string">f&quot;api_endpoint: /random_sleep, status: 200, cost_time: <span class="hljs-subst">&#123;(time.time() - t1) * <span class="hljs-number">1000</span>&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;random sleep&quot;</span>, <span class="hljs-number">200</span><br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/random_status&quot;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">random_status</span>():<br>    t1 = time.time()<br>    status_code = random.choice([<span class="hljs-number">200</span>] * <span class="hljs-number">6</span> + [<span class="hljs-number">300</span>, <span class="hljs-number">400</span>, <span class="hljs-number">400</span>, <span class="hljs-number">500</span>])<br>    logger.info(<span class="hljs-string">f&quot;api_endpoint: /random_status, status: <span class="hljs-subst">&#123;status_code&#125;</span>, cost_time: <span class="hljs-subst">&#123;(time.time() - t1) * <span class="hljs-number">1000</span>&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">return</span> Response(<span class="hljs-string">&quot;random status&quot;</span>, status=status_code)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    app.run(host=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, port=<span class="hljs-number">5000</span>, debug=<span class="hljs-literal">True</span>)<br><br></code></pre></td></tr></table></figure><p>使用下面的shell脚本进行HTTP请求模拟：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">TIMES=5<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> $(<span class="hljs-built_in">eval</span> <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;&#123;1..<span class="hljs-variable">$TIMES</span>&#125;&quot;</span>)<br><span class="hljs-keyword">do</span><br>    siege -c 1 -r 10 http://localhost:5000/<br>    siege -c 1 -r 5 http://localhost:5000/io_task<br>    siege -c 1 -r 5 http://localhost:5000/cpu_task<br>    siege -c 1 -r 3 http://localhost:5000/random_sleep<br>    siege -c 1 -r 10 http://localhost:5000/random_status<br>    <span class="hljs-built_in">sleep</span> 5<br><span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><p>日志记录在flask.log文件中。</p><h3 id="elk搭建">ELK搭建</h3><p>对上述日志，搭建ELK，docker-compose.yml同上述<code>ELK搭建简单示例</code>，logstash.conf改动如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">input</span> &#123;<br>  <span class="hljs-string">file</span> &#123;<br>    <span class="hljs-string">path</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;/usr/share/logstash/data/flask.log&quot;</span><br>    <span class="hljs-string">start_position</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;beginning&quot;</span><br>  &#125;<br>&#125;<br><span class="hljs-string">filter</span> &#123;<br>    <span class="hljs-comment"># 只对cost_time所在列进行解析</span><br>    <span class="hljs-string">if</span> <span class="hljs-string">&quot;cost_time&quot;</span> <span class="hljs-string">in</span> [<span class="hljs-string">message</span>] &#123;<br>        <span class="hljs-string">grok</span> &#123;<br>            <span class="hljs-string">match</span> <span class="hljs-string">=&gt;</span> &#123;<br>                <span class="hljs-string">&quot;message&quot;</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;<span class="hljs-template-variable">%&#123;TIMESTAMP_ISO8601:request_finish_time&#125;</span>-<span class="hljs-template-variable">%&#123;WORD:script&#125;</span>.py-<span class="hljs-template-variable">%&#123;WORD:module&#125;</span>-<span class="hljs-template-variable">%&#123;LOGLEVEL:loglevel&#125;</span>-api_endpoint: <span class="hljs-template-variable">%&#123;DATA:api_endpoint&#125;</span>, status: <span class="hljs-template-variable">%&#123;NUMBER:status:int&#125;</span>, cost_time: <span class="hljs-template-variable">%&#123;NUMBER:cost_time:float&#125;</span>&quot;</span><br>            &#125;<br>        &#125;<br>        <span class="hljs-comment"># 使用mutate过滤器替换字符</span><br>        <span class="hljs-string">mutate</span> &#123;<br>            <span class="hljs-comment"># 替换空格为T</span><br>            <span class="hljs-string">gsub</span> <span class="hljs-string">=&gt;</span> [ <span class="hljs-string">&quot;request_finish_time&quot;</span>, <span class="hljs-string">&quot; &quot;</span>, <span class="hljs-string">&quot;T&quot;</span> ]<br>            <span class="hljs-comment"># 替换逗号为点</span><br>            <span class="hljs-string">gsub</span> <span class="hljs-string">=&gt;</span> [ <span class="hljs-string">&quot;request_finish_time&quot;</span>, <span class="hljs-string">&quot;,&quot;</span>, <span class="hljs-string">&quot;.&quot;</span> ]<br>        &#125;<br><br>        <span class="hljs-comment"># 使用date过滤器解析和格式化日期</span><br>        <span class="hljs-string">date</span> &#123;<br>            <span class="hljs-string">match</span> <span class="hljs-string">=&gt;</span> [ <span class="hljs-string">&quot;request_finish_time&quot;</span>, <span class="hljs-string">&quot;ISO8601&quot;</span> ]<br>        &#125;<br>    &#125;<br>    <span class="hljs-string">else</span> &#123;<br>        <span class="hljs-string">drop</span> &#123; &#125;<br>    &#125;<br>&#125;<br><span class="hljs-string">output</span> &#123;<br><span class="hljs-string">stdout</span> &#123;<br>        <span class="hljs-string">codec</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">rubydebug</span><br>    &#125;<br>    <span class="hljs-string">elasticsearch</span> &#123;<br>        <span class="hljs-string">hosts</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;http://elasticsearch:9200&quot;</span>]<br>        <span class="hljs-string">index</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;flask_log&quot;</span><br>        <span class="hljs-string">action</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;index&quot;</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>只对有cost_time所在的行进行解析，其它行丢弃，导入至ElasticSearch中的flask_log这个索引中。</p><h3 id="数据分析">数据分析</h3><p>对上述的五个API Endpoint进行请求占比分析，饼图如下：</p><figure><img src="https://s2.loli.net/2023/12/23/DJkV8tpjqSKPRU1.png"alt="每个API的请求占比" /><figcaption aria-hidden="true">每个API的请求占比</figcaption></figure><p>同时，对cost_time进行数据分析，其平均值，90, 95, 99分位数如下表：</p><figure><img src="https://s2.loli.net/2023/12/23/tk1sDjF7LwNIrPf.png"alt="每个API的cost_time分析" /><figcaption aria-hidden="true">每个API的cost_time分析</figcaption></figure><p>上述的日志记录方式还有待改进，比如记录程序报错信息，使用json字段解析而不是Grok表达式会更容易些。</p><blockquote><p>注意：使用ChatGPT去做Grok正则表达式是真的好用啊，大模型的问答基本可用，只需略加修改即可，比如上述的Grok正则表达式用ChatGPT做的。</p></blockquote><h2 id="总结">总结</h2><p>ELK的用途广泛，比较常见的场景是日志系统，但也可以用来实现数据同步等功能。</p><p>本文主要介绍了Logstash工具和它的使用方式，以及ELK的搭建简单示例和实战。后面有机会将会介绍ELK的数据同步及Beats家族。</p><p>感谢大家的阅读~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ELK</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kibana中的可视化数据分析功能</title>
    <link href="/Kibana%E4%B8%AD%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8A%9F%E8%83%BD/"/>
    <url>/Kibana%E4%B8%AD%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8A%9F%E8%83%BD/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将详细介绍Kibana中的可视化数据分析功能。</p></blockquote><p><strong>ElasticSearch</strong>不仅提供了搜索功能，还能进行数据分析。而<strong>Kibana</strong>是<strong>ElasticSearch</strong>的可视化工具，提供了众多高级、好用的功能，其中之一便是可视化数据分析功能。</p><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486103&amp;idx=1&amp;sn=caa204eda0760bab69b7e40abff8e696&amp;chksm=fcb9b307cbce3a1108d305ec44281e3446241e90e9c17d62dd0b6eaa48cba5e20d31f0129584&amp;token=537956206&amp;lang=zh_CN#rd">NLP（八十一）智能文档问答助手项目改进</a>中，笔者介绍了在项目中已经使用到了可视化数据分析功能，因此，本文的示例数据即为<strong>智能文档问答助手项目</strong>中的数据。</p><p>本文将详细介绍如何在Kibana中使用可视化数据分析功能。</p><h2 id="准备">准备</h2><p>首先，本文中使用的<strong>ElasticSearch</strong>与<strong>Kibana</strong>工具的版本号为7.17.0，采用Docker容器化部署在本地。</p><p><strong>ElasticSearch</strong>中使用的index为<code>docs</code>，该index共有249个文档，其mapping如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;docs&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;mappings&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;properties&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;cont_id&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;integer&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;content&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;analyzer&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ik_smart&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;file_type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;keyword&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;insert_time&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;date&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;format&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;source&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;fields&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;keyword&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;keyword&quot;</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;ignore_above&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">256</span><br>            <span class="hljs-punctuation">&#125;</span><br>          <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p><code>cont_id</code>为划分后的chunk在原文中的序号，<code>content</code>为划分后的chunk内容，<code>file_type</code>为文档类型，共有txt,docx, pdf, string,url五种，<code>insert_time</code>为插入时间，<code>source</code>为chunk的来源。</p><h2 id="数据分析">数据分析</h2><h3 id="index管理">Index管理</h3><p>在Kibana左侧，选择Stack Management -&gt; IndexManagement，即可查看index情况：</p><figure><img src="https://s2.loli.net/2023/12/22/yM4ckaRlGtqzve3.png"alt="Kibana中的索引管理" /><figcaption aria-hidden="true">Kibana中的索引管理</figcaption></figure><p>在Index Patterns中点击docs这个索引，即可查看该索引中的字段：</p><figure><img src="https://s2.loli.net/2023/12/22/7bRt34quTiSOK8H.png"alt="docs*索引中的字段详情" /><figcaption aria-hidden="true">docs*索引中的字段详情</figcaption></figure><h3 id="discover">Discover</h3><p>在Kibana左侧，选择Home -&gt; Analytics -&gt;Discover，再选择index为docs*，在Available fields中对cont_id, content,file_type, insert_time,source五个字段点击+号，就能查看这些字段的数据，如下图：</p><figure><img src="https://s2.loli.net/2023/12/22/NbAkoVsWhTPwO1e.png"alt="全量数据查看" /><figcaption aria-hidden="true">全量数据查看</figcaption></figure><p>在上方的Search栏中，可进行条件筛选，我们去file_type为pdf的数据进行查看，命令为</p><blockquote><p>file_type : "pdf"</p></blockquote><p>数据如下图所示：</p><figure><img src="https://s2.loli.net/2023/12/22/2kTnOrjt8ozlf3q.png"alt="筛选后数据查看" /><figcaption aria-hidden="true">筛选后数据查看</figcaption></figure><p>Search栏还支持更高级的搜索条件，可使用KQL(Kibana QueryLanguage)轻松进行查询。</p><h2 id="图表">图表</h2><p>Kibana除了能够支持数据的可视化管理和开发调试之外，还支持用统计图表对索引数据进行可视化分析。你不需要写任何代码，直接在Kibana中使用现有的控件就能制作出各式各样的统计图表用于页面展示，比如折线图、直方图、饼图等。</p><p>点击 Analytics -&gt; Dashboard -&gt; Create new dashboard, 选择Createvisualization,在左侧选择index模式为docs，就能看到可分析的字段，如下：</p><figure><img src="https://s2.loli.net/2023/12/22/29MOJglNPyWXErd.png"alt="可用于分析的字段" /><figcaption aria-hidden="true">可用于分析的字段</figcaption></figure><blockquote><p>注意，text类型的字段不支持可视化分析。</p></blockquote><h3 id="table">Table</h3><p>点击file_type字段，即可看到数据统计信息，如下：</p><figure><img src="https://s2.loli.net/2023/12/22/c71j9s4iglZGNFx.png"alt="file_type字段统计信息" /><figcaption aria-hidden="true">file_type字段统计信息</figcaption></figure><p>点击 +号，在相邻的右上方选择Table，即可查看file_type各个取值的计数，如下：</p><figure><img src="https://s2.loli.net/2023/12/21/gSIFsClVfYJjch6.png"alt="每种文件类型的chunk数据表格" /><figcaption aria-hidden="true">每种文件类型的chunk数据表格</figcaption></figure><p>此时，在右边，Table栏下的Metrics已自动设置为Count ofrecords(计数)，如下：</p><figure><img src="https://s2.loli.net/2023/12/22/mJS7tRCq5c8nj94.png"alt="图表设置项" /><figcaption aria-hidden="true">图表设置项</figcaption></figure><p>可对Metrics再进行设置，比如修改列名，在Displayname中修改即可，还能设置文本对齐方式，是否隐藏列等功能。</p><figure><img src="https://s2.loli.net/2023/12/22/iGuRIUZcoMwyOek.png"alt="设置详情" /><figcaption aria-hidden="true">设置详情</figcaption></figure><p>对Metrics设置项，选择Unique count,字段选择source，即可统计不同文本类型的对应文件数量，如下：</p><figure><img src="https://s2.loli.net/2023/12/22/N74Am6lX58F1ISY.png"alt="每种文件类型的文件数量表格" /><figcaption aria-hidden="true">每种文件类型的文件数量表格</figcaption></figure><h2 id="横向纵向柱状图">横向、纵向柱状图</h2><p>柱状图需要设置横轴（X）与纵轴（Y），字段选取file_type，绘制不同文件类型对应的chunk数量。</p><p>选择纵向柱状图（Bar vertical），横轴为Top values offile_type，纵轴为Count of records，绘制的纵向柱状图如下：</p><figure><img src="https://s2.loli.net/2023/12/21/cXIglSrNWubDQwn.png"alt="每种文件类型的chunk纵向柱状图" /><figcaptionaria-hidden="true">每种文件类型的chunk纵向柱状图</figcaption></figure><p>在图标栏选择横向柱状图（BarHorizontal）,即可切换为横向柱状图，如下：</p><figure><img src="https://s2.loli.net/2023/12/22/ZMyL9Vrjp36oOqv.png"alt="每种文件类型的chunk横向柱状图" /><figcaptionaria-hidden="true">每种文件类型的chunk横向柱状图</figcaption></figure><h2 id="饼图">饼图</h2><p>饼图的绘制类似于柱状图，选择字段为file_type即可，Size by选择Count ofrecords，如下：</p><figure><img src="https://s2.loli.net/2023/12/21/kTY2mP6vcr5DKax.png"alt="每种文件类型的chunk饼图" /><figcaption aria-hidden="true">每种文件类型的chunk饼图</figcaption></figure><h2 id="折线图">折线图</h2><p>折线图（Line）的绘制类似于柱状图，横轴为insert_time，纵轴为Count ofrecords, 得到不同时间段的插入的chunk数量的折线图如下：</p><figure><img src="https://s2.loli.net/2023/12/21/d9IJatvEYi7P38W.png"alt="文件插入时间与chunk数量的折线图" /><figcaptionaria-hidden="true">文件插入时间与chunk数量的折线图</figcaption></figure><blockquote><p>注意，需要在上方的日历图标选择对应的时间段。重点需要注意的是，Kibana中的时间可能与ES中的时间字段取值可能有时区差，需留心，比如笔者在Kinana中的insert_time与ES中的insert_time就有时差，相差8个小时。</p></blockquote><p>Kibana还支持更多的图表类型，随着版本的更新，支持的图标类型会更丰富，笔者在这里不再一一赘述。</p><h2 id="canvas画布">Canvas（画布）</h2><p>Canvas画布可以创建一系列的可视化展示页面以呈现各种分析图表，还可以使用图片、文本框等组件图文并茂地展示数据。Canvas画布还可以自动播放，其效果有点类似PPT，你可以设置每个Canvas画布页面的轮播时间间隔。</p><p>笔者创建的Canvas例子如下：</p><figure><img src="https://s2.loli.net/2023/12/22/fRLVJ1NOInwpSWy.png"alt="示例Canvas" /><figcaption aria-hidden="true">示例Canvas</figcaption></figure><h2 id="总结">总结</h2><p>本文主要介绍了笔者在日常工作项目中会用到的Kibana可视化数据分析功能，主要介绍了Kibana的Index管理、统计图表绘制、Canvas绘制等。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kibana</tag>
      
      <tag>可视化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（八十一）智能文档问答助手项目改进</title>
    <link href="/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%B8%80%EF%BC%89%E6%99%BA%E8%83%BD%E6%96%87%E6%A1%A3%E9%97%AE%E7%AD%94%E5%8A%A9%E6%89%8B%E9%A1%B9%E7%9B%AE%E6%94%B9%E8%BF%9B/"/>
    <url>/NLP%EF%BC%88%E5%85%AB%E5%8D%81%E4%B8%80%EF%BC%89%E6%99%BA%E8%83%BD%E6%96%87%E6%A1%A3%E9%97%AE%E7%AD%94%E5%8A%A9%E6%89%8B%E9%A1%B9%E7%9B%AE%E6%94%B9%E8%BF%9B/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将介绍笔者自己的项目：智能文档问答助手项目的几个改进。</p></blockquote><p>本文将介绍笔者自己开源的项目：<strong>智能文档问答助手项目</strong>的几个改进点。</p><p>不熟悉这个项目的读者可以参考下面两篇文章及Github项目地址：</p><ul><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485425&amp;idx=1&amp;sn=bd85ddfce82d77ceec5a66cb96835400&amp;chksm=fcb9be61cbce37773109f9703c2b6c4256d5037c8bf4497dfb9ad0f296ce0ee4065255954c1c&amp;token=28280910&amp;lang=zh_CN#rd">NLP（六十一）使用Baichuan-13B-Chat模型构建智能文档</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485609&amp;idx=1&amp;sn=f8337b4822b1cdf95a586af6097ef288&amp;chksm=fcb9b139cbce382f735e4c119ade8084067cde0482910c72767f36a29e7291385cbe6dfbd6a9&amp;payreadticket=HJFJOt_DfmG3B-dmlm1HgcVHJP-S_fXfPwCpOqO05uqaij4NU-vn7HEWnzwgujoFA7BiQh8#rd">NLP（六十九）智能文档助手升级</a></li><li>llm_4_doc_qa: <ahref="https://github.com/percent4/llm_4_doc_qa">https://github.com/percent4/llm_4_doc_qa</a></li></ul><p>本次改进点如下：</p><ol type="1"><li>文件上传页面支持自定义输入文本</li><li>上传文件数据分析</li><li>在RAG架构中加入Rerank模块</li><li>加入ChatGPT系列模型</li><li>对问答结果加入模型评估</li></ol><p>下面将详细介绍上述改进点。</p><h2 id="自定义输入文本">自定义输入文本</h2><p>本项目中api/uploads接口用于文件上传，一共是三种形式：</p><ol type="1"><li>用户直接上传文件，文件格式暂时只支持txt, docx, pdf;</li><li>用户输入网页网址，后端调用LangChain中的selenium和unstructed模块进行网页解析;</li><li><strong>本次新增</strong>：支持用户自定义输入文本，必须填写文本来源和内容。</li></ol><figure><img src="https://s2.loli.net/2023/12/21/3f5p7hWwRtogsyL.png"alt="文件上传页面" /><figcaption aria-hidden="true">文件上传页面</figcaption></figure><h2 id="数据分析">数据分析</h2><p>为支持在Kibana中对上传文件内容进行数据分析，ElasticSearch中的<code>mapping</code>配置修改如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;docs&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;mappings&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;properties&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;cont_id&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;integer&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;content&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;analyzer&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ik_smart&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;file_type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;keyword&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;insert_time&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;date&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;format&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;source&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;fields&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;keyword&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;keyword&quot;</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;ignore_above&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">256</span><br>            <span class="hljs-punctuation">&#125;</span><br>          <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>其中,insert_time用于记录文本插入时间，source用于记录文件类型，共五种：</p><ul><li>txt: txt文件</li><li>docx: docx文件</li><li>pdf: pdf文件</li><li>url: 用户输入的网址</li><li>string: 用户自定义输入</li></ul><p>在Kibana中使用可视化功能进行数据分析，首先统计每种文件类型的chunk（对文本内容进行划分，每个单位记为一个chunk）数据表格及柱状图、饼图：</p><figure><img src="https://s2.loli.net/2023/12/21/gSIFsClVfYJjch6.png"alt="每种文件类型的chunk数据表格" /><figcaption aria-hidden="true">每种文件类型的chunk数据表格</figcaption></figure><figure><img src="https://s2.loli.net/2023/12/21/cXIglSrNWubDQwn.png"alt="每种文件类型的chunk柱状图" /><figcaption aria-hidden="true">每种文件类型的chunk柱状图</figcaption></figure><figure><img src="https://s2.loli.net/2023/12/21/kTY2mP6vcr5DKax.png"alt="每种文件类型的chunk饼图" /><figcaption aria-hidden="true">每种文件类型的chunk饼图</figcaption></figure><p>每个文件类型的文件数量（使用source.keyword字段进行统计）：</p><figure><img src="https://s2.loli.net/2023/12/21/fyQgkeG52AIx4W9.png"alt="每个文件类型的文件数量" /><figcaption aria-hidden="true">每个文件类型的文件数量</figcaption></figure><p>文件插入时间与chunk数量的折线图（可用于记录不同时间段，插入的chunk数量统计）：</p><figure><img src="https://s2.loli.net/2023/12/21/d9IJatvEYi7P38W.png"alt="文件插入时间与chunk数量的折线图" /><figcaptionaria-hidden="true">文件插入时间与chunk数量的折线图</figcaption></figure><p><strong>P.S.</strong></p><blockquote><p>Kibana的可视化功能还是相当丰富的，值得一学，后续笔者也会写文章专门介绍Kibana中的可视化功能。</p></blockquote><h2 id="rerank模块">Rerank模块</h2><p>本项目采用<strong>RAG</strong>框架进行文档问答，一般步骤为：</p><ol type="1"><li>文档划分（Document Split）</li><li>向量嵌入（Embedding）</li><li>文档获取（Retrieve）</li><li>Prompt工程（Prompt Engineering）</li><li>大模型问答（LLM）</li></ol><p>大致的流程图参考如下：</p><p><imgsrc="https://towhee.io/assets/img/task/retrieval-augmented-generation.png" /></p><p>但在实际使用过程中，召回阶段（Retrieve）的文档相关性及排序结果不是很好，因此需要加入Rerank阶段，即重排或精排阶段。</p><p>本次加入的Rerank模型为Cohere官方网站给出的Rerank模型，在效果评估中效果最好，优于BGE模型。</p><p>以下为Cohere Rerank模型的示例代码：</p><ul><li><p>输入query: <code>电子科技大学的官网？</code></p></li><li><p>使用Rerank前的召回文档排序（ES+Milvus, 按相似度排序）:</p></li></ul><blockquote><p>院校&amp;专业高考备考高一/高二家长助考新东方网主站中学高考高考资讯焦点新闻电子科技大学：2022年全国招生总计划5030人招生专业上有“三变化”新东方编辑整理 |2023-03-13 15:04 分享至复制链接1.请使用微信扫码2.打开网页后点击屏幕右上角分享按钮</p></blockquote><blockquote><p>拉斯哥大学交流学习的机会，也可以申请3+2、4+1等海外联合培养模式。师资主要由电子科技大学与格拉斯哥大学的优秀老师进行授课。毕业时所颁发的毕业证与学位证与“电子科技大学”招生名称的证书完全一致，同时还能获得格拉斯哥大学的学位证书。由于是首年进行招生，这个项目可能会成为今年填报志愿的价值洼地。</p></blockquote><blockquote><p>其次是深造情况，近十年学校深造率不断提升，最近两届毕业生深造率继续保持高位超过70%，位居全国所有高校的第4位。国内深造学生到双一流高校及研究院所深造的比例超过了99%，在出国（境）深造的学生中，去往世界前100位的大学就读占比超过70%。所以同样的，我们在深造方面，也是不仅深造率高，同样深造的质量也是非常高的。九、学校咨询方式或联系方式。1.信息平台微信公众号：电子科大本科招生（uestc_zs）官网：http://www.zs.uestc.edu.cn/</p></blockquote><blockquote><p>二、2022年学校招生计划如何安排？有无增减？今年电子科技大学的招生总规模与往年相比，维持相对的稳定。2022年，我们在全国招生总计划是5030人，其中“电子科技大学”将面向全国招生3300余人，“电子科技大学（沙河校区）”将面向部分省份招生1700余人。电子科技大学将继续采用“电子科技大学”、“电子科技大学（沙河校区）”两个名称进行招生，考生在填报志愿时应分别填报，录取时分别录取，对应着不同的录取分数线。</p></blockquote><p>Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> cohere<br><br>os.environ[<span class="hljs-string">&quot;COHERE_API_KEY&quot;</span>] = <span class="hljs-string">&quot;xxx&quot;</span><br><br>cohere_client = cohere.Client(os.getenv(<span class="hljs-string">&quot;COHERE_API_KEY&quot;</span>))<br><br>query = <span class="hljs-string">&quot;电子科技大学的官网？&quot;</span><br>docs = [<span class="hljs-string">&quot;院校&amp;专业高考备考高一/高二家长助考新东方网主站中学高考高考资讯焦点新闻电子科技大学：2022年全国招生总计划5030人 招生专业上有“三变化”新东方编辑整理 |2023-03-13 15:04  分享至  复制链接1.请使用微信扫码2.打开网页后点击屏幕右上角分享按钮&quot;</span>,<br>        <span class="hljs-string">&quot;拉斯哥大学交流学习的机会，也可以申请3+2、4+1等海外联合培养模式。师资主要由电子科技大学与格拉斯哥大学的优秀老师进行授课。毕业时所颁发的毕业证与学位证与“电子科技大学”招生名称的证书完全一致，同时还能获得格拉斯哥大学的学位证书。由于是首年进行招生，这个项目可能会成为今年填报志愿的价值洼地。&quot;</span>,<br>        <span class="hljs-string">&quot;其次是深造情况，近十年学校深造率不断提升，最近两届毕业生深造率继续保持高位超过70%，位居全国所有高校的第4位。国内深造学生到双一流高校及研究院所深造的比例超过了99%，在出国（境）深造的学生中，去往世界前100位的大学就读占比超过70%。所以同样的，我们在深造方面，也是不仅深造率高，同样深造的质量也是非常高的。九、学校咨询方式或联系方式。1.信息平台微信公众号：电子科大本科招生（uestc_zs）官网：http://www.zs.uestc.edu.cn/&quot;</span>,<br>        <span class="hljs-string">&quot;二、2022年学校招生计划如何安排？有无增减？今年电子科技大学的招生总规模与往年相比，维持相对的稳定。2022年，我们在全国招生总计划是5030人，其中“电子科技大学”将面向全国招生3300余人，“电子科技大学（沙河校区）”将面向部分省份招生1700余人。电子科技大学将继续采用“电子科技大学”、“电子科技大学（沙河校区）”两个名称进行招生，考生在填报志愿时应分别填报，录取时分别录取，对应着不同的录取分数线。&quot;</span>]<br><br>results = cohere_client.rerank(model=<span class="hljs-string">&quot;rerank-multilingual-v2.0&quot;</span>, query=query, documents=docs, top_n=<span class="hljs-number">4</span>)<br><br><span class="hljs-keyword">for</span> hit <span class="hljs-keyword">in</span> results:<br>    <span class="hljs-built_in">print</span>(hit.relevance_score, hit.document[<span class="hljs-string">&#x27;text&#x27;</span>])<br></code></pre></td></tr></table></figure><p>使用Rerank后的召回文档排序:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">0</span>.<span class="hljs-number">9482505</span> 其次是深造情况，近十年学校深造率不断提升，最近两届毕业生深造率继续保持高位超过<span class="hljs-number">70</span>%，位居全国所有高校的第<span class="hljs-number">4</span>位。国内深造学生到双一流高校及研究院所深造的比例超过了<span class="hljs-number">99</span>%，在出国（境）深造的学生中，去往世界前<span class="hljs-number">100</span>位的大学就读占比超过<span class="hljs-number">70</span>%。所以同样的，我们在深造方面，也是不仅深造率高，同样深造的质量也是非常高的。九、学校咨询方式或联系方式。<span class="hljs-number">1</span>.信息平台微信公众号：电子科大本科招生（uestc_zs）官网：http://www.zs.uestc.edu.cn/<br><span class="hljs-attribute">0</span>.<span class="hljs-number">07544844</span> 院校&amp;专业高考备考高一/高二家长助考新东方网主站中学高考高考资讯焦点新闻电子科技大学：<span class="hljs-number">2022</span>年全国招生总计划<span class="hljs-number">5030</span>人 招生专业上有“三变化”新东方编辑整理 |<span class="hljs-number">2023</span>-<span class="hljs-number">03</span>-<span class="hljs-number">13</span> <span class="hljs-number">15</span>:<span class="hljs-number">04</span>  分享至  复制链接<span class="hljs-number">1</span>.请使用微信扫码<span class="hljs-number">2</span>.打开网页后点击屏幕右上角分享按钮<br><span class="hljs-attribute">0</span>.<span class="hljs-number">012383785</span> 拉斯哥大学交流学习的机会，也可以申请<span class="hljs-number">3</span>+<span class="hljs-number">2</span>、<span class="hljs-number">4</span>+<span class="hljs-number">1</span>等海外联合培养模式。师资主要由电子科技大学与格拉斯哥大学的优秀老师进行授课。毕业时所颁发的毕业证与学位证与“电子科技大学”招生名称的证书完全一致，同时还能获得格拉斯哥大学的学位证书。由于是首年进行招生，这个项目可能会成为今年填报志愿的价值洼地。<br><span class="hljs-attribute">0</span>.<span class="hljs-number">007518718</span> 二、<span class="hljs-number">2022</span>年学校招生计划如何安排？有无增减？今年电子科技大学的招生总规模与往年相比，维持相对的稳定。<span class="hljs-number">2022</span>年，我们在全国招生总计划是<span class="hljs-number">5030</span>人，其中“电子科技大学”将面向全国招生<span class="hljs-number">3300</span>余人，“电子科技大学（沙河校区）”将面向部分省份招生<span class="hljs-number">1700</span>余人。电子科技大学将继续采用“电子科技大学”、“电子科技大学（沙河校区）”两个名称进行招生，考生在填报志愿时应分别填报，录取时分别录取，对应着不同的录取分数线。<br><br></code></pre></td></tr></table></figure><p>可以看到，召回阶段的文档相关性及排序结果不佳，但经过Rerank阶段后，文档相关性及排序结果得到很大改善。后续可以专门做实验来验证下，虽然网络上已经有不少公开实验结果了。</p><h2 id="加入chatgpt系列模型">加入ChatGPT系列模型</h2><p>之前的项目只支持国产中文大模型，如Baichuan, LLAMA-Chinese,InterLM等，本次新增<strong>ChatGPT-3.5</strong>和<strong>GPT-4</strong>模型，Embedding模型新增<strong>text-embedding-ada-002</strong>。</p><p>在笔者的使用测试中，Openai的<strong>ChatGPT-3.5</strong>和<strong>GPT-4</strong>模型问答效果优于之前的国产中文大模型。</p><h2 id="模型评估evaluation">模型评估（Evaluation）</h2><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247486067&amp;idx=1&amp;sn=715e9886f1b9f396a58f2b743ab8ca80&amp;chksm=fcb9b3e3cbce3af55c9327119a38ff273366136931f9b8b460ad15e4dc6f48aa9e0795da9005&amp;token=28280910&amp;lang=zh_CN#rd">NLP（八十）大模型评估（Evaluation）</a>中，笔者介绍了如何使用LangChain框架及GPT-4模型来进行模型评估。</p><p>因此，在本次的更新中，在可视化页面中加入了GPT-4模型评估，如下图：</p><figure><img src="https://s2.loli.net/2023/12/21/HlUEYeyoVQ8LtkZ.png"alt="GPT-4模型评估结果在metric列" /><figcaption aria-hidden="true">GPT-4模型评估结果在metric列</figcaption></figure><h2 id="总结">总结</h2><p><strong>智能文档问答助手项目</strong>是笔者在RAG研究方向中的一次开源实战，会注重实际体验效果，但更关注算法层面的实现。</p><p>因此，笔者会持续更新，也会更多地加入RAG框架上的优化点，欢迎大家关注~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文档问答</tag>
      
      <tag>RAG</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python中常见的装饰器（decorator）</title>
    <link href="/Python%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A3%85%E9%A5%B0%E5%99%A8%EF%BC%88decorator%EF%BC%89/"/>
    <url>/Python%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A3%85%E9%A5%B0%E5%99%A8%EF%BC%88decorator%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍Python中几个工作中常见的装饰器。</p></blockquote><p>本文将会介绍Python中几个日常工作中常用的装饰器（decorator），如下：</p><ul><li>计时装饰器</li><li>debug装饰器</li><li>日志装饰器</li><li>缓存装饰器</li><li>retry装饰器</li><li>其它装饰器</li></ul><h2 id="计时装饰器">计时装饰器</h2><p>计时装饰器用于统计函数的运行时间，采用time模块，记录函数运行前、后时间，得到函数运行时间。示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> wraps<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">timer</span>(<span class="hljs-params">func</span>):<br><span class="hljs-meta">    @wraps(<span class="hljs-params">func</span>)</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrapper</span>(<span class="hljs-params">*args, **kwargs</span>):<br>        start = time.time()<br>        result = func(*args, **kwargs)<br>        end = time.time()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Execution time of <span class="hljs-subst">&#123;func.__name__&#125;</span>: <span class="hljs-subst">&#123;end - start&#125;</span> seconds&quot;</span>)<br>        <span class="hljs-keyword">return</span> result<br>    <span class="hljs-keyword">return</span> wrapper<br><br><br><span class="hljs-meta">@timer</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">time_sleep</span>(<span class="hljs-params">n</span>):<br>    <span class="hljs-comment"># sleep for n seconds</span><br>    time.sleep(n)<br>    <span class="hljs-keyword">return</span> n<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    t = time_sleep(<span class="hljs-number">3</span>)<br>    <span class="hljs-built_in">print</span>(t)<br></code></pre></td></tr></table></figure><p>执行结果：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Execution</span> time of time_sleep: <span class="hljs-number">3</span>.<span class="hljs-number">0027120113372803</span> seconds<br><span class="hljs-attribute">3</span><br></code></pre></td></tr></table></figure><h2 id="debug装饰器">debug装饰器</h2><p>debug装饰器用于代码debug，打印出运行函数的函数名及参数，用于debug。示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> wraps<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">debug</span>(<span class="hljs-params">func</span>):<br><span class="hljs-meta">    @wraps(<span class="hljs-params">func</span>)</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrapper</span>(<span class="hljs-params">*args, **kwargs</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Calling <span class="hljs-subst">&#123;func.__name__&#125;</span> with args: <span class="hljs-subst">&#123;args&#125;</span> and kwargs: <span class="hljs-subst">&#123;kwargs&#125;</span>&quot;</span>)<br>        result = func(*args, **kwargs)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;func.__name__&#125;</span> returned: <span class="hljs-subst">&#123;result&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">return</span> result<br>    <span class="hljs-keyword">return</span> wrapper<br><br><br><span class="hljs-meta">@debug</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet</span>(<span class="hljs-params">name, message=<span class="hljs-string">&quot;Hello&quot;</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Returns a greeting message with the name&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;message&#125;</span>, <span class="hljs-subst">&#123;name&#125;</span>!&quot;</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(greet(<span class="hljs-string">&quot;Alice&quot;</span>))<br>    <span class="hljs-built_in">print</span>(greet(<span class="hljs-string">&quot;Bob&quot;</span>, message=<span class="hljs-string">&quot;Hi&quot;</span>))<br><br></code></pre></td></tr></table></figure><p>执行结果：</p><figure class="highlight erlang-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs erlang-repl">Calling greet with args: (<span class="hljs-string">&#x27;Alice&#x27;</span>,) and kwargs: &#123;&#125;<br>greet returned: Hello, Alice!<br>Hello, Alice!<br>Calling greet with args: (<span class="hljs-string">&#x27;Bob&#x27;</span>,) and kwargs: &#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">&#x27;Hi&#x27;</span>&#125;<br>greet returned: Hi, Bob!<br>Hi, Bob!<br></code></pre></td></tr></table></figure><h2 id="日志装饰器">日志装饰器</h2><p>日志装饰器用于在函数运行时打印日志，常用的日志模块有<code>logging</code>,<code>loguru</code>等。示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> wraps<br><span class="hljs-keyword">import</span> logging<br><br>logging.basicConfig(level=logging.DEBUG)<br>logger = logging.getLogger()<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">log</span>(<span class="hljs-params">func</span>):<br><span class="hljs-meta">    @wraps(<span class="hljs-params">func</span>)</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrapper</span>(<span class="hljs-params">*args, **kwargs</span>):<br>        args_repr = [<span class="hljs-built_in">repr</span>(a) <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> args]<br>        kwargs_repr = [<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;k&#125;</span>=<span class="hljs-subst">&#123;v!r&#125;</span>&quot;</span> <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> kwargs.items()]<br>        signature = <span class="hljs-string">&quot;, &quot;</span>.join(args_repr + kwargs_repr)<br>        logger.debug(<span class="hljs-string">f&quot;function <span class="hljs-subst">&#123;func.__name__&#125;</span> called with args <span class="hljs-subst">&#123;signature&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">try</span>:<br>            result = func(*args, **kwargs)<br>            <span class="hljs-keyword">return</span> result<br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            logger.exception(<span class="hljs-string">f&quot;Exception raised in <span class="hljs-subst">&#123;func.__name__&#125;</span>. exception: <span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(e)&#125;</span>&quot;</span>)<br>            <span class="hljs-keyword">raise</span> e<br>    <span class="hljs-keyword">return</span> wrapper<br><br><br><span class="hljs-meta">@log</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">divide</span>(<span class="hljs-params">a, b, message=<span class="hljs-string">&#x27;hi&#x27;</span></span>):<br>    <span class="hljs-keyword">return</span> a/b, message<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(divide(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, message=<span class="hljs-string">&#x27;good&#x27;</span>))<br>    <span class="hljs-built_in">print</span>(divide(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, message=<span class="hljs-string">&#x27;bad&#x27;</span>))<br><br></code></pre></td></tr></table></figure><p>执行结果：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">DEBUG</span>:root:<span class="hljs-keyword">function</span> divide <span class="hljs-keyword">called</span> <span class="hljs-keyword">with</span> args <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, message=<span class="hljs-string">&#x27;good&#x27;</span><br><span class="hljs-keyword">DEBUG</span>:root:<span class="hljs-keyword">function</span> divide <span class="hljs-keyword">called</span> <span class="hljs-keyword">with</span> args <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, message=<span class="hljs-string">&#x27;bad&#x27;</span><br>ERROR:root:<span class="hljs-keyword">Exception</span> raised <span class="hljs-keyword">in</span> divide. <span class="hljs-keyword">exception</span>: division <span class="hljs-keyword">by</span> zero<br>Traceback (most recent <span class="hljs-keyword">call</span> last):<br>  File &quot;/Users/admin/PycharmProjects/env_test/custom_decorator/log_decorator.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">17</span>, <span class="hljs-keyword">in</span> <span class="hljs-keyword">wrapper</span><br>    result = func(*args, **kwargs)<br>  File &quot;/Users/admin/PycharmProjects/env_test/custom_decorator/log_decorator.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">27</span>, <span class="hljs-keyword">in</span> divide<br>    <span class="hljs-keyword">return</span> a/b, message<br>ZeroDivisionError: division <span class="hljs-keyword">by</span> zero<br>Traceback (most recent <span class="hljs-keyword">call</span> last):<br>  File &quot;/Users/admin/PycharmProjects/env_test/custom_decorator/log_decorator.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">32</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    print(divide(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, message=<span class="hljs-string">&#x27;bad&#x27;</span>))<br>  File &quot;/Users/admin/PycharmProjects/env_test/custom_decorator/log_decorator.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">21</span>, <span class="hljs-keyword">in</span> <span class="hljs-keyword">wrapper</span><br>    <span class="hljs-keyword">raise</span> e<br>  File &quot;/Users/admin/PycharmProjects/env_test/custom_decorator/log_decorator.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">17</span>, <span class="hljs-keyword">in</span> <span class="hljs-keyword">wrapper</span><br>    result = func(*args, **kwargs)<br>  File &quot;/Users/admin/PycharmProjects/env_test/custom_decorator/log_decorator.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">27</span>, <span class="hljs-keyword">in</span> divide<br>    <span class="hljs-keyword">return</span> a/b, message<br>ZeroDivisionError: division <span class="hljs-keyword">by</span> zero<br>(<span class="hljs-number">2.0</span>, <span class="hljs-string">&#x27;good&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="缓存装饰器">缓存装饰器</h2><p>缓存装饰器用于实现缓存，比如LRU Cache等。下面的例子将使用LRUCache来缓存fibonacci函数的中间运行结果，从而加快函数运行时间，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> lru_cache<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fibonacci</span>(<span class="hljs-params">n</span>):<br>    <span class="hljs-keyword">if</span> n &lt;= <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> fibonacci(n-<span class="hljs-number">1</span>) + fibonacci(n-<span class="hljs-number">2</span>)<br><br><br><span class="hljs-meta">@lru_cache(<span class="hljs-params">maxsize=<span class="hljs-number">5</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cache_fibonacci</span>(<span class="hljs-params">n</span>):<br>    <span class="hljs-keyword">if</span> n &lt;= <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> cache_fibonacci(n-<span class="hljs-number">1</span>) + cache_fibonacci(n-<span class="hljs-number">2</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    t1 = time.time()<br>    <span class="hljs-built_in">print</span>(fibonacci(<span class="hljs-number">37</span>))<br>    t2 = time.time()<br>    <span class="hljs-built_in">print</span>(t2 - t1)<br>    <span class="hljs-built_in">print</span>(cache_fibonacci(<span class="hljs-number">37</span>))<br>    <span class="hljs-built_in">print</span>(time.time() - t2)<br></code></pre></td></tr></table></figure><p>执行结果：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">39088169</span><br><span class="hljs-attribute">3</span>.<span class="hljs-number">7291252613067627</span><br><span class="hljs-attribute">39088169</span><br><span class="hljs-attribute">4</span>.<span class="hljs-number">291534423828125</span>e-<span class="hljs-number">05</span><br></code></pre></td></tr></table></figure><h2 id="retry装饰器">retry装饰器</h2><p>在工程项目中，尝尝会遇到数据库连接、HTTP连接等，这时一般都会加个retry（重连）机制，用于连接中断时发起重新连接，避免不必要的错误。Python中常见的retry模块有retry,tenacity等。</p><p>下面的示例代码将演示在断网情况下的HTTP重连：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br>import requests<br><span class="hljs-keyword">from</span> retry import retry<br>import<span class="hljs-built_in"> logging</span><br><span class="hljs-built_in"></span><br>logging.basicConfig(<span class="hljs-attribute">level</span>=logging.DEBUG,<br>                    <span class="hljs-attribute">format</span>=<span class="hljs-string">&#x27;%(asctime)s  %(filename)s : %(levelname)s  %(message)s&#x27;</span>)<br>logger = logging.getLogger()<br><br><br>@retry(<span class="hljs-attribute">exceptions</span>=Exception, <span class="hljs-attribute">tries</span>=5, <span class="hljs-attribute">delay</span>=1, <span class="hljs-attribute">backoff</span>=2, <span class="hljs-attribute">max_delay</span>=30, <span class="hljs-attribute">logger</span>=logger)<br>def make_requests():<br>    url = <span class="hljs-string">&quot;https://www.example.com/&quot;</span><br>    response = requests.<span class="hljs-built_in">get</span>(url)<br>    return response.content<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(make_requests())<br><br></code></pre></td></tr></table></figure><p>执行结果：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">18</span> <span class="hljs-number">13</span>:<span class="hljs-number">09</span>:<span class="hljs-number">28</span>,<span class="hljs-number">869</span>  connectionpool.py : DEBUG  Starting <span class="hljs-keyword">new</span> HTTPS connection (<span class="hljs-number">1</span>): www.example.com:<span class="hljs-number">443</span><br><span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">18</span> <span class="hljs-number">13</span>:<span class="hljs-number">09</span>:<span class="hljs-number">28</span>,<span class="hljs-number">870</span>  api.py : WARNING  <span class="hljs-constructor">HTTPSConnectionPool(<span class="hljs-params">host</span>=&#x27;<span class="hljs-params">www</span>.<span class="hljs-params">example</span>.<span class="hljs-params">com</span>&#x27;, <span class="hljs-params">port</span>=443)</span>: Max retries exceeded <span class="hljs-keyword">with</span> url:<span class="hljs-operator"> / </span>(Caused by <span class="hljs-constructor">NewConnectionError(&#x27;&lt;<span class="hljs-params">urllib3</span>.<span class="hljs-params">connection</span>.HTTPSConnection <span class="hljs-params">object</span> <span class="hljs-params">at</span> 0x103959e10&gt;: Failed <span class="hljs-params">to</span> <span class="hljs-params">establish</span> <span class="hljs-params">a</span> <span class="hljs-params">new</span> <span class="hljs-params">connection</span>: [Errno 8] <span class="hljs-params">nodename</span> <span class="hljs-params">nor</span> <span class="hljs-params">servname</span> <span class="hljs-params">provided</span>, <span class="hljs-params">or</span> <span class="hljs-params">not</span> <span class="hljs-params">known</span>&#x27;)</span>), retrying <span class="hljs-keyword">in</span> <span class="hljs-number">1</span> seconds...<br><span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">18</span> <span class="hljs-number">13</span>:<span class="hljs-number">09</span>:<span class="hljs-number">29</span>,<span class="hljs-number">872</span>  connectionpool.py : DEBUG  Starting <span class="hljs-keyword">new</span> HTTPS connection (<span class="hljs-number">1</span>): www.example.com:<span class="hljs-number">443</span><br><span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">18</span> <span class="hljs-number">13</span>:<span class="hljs-number">09</span>:<span class="hljs-number">29</span>,<span class="hljs-number">872</span>  api.py : WARNING  <span class="hljs-constructor">HTTPSConnectionPool(<span class="hljs-params">host</span>=&#x27;<span class="hljs-params">www</span>.<span class="hljs-params">example</span>.<span class="hljs-params">com</span>&#x27;, <span class="hljs-params">port</span>=443)</span>: Max retries exceeded <span class="hljs-keyword">with</span> url:<span class="hljs-operator"> / </span>(Caused by <span class="hljs-constructor">NewConnectionError(&#x27;&lt;<span class="hljs-params">urllib3</span>.<span class="hljs-params">connection</span>.HTTPSConnection <span class="hljs-params">object</span> <span class="hljs-params">at</span> 0x1039590f0&gt;: Failed <span class="hljs-params">to</span> <span class="hljs-params">establish</span> <span class="hljs-params">a</span> <span class="hljs-params">new</span> <span class="hljs-params">connection</span>: [Errno 8] <span class="hljs-params">nodename</span> <span class="hljs-params">nor</span> <span class="hljs-params">servname</span> <span class="hljs-params">provided</span>, <span class="hljs-params">or</span> <span class="hljs-params">not</span> <span class="hljs-params">known</span>&#x27;)</span>), retrying <span class="hljs-keyword">in</span> <span class="hljs-number">2</span> seconds...<br><span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">18</span> <span class="hljs-number">13</span>:<span class="hljs-number">09</span>:<span class="hljs-number">31</span>,<span class="hljs-number">874</span>  connectionpool.py : DEBUG  Starting <span class="hljs-keyword">new</span> HTTPS connection (<span class="hljs-number">1</span>): www.example.com:<span class="hljs-number">443</span><br><span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">18</span> <span class="hljs-number">13</span>:<span class="hljs-number">09</span>:<span class="hljs-number">31</span>,<span class="hljs-number">875</span>  api.py : WARNING  <span class="hljs-constructor">HTTPSConnectionPool(<span class="hljs-params">host</span>=&#x27;<span class="hljs-params">www</span>.<span class="hljs-params">example</span>.<span class="hljs-params">com</span>&#x27;, <span class="hljs-params">port</span>=443)</span>: Max retries exceeded <span class="hljs-keyword">with</span> url:<span class="hljs-operator"> / </span>(Caused by <span class="hljs-constructor">NewConnectionError(&#x27;&lt;<span class="hljs-params">urllib3</span>.<span class="hljs-params">connection</span>.HTTPSConnection <span class="hljs-params">object</span> <span class="hljs-params">at</span> 0x103959210&gt;: Failed <span class="hljs-params">to</span> <span class="hljs-params">establish</span> <span class="hljs-params">a</span> <span class="hljs-params">new</span> <span class="hljs-params">connection</span>: [Errno 8] <span class="hljs-params">nodename</span> <span class="hljs-params">nor</span> <span class="hljs-params">servname</span> <span class="hljs-params">provided</span>, <span class="hljs-params">or</span> <span class="hljs-params">not</span> <span class="hljs-params">known</span>&#x27;)</span>), retrying <span class="hljs-keyword">in</span> <span class="hljs-number">4</span> seconds...<br><span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">18</span> <span class="hljs-number">13</span>:<span class="hljs-number">09</span>:<span class="hljs-number">35</span>,<span class="hljs-number">878</span>  connectionpool.py : DEBUG  Starting <span class="hljs-keyword">new</span> HTTPS connection (<span class="hljs-number">1</span>): www.example.com:<span class="hljs-number">443</span><br><span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">18</span> <span class="hljs-number">13</span>:<span class="hljs-number">09</span>:<span class="hljs-number">35</span>,<span class="hljs-number">878</span>  api.py : WARNING  <span class="hljs-constructor">HTTPSConnectionPool(<span class="hljs-params">host</span>=&#x27;<span class="hljs-params">www</span>.<span class="hljs-params">example</span>.<span class="hljs-params">com</span>&#x27;, <span class="hljs-params">port</span>=443)</span>: Max retries exceeded <span class="hljs-keyword">with</span> url:<span class="hljs-operator"> / </span>(Caused by <span class="hljs-constructor">NewConnectionError(&#x27;&lt;<span class="hljs-params">urllib3</span>.<span class="hljs-params">connection</span>.HTTPSConnection <span class="hljs-params">object</span> <span class="hljs-params">at</span> 0x103959510&gt;: Failed <span class="hljs-params">to</span> <span class="hljs-params">establish</span> <span class="hljs-params">a</span> <span class="hljs-params">new</span> <span class="hljs-params">connection</span>: [Errno 8] <span class="hljs-params">nodename</span> <span class="hljs-params">nor</span> <span class="hljs-params">servname</span> <span class="hljs-params">provided</span>, <span class="hljs-params">or</span> <span class="hljs-params">not</span> <span class="hljs-params">known</span>&#x27;)</span>), retrying <span class="hljs-keyword">in</span> <span class="hljs-number">8</span> seconds...<br><span class="hljs-number">2023</span>-<span class="hljs-number">12</span>-<span class="hljs-number">18</span> <span class="hljs-number">13</span>:<span class="hljs-number">09</span>:<span class="hljs-number">43</span>,<span class="hljs-number">882</span>  connectionpool.py : DEBUG  Starting <span class="hljs-keyword">new</span> HTTPS connection (<span class="hljs-number">1</span>): www.example.com:<span class="hljs-number">443</span><br></code></pre></td></tr></table></figure><h2 id="其它装饰器">其它装饰器</h2><p>Python中还有许许多多的装饰器，使用装饰器不仅能使我们的代码简洁美观，而且非常方便实用，比如在Torch中，可以使用@torch.no_grad()装饰器来代替torch.no_grad()写法，非常方便，如下：</p><p>torch.no_grad() 的装饰器使用方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@torch.no_grad()</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">eval</span>():<br>...<br></code></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>在Python中，装饰器是十分常见且好用的功能，实现起来也不困难，后续有机会讲仔细讲解装饰器的原理及其实现。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（八十）大模型评估（Evaluation）</title>
    <link href="/NLP%EF%BC%88%E5%85%AB%E5%8D%81%EF%BC%89%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%EF%BC%88Evaluation%EF%BC%89/"/>
    <url>/NLP%EF%BC%88%E5%85%AB%E5%8D%81%EF%BC%89%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%EF%BC%88Evaluation%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将介绍如何使用LangChain中的Evalution工具来实现大模型评估。</p></blockquote><h2 id="概念澄清">概念澄清</h2><p>首先，让我们来澄清下大模型的<code>评测</code>与<code>评估</code>的区别，虽然它们的英文都为evaluation.</p><p>在本文中，大模型的评测指的是带有评测数据集（比如MMLU, AGIEval,C-Eval等）的大模型能力评估，通常会带有评估指标，如accuracy等。大模型评测较为客观、全面，考虑的是模型本身自带的能力与世界知识。</p><p>在文本中，大模型的评估指的是针对具体问题时，大模型的回复质量，包括正确性、简洁性等。大模型评估偏重实际应用中的问题，考虑的是大模型能力的扩展与外延。</p><p>当然，这两者的区别仅是本文提出的概念上的区别，仅是为了叙述方便，不至于使读者产生混淆。实际上，关于大模型能力的评估，虽然业界有一些合理的方案，但现阶段仍是百家争鸣，并没有统一的评价标准。</p><h2 id="介绍">介绍</h2><p>大模型评估无疑是大模型生态中重要的一环，<code>LangChain</code>提供了<ahref="https://python.langchain.com/docs/guides/evaluation/">Evaluation工具</a>，能帮助我们更好、更方便地进行大模型评估。</p><p>LangChain中的每种评估器类型（evaluatortype）都附带即用型的实现和可扩展API，允许根据用户的独特需求进行定制。以下是LangChain中提供的常见评估器类型：</p><ul><li>字符串评估器（StringEvaluators）：这些评估器评估给定输入的预测字符串，通常将其与参考字符串进行比较。</li><li>轨迹评估器（TrajectoryEvaluators）：用于评估代理动作的整个轨迹。</li><li>比较评估器（ComparisonEvaluators）：这些评估器旨在比较公共输入上两次运行的预测。</li></ul><p>参考LangChain(版本为:langchain==0.0.340)中的源码，给出的评估器类型及说明如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">EvaluatorType</span>(<span class="hljs-built_in">str</span>, Enum):<br>    <span class="hljs-string">&quot;&quot;&quot;The types of the evaluators.&quot;&quot;&quot;</span><br><br>    QA = <span class="hljs-string">&quot;qa&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Question answering evaluator, which grades answers to questions</span><br><span class="hljs-string">    directly using an LLM.&quot;&quot;&quot;</span><br>    COT_QA = <span class="hljs-string">&quot;cot_qa&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Chain of thought question answering evaluator, which grades</span><br><span class="hljs-string">    answers to questions using</span><br><span class="hljs-string">    chain of thought &#x27;reasoning&#x27;.&quot;&quot;&quot;</span><br>    CONTEXT_QA = <span class="hljs-string">&quot;context_qa&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Question answering evaluator that incorporates &#x27;context&#x27; in the response.&quot;&quot;&quot;</span><br>    PAIRWISE_STRING = <span class="hljs-string">&quot;pairwise_string&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;The pairwise string evaluator, which predicts the preferred prediction from</span><br><span class="hljs-string">    between two models.&quot;&quot;&quot;</span><br>    SCORE_STRING = <span class="hljs-string">&quot;score_string&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;The scored string evaluator, which gives a score between 1 and 10 </span><br><span class="hljs-string">    to a prediction.&quot;&quot;&quot;</span><br>    LABELED_PAIRWISE_STRING = <span class="hljs-string">&quot;labeled_pairwise_string&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;The labeled pairwise string evaluator, which predicts the preferred prediction</span><br><span class="hljs-string">    from between two models based on a ground truth reference label.&quot;&quot;&quot;</span><br>    LABELED_SCORE_STRING = <span class="hljs-string">&quot;labeled_score_string&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;The labeled scored string evaluator, which gives a score between 1 and 10</span><br><span class="hljs-string">    to a prediction based on a ground truth reference label.&quot;&quot;&quot;</span><br>    AGENT_TRAJECTORY = <span class="hljs-string">&quot;trajectory&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;The agent trajectory evaluator, which grades the agent&#x27;s intermediate steps.&quot;&quot;&quot;</span><br>    CRITERIA = <span class="hljs-string">&quot;criteria&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;The criteria evaluator, which evaluates a model based on a</span><br><span class="hljs-string">    custom set of criteria without any reference labels.&quot;&quot;&quot;</span><br>    LABELED_CRITERIA = <span class="hljs-string">&quot;labeled_criteria&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;The labeled criteria evaluator, which evaluates a model based on a</span><br><span class="hljs-string">    custom set of criteria, with a reference label.&quot;&quot;&quot;</span><br>    STRING_DISTANCE = <span class="hljs-string">&quot;string_distance&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Compare predictions to a reference answer using string edit distances.&quot;&quot;&quot;</span><br>    EXACT_MATCH = <span class="hljs-string">&quot;exact_match&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Compare predictions to a reference answer using exact matching.&quot;&quot;&quot;</span><br>    REGEX_MATCH = <span class="hljs-string">&quot;regex_match&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Compare predictions to a reference answer using regular expressions.&quot;&quot;&quot;</span><br>    PAIRWISE_STRING_DISTANCE = <span class="hljs-string">&quot;pairwise_string_distance&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Compare predictions based on string edit distances.&quot;&quot;&quot;</span><br>    EMBEDDING_DISTANCE = <span class="hljs-string">&quot;embedding_distance&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Compare a prediction to a reference label using embedding distance.&quot;&quot;&quot;</span><br>    PAIRWISE_EMBEDDING_DISTANCE = <span class="hljs-string">&quot;pairwise_embedding_distance&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Compare two predictions using embedding distance.&quot;&quot;&quot;</span><br>    JSON_VALIDITY = <span class="hljs-string">&quot;json_validity&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Check if a prediction is valid JSON.&quot;&quot;&quot;</span><br>    JSON_EQUALITY = <span class="hljs-string">&quot;json_equality&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Check if a prediction is equal to a reference JSON.&quot;&quot;&quot;</span><br>    JSON_EDIT_DISTANCE = <span class="hljs-string">&quot;json_edit_distance&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Compute the edit distance between two JSON strings after canonicalization.&quot;&quot;&quot;</span><br>    JSON_SCHEMA_VALIDATION = <span class="hljs-string">&quot;json_schema_validation&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;Check if a prediction is valid JSON according to a JSON schema.&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><p>本文将介绍其中的三种：</p><ul><li>CRITERIA</li><li>LABELED_CRITERIA</li><li>CONTEXT_QA</li></ul><p>一般使用<strong>GPT-4模型</strong>作为评估模型。</p><h2 id="criteria-evaluation">CRITERIA Evaluation</h2><p>CRITERIAEvaluation一般不带reference(参考答案)，常见的CRITERIA如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><span class="hljs-keyword">from</span> langchain.evaluation <span class="hljs-keyword">import</span> Criteria<br><br><span class="hljs-comment"># list criteria</span><br>pprint(<span class="hljs-built_in">list</span>(Criteria))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">[&lt;Criteria.CONCISENESS: <span class="hljs-string">&#x27;conciseness&#x27;</span>&gt;,<br> &lt;Criteria.RELEVANCE: <span class="hljs-string">&#x27;relevance&#x27;</span>&gt;,<br> &lt;Criteria.CORRECTNESS: <span class="hljs-string">&#x27;correctness&#x27;</span>&gt;,<br> &lt;Criteria.COHERENCE: <span class="hljs-string">&#x27;coherence&#x27;</span>&gt;,<br> &lt;Criteria.HARMFULNESS: <span class="hljs-string">&#x27;harmfulness&#x27;</span>&gt;,<br> &lt;Criteria.MALICIOUSNESS: <span class="hljs-string">&#x27;maliciousness&#x27;</span>&gt;,<br> &lt;Criteria.HELPFULNESS: <span class="hljs-string">&#x27;helpfulness&#x27;</span>&gt;,<br> &lt;Criteria.CONTROVERSIALITY: <span class="hljs-string">&#x27;controversiality&#x27;</span>&gt;,<br> &lt;Criteria.MISOGYNY: <span class="hljs-string">&#x27;misogyny&#x27;</span>&gt;,<br> &lt;Criteria.CRIMINALITY: <span class="hljs-string">&#x27;criminality&#x27;</span>&gt;,<br> &lt;Criteria.INSENSITIVITY: <span class="hljs-string">&#x27;insensitivity&#x27;</span>&gt;,<br> &lt;Criteria.DEPTH: <span class="hljs-string">&#x27;depth&#x27;</span>&gt;,<br> &lt;Criteria.CREATIVITY: <span class="hljs-string">&#x27;creativity&#x27;</span>&gt;,<br> &lt;Criteria.DETAIL: <span class="hljs-string">&#x27;detail&#x27;</span>&gt;]<br></code></pre></td></tr></table></figure><p>以<code>简洁性(CONCISENESS)</code>标准为例，示例评估代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> langchain.evaluation <span class="hljs-keyword">import</span> load_evaluator, EvaluatorType, Criteria<br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = os.getenv(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>)<br>evaluation_llm = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-4&quot;</span>, temperature=<span class="hljs-number">0</span>)<br><br>evaluator = load_evaluator(EvaluatorType.CRITERIA,<br>                           criteria=Criteria.CONCISENESS,<br>                           llm=evaluation_llm)<br><br>eval_result = evaluator.evaluate_strings(<br>    prediction=<span class="hljs-string">&quot;What&#x27;s 2+2? That&#x27;s an elementary question. The answer you&#x27;re looking for is that two and two is four.&quot;</span>,<br>    <span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;What&#x27;s 2+2?&quot;</span>,<br>)<br>pprint(eval_result)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>&#x27;reasoning&#x27;<span class="hljs-punctuation">:</span> &#x27;The criterion is conciseness<span class="hljs-punctuation">,</span> which means the submission should &#x27;<br>              &#x27;be brief and to the point. \n&#x27;<br>              &#x27;\n&#x27;<br>              &#x27;Looking at the submission<span class="hljs-punctuation">,</span> the answer to the question <span class="hljs-string">&quot;What\&#x27;s &#x27;</span><br><span class="hljs-string">              &#x27;2+2?&quot;</span> is given as <span class="hljs-string">&quot;The answer you\&#x27;re looking for is that two &#x27;</span><br><span class="hljs-string">              &#x27;and two is four.&quot;</span> However<span class="hljs-punctuation">,</span> before providing the answer<span class="hljs-punctuation">,</span> the &#x27;<br>              &#x27;respondent adds an unnecessary comment<span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;That\&#x27;s an elementary &#x27;</span><br><span class="hljs-string">              &#x27;question.&quot;</span> \n&#x27;<br>              &#x27;\n&#x27;<br>              &#x27;This additional comment does not contribute to answering the &#x27;<br>              &#x27;question and therefore makes the response less concise. \n&#x27;<br>              &#x27;\n&#x27;<br>              &#x27;So<span class="hljs-punctuation">,</span> based on the criterion of conciseness<span class="hljs-punctuation">,</span> the submission does &#x27;<br>              &#x27;not meet the criterion.\n&#x27;<br>              &#x27;\n&#x27;<br>              &#x27;N&#x27;<span class="hljs-punctuation">,</span><br> &#x27;score&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br> &#x27;value&#x27;<span class="hljs-punctuation">:</span> &#x27;N&#x27;<span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>输出结果包括三个字段：</p><ul><li>score:评估分数，这里取0或1，1代表输出答案与标准（CRITERIA）符合，0则不符合</li><li>value: 评估值，这里取Y(Yes)或N(No)</li><li>reasoning: 评估理由，evaluator会给出评估结果的理由</li></ul><p>在上述的例子中，<strong>GPT-4模型</strong>作为评估模型器，判断给出的答案不符合简洁性标准，并给出了具体的判断理由。</p><h2 id="labeled_criteria-evaluation">LABELED_CRITERIA Evaluation</h2><p>CRITERIAEvaluation一般带有reference(参考答案)，有了参考答案，评估结果会更加可靠。</p><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> langchain.evaluation <span class="hljs-keyword">import</span> load_evaluator, EvaluatorType, Criteria<br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = os.getenv(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>)<br>evaluation_llm = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-4&quot;</span>, temperature=<span class="hljs-number">0</span>)<br><br>evaluator = load_evaluator(EvaluatorType.LABELED_CRITERIA,<br>                           criteria=Criteria.CORRECTNESS,<br>                           llm=evaluation_llm)<br><br>eval_result = evaluator.evaluate_strings(<br>    <span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;What is the capital city of the Jiangsu Province?&quot;</span>,<br>    prediction=<span class="hljs-string">&quot;Suzhou&quot;</span>,<br>    reference=<span class="hljs-string">&quot;The capital city of Jiangsu Province is Nanjing.&quot;</span>,<br>)<br>pprint(eval_result)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>&#x27;reasoning&#x27;<span class="hljs-punctuation">:</span> &#x27;The criterion for this task is the correctness of the submitted &#x27;<br>              &#x27;answer. This means the answer should be accurate and factual.\n&#x27;<br>              &#x27;\n&#x27;<br>              &#x27;The input asks for the capital city of the Jiangsu Province.\n&#x27;<br>              &#x27;\n&#x27;<br>              &#x27;The submitted answer is Suzhou.\n&#x27;<br>              &#x27;\n&#x27;<br>              &#x27;The reference answer<span class="hljs-punctuation">,</span> however<span class="hljs-punctuation">,</span> states that the capital city of &#x27;<br>              &#x27;Jiangsu Province is Nanjing.\n&#x27;<br>              &#x27;\n&#x27;<br>              &#x27;Comparing the submitted answer with the reference answer<span class="hljs-punctuation">,</span> it is &#x27;<br>              &#x27;clear that the submitted answer is incorrect. Suzhou is not the &#x27;<br>              &#x27;capital of Jiangsu Province<span class="hljs-punctuation">,</span> Nanjing is.\n&#x27;<br>              &#x27;\n&#x27;<br>              &#x27;Therefore<span class="hljs-punctuation">,</span> the submission does not meet the criterion of &#x27;<br>              &#x27;correctness.\n&#x27;<br>              &#x27;\n&#x27;<br>              &#x27;N&#x27;<span class="hljs-punctuation">,</span><br> &#x27;score&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br> &#x27;value&#x27;<span class="hljs-punctuation">:</span> &#x27;N&#x27;<span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h2 id="context_qa-evaluation">CONTEXT_QA Evaluation</h2><p>CONTEXT_QAEvaluation会对文档问答的回复进行评估，当然这也可用于RAG(RetrievalAugmented Generation)的回复结果评估。</p><p>此时，需要提供的reference即为文档问答中的文档（document）.</p><p>示例代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> langchain.evaluation <span class="hljs-keyword">import</span> load_evaluator, EvaluatorType, Criteria<br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = os.getenv(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>)<br>evaluation_llm = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-4&quot;</span>, temperature=<span class="hljs-number">0</span>)<br><br>evaluator = load_evaluator(EvaluatorType.CONTEXT_QA,<br>                           criteria=Criteria.CORRECTNESS,<br>                           llm=evaluation_llm,<br>                           requires_reference=<span class="hljs-literal">True</span>)<br><br><br>question = <span class="hljs-string">&quot;2022年上海的常住人口是多少?&quot;</span><br>context = <span class="hljs-string">&quot;上海市，简称沪。 是中华人民共和国直辖市、中国共产党诞生地、国家中心城市、超大城市 、上海大都市圈核心城市、中国历史文化名城、&quot;</span> \<br>          <span class="hljs-string">&quot;世界一线城市。 上海基本建成国际经济、金融、贸易、航运中心，形成具有全球影响力的科技创新中心基本框架。&quot;</span> \<br>          <span class="hljs-string">&quot;上海市总面积6340.5平方千米，辖16个区。 2022年，上海市常住人口为2475.89万人。&quot;</span><br><br>pred = <span class="hljs-string">&quot;2022年，上海市的常住人口为2000万人。&quot;</span><br><span class="hljs-comment"># evaluate</span><br>eval_result = evaluator.evaluate_strings(<br>  <span class="hljs-built_in">input</span>=question,<br>  prediction=pred,<br>  reference=context<br>)<br><span class="hljs-built_in">print</span>(eval_result)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&#123;<span class="hljs-string">&#x27;reasoning&#x27;</span>: <span class="hljs-string">&#x27;INCORRECT&#x27;</span>, <span class="hljs-string">&#x27;value&#x27;</span>: <span class="hljs-string">&#x27;INCORRECT&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: 0&#125;<br></code></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>本文介绍了LangChain中的Evaluation工具，并演示了三种评估类型的使用方式。</p><p>当然，还有更多的评估类型值得探索，本文仅是抛砖引玉，希望能给读者带来启发~</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>LangChain Evaluation: <ahref="https://python.langchain.com/docs/guides/evaluation/"class="uri">https://python.langchain.com/docs/guides/evaluation/</a></li><li>criteria evaluation: <ahref="https://python.langchain.com/docs/guides/evaluation/string/criteria_eval_chain"class="uri">https://python.langchain.com/docs/guides/evaluation/string/criteria_eval_chain</a></li><li>Evaluate LLMs and RAG a practical example using Langchain andHugging Face: <a href="https://www.philschmid.de/evaluate-llm"class="uri">https://www.philschmid.de/evaluate-llm</a>)</li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM Evaluation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（七十九）函数调用（function_calling）</title>
    <link href="/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%B9%9D%EF%BC%89%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%EF%BC%88function-calling%EF%BC%89/"/>
    <url>/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%B9%9D%EF%BC%89%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%EF%BC%88function-calling%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将介绍大模型中的函数调用（function calling），并介绍其在openai,langchain模块中的使用，以及Assistant API对function calling的支持。</p></blockquote><p><strong>函数调用</strong>（FunctionCalling）是<code>OpenAI</code>在今年6月13日对外发布的新能力。根据OpenAI官方博客描述，函数调用能力可以让大模型输出一个请求调用函数的消息，其中包含所需调用的函数信息、以及调用函数时所携带的参数信息。这是一种将<code>大模型</code>（LLM）能力与<code>外部工具/API</code>连接起来的新方式。</p><p>比如用户输入:</p><blockquote><p>What’s the weather like in Shanghai?</p></blockquote><p>使用functioncalling，可实现函数执行<code>get_current_weather(location: string)</code>，从而获取函数输出，即得到对应地理位置的天气情况。这其中，<code>location</code>这个参数及其取值是借助大模型能力从用户输入中抽取出来的，同时，大模型判断得到调用的函数为<code>get_current_weather</code>。</p><p>开发人员可以使用大模型的function calling能力实现：</p><ul><li>在进行自然语言交流时，通过调用外部工具回答问题（类似于ChatGPT插件）；</li><li>将自然语言转换为调用API调用，或数据库查询语句；</li><li>从文本中抽取结构化数据</li><li>其它</li></ul><p>那么，在OpenAI发布的模型中，是如何实现function calling的呢？</p><p>本文中，使用的第三方模块信息如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">openai==1.3.2<br>langchain==0.0.339<br></code></pre></td></tr></table></figure><h2 id="入门例子">入门例子</h2><p>我们以函数<code>get_weather_info</code>为例，其实现逻辑（模拟实现世界中的API调用，获取对应城市的天气状况）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_weather_info</span>(<span class="hljs-params">city: <span class="hljs-built_in">str</span></span>):<br>    weather_info = &#123;<span class="hljs-string">&quot;Shanghai&quot;</span>: <span class="hljs-string">&quot;Rainy&quot;</span>, <span class="hljs-string">&quot;Beijing&quot;</span>: <span class="hljs-string">&quot;Snow&quot;</span>&#125;<br>    <span class="hljs-keyword">return</span> weather_info.get(city, <span class="hljs-string">&quot;Sunny&quot;</span>)<br></code></pre></td></tr></table></figure><p>该函数只有一个参数：字符串变量city，即城市名称。为了实现functioncalling功能，需配置函数描述（类似JSON化的API描述），代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">functions = [<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_weather_info&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get the weather information of a city&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;city&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The name of the city, e.g. Shanghai&quot;</span>,<br>                &#125;,<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;city&quot;</span>],<br>        &#125;<br>    &#125;<br>]<br></code></pre></td></tr></table></figure><p>对于一般的用户输入（query），大模型回复结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI<br><br>client = OpenAI(api_key=<span class="hljs-string">&quot;sk-xxx&quot;</span>)<br><br>query = <span class="hljs-string">&quot;What is the capital of france?&quot;</span><br>response = client.chat.completions.create(<br>        model=<span class="hljs-string">&quot;gpt-3.5-turbo-0613&quot;</span>,<br>        messages=[&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query&#125;],<br>        functions=functions<br>    )<br>message = response.<span class="hljs-built_in">dict</span>()[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>]<br><span class="hljs-built_in">print</span>(message)<br><br><span class="hljs-meta">&gt;&gt;&gt; </span>&#123;<span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-string">&#x27;The capital of France is Paris.&#x27;</span>, <span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;assistant&#x27;</span>, <span class="hljs-string">&#x27;function_call&#x27;</span>: <span class="hljs-literal">None</span>, <span class="hljs-string">&#x27;tool_calls&#x27;</span>: <span class="hljs-literal">None</span>&#125;<br></code></pre></td></tr></table></figure><p>此时<code>function_call</code>为None，即大模型判断不需要functioncalling.</p><p>对于查询天气的query，大模型输出结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI<br><br>client = OpenAI(api_key=<span class="hljs-string">&quot;sk-xxx&quot;</span>)<br><br>query = <span class="hljs-string">&quot;What is the weather like in Beijing?&quot;</span><br>response = client.chat.completions.create(<br>        model=<span class="hljs-string">&quot;gpt-3.5-turbo-0613&quot;</span>,<br>        messages=[&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query&#125;],<br>        functions=functions<br>    )<br>message = response.<span class="hljs-built_in">dict</span>()[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>]<br><span class="hljs-built_in">print</span>(message)<br><br><span class="hljs-meta">&gt;&gt;&gt; </span>&#123;<span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-literal">None</span>, <span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;assistant&#x27;</span>, <span class="hljs-string">&#x27;function_call&#x27;</span>: &#123;<span class="hljs-string">&#x27;arguments&#x27;</span>: <span class="hljs-string">&#x27;&#123;\n  &quot;city&quot;: &quot;Beijing&quot;\n&#125;&#x27;</span>, <span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;get_weather_info&#x27;</span>&#125;, <span class="hljs-string">&#x27;tool_calls&#x27;</span>: <span class="hljs-literal">None</span>&#125;<br></code></pre></td></tr></table></figure><p>此时我们看到了令人吃惊的输出，大模型的输出内容为空，而判断需要functioncalling,函数名称为<code>get_weather_info</code>，参数为<code>&#123;'arguments': '&#123;\n  "city": "Beijing"\n&#125;</code>。</p><p>下一步，我们可以调用该函数，传入参数，得到函数输出，并再次调用大模型得到答案回复。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">func_name = message[<span class="hljs-string">&quot;function_call&quot;</span>][<span class="hljs-string">&quot;name&quot;</span>]<br>func_args = json.loads(message[<span class="hljs-string">&quot;function_call&quot;</span>][<span class="hljs-string">&quot;arguments&quot;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;func name and args: &quot;</span>, func_name, func_args)<br>func_response = get_weather_info(**func_args)<br><br>final_response = client.chat.completions.create(<br>                model=<span class="hljs-string">&quot;gpt-3.5-turbo-0613&quot;</span>,<br>                messages=[<br>                    &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query&#125;,<br>                    &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-literal">None</span>, <span class="hljs-string">&quot;function_call&quot;</span>: message[<span class="hljs-string">&quot;function_call&quot;</span>]&#125;,<br>                    &#123;<br>                        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;function&quot;</span>,<br>                        <span class="hljs-string">&quot;name&quot;</span>: func_name,<br>                        <span class="hljs-string">&quot;content&quot;</span>: func_response<br>                    &#125;,<br>                ],<br>            )<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;answer: &quot;</span>, final_response.<span class="hljs-built_in">dict</span>()[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>][<span class="hljs-string">&quot;content&quot;</span>])<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">func name and args:  get_weather_info &#123;<span class="hljs-string">&#x27;city&#x27;</span>: <span class="hljs-string">&#x27;Beijing&#x27;</span>&#125;<br>answer:  The weather <span class="hljs-keyword">in</span> Beijing is currently snowy.<br></code></pre></td></tr></table></figure><p>以上仅是functioncalling的简单示例，采用一步一步的详细过程来演示大模型中functioncalling如何使用。</p><p>在实际场景中，我们还需要实现中间过程的函数执行过程。</p><p>以下将介绍在OpenAI, LangChain中如何实现functioncalling。后面我们将使用的3个函数（这些函数仅用于测试，实际场景中可替换为具体的工具或API）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_pizza_info</span>(<span class="hljs-params">pizza_name: <span class="hljs-built_in">str</span></span>):<br>    <span class="hljs-comment"># get pizza info by pizza name</span><br>    pizza_info = &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: pizza_name,<br>        <span class="hljs-string">&quot;price&quot;</span>: <span class="hljs-string">&quot;10.99&quot;</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> json.dumps(pizza_info)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_weather_info</span>(<span class="hljs-params">city: <span class="hljs-built_in">str</span></span>):<br>    <span class="hljs-comment"># get city weather info with mock result</span><br>    weather_info = &#123;<span class="hljs-string">&quot;Shanghai&quot;</span>: <span class="hljs-string">&quot;Rainy&quot;</span>, <span class="hljs-string">&quot;Beijing&quot;</span>: <span class="hljs-string">&quot;Snow&quot;</span>&#125;<br>    <span class="hljs-keyword">return</span> weather_info.get(city, <span class="hljs-string">&quot;Sunny&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_rectangle_area</span>(<span class="hljs-params">width: <span class="hljs-built_in">float</span>, length: <span class="hljs-built_in">float</span></span>):<br>    <span class="hljs-comment"># calculate the rectangle with given width and length</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;The area of this rectangle is <span class="hljs-subst">&#123;width * length&#125;</span>.&quot;</span><br></code></pre></td></tr></table></figure><h2 id="openai调用function-calling">openai调用function calling</h2><p>在OpenAI的官方模块<code>openai</code>中实现<code>function calling</code>的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">import</span> json<br><br>client = OpenAI(api_key=<span class="hljs-string">&quot;sk-xxx&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_pizza_info</span>(<span class="hljs-params">pizza_name: <span class="hljs-built_in">str</span></span>):<br>    pizza_info = &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: pizza_name,<br>        <span class="hljs-string">&quot;price&quot;</span>: <span class="hljs-string">&quot;10.99&quot;</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> json.dumps(pizza_info)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_weather_info</span>(<span class="hljs-params">city: <span class="hljs-built_in">str</span></span>):<br>    weather_info = &#123;<span class="hljs-string">&quot;Shanghai&quot;</span>: <span class="hljs-string">&quot;Rainy&quot;</span>, <span class="hljs-string">&quot;Beijing&quot;</span>: <span class="hljs-string">&quot;Snow&quot;</span>&#125;<br>    <span class="hljs-keyword">return</span> weather_info.get(city, <span class="hljs-string">&quot;Sunny&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_rectangle_area</span>(<span class="hljs-params">width: <span class="hljs-built_in">float</span>, length: <span class="hljs-built_in">float</span></span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;The area of this rectangle is <span class="hljs-subst">&#123;width * length&#125;</span>.&quot;</span><br><br><br>function_mapping = &#123;<span class="hljs-string">&quot;get_pizza_info&quot;</span>: get_pizza_info,<br>                    <span class="hljs-string">&quot;get_weather_info&quot;</span>: get_weather_info,<br>                    <span class="hljs-string">&quot;get_rectangle_area&quot;</span>: get_rectangle_area&#125;<br><br><br>functions = [<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_pizza_info&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get name and price of a pizza of the restaurant&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;pizza_name&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The name of the pizza, e.g. Salami&quot;</span>,<br>                &#125;,<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;pizza_name&quot;</span>],<br>        &#125;<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_weather_info&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get the weather information of a city&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;city&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The name of the city, e.g. Shanghai&quot;</span>,<br>                &#125;,<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;city&quot;</span>],<br>        &#125;<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_rectangle_area&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get the area of a rectangle with given width and length&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;width&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;number&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The width of a rectangle&quot;</span>,<br>                &#125;,<br>                <span class="hljs-string">&quot;length&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;number&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The length of a rectangle&quot;</span>,<br>                &#125;<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;width&quot;</span>, <span class="hljs-string">&quot;length&quot;</span>],<br>        &#125;<br>    &#125;<br>]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat</span>(<span class="hljs-params">query</span>):<br>    response = client.chat.completions.create(<br>        model=<span class="hljs-string">&quot;gpt-3.5-turbo-0613&quot;</span>,<br>        messages=[&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query&#125;],<br>        functions=functions<br>    )<br>    message = response.<span class="hljs-built_in">dict</span>()[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;message: &#x27;</span>, message)<br><br>    function_call_info = message.get(<span class="hljs-string">&quot;function_call&quot;</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> function_call_info:<br>        <span class="hljs-keyword">return</span> message<br>    <span class="hljs-keyword">else</span>:<br>        function_name = function_call_info[<span class="hljs-string">&quot;name&quot;</span>]<br>        arg_name = json.loads(function_call_info[<span class="hljs-string">&quot;arguments&quot;</span>])<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;function name and arg name: &quot;</span>, function_name, arg_name)<br><br>        <span class="hljs-keyword">if</span> function_name <span class="hljs-keyword">in</span> function_mapping:<br>            function_response = function_mapping[function_name](**arg_name)<br><br>            final_response = client.chat.completions.create(<br>                model=<span class="hljs-string">&quot;gpt-3.5-turbo-0613&quot;</span>,<br>                messages=[<br>                    &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query&#125;,<br>                    &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-literal">None</span>, <span class="hljs-string">&quot;function_call&quot;</span>: function_call_info&#125;,<br>                    &#123;<br>                        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;function&quot;</span>,<br>                        <span class="hljs-string">&quot;name&quot;</span>: function_name,<br>                        <span class="hljs-string">&quot;content&quot;</span>: function_response<br>                    &#125;,<br>                ],<br>            )<br>            <span class="hljs-keyword">return</span> final_response.<span class="hljs-built_in">dict</span>()[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;wrong function name with function call&quot;</span><br><br><br>query1 = <span class="hljs-string">&quot;What is the capital of france?&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;answer: &quot;</span>, chat(query1), end=<span class="hljs-string">&quot;\n\n&quot;</span>)<br><br>query2 = <span class="hljs-string">&quot;How much does pizza Domino cost?&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;answer: &quot;</span>, chat(query2), end=<span class="hljs-string">&quot;\n\n&quot;</span>)<br><br>query3 = <span class="hljs-string">&quot;What is the weather like in Beijing?&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;answer: &quot;</span>, chat(query3), end=<span class="hljs-string">&quot;\n\n&quot;</span>)<br><br>query4 = <span class="hljs-string">&quot;calculate the rectangle area with width 3 and length 5.&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;answer: &quot;</span>, chat(query4), end=<span class="hljs-string">&quot;\n\n&quot;</span>)<br><br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">query:  What is the capital of france?<br>message:  &#123;<span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-string">&#x27;The capital of France is Paris.&#x27;</span>, <span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;assistant&#x27;</span>, <span class="hljs-string">&#x27;function_call&#x27;</span>: None, <span class="hljs-string">&#x27;tool_calls&#x27;</span>: None&#125;<br>answer:  &#123;<span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-string">&#x27;The capital of France is Paris.&#x27;</span>, <span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;assistant&#x27;</span>, <span class="hljs-string">&#x27;function_call&#x27;</span>: None, <span class="hljs-string">&#x27;tool_calls&#x27;</span>: None&#125;<br><br>query:  How much does pizza Domino cost?<br>message:  &#123;<span class="hljs-string">&#x27;content&#x27;</span>: None, <span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;assistant&#x27;</span>, <span class="hljs-string">&#x27;function_call&#x27;</span>: &#123;<span class="hljs-string">&#x27;arguments&#x27;</span>: <span class="hljs-string">&#x27;&#123;\n  &quot;pizza_name&quot;: &quot;Domino&quot;\n&#125;&#x27;</span>, <span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;get_pizza_info&#x27;</span>&#125;, <span class="hljs-string">&#x27;tool_calls&#x27;</span>: None&#125;<br><span class="hljs-keyword">function</span> name and arg name:  get_pizza_info &#123;<span class="hljs-string">&#x27;pizza_name&#x27;</span>: <span class="hljs-string">&#x27;Domino&#x27;</span>&#125;<br>answer:  The cost of a Domino pizza is <span class="hljs-variable">$10</span>.99.<br><br>query:  What is the weather like <span class="hljs-keyword">in</span> Beijing?<br>message:  &#123;<span class="hljs-string">&#x27;content&#x27;</span>: None, <span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;assistant&#x27;</span>, <span class="hljs-string">&#x27;function_call&#x27;</span>: &#123;<span class="hljs-string">&#x27;arguments&#x27;</span>: <span class="hljs-string">&#x27;&#123;\n  &quot;city&quot;: &quot;Beijing&quot;\n&#125;&#x27;</span>, <span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;get_weather_info&#x27;</span>&#125;, <span class="hljs-string">&#x27;tool_calls&#x27;</span>: None&#125;<br><span class="hljs-keyword">function</span> name and arg name:  get_weather_info &#123;<span class="hljs-string">&#x27;city&#x27;</span>: <span class="hljs-string">&#x27;Beijing&#x27;</span>&#125;<br>answer:  The weather <span class="hljs-keyword">in</span> Beijing is currently experiencing snow.<br><br>query:  calculate the rectangle area with width 3 and length 5.<br>message:  &#123;<span class="hljs-string">&#x27;content&#x27;</span>: None, <span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;assistant&#x27;</span>, <span class="hljs-string">&#x27;function_call&#x27;</span>: &#123;<span class="hljs-string">&#x27;arguments&#x27;</span>: <span class="hljs-string">&#x27;&#123;\n  &quot;width&quot;: 3,\n  &quot;length&quot;: 5\n&#125;&#x27;</span>, <span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;get_rectangle_area&#x27;</span>&#125;, <span class="hljs-string">&#x27;tool_calls&#x27;</span>: None&#125;<br><span class="hljs-keyword">function</span> name and arg name:  get_rectangle_area &#123;<span class="hljs-string">&#x27;width&#x27;</span>: 3, <span class="hljs-string">&#x27;length&#x27;</span>: 5&#125;<br>answer:  The area of a rectangle can be calculated by multiplying its width by its length. In this <span class="hljs-keyword">case</span>, the width is 3 and the length is 5. Therefore, the area of the rectangle is 3 * 5 = 15 square units.<br></code></pre></td></tr></table></figure><h2 id="langchain调用function-calling">LangChain调用functioncalling</h2><p>在<code>langchain</code>中实现<code>function calling</code>的代码相对简洁写，<code>function calling</code>的结果在Message中的additional_kwargs变量中，实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> langchain.schema <span class="hljs-keyword">import</span> HumanMessage, AIMessage, ChatMessage<br><br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&quot;sk-xxx&quot;</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_pizza_info</span>(<span class="hljs-params">pizza_name: <span class="hljs-built_in">str</span></span>):<br>    pizza_info = &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: pizza_name,<br>        <span class="hljs-string">&quot;price&quot;</span>: <span class="hljs-string">&quot;10.99&quot;</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> json.dumps(pizza_info)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_weather_info</span>(<span class="hljs-params">city: <span class="hljs-built_in">str</span></span>):<br>    weather_info = &#123;<span class="hljs-string">&quot;Shanghai&quot;</span>: <span class="hljs-string">&quot;Rainy&quot;</span>, <span class="hljs-string">&quot;Beijing&quot;</span>: <span class="hljs-string">&quot;Snow&quot;</span>&#125;<br>    <span class="hljs-keyword">return</span> weather_info.get(city, <span class="hljs-string">&quot;Sunny&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_rectangle_area</span>(<span class="hljs-params">width: <span class="hljs-built_in">float</span>, length: <span class="hljs-built_in">float</span></span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;The area of this rectangle is <span class="hljs-subst">&#123;width * length&#125;</span>.&quot;</span><br><br><br>function_mapping = &#123;<span class="hljs-string">&quot;get_pizza_info&quot;</span>: get_pizza_info,<br>                    <span class="hljs-string">&quot;get_weather_info&quot;</span>: get_weather_info,<br>                    <span class="hljs-string">&quot;get_rectangle_area&quot;</span>: get_rectangle_area&#125;<br><br><br>functions = [<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_pizza_info&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get name and price of a pizza of the restaurant&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;pizza_name&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The name of the pizza, e.g. Salami&quot;</span>,<br>                &#125;,<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;pizza_name&quot;</span>],<br>        &#125;<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_weather_info&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get the weather information of a city&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;city&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The name of the city, e.g. Shanghai&quot;</span>,<br>                &#125;,<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;city&quot;</span>],<br>        &#125;<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_rectangle_area&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get the area of a rectangle with given width and length&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;width&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;number&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The width of a rectangle&quot;</span>,<br>                &#125;,<br>                <span class="hljs-string">&quot;length&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;number&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The length of a rectangle&quot;</span>,<br>                &#125;<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;width&quot;</span>, <span class="hljs-string">&quot;length&quot;</span>],<br>        &#125;<br>    &#125;<br>]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat</span>(<span class="hljs-params">query</span>):<br>    llm = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-3.5-turbo-0613&quot;</span>)<br>    message = llm.predict_messages(<br>        [HumanMessage(content=query)], functions=functions<br>    )<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;message: &#x27;</span>, message, <span class="hljs-built_in">type</span>(message))<br><br>    function_call_info = message.additional_kwargs.get(<span class="hljs-string">&quot;function_call&quot;</span>, <span class="hljs-literal">None</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> function_call_info:<br>        <span class="hljs-keyword">return</span> message<br>    <span class="hljs-keyword">else</span>:<br>        function_name = function_call_info[<span class="hljs-string">&quot;name&quot;</span>]<br>        arg_name = json.loads(function_call_info[<span class="hljs-string">&quot;arguments&quot;</span>])<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;function name and arg name: &quot;</span>, function_name, arg_name)<br><br>        <span class="hljs-keyword">if</span> function_name <span class="hljs-keyword">in</span> function_mapping:<br>            function_response = function_mapping[function_name](**arg_name)<br><br>            final_response = llm.predict_messages(<br>                [<br>                    HumanMessage(content=query),<br>                    AIMessage(content=<span class="hljs-built_in">str</span>(message.additional_kwargs)),<br>                    ChatMessage(<br>                        role=<span class="hljs-string">&quot;function&quot;</span>,<br>                        additional_kwargs=&#123;<br>                            <span class="hljs-string">&quot;name&quot;</span>: function_name<br>                        &#125;,<br>                        content=function_response<br>                    ),<br>                ]<br>            )<br>            <span class="hljs-keyword">return</span> final_response.content<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;wrong function name with function call&quot;</span><br><br><br>query1 = <span class="hljs-string">&quot;What is the capital of Japan?&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;answer:&quot;</span>, chat(query1), end=<span class="hljs-string">&#x27;\n\n&#x27;</span>)<br><br>query2 = <span class="hljs-string">&quot;How much does pizza Domino cost?&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;answer:&quot;</span>, chat(query2), end=<span class="hljs-string">&#x27;\n\n&#x27;</span>)<br><br>query3 = <span class="hljs-string">&quot;What is the weather like in Paris?&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;answer: &quot;</span>, chat(query3), end=<span class="hljs-string">&quot;\n\n&quot;</span>)<br><br>query4 = <span class="hljs-string">&quot;calculate the rectangle area with width 3 and length 10&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;answer: &quot;</span>, chat(query4), end=<span class="hljs-string">&quot;\n\n&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="openai-assistant-api支持function-calling">OpenAI AssistantAPI支持function calling</h2><p><code>Assistant API</code>是OpenAI在今年OpenAI开发者大会中提出的创新功能。<code>Assistants API</code>允许用户在自己的应用程序中构建AI助手。助手有指令，可以利用模型、工具和知识来响应用户查询。<code>Assistants API</code>目前支持三种类型的工具：<strong>代码解释器</strong>（<strong>CodeInterpreter</strong>）、<strong>检索</strong>（<strong>Retrieval</strong>）和<strong>函数调用</strong>（<strong>FunctionCalling</strong>）。</p><p><imgsrc="https://raw.githubusercontent.com/openai/openai-cookbook/feef1bf3982e15ad180e17732525ddbadaf2b670/images/assistants_overview_diagram.png" /></p><p>我们来看看，在openai中的Assistant API如何支持function calling。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_pizza_info</span>(<span class="hljs-params">pizza_name: <span class="hljs-built_in">str</span></span>):<br>    pizza_info = &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: pizza_name,<br>        <span class="hljs-string">&quot;price&quot;</span>: <span class="hljs-string">&quot;10.99&quot;</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> json.dumps(pizza_info)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_weather_info</span>(<span class="hljs-params">city: <span class="hljs-built_in">str</span></span>):<br>    weather_info = &#123;<span class="hljs-string">&quot;Shanghai&quot;</span>: <span class="hljs-string">&quot;Rainy&quot;</span>, <span class="hljs-string">&quot;Beijing&quot;</span>: <span class="hljs-string">&quot;Snow&quot;</span>&#125;<br>    <span class="hljs-keyword">return</span> weather_info.get(city, <span class="hljs-string">&quot;Sunny&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_rectangle_area</span>(<span class="hljs-params">width: <span class="hljs-built_in">float</span>, length: <span class="hljs-built_in">float</span></span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;The area of this rectangle is <span class="hljs-subst">&#123;width * length&#125;</span>.&quot;</span><br><br><br>function_mapping = &#123;<span class="hljs-string">&quot;get_pizza_info&quot;</span>: get_pizza_info,<br>                    <span class="hljs-string">&quot;get_weather_info&quot;</span>: get_weather_info,<br>                    <span class="hljs-string">&quot;get_rectangle_area&quot;</span>: get_rectangle_area&#125;<br><br><br>functions = [<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_pizza_info&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get name and price of a pizza of the restaurant&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;pizza_name&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The name of the pizza, e.g. Salami&quot;</span>,<br>                &#125;,<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;pizza_name&quot;</span>],<br>        &#125;<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_weather_info&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get the weather information of a city&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;city&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The name of the city, e.g. Shanghai&quot;</span>,<br>                &#125;,<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;city&quot;</span>],<br>        &#125;<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_rectangle_area&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get the area of a rectangle with given width and length&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;width&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;number&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The width of a rectangle&quot;</span>,<br>                &#125;,<br>                <span class="hljs-string">&quot;length&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;number&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The length of a rectangle&quot;</span>,<br>                &#125;<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;width&quot;</span>, <span class="hljs-string">&quot;length&quot;</span>],<br>        &#125;<br>    &#125;<br>]<br><br><br>client = OpenAI(api_key=<span class="hljs-string">&quot;sk-xxx&quot;</span>)<br><br>assistant = client.beta.assistants.create(<br>    name=<span class="hljs-string">&quot;assistant test&quot;</span>,<br>    instructions=<span class="hljs-string">&quot;You are a helpful assistant, ready to answer user&#x27;s questions.&quot;</span>,<br>    model=<span class="hljs-string">&quot;gpt-3.5-turbo-0613&quot;</span>,<br>)<br>MATH_ASSISTANT_ID = assistant.<span class="hljs-built_in">id</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;assistant id: &quot;</span>, MATH_ASSISTANT_ID)<br><br>assistant = client.beta.assistants.update(<br>    MATH_ASSISTANT_ID,<br>    tools=[<br>        &#123;<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;function&quot;</span>, <span class="hljs-string">&quot;function&quot;</span>: function&#125; <span class="hljs-keyword">for</span> function <span class="hljs-keyword">in</span> functions<br>    ],<br>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;assistant id: &quot;</span>, assistant.<span class="hljs-built_in">id</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">submit_message</span>(<span class="hljs-params">assistant_id, thread, user_message</span>):<br>    client.beta.threads.messages.create(<br>        thread_id=thread.<span class="hljs-built_in">id</span>, role=<span class="hljs-string">&quot;user&quot;</span>, content=user_message<br>    )<br>    <span class="hljs-keyword">return</span> client.beta.threads.runs.create(<br>        thread_id=thread.<span class="hljs-built_in">id</span>,<br>        assistant_id=assistant_id,<br>    )<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_thread_and_run</span>(<span class="hljs-params">user_input</span>):<br>    thread = client.beta.threads.create()<br>    run = submit_message(MATH_ASSISTANT_ID, thread, user_input)<br>    <span class="hljs-keyword">return</span> thread, run<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">wait_on_run</span>(<span class="hljs-params">run, thread</span>):<br>    <span class="hljs-keyword">while</span> run.status == <span class="hljs-string">&quot;queued&quot;</span> <span class="hljs-keyword">or</span> run.status == <span class="hljs-string">&quot;in_progress&quot;</span>:<br>        run = client.beta.threads.runs.retrieve(<br>            thread_id=thread.<span class="hljs-built_in">id</span>,<br>            run_id=run.<span class="hljs-built_in">id</span>,<br>        )<br>        time.sleep(<span class="hljs-number">0.5</span>)<br>    <span class="hljs-keyword">return</span> run<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_response</span>(<span class="hljs-params">thread</span>):<br>    <span class="hljs-keyword">return</span> client.beta.threads.messages.<span class="hljs-built_in">list</span>(thread_id=thread.<span class="hljs-built_in">id</span>, order=<span class="hljs-string">&quot;asc&quot;</span>)<br><br><br><span class="hljs-comment"># Pretty printing helper</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pretty_print</span>(<span class="hljs-params">messages</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;# Messages&quot;</span>)<br>    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> messages:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;m.role&#125;</span>: <span class="hljs-subst">&#123;m.content[<span class="hljs-number">0</span>].text.value&#125;</span>&quot;</span>)<br>    <span class="hljs-built_in">print</span>()<br><br><br>query = <span class="hljs-string">&quot;How much does pizza Domino cost?&quot;</span><br><br>thread, run = create_thread_and_run(query)<br>run = wait_on_run(run, thread)<br><br><span class="hljs-comment"># Extract single tool call</span><br>tool_call = run.required_action.submit_tool_outputs.tool_calls[<span class="hljs-number">0</span>]<br>name = tool_call.function.name<br>arguments = json.loads(tool_call.function.arguments)<br>my_response = function_mapping[name](**arguments)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;function response: &quot;</span>, my_response)<br><br><span class="hljs-comment"># use function response for rerun</span><br>final_run = client.beta.threads.runs.submit_tool_outputs(<br>    thread_id=thread.<span class="hljs-built_in">id</span>,<br>    run_id=run.<span class="hljs-built_in">id</span>,<br>    tool_outputs=[<br>        &#123;<br>            <span class="hljs-string">&quot;tool_call_id&quot;</span>: tool_call.<span class="hljs-built_in">id</span>,<br>            <span class="hljs-string">&quot;output&quot;</span>: json.dumps(my_response),<br>        &#125;<br>    ],<br>)<br><br>final_run = wait_on_run(final_run, thread)<br>pretty_print(get_response(thread))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">assistant <span class="hljs-built_in">id</span>:  asst_ElovRUJRLqBeYk2Gu2CUIiU9<br>assistant <span class="hljs-built_in">id</span>:  asst_ElovRUJRLqBeYk2Gu2CUIiU9<br><span class="hljs-keyword">function</span> response:  &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;Domino&quot;</span>, <span class="hljs-string">&quot;price&quot;</span>: <span class="hljs-string">&quot;10.99&quot;</span>&#125;<br><span class="hljs-comment"># Messages</span><br>user: How much does pizza Domino cost?<br>assistant: The pizza Domino from the restaurant costs <span class="hljs-variable">$10</span>.99.<br></code></pre></td></tr></table></figure><h2 id="langchain-assistant-api支持function-calling">LangChain AssistantAPI支持function calling</h2><p>可以看到在openai模块中，在Assistant API中实现functioncalling，较为麻烦。而新版的langchain(0.0.339)中已经添加对AssistantAPI的支持，我们来看看在langchain中如何支持function calling。</p><p>实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai </span><br><span class="hljs-comment"># @contact: lianmingjie@shanda.com</span><br><span class="hljs-comment"># @file: assistant_api_with_functions.py</span><br><span class="hljs-comment"># @time: 2023/11/23 11:00</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> langchain.agents.openai_assistant <span class="hljs-keyword">import</span> OpenAIAssistantRunnable<br><span class="hljs-keyword">from</span> langchain.schema.agent <span class="hljs-keyword">import</span> AgentFinish<br><span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> Tool<br><span class="hljs-keyword">from</span> langchain.tools <span class="hljs-keyword">import</span> StructuredTool<br><br><br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&quot;sk-xxx&quot;</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_pizza_info</span>(<span class="hljs-params">pizza_name: <span class="hljs-built_in">str</span></span>):<br>    pizza_info = &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: pizza_name,<br>        <span class="hljs-string">&quot;price&quot;</span>: <span class="hljs-string">&quot;10.99&quot;</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> json.dumps(pizza_info)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_weather_info</span>(<span class="hljs-params">city: <span class="hljs-built_in">str</span></span>):<br>    weather_info = &#123;<span class="hljs-string">&quot;Shanghai&quot;</span>: <span class="hljs-string">&quot;Rainy&quot;</span>, <span class="hljs-string">&quot;Beijing&quot;</span>: <span class="hljs-string">&quot;Snow&quot;</span>&#125;<br>    <span class="hljs-keyword">return</span> weather_info.get(city, <span class="hljs-string">&quot;Sunny&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_rectangle_area</span>(<span class="hljs-params">width: <span class="hljs-built_in">float</span> = <span class="hljs-number">1.0</span>, length: <span class="hljs-built_in">float</span> = <span class="hljs-number">1.0</span></span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;The area of this rectangle is <span class="hljs-subst">&#123;width * length&#125;</span>.&quot;</span><br><br><br>function_mapping = &#123;<span class="hljs-string">&quot;get_pizza_info&quot;</span>: get_pizza_info,<br>                    <span class="hljs-string">&quot;get_weather_info&quot;</span>: get_weather_info,<br>                    <span class="hljs-string">&quot;get_rectangle_area&quot;</span>: get_rectangle_area&#125;<br><br><br>functions = [<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_pizza_info&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get name and price of a pizza of the restaurant&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;pizza_name&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The name of the pizza, e.g. Salami&quot;</span>,<br>                &#125;,<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;pizza_name&quot;</span>],<br>        &#125;<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_weather_info&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get the weather information of a city&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;city&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The name of the city, e.g. Shanghai&quot;</span>,<br>                &#125;,<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;city&quot;</span>],<br>        &#125;<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;get_rectangle_area&quot;</span>,<br>        <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Get the area of a rectangle with given width and length&quot;</span>,<br>        <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>            <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;width&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;number&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The width of a rectangle&quot;</span>,<br>                &#125;,<br>                <span class="hljs-string">&quot;length&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;number&quot;</span>,<br>                    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;The length of a rectangle&quot;</span>,<br>                &#125;<br>            &#125;,<br>            <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;width&quot;</span>, <span class="hljs-string">&quot;length&quot;</span>],<br>        &#125;<br>    &#125;<br>]<br><br>tools = [Tool(name=func[<span class="hljs-string">&quot;name&quot;</span>],<br>              func=function_mapping[func[<span class="hljs-string">&quot;name&quot;</span>]],<br>              description=func[<span class="hljs-string">&quot;description&quot;</span>]) <span class="hljs-keyword">for</span> func <span class="hljs-keyword">in</span> functions[:-<span class="hljs-number">1</span>]]<br><br>tools.append(StructuredTool.from_function(get_rectangle_area, name=<span class="hljs-string">&quot;get_rectangle_area&quot;</span>, description=<span class="hljs-string">&quot;Get the area of a rectangle with given width and length&quot;</span>))<br><br>agent = OpenAIAssistantRunnable.create_assistant(<br>    name=<span class="hljs-string">&quot;langchain assistant&quot;</span>,<br>    instructions=<span class="hljs-string">&quot;You are a helpful assistant, ready to answer user&#x27;s questions.&quot;</span>,<br>    tools=tools,<br>    model=<span class="hljs-string">&quot;gpt-3.5-turbo-0613&quot;</span>,<br>    as_agent=<span class="hljs-literal">True</span>,<br>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">execute_agent</span>(<span class="hljs-params">agent, tools, <span class="hljs-built_in">input</span></span>):<br>    tool_map = &#123;tool.name: tool <span class="hljs-keyword">for</span> tool <span class="hljs-keyword">in</span> tools&#125;<br>    response = agent.invoke(<span class="hljs-built_in">input</span>)<br>    <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(response, AgentFinish):<br>        tool_outputs = []<br>        <span class="hljs-keyword">for</span> action <span class="hljs-keyword">in</span> response:<br>            <span class="hljs-built_in">print</span>(action.tool, action.tool_input)<br>            tool_output = tool_map[action.tool].invoke(action.tool_input)<br>            <span class="hljs-built_in">print</span>(action.tool, action.tool_input, tool_output, end=<span class="hljs-string">&quot;\n\n&quot;</span>)<br>            tool_outputs.append(<br>                &#123;<span class="hljs-string">&quot;output&quot;</span>: tool_output, <span class="hljs-string">&quot;tool_call_id&quot;</span>: action.tool_call_id&#125;<br>            )<br>        response = agent.invoke(<br>            &#123;<br>                <span class="hljs-string">&quot;tool_outputs&quot;</span>: tool_outputs,<br>                <span class="hljs-string">&quot;run_id&quot;</span>: action.run_id,<br>                <span class="hljs-string">&quot;thread_id&quot;</span>: action.thread_id,<br>            &#125;<br>        )<br><br>    <span class="hljs-keyword">return</span> response<br><br><br>query = <span class="hljs-string">&quot;How much does pizza Domino cost?&quot;</span><br>query = <span class="hljs-string">&quot;What is the capital of france?&quot;</span><br>query = <span class="hljs-string">&quot;What is the weather like in Beijing?&quot;</span><br>query = <span class="hljs-string">&quot;calculate the rectangle area with width 3 and length 5.&quot;</span><br><br>response = execute_agent(agent, tools, &#123;<span class="hljs-string">&quot;content&quot;</span>: query&#125;)<br><span class="hljs-built_in">print</span>(response.return_values[<span class="hljs-string">&quot;output&quot;</span>])<br></code></pre></td></tr></table></figure><p>注意，函数<code>get_rectangle_area</code>为多参数输入，因此需使用StructuredTool.</p><h2 id="网页assistant支持function-calling">网页Assistant支持functioncalling</h2><p>在OpenAI中的官网中，Assistant已经支持function calling.</p><figure><img src="https://s2.loli.net/2023/11/23/HBzv4iCwotgr5YX.png"alt="Assistant加入function calling" /><figcaption aria-hidden="true">Assistant加入functioncalling</figcaption></figure><h2 id="总结">总结</h2><p>本文是这几天来笔者对于function calling的一个总结。原本以为functioncalling功能简单好用，但在实际的代码实现中，还是有点难度的，尤其是AssistantAPI出来后，如何加入外部工具显得尤为重要。</p><p>本文作为functioncalling的一个系统性小结，并给出了详细的代码，希望能对读者有所帮助。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>Function calling and other API updates: <ahref="https://openai.com/blog/function-calling-and-other-api-updates"class="uri">https://openai.com/blog/function-calling-and-other-api-updates</a></li><li>OpenAI assistants in LangChain: <ahref="https://python.langchain.com/docs/modules/agents/agent_types/openai_assistants"class="uri">https://python.langchain.com/docs/modules/agents/agent_types/openai_assistants</a></li><li>Multi-Input Tools in LangChain: <ahref="https://python.langchain.com/docs/modules/agents/tools/multi_input_tool"class="uri">https://python.langchain.com/docs/modules/agents/tools/multi_input_tool</a></li><li>examples/Assistants_API_overview_python.ipynb: <ahref="https://github.com/openai/openai-cookbook/blob/main/examples/Assistants_API_overview_python.ipynb"class="uri">https://github.com/openai/openai-cookbook/blob/main/examples/Assistants_API_overview_python.ipynb</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>function calling</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>FastAPI入门教程</title>
    <link href="/FastAPI%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"/>
    <url>/FastAPI%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会通过与Flask的对比，来介绍FastAPI的基础使用。熟悉Flask的读者，阅读本文后应当不难掌握FastAPI。</p></blockquote><p><img src="https://amitness.com/images/flask-to-fastapi.png" /></p><p><code>Flask</code>作为Python语言中的老牌Web框架，已经被应用于大量的PythonWeb开发项目，其使用简洁，支持工具众多，工具丰富，社区活跃，是PythonWeb框架中的佼佼者之一。</p><p>而近来，<code>FastAPI</code>的出众表现，已使得其越来越受到众多开发者的关注，成为Web开发主流框架之一。<ahref="https://fastapi.tiangolo.com/">FastAPI优势</a>如下：</p><ul><li><p><strong>快速</strong>：可与 NodeJS 和 Go 并肩的极高性能（归功于Starlette 和 Pydantic）。最快的 Python web 框架之一。</p></li><li><p><strong>高效编码</strong>：提高功能开发速度约 200％ 至300％。</p></li><li><p><strong>更少 bug</strong>：减少约 40％的人为（开发者）导致错误。</p></li><li><p><strong>智能</strong>：极佳的编辑器支持。处处皆可自动补全，减少调试时间。</p></li><li><p><strong>简单</strong>：设计的易于使用和学习，阅读文档的时间更短。</p></li><li><p><strong>简短</strong>：使代码重复最小化。通过不同的参数声明实现丰富功能。bug更少。</p></li><li><p><strong>健壮</strong>：生产可用级别的代码。还有自动生成的交互式文档。</p></li><li><p><strong>标准化</strong>：基于（并完全兼容）API的相关开放标准：OpenAPI (以前被称为 Swagger) 和 JSON Schema。</p></li></ul><p>下面将会结合<code>Flask</code>的使用作为对比，来介绍<code>FastAPI</code>，作为<code>FastAPI</code>的入门教程。</p><p>本文使用的两个Web框架版本如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">fastapi==0.101.1<br>Flask==2.3.3<br></code></pre></td></tr></table></figure><h2 id="hello-world">Hello World</h2><p>Flask的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># app.py</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><br>app = Flask(__name__)<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">home</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;hello world&#x27;</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    app.run()<br></code></pre></td></tr></table></figure><p>FastAPI的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># app.py</span><br><span class="hljs-keyword">import</span> uvicorn<br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI<br><br>app = FastAPI()<br><br><br><span class="hljs-meta">@app.get(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">home</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;hello world&#x27;</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    uvicorn.run(app)<br></code></pre></td></tr></table></figure><p>两者的代码差别不多，运行时Flask的默认端口为5000，FastAPI的端口为8000，使用curl命令请求（FastAPI），返回结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl localhost:8000/<br><span class="hljs-string">&quot;hello world&quot;</span><br></code></pre></td></tr></table></figure><p>在部署生产代码时，Flask使用<code>gunicorn</code>，示例命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">gunicorn app:app<br></code></pre></td></tr></table></figure><p>而FastAPI使用<code>uvicorn</code>，示例命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">uvicorn app:app<br></code></pre></td></tr></table></figure><p>当然，在实际部署时还可指定端口（port）、worker数量、最大连接数等，本文不再详述。</p><h2 id="http方法">HTTP方法</h2><p>常见的HTTP请求方法有GET, POST, PUT, PATCH, DELETE等。</p><p>以POST方法为例，Flask的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span>, methods=[<span class="hljs-string">&#x27;POST&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">example</span>():<br>    ...<br></code></pre></td></tr></table></figure><p>FastAPI的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.post(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">example</span>():<br>    ...<br></code></pre></td></tr></table></figure><p>其它HTTP请求方法的使用方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.get(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-meta">@app.put(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-meta">@app.patch(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-meta">@app.delete(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br></code></pre></td></tr></table></figure><h2 id="url-变量">URL 变量</h2><p>我们想从URL中获取user id，比如<code>/users/1</code>，然后将userid返回给用户。</p><p>Flask的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/users/&lt;int:user_id&gt;&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_user_details</span>(<span class="hljs-params">user_id</span>):<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;user_id&#x27;</span>: user_id&#125;<br></code></pre></td></tr></table></figure><p>FastAPI的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.get(<span class="hljs-params"><span class="hljs-string">&#x27;/users/&#123;user_id&#125;&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_user_details</span>(<span class="hljs-params">user_id: <span class="hljs-built_in">int</span></span>):<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;user_id&#x27;</span>: user_id&#125;<br></code></pre></td></tr></table></figure><p>使用curl命令模拟请求如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl localhost:8000/users/2<br>&#123;<span class="hljs-string">&quot;user_id&quot;</span>:2&#125;<br></code></pre></td></tr></table></figure><h2 id="查询字符串">查询字符串</h2><p>我们希望允许用户在URL中使用查询字符串 <code>?q=abc</code>来指定搜索词。</p><p>Flask的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> request<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/search&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">search</span>():<br>    query = request.args.get(<span class="hljs-string">&#x27;q&#x27;</span>)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;query&#x27;</span>: query&#125;<br></code></pre></td></tr></table></figure><p>FastAPI的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.get(<span class="hljs-params"><span class="hljs-string">&#x27;/search&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">search</span>(<span class="hljs-params">q: <span class="hljs-built_in">str</span></span>):<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;query&#x27;</span>: q&#125;<br></code></pre></td></tr></table></figure><p>使用curl命令模拟请求如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl <span class="hljs-string">&#x27;localhost:8000/search?q=abcde&#x27;</span><br>&#123;<span class="hljs-string">&quot;query&quot;</span>:<span class="hljs-string">&quot;abcde&quot;</span>&#125;<br></code></pre></td></tr></table></figure><p>如果要指定多个搜索词，可以&amp;符号隔开，比如：</p><blockquote><p>?name=Jack&amp;id=1</p></blockquote><h2 id="json-post-请求">JSON Post 请求</h2><p>我们希望发送一个带有text参数JSON POST请求，返回其小写形式。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text"># Request<br>&#123;&quot;text&quot;: &quot;HELLO&quot;&#125;<br><br># Response<br>&#123;&quot;text&quot;: &quot;hello&quot;&#125;<br></code></pre></td></tr></table></figure><p>Flask代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> request<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/lowercase&#x27;</span>, methods=[<span class="hljs-string">&#x27;POST&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lower_case</span>():<br>    text = request.json.get(<span class="hljs-string">&#x27;text&#x27;</span>)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;text&#x27;</span>: text.lower()&#125;<br></code></pre></td></tr></table></figure><p>FastAPI代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Dict</span><br><br><span class="hljs-meta">@app.post(<span class="hljs-params"><span class="hljs-string">&#x27;/lowercase&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lower_case</span>(<span class="hljs-params">json_data: <span class="hljs-type">Dict</span></span>):<br>    text = json_data.get(<span class="hljs-string">&#x27;text&#x27;</span>)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;text&#x27;</span>: text.lower()&#125;<br></code></pre></td></tr></table></figure><p><strong>注意</strong>：FastAPI还有更优雅的处理方式，那就是引入<code>Pydantic schema</code>，它可以将JSON格式数据映射为schema对象，同时对该对象中的数据类型进行校验，如校验不通过，则会返回自动生成的校验错误。</p><p>FastAPI更优雅的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Sentence</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    text: <span class="hljs-built_in">str</span><br><br><span class="hljs-meta">@app.post(<span class="hljs-params"><span class="hljs-string">&#x27;/lowercase&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lower_case</span>(<span class="hljs-params">sentence: Sentence</span>):<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;text&#x27;</span>: sentence.text.lower()&#125;<br></code></pre></td></tr></table></figure><p>使用curl命令模拟请求如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl --location <span class="hljs-string">&#x27;localhost:8000/lowercase&#x27;</span> \<br>--header <span class="hljs-string">&#x27;Content-Type: application/json&#x27;</span> \<br>--data <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">    &quot;text&quot;: &quot;HELLO&quot;</span><br><span class="hljs-string">&#125;&#x27;</span><br>&#123;<span class="hljs-string">&quot;text&quot;</span>:<span class="hljs-string">&quot;hello&quot;</span>&#125;<br></code></pre></td></tr></table></figure><p>在请求时，如果text对应的value为数字时，FastAPI会自动将数字转化为字符串，不会报错；如果text对应的value为null时，FastAPI将会报错，信息如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;detail&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;loc&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-string">&quot;body&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-string">&quot;text&quot;</span><br>      <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;msg&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;none is not an allowed value&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;type_error.none.not_allowed&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h2 id="文件上传">文件上传</h2><p>我们来创建一个上传文件的API，返回上传文件的文件名。</p><p>Flask代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># app.py</span><br><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request<br>app = Flask(__name__)<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/upload&#x27;</span>, methods=[<span class="hljs-string">&#x27;POST&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">upload_file</span>():<br>    file = request.files.get(<span class="hljs-string">&#x27;file&#x27;</span>)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;name&#x27;</span>: file.filename&#125;<br></code></pre></td></tr></table></figure><p>FastAPI的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># app.py</span><br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI, UploadFile, File<br><br>app = FastAPI()<br><br><span class="hljs-meta">@app.post(<span class="hljs-params"><span class="hljs-string">&#x27;/upload&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">upload_file</span>(<span class="hljs-params">file: UploadFile = File(<span class="hljs-params">...</span>)</span>):<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;name&#x27;</span>: file.filename&#125;<br></code></pre></td></tr></table></figure><p>使用Postman模拟请求如下：</p><pre><code class="hljs">$ curl --location &#39;localhost:8000/upload&#39; \--header &#39;Content-Type: multipart/form-data&#39; \--form &#39;file=@&quot;/Users/admin/Documents/test.pdf&quot;&#39;&#123;&quot;name&quot;: &quot;test.pdf&quot;&#125;</code></pre><h2 id="表单提交">表单提交</h2><p>我们希望从表单中获取text类型的变量，并返回它的值，如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&#x27;city&#x27;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&#x27;text&#x27;</span>&gt;</span><br></code></pre></td></tr></table></figure><p>Flask代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># app.py</span><br><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request<br>app = Flask(__name__)<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/submit&#x27;</span>, methods=[<span class="hljs-string">&#x27;POST&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">echo</span>():<br>    city = request.form.get(<span class="hljs-string">&#x27;city&#x27;</span>)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;city&#x27;</span>: city&#125;<br></code></pre></td></tr></table></figure><p>FastAPI代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># app.py</span><br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI, Form<br>app = FastAPI()<br><br><span class="hljs-meta">@app.post(<span class="hljs-params"><span class="hljs-string">&#x27;/submit&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">echo</span>(<span class="hljs-params">city: <span class="hljs-built_in">str</span> = Form(<span class="hljs-params">...</span>)</span>):<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;city&#x27;</span>: city&#125;<br></code></pre></td></tr></table></figure><p>使用curl命令模拟请求如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl --location <span class="hljs-string">&#x27;localhost:8000/submit&#x27;</span> \<br>--form <span class="hljs-string">&#x27;city=&quot;shanghai&quot;&#x27;</span><br>&#123;<span class="hljs-string">&quot;city&quot;</span>:<span class="hljs-string">&quot;shanghai&quot;</span>&#125;<br></code></pre></td></tr></table></figure><h2 id="cookies">Cookies</h2><p>我们希望从请求的cookie中获取name字段的值。</p><p>Flask代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># app.py</span><br><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request<br>app = Flask(__name__)<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/profile&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">profile</span>():<br>    name = request.cookies.get(<span class="hljs-string">&#x27;name&#x27;</span>)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;name&#x27;</span>: name&#125;<br></code></pre></td></tr></table></figure><p>FastAPI代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># app.py</span><br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI, Cookie<br>app = FastAPI()<br><br><span class="hljs-meta">@app.get(<span class="hljs-params"><span class="hljs-string">&#x27;/profile&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">profile</span>(<span class="hljs-params">name=Cookie(<span class="hljs-params"><span class="hljs-literal">None</span></span>)</span>):<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;name&#x27;</span>: name&#125;<br></code></pre></td></tr></table></figure><h2 id="模块化视图">模块化视图</h2><p>我们希望将单个的app.py文件分解成视图（多个独立的文件），如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">- app.py<br>- views<br>  - user.py<br></code></pre></td></tr></table></figure><p>在Flask中，我们可以使用<strong>蓝图</strong>（Blueprint）来管理，代码如下：</p><p>user.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># views/user.py</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Blueprint<br>user_blueprint = Blueprint(<span class="hljs-string">&#x27;user&#x27;</span>, __name__)<br><br><span class="hljs-meta">@user_blueprint.route(<span class="hljs-params"><span class="hljs-string">&#x27;/users&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">list_users</span>():<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;users&#x27;</span>: [<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>]&#125;<br></code></pre></td></tr></table></figure><p>app.py</p><pre><code class="hljs"># app.pyfrom flask import Flaskfrom views.user import user_blueprintapp = Flask(__name__)app.register_blueprint(user_blueprint)</code></pre><p>在FastAPI中，与蓝图等价的实现形式为<strong>router</strong>，首先需创建一个userrouter如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># routers/user.py</span><br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> APIRouter<br>router = APIRouter()<br><br><span class="hljs-meta">@router.get(<span class="hljs-params"><span class="hljs-string">&#x27;/users&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">list_users</span>():<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;users&#x27;</span>: [<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>]&#125;<br></code></pre></td></tr></table></figure><p>将其加入app.py中，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># app.py</span><br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI<br><span class="hljs-keyword">from</span> routers <span class="hljs-keyword">import</span> user<br><br>app = FastAPI()<br>app.include_router(user.router)<br></code></pre></td></tr></table></figure><h2 id="数据校验">数据校验</h2><p>Flask本身并没有提供数据校验功能，可使用<code>marshmalllow</code>或<code>pydantic</code>模块来辅助实现。</p><p>而FastAPI在其框架中已包装<code>pydantic</code>模块，可轻松实现数据校验。示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> uvicorn<br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI<br><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel<br><br>app = FastAPI()<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    name: <span class="hljs-built_in">str</span><br>    age: <span class="hljs-built_in">int</span><br><br><br><span class="hljs-meta">@app.post(<span class="hljs-params"><span class="hljs-string">&#x27;/users&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">save_user</span>(<span class="hljs-params">user: User</span>):<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;name&#x27;</span>: user.name,<br>            <span class="hljs-string">&#x27;age&#x27;</span>: user.age&#125;<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    uvicorn.run(app)<br></code></pre></td></tr></table></figure><p>关于<code>pydantic</code>的schema与JSON格式对应关系，在此给出三个例子：</p><p><code>例子1</code> 键值对（key-value pairs）</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Isaac&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;age&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">60</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    name: <span class="hljs-built_in">str</span><br>    age: <span class="hljs-built_in">int</span><br></code></pre></td></tr></table></figure><p><code>例子2</code> 列表</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;series&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;GOT&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Dark&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Mr. Robot&quot;</span><span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Metadata</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    series: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]<br></code></pre></td></tr></table></figure><p><code>例子3</code> 嵌套对象</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;users&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;xyz&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;age&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">25</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;abc&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;age&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">30</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;group&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Group A&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    name: <span class="hljs-built_in">str</span><br>    age: <span class="hljs-built_in">int</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">UserGroup</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    users: <span class="hljs-type">List</span>[User]<br>    group: <span class="hljs-built_in">str</span><br></code></pre></td></tr></table></figure><h2 id="自动化文档">自动化文档</h2><p>Flask并没有提供内置的自动化文档生成，可使用<code>flask-swagger</code>或<code>flask-restful</code>模块来辅助实现。</p><p>FastAPI可生成自动化文档，文档风格包括swagger和redoc，其中swagger对应路径为/docs，redoc对应路径为/redoc，如下所示：</p><h3 id="swagger风格">Swagger风格</h3><figure><img src="https://amitness.com/images/fastapi-swagger.png"alt="swagger风格文档" /><figcaption aria-hidden="true">swagger风格文档</figcaption></figure><figure><img src="https://amitness.com/images/fastapi-swagger-interactive.png"alt="查看某个接口" /><figcaption aria-hidden="true">查看某个接口</figcaption></figure><h3 id="redoc风格">ReDoc风格</h3><figure><img src="https://amitness.com/images/fastapi-redoc.png"alt="ReDoc风格文档" /><figcaption aria-hidden="true">ReDoc风格文档</figcaption></figure><h2 id="cors">CORS</h2><p>Flask本身不支持CORS，可使用<code>flask-cors</code>模块辅助实现，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># app.py</span><br><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><span class="hljs-keyword">from</span> flask_cors <span class="hljs-keyword">import</span> CORS<br><br>app_ = Flask(__name__)<br>CORS(app_)<br></code></pre></td></tr></table></figure><p>FastAPI提供了内置的中间件来处理CORS，示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># app.py</span><br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI<br><span class="hljs-keyword">from</span> fastapi.middleware.cors <span class="hljs-keyword">import</span> CORSMiddleware<br><br>app = FastAPI()<br><br>app.add_middleware(<br>    CORSMiddleware,<br>    allow_origins=[<span class="hljs-string">&#x27;*&#x27;</span>],<br>    allow_credentials=<span class="hljs-literal">True</span>,<br>    allow_methods=[<span class="hljs-string">&quot;*&quot;</span>],<br>    allow_headers=[<span class="hljs-string">&quot;*&quot;</span>],<br>)<br></code></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>本文通过与Flask的对比，来介绍FastAPI的基础使用。如果读者想进一步了解FastAPI的高级使用方法，可参考<ahref="https://fastapi.tiangolo.com/zh/">FastAPI官方文档</a>。</p><p>感谢阅读~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>FastAPI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（七十八）大模型探索：MMLU数据集评测</title>
    <link href="/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E5%85%AB%EF%BC%89%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A2%E7%B4%A2%EF%BC%9AMMLU%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%84%E6%B5%8B/"/>
    <url>/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E5%85%AB%EF%BC%89%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A2%E7%B4%A2%EF%BC%9AMMLU%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%84%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何使用大模型（LLM）对MMLU数据集进行评测。</p></blockquote><p>大模型（LLM）的评测是衡量大模型效果的关键步骤，也是模型流水线中必不可少的过程。常见的大模型排行榜或平台有<ahref="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">🤗Open LLM Leaderboard</a>、<ahref="https://opencompass.org.cn/leaderboard-llm">OpenCompass</a>、<ahref="https://lmsys.org/blog/2023-05-25-leaderboard/">Chatbot ArenaLeaderboard</a>.</p><p>那么，大模型的评测是如何实现的呢？</p><p>本文将会以<code>MMLU</code>数据集为例，考察主流开源大模型，如LLAMA-2,BaiChuan-2等模型的评估实现及结果，希望能管中规豹，一探究竟。</p><h2 id="mmlu数据集">MMLU数据集</h2><p><ahref="https://github.com/hendrycks/test"><code>MMLU</code>数据集</a>已开源至Github平台，访问网址为：https://github.com/hendrycks/test.</p><p><strong>MMLU</strong>（Massive Multitask LanguageUnderstanding）是一个新的基准，用于衡量在<strong>零样本</strong>（zero-shot）和<strong>少样本</strong>（few-shot）情形下，大模型在预训练期间获得的世界知识。这使得该基准测试更具挑战性，也更类似于我们评估人类的方式。该基准涵盖STEM、人文（humanities）、社会科学（social sciences）等领域的 57个学科（subject）。它的难度从初级到高级，既考验世界知识，又考验解决问题的能力。学科范围从数学和历史等传统领域到法律和伦理等更为专业的领域。学科的粒度和广度使该基准成为识别模型盲点的理想选择。</p><p>MMLU数据集共收集了15908个问题，并将其分为few-shot开发集、验证集和测试集。few-shot开发集每个学科有5个问题，验证集可用于选择超参数，由1540个问题组成，测试集有14079个问题。每个学科至少包含100个测试问题，这比大多数旨在评估人类的考试都要长。</p><p>我们来看其中一个示例：</p><figure class="highlight mercury"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs mercury">Question: Glucose <span class="hljs-keyword">is</span> transported into the muscle cell:<br><br>Choices:<br>A. via protein transporters called GLUT4.<br>B. only in the presence of insulin.<br>C. via hexokinase.<br>D. via monocarbylic acid transporters.<br><br>Correct answer: A<br></code></pre></td></tr></table></figure><h2 id="评测代码">评测代码</h2><p>对于MMLU数据集的评测，<ahref="https://huggingface.co/blog/evaluating-mmlu-leaderboard">MMLU评测官方方案</a>为：</p><blockquote><p>判断 LLM 后续 token 为 A, B, C 或 D的概率，只要生成token为A的概率在四个token中概率最大，则回答正确。该方案明显的弊端就是，即便ABCD中，生成A的概率最大，在实际解码过程中，LLM 实际生成的也不一定是 tokenA。</p></blockquote><p>如下图所示：</p><figure><img src="https://s2.loli.net/2023/10/18/iRUlDCegdZBbjv2.png"alt="MMLU方案评测" /><figcaption aria-hidden="true">MMLU方案评测</figcaption></figure><p>为了使得在MMLU数据集上的评测结果更可靠，我们选择官方方案。同时，为了兼容更多大模型以及保存模型评测结果、推理时间等，我们参考Github上的项目<ahref="https://github.com/ollmer/mmlu">ollmer/mmlu</a>中的代码，并稍作调整，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- encoding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer<br><br><span class="hljs-keyword">from</span> categories <span class="hljs-keyword">import</span> categories, subcategories<br><br>choices = [<span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-string">&quot;B&quot;</span>, <span class="hljs-string">&quot;C&quot;</span>, <span class="hljs-string">&quot;D&quot;</span>]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">format_subject</span>(<span class="hljs-params">subject</span>):<br>    l = subject.split(<span class="hljs-string">&quot;_&quot;</span>)<br>    s = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> entry <span class="hljs-keyword">in</span> l:<br>        s += <span class="hljs-string">&quot; &quot;</span> + entry<br>    <span class="hljs-keyword">return</span> s<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">format_example</span>(<span class="hljs-params">df, idx, include_answer=<span class="hljs-literal">True</span></span>):<br>    prompt = df.iloc[idx, <span class="hljs-number">0</span>]<br>    k = df.shape[<span class="hljs-number">1</span>] - <span class="hljs-number">2</span><br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>        prompt += <span class="hljs-string">&quot;\n&#123;&#125;. &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(choices[j], df.iloc[idx, j + <span class="hljs-number">1</span>])<br>    prompt += <span class="hljs-string">&quot;\nAnswer:&quot;</span><br>    <span class="hljs-keyword">if</span> include_answer:<br>        prompt += <span class="hljs-string">&quot; &#123;&#125;\n\n&quot;</span>.<span class="hljs-built_in">format</span>(df.iloc[idx, k + <span class="hljs-number">1</span>])<br>    <span class="hljs-keyword">return</span> prompt<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gen_prompt</span>(<span class="hljs-params">train_df, subject, k=-<span class="hljs-number">1</span></span>):<br>    prompt = <span class="hljs-string">&quot;The following are multiple choice questions (with answers) about &#123;&#125;.\n\n&quot;</span>.<span class="hljs-built_in">format</span>(<br>        format_subject(subject)<br>    )<br>    <span class="hljs-keyword">if</span> k == -<span class="hljs-number">1</span>:<br>        k = train_df.shape[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>        prompt += format_example(train_df, i)<br>    <span class="hljs-keyword">return</span> prompt<br><br><br><span class="hljs-meta">@torch.no_grad()</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">eval</span>(<span class="hljs-params">args, subject, model, tokenizer, dev_df, test_df</span>):<br>    cors = []<br>    all_probs = []<br>    answers = choices[: test_df.shape[<span class="hljs-number">1</span>] - <span class="hljs-number">2</span>]<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(test_df.shape[<span class="hljs-number">0</span>]):<br>        <span class="hljs-comment"># get prompt and make sure it fits</span><br>        k = args.ntrain<br>        prompt_end = format_example(test_df, i, include_answer=<span class="hljs-literal">False</span>)<br>        train_prompt = gen_prompt(dev_df, subject, k)<br>        prompt = train_prompt + prompt_end<br><br>        input_ids = tokenizer(prompt, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids.to(model.device)<br><br>        <span class="hljs-keyword">while</span> input_ids.shape[-<span class="hljs-number">1</span>] &gt; <span class="hljs-number">2048</span>:<br>            k -= <span class="hljs-number">1</span><br>            train_prompt = gen_prompt(dev_df, subject, k)<br>            prompt = train_prompt + prompt_end<br>            input_ids = tokenizer(prompt, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids.to(<br>                model.device<br>            )<br><br>        label = test_df.iloc[i, test_df.shape[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>]<br><br>        logits = model(input_ids=input_ids).logits[<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>]<br><br>        probs = (<br>            torch.nn.functional.softmax(<br>                torch.tensor(<br>                    [<br>                        logits[tokenizer(<span class="hljs-string">&quot;A&quot;</span>).input_ids[-<span class="hljs-number">1</span>]],<br>                        logits[tokenizer(<span class="hljs-string">&quot;B&quot;</span>).input_ids[-<span class="hljs-number">1</span>]],<br>                        logits[tokenizer(<span class="hljs-string">&quot;C&quot;</span>).input_ids[-<span class="hljs-number">1</span>]],<br>                        logits[tokenizer(<span class="hljs-string">&quot;D&quot;</span>).input_ids[-<span class="hljs-number">1</span>]],<br>                    ]<br>                ).<span class="hljs-built_in">float</span>(),<br>                dim=<span class="hljs-number">0</span>,<br>            )<br>            .detach()<br>            .cpu()<br>            .numpy()<br>        )<br>        pred = &#123;<span class="hljs-number">0</span>: <span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;B&quot;</span>, <span class="hljs-number">2</span>: <span class="hljs-string">&quot;C&quot;</span>, <span class="hljs-number">3</span>: <span class="hljs-string">&quot;D&quot;</span>&#125;[np.argmax(probs)]<br><br>        cor = pred == label<br>        cors.append(cor)<br>        all_probs.append(probs)<br><br>    acc = np.mean(cors)<br>    cors = np.array(cors)<br><br>    all_probs = np.array(all_probs)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Average accuracy &#123;:.3f&#125; - &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(acc, subject))<br><br>    <span class="hljs-keyword">return</span> cors, acc, all_probs<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">args</span>):<br>    model = AutoModelForCausalLM.from_pretrained(<br>        args.model,<br>        torch_dtype=torch.float16,<br>        load_in_8bit=<span class="hljs-literal">False</span>,<br>        low_cpu_mem_usage=<span class="hljs-literal">True</span>,<br>        device_map=<span class="hljs-string">&quot;auto&quot;</span>,<br>        trust_remote_code=<span class="hljs-literal">True</span><br>    )<br>    tokenizer = AutoTokenizer.from_pretrained(args.model, trust_remote_code=<span class="hljs-literal">True</span>)<br>    model.<span class="hljs-built_in">eval</span>()<br>    subjects = <span class="hljs-built_in">sorted</span>(<br>        [<br>            f.split(<span class="hljs-string">&quot;_test.csv&quot;</span>)[<span class="hljs-number">0</span>]<br>            <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> os.listdir(os.path.join(args.data_dir, <span class="hljs-string">&quot;test&quot;</span>))<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;_test.csv&quot;</span> <span class="hljs-keyword">in</span> f<br>        ]<br>    )<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(args.save_dir):<br>        os.makedirs(args.save_dir)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(os.path.join(args.save_dir, <span class="hljs-string">&quot;results_&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(args.model.split(<span class="hljs-string">&quot;/&quot;</span>)[-<span class="hljs-number">1</span>]))):<br>        os.makedirs(os.path.join(args.save_dir, <span class="hljs-string">&quot;results_&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(args.model.split(<span class="hljs-string">&quot;/&quot;</span>)[-<span class="hljs-number">1</span>])))<br><br>    all_cors = []<br>    subcat_cors = &#123;<br>        subcat: [] <span class="hljs-keyword">for</span> subcat_lists <span class="hljs-keyword">in</span> subcategories.values() <span class="hljs-keyword">for</span> subcat <span class="hljs-keyword">in</span> subcat_lists<br>    &#125;<br>    cat_cors = &#123;cat: [] <span class="hljs-keyword">for</span> cat <span class="hljs-keyword">in</span> categories&#125;<br><br>    start_time = time.time()<br>    <span class="hljs-keyword">for</span> subject <span class="hljs-keyword">in</span> subjects:<br>        dev_df = pd.read_csv(<br>            os.path.join(args.data_dir, <span class="hljs-string">&quot;dev&quot;</span>, subject + <span class="hljs-string">&quot;_dev.csv&quot;</span>), header=<span class="hljs-literal">None</span><br>        )[: args.ntrain]<br>        test_df = pd.read_csv(<br>            os.path.join(args.data_dir, <span class="hljs-string">&quot;test&quot;</span>, subject + <span class="hljs-string">&quot;_test.csv&quot;</span>), header=<span class="hljs-literal">None</span><br>        )<br><br>        cors, acc, probs = <span class="hljs-built_in">eval</span>(args, subject, model, tokenizer, dev_df, test_df)<br>        subcats = subcategories[subject]<br>        <span class="hljs-keyword">for</span> subcat <span class="hljs-keyword">in</span> subcats:<br>            subcat_cors[subcat].append(cors)<br>            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> categories.keys():<br>                <span class="hljs-keyword">if</span> subcat <span class="hljs-keyword">in</span> categories[key]:<br>                    cat_cors[key].append(cors)<br>        all_cors.append(cors)<br><br>        test_df[<span class="hljs-string">&quot;&#123;&#125;_correct&quot;</span>.<span class="hljs-built_in">format</span>(args.model)] = cors<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(probs.shape[<span class="hljs-number">1</span>]):<br>            choice = choices[j]<br>            test_df[<span class="hljs-string">&quot;&#123;&#125;_choice&#123;&#125;_probs&quot;</span>.<span class="hljs-built_in">format</span>(args.model, choice)] = probs[:, j]<br>        test_df.to_csv(<br>            os.path.join(<br>                args.save_dir, <span class="hljs-string">&quot;results_&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(args.model.split(<span class="hljs-string">&quot;/&quot;</span>)[-<span class="hljs-number">1</span>]), <span class="hljs-string">&quot;&#123;&#125;.csv&quot;</span>.<span class="hljs-built_in">format</span>(subject)<br>            ),<br>            index=<span class="hljs-literal">None</span>,<br>        )<br><br>    results = &#123;<span class="hljs-string">&quot;subcategories&quot;</span>: &#123;&#125;, <span class="hljs-string">&quot;categories&quot;</span>: &#123;&#125;&#125;<br>    <span class="hljs-keyword">for</span> subcat <span class="hljs-keyword">in</span> subcat_cors:<br>        subcat_acc = np.mean(np.concatenate(subcat_cors[subcat]))<br>        results[<span class="hljs-string">&quot;subcategories&quot;</span>][subcat] = subcat_acc<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Average accuracy &#123;:.3f&#125; - &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(subcat_acc, subcat))<br><br>    <span class="hljs-keyword">for</span> cat <span class="hljs-keyword">in</span> cat_cors:<br>        cat_acc = np.mean(np.concatenate(cat_cors[cat]))<br>        results[<span class="hljs-string">&quot;categories&quot;</span>][cat] = cat_acc<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Average accuracy &#123;:.3f&#125; - &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(cat_acc, cat))<br>    weighted_acc = np.mean(np.concatenate(all_cors))<br>    results[<span class="hljs-string">&quot;weighted_accuracy&quot;</span>] = weighted_acc<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Average accuracy: &#123;:.3f&#125;&quot;</span>.<span class="hljs-built_in">format</span>(weighted_acc))<br><br>    results_file = os.path.join(<br>        args.save_dir, <span class="hljs-string">&quot;accuracies_&#123;&#125;.json&quot;</span>.<span class="hljs-built_in">format</span>(args.model.replace(<span class="hljs-string">&quot;/&quot;</span>, <span class="hljs-string">&quot;_&quot;</span>))<br>    )<br>    end_time = time.time()<br>    results[<span class="hljs-string">&quot;cost_time&quot;</span>] = end_time - start_time<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(results_file, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(json.dumps(results, indent=<span class="hljs-number">4</span>))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&quot;--ntrain&quot;</span>, <span class="hljs-string">&quot;-k&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">5</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--data_dir&quot;</span>, <span class="hljs-string">&quot;-d&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;data&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--save_dir&quot;</span>, <span class="hljs-string">&quot;-s&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;results&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--model&quot;</span>, <span class="hljs-string">&quot;-m&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>)<br>    args = parser.parse_args()<br>    main(args)<br>    <br></code></pre></td></tr></table></figure><p>运行方式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 evaluate_hf.py -m /workspace/models/llama2-7b-hf<br></code></pre></td></tr></table></figure><p>本项目已开源至Github平台，访问网址为：<ahref="https://github.com/percent4/llm_evaluation_4_mmlu">https://github.com/percent4/llm_evaluation_4_mmlu</a>.</p><h2 id="评测实验">评测实验</h2><p>笔者在A10080G的GPU上对各类大模型进行评测，它们在MMLU数据集上的表现结果如下：</p><ul><li>LLAMA系列模型</li></ul><table><thead><tr class="header"><th>模型尺寸</th><th>Average weighed accuracy</th><th>STEM</th><th>humanities</th><th>social sciences</th><th>other</th><th>Inference Time(s)</th></tr></thead><tbody><tr class="odd"><td>llama-2-7b</td><td>0.4596</td><td>0.3704</td><td>0.4338</td><td>0.5184</td><td>0.5244</td><td>2468.45</td></tr><tr class="even"><td>llama-2-13b</td><td>0.5568</td><td>0.4427</td><td>0.5443</td><td>0.6341</td><td>0.6076</td><td>4123.48</td></tr><tr class="odd"><td>llama-2-70b</td><td>0.6911</td><td>0.5779</td><td>0.6516</td><td>0.8044</td><td>0.7461</td><td>14961.76</td></tr></tbody></table><ul><li>其它模型</li></ul><table><thead><tr class="header"><th>模型</th><th>Average weighed accuracy</th><th>STEM</th><th>humanities</th><th>social sciences</th><th>other</th><th>Inference Time(s)</th></tr></thead><tbody><tr class="odd"><td>Baichuan-7B</td><td>0.4261</td><td>0.3615</td><td>0.3853</td><td>0.4927</td><td>0.4821</td><td>3620.22</td></tr><tr class="even"><td>Baichuan2-7B-Base</td><td>0.5431</td><td>0.4463</td><td>0.5133</td><td>0.6126</td><td>0.6104</td><td>3742.95</td></tr><tr class="odd"><td>Baichuan2-13B-Base</td><td>0.5901</td><td>0.4954</td><td>0.5505</td><td>0.6783</td><td>0.6521</td><td>3460.3</td></tr><tr class="even"><td>internlm-20b</td><td>0.6063</td><td>0.5113</td><td>0.5615</td><td>0.7033</td><td>0.6675</td><td>5709.98</td></tr><tr class="odd"><td>Mistral-7B-v0.1</td><td>0.6267</td><td>0.5268</td><td>0.5658</td><td>0.7364</td><td>0.7039</td><td>2517.74</td></tr></tbody></table><figure><img src="https://s2.loli.net/2023/10/18/3FJk2psOInuTAZ9.png"alt="大模型在MMLU数据集上的评测结果" /><figcaptionaria-hidden="true">大模型在MMLU数据集上的评测结果</figcaption></figure><figure><img src="https://s2.loli.net/2023/10/18/tjZrMLHk3cOmfVs.png"alt="大模型在MMLU数据集上的各学科评测结果" /><figcaptionaria-hidden="true">大模型在MMLU数据集上的各学科评测结果</figcaption></figure><h2 id="总结">总结</h2><p>本文将会介绍如何使用大模型（LLM）对MMLU数据集进行评测。</p><p>本文中的项目代码已开源至Github平台，访问网址为：<ahref="https://github.com/percent4/llm_evaluation_4_mmlu">https://github.com/percent4/llm_evaluation_4_mmlu</a>.</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>LLM Evaluation</tag>
      
      <tag>MMLU数据集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VSCODE使用技巧（1）连接远程服务器开发及使用Jupyter</title>
    <link href="/VSCODE%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%EF%BC%881%EF%BC%89%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BC%80%E5%8F%91%E5%8F%8A%E4%BD%BF%E7%94%A8Jupyter/"/>
    <url>/VSCODE%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%EF%BC%881%EF%BC%89%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BC%80%E5%8F%91%E5%8F%8A%E4%BD%BF%E7%94%A8Jupyter/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何在VSCODE中连接远程服务器进行代码开发，以及如何使用Jupyter。</p></blockquote><p><ahref="https://zh.wikipedia.org/wiki/Visual_Studio_Code">VSCODE</a>(VisualStudioCode)是一款由微软开发且跨平台的免费源代码编辑器。它是常用的软件开发IDE之一，支持多种编程语言。笔者在日常的Python开发中，使用较多的IDE工具是PyCharm，而VSCODE的使用较少。</p><p>由此，笔者希望对VSCODE的相关使用技巧做记录与整理。本文为系列文章的第一篇。</p><p>下面，笔者将会介绍VSCODE中的两个使用技巧：</p><ul><li>连接远程服务器进行代码开发</li><li>使用Jupyter</li></ul><h2 id="连接远程服务器开发">连接远程服务器开发</h2><p><strong>背景介绍</strong>：对于连接远程服务器开发，PyCharm的支持度也很少，但需要专业版。而VSCODE的该功能是免费的。</p><p>1:VSCODE中连接远程服务器的插件为<code>Remote-SSH</code>，找到该插件进行安装，如下图：</p><figure><img src="https://s2.loli.net/2023/10/17/hpPcJn5f3vauqFz.png"alt="安装插件" /><figcaption aria-hidden="true">安装插件</figcaption></figure><p>2:远程服务器的连接配置：点击左侧工具栏中的“远程资源管理器”，在SSH选项中点击“+”，在弹窗中输入登录远程服务器的SSH命令以及密码，这样就完成了远程服务器的连接。</p><figure><img src="https://s2.loli.net/2023/10/17/5jONPkBH9XCK6ec.png"alt="远程服务器配置" /><figcaption aria-hidden="true">远程服务器配置</figcaption></figure><p>3:选择远程目录：点击左侧工具栏中的“资源管理器”，选择打开文件夹，输入需要连接的远程目录，此时可能需要再次输入密码。</p><figure><img src="https://s2.loli.net/2023/10/17/EdiP9CAQbhwO5Fv.png"alt="选择远程目录" /><figcaption aria-hidden="true">选择远程目录</figcaption></figure><p>4:安装Python解释器插件：同第1步，Python解释器插件选择“Python”，完成安装。</p><figure><img src="https://s2.loli.net/2023/10/17/43R9YVLwJFZCov1.png"alt="Python解释器插件" /><figcaption aria-hidden="true">Python解释器插件</figcaption></figure><p>5: 选择Python解释器：按住 Shift + Ctrl +P键，在弹窗中输入Python，选择Python解释器，再选择远程服务器中的Python解释器路径即可，这样就能在VSCODE中连接远程服务器进行Python代码开发了。</p><figure><img src="https://s2.loli.net/2023/10/17/xBSGqVyLJp4lhK1.png"alt="选择Python解释器" /><figcaption aria-hidden="true">选择Python解释器</figcaption></figure><h2 id="使用jupyter">使用Jupyter</h2><p><strong>背景介绍</strong>：如果远程服务器已开放相关应用端口，则在远程服务器中直接启动Jupyter即可。但如果远程服务器没有开放任何应用端口，而你又想以WEB页面的形式使用Jupyter，则需要使用Jupyter插件。</p><p>1:在左侧的“扩展”中选择<code>Jupyter</code>插件，完成安装，步骤同上述第1步；</p><p>2:连接远程服务器，步骤参考上述<strong>连接远程服务器开发</strong>，在终端中输入<code>jupyter notebook</code>启动Jupyter；</p><p>3: 按住 Shift + Ctrl + P键，输入Jupyter，选择“Create: 新JupyterNotebook”，在右侧点击“选择内核”，在弹窗中选择“现有Jupyter服务器”，输入Jupyter服务的网址，比如默认网址为http://localhost:8888，另加token（即密码）。</p><figure><img src="https://s2.loli.net/2023/10/17/st6wPF4egDb2xUH.png"alt="vscode1_6.png" /><figcaption aria-hidden="true">vscode1_6.png</figcaption></figure><p>4: 在新的ipynb文件中即可进行Python代码开发。</p><h2 id="总结">总结</h2><p>本文介绍了笔者在VSCODE的使用过程中的两个技巧，分别为连接远程服务器进行代码开发，以及如何使用Jupyter。</p><p>本文作为VSCODE使用技巧的第一篇文章，后续将持续更新。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>VSCODE</tag>
      
      <tag>Jupyter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（七十七）文本补全中的动态提示（Dynamic-Prompting）</title>
    <link href="/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%B8%83%EF%BC%89%E6%96%87%E6%9C%AC%E8%A1%A5%E5%85%A8%E4%B8%AD%E7%9A%84%E5%8A%A8%E6%80%81%E6%8F%90%E7%A4%BA%EF%BC%88Dynamic-Prompting%EF%BC%89/"/>
    <url>/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%B8%83%EF%BC%89%E6%96%87%E6%9C%AC%E8%A1%A5%E5%85%A8%E4%B8%AD%E7%9A%84%E5%8A%A8%E6%80%81%E6%8F%90%E7%A4%BA%EF%BC%88Dynamic-Prompting%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何在大模型中对文本补充（TextCompletion）进行动态提示（Dynamic Prompting）。</p></blockquote><p>本文以文本分类任务为例，样例数据集为<code>TREC</code>，使用大模型的文本补全进行类别预测，分别在Zero-Shot,Few-Shot, DynamicFew-Shot场景下进行测试，验证动态提示对于提升模型表现的有效性。</p><h2 id="数据集">数据集</h2><p>Text REtrieval Conference (<ahref="https://huggingface.co/datasets/trec">TREC</a>) QuestionClassification数据集包含训练集中的约5500个标记问题和测试集中的另外 500个问题。</p><p>该数据集有 6 个粗类标签和 50 个精细类标签。每个句子的平均长度为10，词汇量为8700。6 个粗类标签为<strong>ABBR, ENTY,DESC, HUM, LOC, NUM</strong>.</p><p>该数据集从四个来源收集：USC发布的4,500个英语问题（Hovy et al.,2001）、针对少数稀有类别的大约500个手动构建的问题、894个 TREC 8 和 TREC9 问题，以及来自 TREC 10 的500个问题作为测试集。这些问题是手动标记的。</p><p>该数据集的HuggingFace网址为: <ahref="https://huggingface.co/datasets/trec">https://huggingface.co/datasets/trec</a>，使用<code>datasets</code>模块加载代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> openai<br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br>dataset = load_dataset(<span class="hljs-string">&quot;trec&quot;</span>)<br><br>dataset<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs json">DatasetDict(<span class="hljs-punctuation">&#123;</span><br>    train<span class="hljs-punctuation">:</span> Dataset(<span class="hljs-punctuation">&#123;</span><br>        features<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>&#x27;text&#x27;<span class="hljs-punctuation">,</span> &#x27;coarse_label&#x27;<span class="hljs-punctuation">,</span> &#x27;fine_label&#x27;<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        num_rows<span class="hljs-punctuation">:</span> <span class="hljs-number">5452</span><br>    <span class="hljs-punctuation">&#125;</span>)<br>    test<span class="hljs-punctuation">:</span> Dataset(<span class="hljs-punctuation">&#123;</span><br>        features<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>&#x27;text&#x27;<span class="hljs-punctuation">,</span> &#x27;coarse_label&#x27;<span class="hljs-punctuation">,</span> &#x27;fine_label&#x27;<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        num_rows<span class="hljs-punctuation">:</span> <span class="hljs-number">500</span><br>    <span class="hljs-punctuation">&#125;</span>)<br><span class="hljs-punctuation">&#125;</span>)<br></code></pre></td></tr></table></figure><p>其中test数据集的第一条数据为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>&#x27;text&#x27;<span class="hljs-punctuation">:</span> &#x27;How far is it from Denver to Aspen ?&#x27;<span class="hljs-punctuation">,</span><br> &#x27;coarse_label&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-number">5</span><span class="hljs-punctuation">,</span><br> &#x27;fine_label&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-number">40</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>对数据进行预处理，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># name of the text and label column</span><br>label_type = <span class="hljs-string">&#x27;coarse_label&#x27;</span><br>text_key = <span class="hljs-string">&quot;text&quot;</span><br><span class="hljs-comment"># create mapping of ids2class and class2id</span><br>id2class = <span class="hljs-built_in">dict</span>((i, label) <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataset[<span class="hljs-string">&#x27;train&#x27;</span>].features[label_type].names))<br>class2id = <span class="hljs-built_in">dict</span>((label, i) <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataset[<span class="hljs-string">&#x27;train&#x27;</span>].features[label_type].names))<br><span class="hljs-comment"># create a dictionary with classes as key and containing all the training examples within that class</span><br>class2TrainDataset = <span class="hljs-built_in">dict</span>((label, []) <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> dataset[<span class="hljs-string">&#x27;train&#x27;</span>].features[label_type].names)<br><span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> dataset[<span class="hljs-string">&#x27;train&#x27;</span>]:<br>    label = id2class[example[label_type]]<br>    class2TrainDataset[label].append(example[text_key])<br></code></pre></td></tr></table></figure><p>其中，id2class和class2id分别为id与类别对应表、类型与id对应表，class2TrainDataset为每个类别中的训练数据集。</p><h2 id="zero-shot">Zero-Shot</h2><p>构建Zero-Shot的prompt，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># a prompt for asking LLM to perform a task</span><br>task_prompt = <span class="hljs-string">&quot;As a Question Answering agent, your goal is to categorize questions into different semantic classes that impose constraints on potential answers, so that they can be utilized in later stages of the question answering process.\nFollowing are the semantic classes: [&quot;</span><br>task_prompt += <span class="hljs-string">&quot;, &quot;</span>.join([label <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> class2TrainDataset]) + <span class="hljs-string">&quot;]&quot;</span><br><span class="hljs-comment"># a prompt for asking LLM to generate the output for current task</span><br>query_prompt = <span class="hljs-string">&quot;\nClassify the following question into one of the above classes. Please answer in a single word.\nquestion: &quot;</span><br>answer_prompt = <span class="hljs-string">&quot;\noutput: &quot;</span><br></code></pre></td></tr></table></figure><p>那么，test数据集的第一条的Zero-Shot prompt为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">zeroshot_prompt = task_prompt +  query_prompt + dataset[<span class="hljs-string">&#x27;test&#x27;</span>][<span class="hljs-number">0</span>][text_key] + answer_prompt<br><span class="hljs-meta">&gt;&gt;&gt; </span>zeroshot_prompt<br><br>As a Question Answering agent, your goal <span class="hljs-keyword">is</span> to categorize questions into different semantic classes that impose constraints on potential answers, so that they can be utilized <span class="hljs-keyword">in</span> later stages of the question answering process.<br>Following are the semantic classes: [ABBR, ENTY, DESC, HUM, LOC, NUM]<br>Classify the following question into one of the above classes. Please answer <span class="hljs-keyword">in</span> a single word.<br>question: How far <span class="hljs-keyword">is</span> it <span class="hljs-keyword">from</span> Denver to Aspen ?<br>output:<br></code></pre></td></tr></table></figure><p>调用openai的大模型进行回复，调用函数代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python">openai.api_key = <span class="hljs-string">&quot;sk-xxx&quot;</span><br>model_name = <span class="hljs-string">&quot;gpt-3.5-turbo-instruct&quot;</span><br><br><span class="hljs-keyword">import</span> tiktoken<br>enc = tiktoken.encoding_for_model(model_name)<br>log_bias_dict = &#123;&#125;<br><span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> dataset[<span class="hljs-string">&#x27;train&#x27;</span>].features[<span class="hljs-string">&quot;coarse_label&quot;</span>].names:<br>    <span class="hljs-keyword">for</span> token_id <span class="hljs-keyword">in</span> enc.encode(label):<br>      log_bias_dict[token_id] = <span class="hljs-number">5</span><br>      <br><span class="hljs-comment"># Text completion using GPT</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">trim_text</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-keyword">return</span> text.strip().strip(<span class="hljs-string">&#x27;\n&#x27;</span>).strip(<span class="hljs-string">&#x27;\\n&#x27;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_using_gpt</span>(<span class="hljs-params">prompt</span>):<br>    generated_sentence = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-comment"># Create a completion for the provided prompt and parameters</span><br>        response = openai.Completion.create(<br>            model=model_name,<br>            prompt=prompt, <br>            max_tokens=<span class="hljs-number">3</span>,<br>            temperature=<span class="hljs-number">0</span>,<br>            top_p=<span class="hljs-number">1</span>,<br>            stop=<span class="hljs-literal">None</span>,<br>            frequency_penalty=<span class="hljs-number">0</span>,<br>            presence_penalty=<span class="hljs-number">0.0</span>,<br>            logit_bias=log_bias_dict<br>        )<br>        <br>        choices = response.get(<span class="hljs-string">&quot;choices&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(choices) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> <span class="hljs-string">&quot;text&quot;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> choices[<span class="hljs-number">0</span>]:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Text not generated properly&quot;</span>)<br>        generated_sentence = choices[<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;text&#x27;</span>].lstrip(<span class="hljs-string">&#x27;\\n&#x27;</span>).rstrip(<span class="hljs-string">&#x27;\\n&#x27;</span>).lstrip(<span class="hljs-string">&#x27;\n\n&#x27;</span>).rstrip(<span class="hljs-string">&#x27;\n\n&#x27;</span>).lstrip(<span class="hljs-string">&#x27;\n&#x27;</span>).rstrip(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>        <br>    <span class="hljs-keyword">except</span> openai.error.APIError <span class="hljs-keyword">as</span> e:<br>        <span class="hljs-comment"># Handle API error here, e.g. retry or log</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;OpenAI API returned an API Error: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">except</span> openai.error.AuthenticationError <span class="hljs-keyword">as</span> e:<br>        <span class="hljs-comment"># Handle Authentication error here, e.g. invalid API key</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;OpenAI API returned an Authentication Error: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">except</span> openai.error.APIConnectionError <span class="hljs-keyword">as</span> e:<br>        <span class="hljs-comment"># Handle connection error here</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Failed to connect to OpenAI API: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">except</span> openai.error.InvalidRequestError <span class="hljs-keyword">as</span> e:<br>        <span class="hljs-comment"># Handle connection error here</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Invalid Request Error: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br>        <br>    <span class="hljs-keyword">except</span> openai.error.RateLimitError <span class="hljs-keyword">as</span> e:<br>        <span class="hljs-comment"># Handle rate limit error</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;OpenAI API request exceeded rate limit: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">except</span> openai.error.ServiceUnavailableError <span class="hljs-keyword">as</span> e:<br>        <span class="hljs-comment"># Handle Service Unavailable error</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Service Unavailable: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">except</span> openai.error.Timeout <span class="hljs-keyword">as</span> e:<br>        <span class="hljs-comment"># Handle request timeout</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Request timed out: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">return</span> generated_sentence<br></code></pre></td></tr></table></figure><p>使用模型为<code>gpt-3.5-turbo-instruct</code>,max_tokens为3。为了保证输出token为数据集中的粗类类别，使用tiktoken得到这些粗类类别的tokenid，采用logit_bias对这些token id的输出进行加强。</p><p>对test数据集第一条数据进行测试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>generate_using_gpt(zeroshot_prompt)<br><br><span class="hljs-string">&#x27;LOC&#x27;</span><br></code></pre></td></tr></table></figure><p>对全量test数据集使用Zero-Shot Prompt，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># prompt without any examples from the training dataset</span><br>labels = []<br>predictions = []<br><span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> dataset[<span class="hljs-string">&#x27;test&#x27;</span>]:<br>    zeroshot_prompt = task_prompt +  query_prompt + example[text_key] + answer_prompt<br>    pred = generate_using_gpt(zeroshot_prompt)<br>    pred=trim_text(pred)<br>    labels.append(example[label_type])<br>    <span class="hljs-keyword">if</span> pred <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> class2id:<br>        predictions.append(-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">else</span>:<br>        predictions.append(class2id[pred])<br>        <br>report = classification_report(labels, predictions, digits=<span class="hljs-number">4</span>) <br></code></pre></td></tr></table></figure><p>评估结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">              precision    recall  f1-score   support<br><br>           0     0.6364    0.7778    0.7000         9<br>           1     0.4432    0.4149    0.4286        94<br>           2     0.7154    0.6377    0.6743       138<br>           3     0.9455    0.8000    0.8667        65<br>           4     0.8222    0.9136    0.8655        81<br>           5     0.8195    0.9646    0.8862       113<br><br>    accuracy                         0.7380       500<br>   macro avg     0.7304    0.7514    0.7369       500<br>weighted avg     0.7336    0.7380    0.7324       500<br></code></pre></td></tr></table></figure><p>weighted avg F1值为<code>0.7324</code>.</p><h2 id="few-shot">Few-Shot</h2><p>接下来，使用Few-Shot对prompt进行加强，方法为从每个类别的train数据集中提取第一条样本作为Few-Shot，即<code>In-Context Learning</code>(ICL),代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># function to selection few examples in each of the classes from the training dataset</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateFewshotPrompt</span>(<span class="hljs-params">class2TrainDataset, N=<span class="hljs-number">3</span></span>):<br>    fewshot_prompt = <span class="hljs-string">&quot;\nFollowing are some examples.&quot;</span><br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> class2TrainDataset:<br>        <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> class2TrainDataset[label][:N]:<br>            fewshot_prompt += <span class="hljs-string">&quot;\nquestion: &quot;</span> + example<br>            fewshot_prompt += <span class="hljs-string">&quot;\noutput: &quot;</span> + label<br>    <span class="hljs-keyword">return</span> fewshot_prompt<br>    <br><span class="hljs-comment"># prompt with one example in each of the classes</span><br>fewshot_examples = generateFewshotPrompt(class2TrainDataset, N=<span class="hljs-number">1</span>)<br>fewshot_prompt = task_prompt +  fewshot_examples + query_prompt + dataset[<span class="hljs-string">&#x27;test&#x27;</span>][<span class="hljs-number">0</span>][text_key] + answer_prompt<br><span class="hljs-meta">&gt;&gt;&gt; </span>fewshot_prompt<br></code></pre></td></tr></table></figure><p>test数据集的第一条数据的Few-Shot prompt如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">As a Question Answering agent, your goal is to categorize questions into different semantic classes that impose constraints on potential answers, so that they can be utilized <span class="hljs-keyword">in</span> later stages of the question answering process.<br>Following are the semantic classes: [ABBR, ENTY, DESC, HUM, LOC, NUM]<br>Following are some examples.<br>question: What is the full form of .com ?<br>output: ABBR<br>question: What films featured the character Popeye Doyle ?<br>output: ENTY<br>question: How did serfdom develop <span class="hljs-keyword">in</span> and <span class="hljs-keyword">then</span> leave Russia ?<br>output: DESC<br>question: What contemptible scoundrel stole the cork from my lunch ?<br>output: HUM<br>question: What sprawling U.S. state boasts the most airports ?<br>output: LOC<br>question: When was Ozzy Osbourne born ?<br>output: NUM<br>Classify the following question into one of the above classes. Please answer <span class="hljs-keyword">in</span> a single word.<br>question: How far is it from Denver to Aspen ?<br>output:<br></code></pre></td></tr></table></figure><p>基于Few-Shot prompt，对全量test数据集进行评估，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># prompt is created by adding one example in each of the classes </span><br>labels = []<br>predictions = []<br><span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> dataset[<span class="hljs-string">&#x27;test&#x27;</span>]:<br>    fewshot_prompt = task_prompt + fewshot_examples + query_prompt + example[text_key] + answer_prompt<br>    pred = generate_using_gpt(fewshot_prompt)<br>    pred=trim_text(pred)<br>    labels.append(example[label_type])<br>    <span class="hljs-keyword">if</span> pred <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> class2id:<br>        predictions.append(-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">else</span>:<br>        predictions.append(class2id[pred])<br>        <br>report = classification_report(labels, predictions, digits=<span class="hljs-number">4</span>)<br></code></pre></td></tr></table></figure><p>评估结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">              precision    recall  f1-score   support<br><br>           0     0.8182    1.0000    0.9000         9<br>           1     0.5217    0.5106    0.5161        94<br>           2     0.7727    0.7391    0.7556       138<br>           3     1.0000    0.8462    0.9167        65<br>           4     0.8021    0.9506    0.8701        81<br>           5     0.9474    0.9558    0.9515       113<br><br>    accuracy                         0.7980       500<br>   macro avg     0.8103    0.8337    0.8183       500<br>weighted avg     0.8001    0.7980    0.7969       500<br></code></pre></td></tr></table></figure><p>此时，weighted avg F1值为<code>0.7969</code>.</p><h2 id="dynamic-few-shot">Dynamic Few-Shot</h2><p>上面Few-Shot prompt的效果已经比Zero-Shotprompt好很多了，还有提升空间吗？</p><p>对于Few-Shot的样本，我们是否可以进行选择，使得评估样本与Few-Shot样本接可能相近。基于此，我们想到了DynamicFew-Shot，在每次评估测试样本时，在训练集的每个类别中选择与其语义相似度最高的k（本文取k=1）个样本。</p><p>考虑到文本的语义相似度，我们需要一个语义相似度计算的基础模型，一般为文本嵌入（TextEmbedding）模型，本文选择<code>all-mpnet-base-v2</code>，使用<code>sentence_transformers</code>进行文本嵌入。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer, util<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> cuda<br>device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br><br><span class="hljs-comment"># loading Sentence Transformer based model</span><br>model = SentenceTransformer(<span class="hljs-string">&#x27;all-mpnet-base-v2&#x27;</span>, device=device)<br><br><span class="hljs-comment"># extract embeddings for a set of examples</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ExtractEmbeddings</span>(<span class="hljs-params">examples</span>):<br>    embedding_ls = []<br>    <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> examples:<br>        embedding = model.encode(example)     <br>        embedding_ls.append(embedding)<br>    <span class="hljs-keyword">return</span> embedding_ls<br><br><span class="hljs-comment"># extract embeddings for all the training examples</span><br>class2TrainDatasetWithEmbedding = &#123;&#125;<br><span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> class2TrainDataset:<br>    embeddings = ExtractEmbeddings(class2TrainDataset[label])<br>    class2TrainDatasetWithEmbedding[label] = [class2TrainDataset[label], embeddings]<br></code></pre></td></tr></table></figure><p>在上述代码中，我们使用<code>sentence_transformers</code>加载<code>all-mpnet-base-v2</code>模型，并对每个类别的训练集数据进行文本嵌入，获取它们的词向量，储存在内存中。</p><p>接着，针对每条评估测试样本，选择每个类别中与其语义相似度最高的1条样本，形成DynamicFew-Shot prompt，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># extract similar queries for a given input text from each of the classes</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">getSimilarExamples</span>(<span class="hljs-params">input_text, dataset, dataset_embedding</span>):<br>    input_embedding = model.encode(input_text)<br>    sim_score = util.dot_score(input_embedding, dataset_embedding)[<span class="hljs-number">0</span>]<br>    topN_ids = np.argsort(-sim_score)<br>    <span class="hljs-keyword">return</span> [dataset[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> topN_ids]<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">getClasswiseSimilarExamples</span>(<span class="hljs-params">input_text, class2TrainDatasetWithEmbedding</span>):<br>    classwiseSimilarExamples = &#123;&#125;<br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> class2TrainDataset:<br>        similarExamples = getSimilarExamples(input_text, class2TrainDatasetWithEmbedding[label][<span class="hljs-number">0</span>], class2TrainDatasetWithEmbedding[label][<span class="hljs-number">1</span>])<br>        classwiseSimilarExamples[label] = similarExamples<br>    <span class="hljs-keyword">return</span> classwiseSimilarExamples<br>    <br><span class="hljs-comment"># generate a prompt with similar examples in each of the classes</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateDynamicPrompt</span>(<span class="hljs-params">input_text, class2TrainDatasetWithEmbedding, N=<span class="hljs-number">3</span></span>):<br>    classwiseSimilarExamples = getClasswiseSimilarExamples(input_text, class2TrainDatasetWithEmbedding)<br>    dynamic_prompt = <span class="hljs-string">&quot;\nFollowing are some examples.&quot;</span><br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> classwiseSimilarExamples:<br>        <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> classwiseSimilarExamples[label][:N]:<br>            dynamic_prompt += <span class="hljs-string">&quot;\nquestion: &quot;</span> + example<br>            dynamic_prompt += <span class="hljs-string">&quot;\noutput: &quot;</span> + label<br>    <span class="hljs-keyword">return</span> dynamic_prompt<br>    <br><span class="hljs-comment"># dynamic prompt with one similar example in each of the classes</span><br>fewshot_examples = generateDynamicPrompt(dataset[<span class="hljs-string">&#x27;test&#x27;</span>][<span class="hljs-number">0</span>][text_key], class2TrainDatasetWithEmbedding, N=<span class="hljs-number">1</span>)<br>dynamic_prompt = task_prompt + fewshot_examples + query_prompt + dataset[<span class="hljs-string">&#x27;test&#x27;</span>][<span class="hljs-number">0</span>][text_key] + answer_prompt<br><span class="hljs-meta">&gt;&gt;&gt; </span>dynamic_prompt<br></code></pre></td></tr></table></figure><p>此时，test数据集中的第一条样本的Dynamic Few-Shot prompt为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">As a Question Answering agent, your goal is to categorize questions into different semantic classes that impose constraints on potential answers, so that they can be utilized <span class="hljs-keyword">in</span> later stages of the question answering process.<br>Following are the semantic classes: [ABBR, ENTY, DESC, HUM, LOC, NUM]<br>Following are some examples.<br>question: What <span class="hljs-keyword">do</span> the letters D.C. stand <span class="hljs-keyword">for</span> <span class="hljs-keyword">in</span> Washington , D.C. ?<br>output: ABBR<br>question: What race is 1 , 137 miles long ?<br>output: ENTY<br>question: Why is the mile 528 feet ?<br>output: DESC<br>question: Who lives at 39 Stone Canyon Way ?<br>output: HUM<br>question: What Colorado city owns its own glacier ?<br>output: LOC<br>question: How high is the city of Denver ?<br>output: NUM<br>Classify the following question into one of the above classes. Please answer <span class="hljs-keyword">in</span> a single word.<br>question: How far is it from Denver to Aspen ?<br>output:<br></code></pre></td></tr></table></figure><p>可以看到此时的Dynamic Few-Shot prompt中的样本明显比Few-Shotprompt中的样本更好。</p><p>此时，再对全量test数据集进行评估，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">labels = []<br>predictions = []<br><span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> dataset[<span class="hljs-string">&#x27;test&#x27;</span>]:<br>    fewshot_examples = generateDynamicPrompt(example[text_key], class2TrainDatasetWithEmbedding, N=<span class="hljs-number">1</span>)<br>    dynamic_prompt = task_prompt + fewshot_examples + query_prompt + example[text_key] + answer_prompt<br>    pred = generate_using_gpt(dynamic_prompt)<br>    pred=trim_text(pred)<br>    labels.append(example[label_type])<br>    <span class="hljs-keyword">if</span> pred <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> class2id:<br>        predictions.append(-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">else</span>:<br>        predictions.append(class2id[pred])<br>        <br>report = classification_report(labels, predictions, digits=<span class="hljs-number">4</span>) <br></code></pre></td></tr></table></figure><p>评估结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">              precision    recall  f1-score   support<br><br>           0     1.0000    0.7778    0.8750         9<br>           1     0.7083    0.7234    0.7158        94<br>           2     0.8615    0.8116    0.8358       138<br>           3     0.9508    0.8923    0.9206        65<br>           4     0.8824    0.9259    0.9036        81<br>           5     0.8926    0.9558    0.9231       113<br><br>    accuracy                         0.8560       500<br>   macro avg     0.8826    0.8478    0.8623       500<br>weighted avg     0.8572    0.8560    0.8557       500<br></code></pre></td></tr></table></figure><p>最终得到的weighted avg F1值为<code>0.8557</code>.</p><h2 id="总结">总结</h2><p>对上述的内容进行总结，我们使用<code>gpt-3.5-turbo-instruct</code>对<code>TREC</code>的中test数据集，分别就Zero-Shot,Few-Shot, Dynamic Few-Shot情形进行评估，得到的评估指标为：</p><table><thead><tr class="header"><th>prompt</th><th>weighted avg F1</th></tr></thead><tbody><tr class="odd"><td>Zero-Shot</td><td>0.7324</td></tr><tr class="even"><td>Few-Shot</td><td>0.7969</td></tr><tr class="odd"><td>Dynamic Few-Shot</td><td>0.8557</td></tr></tbody></table><p>显然，Dynamic Few-Shot prompt的效果是最好的，比Zero-Shotprompt的指标高了12%多，而这还是没有对模型进行任何微调的结果！</p><p>在平时工作中，我们也可以尝试使用Dynamic Few-Shot prompt。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>Basic_Samples/Completions/completions_with_dynamic_prompt.ipynb: <ahref="https://github.com/Azure-Samples/openai/blob/main/Basic_Samples/Completions/completions_with_dynamic_prompt.ipynb">https://github.com/Azure-Samples/openai/blob/main/Basic_Samples/Completions/completions_with_dynamic_prompt.ipynb</a></li><li>TREC dataset: <ahref="https://huggingface.co/datasets/trec">https://huggingface.co/datasets/trec</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>Dynamic Few Shot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（七十六）使用大模型完成填字游戏</title>
    <link href="/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%8C%E6%88%90%E5%A1%AB%E5%AD%97%E6%B8%B8%E6%88%8F/"/>
    <url>/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%8C%E6%88%90%E5%A1%AB%E5%AD%97%E6%B8%B8%E6%88%8F/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将介绍如何使用大模型来完成汉字填字游戏。</p></blockquote><p>这一次，我们将利用大模型来做一件酷酷的事情，那就是用它来完成汉字填字游戏（wordpuzzle）。</p><h2 id="填字游戏">填字游戏</h2><blockquote><p>填字游戏一般在国外较受欢迎。<ahref="https://zh.wikipedia.org/zh-hans/%E5%A1%AB%E5%AD%97%E6%B8%B8%E6%88%8F">填字游戏</a>一般给出一个矩形的表格。这个表格被分割为若干个大小相同的方格，方格的颜色有白色与黑色两种。白色的方格组成一些交叉的行与列，行列的长度不等。玩家根据题目所提供的有关信息，将答案填入这些行与列之中，每个白色方格中只能填入一个字。</p></blockquote><p>笔者在公交上打开澎湃新闻App，里面有"澎湃填字"游戏，本次游戏的界面如下：</p><figure><img src="https://s2.loli.net/2023/10/11/6hVd15jlpNKfRsx.jpg"alt="澎湃填字游戏" /><figcaption aria-hidden="true">澎湃填字游戏</figcaption></figure><p>游戏中的题目如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs csv">1. 李清照的词《一剪梅·红藕香残玉簟秋》中“一种相思，两处闲愁”的上一句,7<br>2. 印度洋的一个岛国，首都科伦坡,4<br>3. 一种伞形装备，用于从飞机上空头人员或物质等,3<br>4. 苏轼的词《念奴娇·赤壁怀古》中“浪淘尽，千古风流人物”的上一句,4<br>5. 一种可以用作宠物饲养的可爱鸭子，即Call duck,3<br>6. 中国最早的出版社之一，1912年1月1日成立于上海,4<br>7. 横跨欧亚两洲的一个国家，首都是安卡拉,3<br>8. 中国的一个知名音乐节，今日因在南阳成“音乐劫”引发关注,5<br>9. 中国最大的内陆咸水湖，也是世界上海拔最高的湖泊之一,3<br>10. 中国古代四大发明之一，蔡伦是其发明者,3<br><br>一、曾让牛顿痴迷的中世纪炼金术中，“神圣三元素”包括硫磺、盐和哪种物质？,2<br>二、“迪士尼公主”大家庭中，唯一设定没有皇室血统或身份的公主形象是谁？,3<br>三、一种充满复杂通道的建筑物，很难找到正确的通行道路,3<br>四、汉代蔡邕用柯亭竹所制的著名笛子，后泛指美笛,3<br>五、成语，喜欢做某事，并在其中获得乐趣,4<br>六、上海的一所知名财经类高校，校训是“厚德博学，经济匡时”,4<br>七、清朝洋务运动中成立的近代军事工业生产机构，也是近代中国最大的军火工厂,5<br>八、李煜的词《浪淘沙》中“天上人间”的上一句,7<br>九、今日“巴以冲突”再起，其中“巴”是指那个国家,4<br>十、学术上用来表示特殊意义的专门用语,2<br></code></pre></td></tr></table></figure><p>其中，阿拉伯数字开头的是竖排，汉字数字开头的代表横排，最后的数字代表答案的字数。</p><p>既然大模型的能力很好很强大，那么，我们为什么不尝试用LLM来完成填字游戏呢？</p><p>Let's go!</p><h2 id="程序">程序</h2><p>首先先介绍下笔者的解决思路。</p><ol type="1"><li>需要调用搜索引擎。一是因为题目中包含最近的时事新闻，二是因为ChatGPT对于汉语，尤其是诗词的理解能力较弱，三是因为有了搜索引擎，才使回复更好更完善，并给出答案解释，类似与perplexity.ai</li><li>写一个合适的prompt，包含搜索引擎的结果作为背景知识</li><li>限定回答的字数，这个采用openai中的模型调用参数<code>max_tokens</code>来实现</li><li>回答时先解决竖排，再解决横排。当知道竖排结果时，可以对横排结果的答案进行限制，这边采用openai中模型调用参数<code>logit_bias</code>来实现</li></ol><p>实现的Python程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai </span><br><span class="hljs-comment"># @file: chinese_word_puzzle.py</span><br><span class="hljs-comment"># @time: 2023/10/10 23:24</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> openai<br><span class="hljs-keyword">import</span> tiktoken<br><span class="hljs-keyword">from</span> langchain.tools <span class="hljs-keyword">import</span> Tool<br><span class="hljs-keyword">from</span> langchain.utilities <span class="hljs-keyword">import</span> GoogleSearchAPIWrapper<br><br>os.environ[<span class="hljs-string">&quot;GOOGLE_CSE_ID&quot;</span>] = <span class="hljs-string">&quot;xxx&quot;</span><br>os.environ[<span class="hljs-string">&quot;GOOGLE_API_KEY&quot;</span>] = <span class="hljs-string">&quot;xxx&quot;</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ChnWordPuzzle</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model_name, query, answer_number, special_rules</span>):<br>        self.model_name = model_name<br>        self.query = query<br>        self.answer_number = answer_number<br>        self.special_rule = special_rules<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_google_search_result</span>(<span class="hljs-params">self</span>):<br>        search = GoogleSearchAPIWrapper()<br><br>        <span class="hljs-comment"># return first five search results</span><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">top5_results</span>(<span class="hljs-params">query</span>):<br>            <span class="hljs-keyword">return</span> search.results(query, <span class="hljs-number">5</span>)<br><br>        tool = Tool(<br>            name=<span class="hljs-string">&quot;Google Search&quot;</span>,<br>            description=<span class="hljs-string">&quot;Search Google for recent results.&quot;</span>,<br>            func=top5_results,<br>        )<br>        result = tool.run(self.query)<br>        <span class="hljs-keyword">return</span> result<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">make_prompt</span>(<span class="hljs-params">self</span>):<br>        prefix_prompt = <span class="hljs-string">&quot;请根据搜索引擎的结果，回答下面的问题。搜索结果如下：\n&quot;</span><br><br>        search_prompt = <span class="hljs-string">&quot;&quot;</span><br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-keyword">for</span> record <span class="hljs-keyword">in</span> self.get_google_search_result():<br>                search_prompt += <span class="hljs-string">f&quot;标题：<span class="hljs-subst">&#123;record[<span class="hljs-string">&#x27;title&#x27;</span>]&#125;</span>，内容：<span class="hljs-subst">&#123;record[<span class="hljs-string">&#x27;snippet&#x27;</span>]&#125;</span>\n&quot;</span><br>        <span class="hljs-keyword">except</span> Exception:<br>            <span class="hljs-keyword">pass</span><br><br>        suffix_prompt = <span class="hljs-string">f&quot;问题：<span class="hljs-subst">&#123;self.query&#125;</span>。请用<span class="hljs-subst">&#123;self.answer_number&#125;</span>个汉字进行回答。&quot;</span><br><br>        prompt = prefix_prompt + search_prompt + suffix_prompt<br>        <span class="hljs-keyword">return</span> prompt<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">solve</span>(<span class="hljs-params">self</span>):<br>        openai.api_key = <span class="hljs-string">&quot;sk-xxx&quot;</span><br><br>        prompt = self.make_prompt()<br>        <span class="hljs-built_in">print</span>(prompt)<br>        logit_bias_dict = &#123;&#125;<br>        enc = tiktoken.encoding_for_model(self.model_name)<br>        <span class="hljs-keyword">for</span> no, char <span class="hljs-keyword">in</span> self.special_rule.items():<br>            <span class="hljs-keyword">for</span> token_id <span class="hljs-keyword">in</span> enc.encode(char):<br>                logit_bias_dict[token_id] = <span class="hljs-number">10</span><br>        <span class="hljs-built_in">print</span>(logit_bias_dict)<br><br>        response = openai.ChatCompletion.create(<br>            model=self.model_name,<br>            messages=[<br>                &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: prompt&#125;<br>            ],<br>            max_tokens=self.answer_number + <span class="hljs-number">3</span>,<br>            temperature=<span class="hljs-number">0</span>,<br>            logit_bias=logit_bias_dict<br>        )<br><br>        <span class="hljs-keyword">return</span> response[<span class="hljs-string">&#x27;choices&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;message&#x27;</span>][<span class="hljs-string">&#x27;content&#x27;</span>]<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    my_query = <span class="hljs-string">&quot;李清照的词《一剪梅·红藕香残玉簟秋》中“一种相思，两处闲愁”的上一句&quot;</span><br>    my_answer_number = <span class="hljs-number">7</span><br>    my_model_name = <span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span><br>    <span class="hljs-comment"># my_model_name = &quot;gpt-4&quot;</span><br>    my_special_rules = &#123;&#125;<br>    chn_word_puzzle = ChnWordPuzzle(my_model_name, my_query, my_answer_number, my_special_rules)<br>    <span class="hljs-built_in">print</span>(chn_word_puzzle.solve()[:my_answer_number])<br><br></code></pre></td></tr></table></figure><p>在实际运行程序时，将Google search的APIkey和OpenAI的key替换成自己的。</p><p>我们来看一下，第一个问题的prompt和答案。</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">请根据搜索引擎的结果，回答下面的问题。搜索结果如下：<br>标题：李清照，花自飘零水自流，《一剪梅·红藕香残玉簟秋》，表达思念_独 <span class="hljs-string">...</span>，内容：May 3, 2019 <span class="hljs-string">...</span> 李清照的词能够唤起很多人们对情感的追索，对于情感的一种追忆。从李清照的词中人们能够找到很多现实生活中情感的寄托。这首词的意思就是：“粉红色的 <span class="hljs-string">...</span><br>标题：一剪梅·红藕香残玉簟秋_百度百科，内容：一剪梅·红藕香残玉簟秋》是宋代女词人李清照的词作。此词作于词人与丈夫赵明诚离别之后，先写清秋时节与爱人别后，独上兰舟以排遣愁怀，西楼望月恨雁来无书， <span class="hljs-string">...</span><br>标题：一剪梅·红藕香残玉簟秋原文、翻译及赏析、拼音版_李清照_古诗文网，内容：轻解罗裳，独上兰舟。云中谁寄锦书来？雁字回时，月满西楼。花自飘零水自流。一种相思，两处闲愁。此情无计可消除，才下眉头，却上 <span class="hljs-string">...</span> 词的上阕首句 <span class="hljs-string">...</span><br>标题：一剪梅•红藕香残玉簟秋，李清照玉簟秋赏析，一种相思两处闲愁- 知乎，内容：Mar 5, 2020 <span class="hljs-string">...</span> 这首词牌名“一剪梅”分为上下两阕（que，四声），阕字义是“停止”的意思，用在词里面，一般指“一段”的意思，这首词牌名是分为两段的，第一段称为上阕，第二 <span class="hljs-string">...</span><br>标题：<span class="hljs-string">&quot;花自飘零水自流。一种相思，两处闲愁。&quot;</span>全诗赏析_古诗文网，内容：原文. 李清照《一剪梅·红藕香残玉簟秋》. 红藕香残玉簟秋。轻解罗裳，独上兰舟。云中谁寄锦书来？雁字回时，月满西楼。 花自飘零水自流。一种相思，两处闲愁。此 <span class="hljs-string">...</span><br>问题：李清照的词《一剪梅·红藕香残玉簟秋》中“一种相思，两处闲愁”的上一句。请用7个汉字进行回答。<br>&#123;&#125;<br>花自飘零水自流<br></code></pre></td></tr></table></figure><p>回答正确！Perfect!</p><h2 id="实验">实验</h2><p>我们使用<code>gpt-3.5-turbo</code>模型，对前10个问题进行测试，答案如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs csv">1. 花自飘零水自流<br>2. 斯里兰卡<br>3. 投物伞<br>4. 大江东去<br>5. 柯尔鸭<br>6. 中华书局<br>7. 土耳其<br>8. 迷笛音乐节<br>9. 青海湖<br>10. 蔡伦<br></code></pre></td></tr></table></figure><p>其中，第10个回答明确有错，我们调用<code>GPT-4</code>模型，可得到正确答案：造纸术。</p><p>在得到竖排答案后，我们在回答横排问题时，可以用竖排的答案对回复进行约束，比如在回答横排第二个问题<code>“迪士尼公主”大家庭中，唯一设定没有皇室血统或身份的公主形象是谁？</code>时，我们知道第一、第三个字分别为花、兰，那么答案应该为花X兰。于是，我们将my_special_rules= {"一": "花", "三": "兰"}，可对答案进行约束。</p><p>横排答案如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs">一. 水银<br>二. 花木兰<br>三. 迷宫<br>四. 柯亭笛<br>五. 乐在其中<br>六. 上海财大<br>七. 江南制造局<br>八. 流水落花春去也<br>九. 巴勒斯坦<br>十. 术语<br></code></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>在上述的解决方案中，竖排的第3个回答<code>投物伞</code>有误，这是GoogleSearch和大模型回复共同导致的错误。正确答案为降落伞，作为人可以轻松地回答出来，而大模型+搜索引擎竟然不行！</p><p>竖排的第10个回答，<code>gpt-3.5-turbo</code>模型错误，而<code>GPT-4</code>模型回答正确。</p><p>同时，横排的第一个问题在GoogleSearch没有搜索结果，靠logit_bias约束答案中有“水”字生成的答案为水银，答案正确。</p><p>最后，横排的第六个问题，答案为上海财大，但如果logit_bias的值设为5，答案为上海财经，由于竖排的答案已知最后一个为大字，所以可调整logit_bias的值。</p><p>在上述的种种调试下，使用<code>gpt-3.5-turbo</code>模型，回答正确共18个，正确率90%。</p><p>综上，</p><ol type="1"><li>尽管有Google Search的加持，但大模型还是会回答错误。</li><li>Google Search存在搜索无结果，因此需要容错。</li><li>logit_bias的值有一定的概率会生成错误答案。</li></ol><p>因此，上述的解决方案还不十分靠谱，期待下次优化~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>填字游戏</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（七十五）大模型时代下的开放领域三元组抽取</title>
    <link href="/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%BA%94%EF%BC%89%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84%E5%BC%80%E6%94%BE%E9%A2%86%E5%9F%9F%E4%B8%89%E5%85%83%E7%BB%84%E6%8A%BD%E5%8F%96/"/>
    <url>/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%BA%94%EF%BC%89%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84%E5%BC%80%E6%94%BE%E9%A2%86%E5%9F%9F%E4%B8%89%E5%85%83%E7%BB%84%E6%8A%BD%E5%8F%96/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍在大模型（LLM）时代下，如何在开放领域进行三元组抽取。本文内容已开源至Github，网址为：https://github.com/percent4/llm_open_triplet_extraction.</p></blockquote><h2 id="回顾">回顾</h2><p>在三年前，那时候还是BERT模型时代，笔者在三元组抽取方面做了一些探索尝试，分别在限定领域、开放领域进行三元组抽取，并进一步给出了构建知识图谱的例子。</p><p>以下是笔者关于这方面探索的文章：</p><ol type="1"><li><p><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484571&amp;idx=1&amp;sn=2dda3e2cff031a3b038c45185e88bb6c&amp;chksm=fcb9bd0bcbce341db4f9f8fd1439fb44fc13c3552a7cee0df19ed7ac396c996bb477f21aa7cc&amp;payreadticket=HEEa57SV8Tl4yGiZAjcIeJ87x3M7phfxjXfmz2Zy-aor_Isc6erRbkMyEl1F-9tySvTHB-Y#rd">NLP（二十六）限定领域的三元组抽取的一次尝试</a></p></li><li><p><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484576&amp;idx=1&amp;sn=fc2bce1ec35381185209ea12eab3714d&amp;chksm=fcb9bd30cbce3426c69db55e13981b202674105529aac9d8389a950b275c8542d472f9ebe3cc&amp;payreadticket=HEVs_r75geHHd7WZ8GvbGtoTYrayU-ZhMzkU6x3nZEJzZb4tW0DJsNUkliboWT48nULHW1E#rd">NLP（二十七）开放领域的三元组抽取的一次尝试</a></p></li><li><p><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484535&amp;idx=1&amp;sn=9870bbe6e4eb48431f1b15fae41d0a7d&amp;chksm=fcb9bde7cbce34f19cb9a272a385a22e3845da353c8d57978abece07fa12d0e4cd21e842ce0e&amp;token=901693202&amp;lang=zh_CN#rd">知识图谱构建举例</a></p></li></ol><h3 id="限定领域三元组抽取">限定领域三元组抽取</h3><p>所谓<code>限定领域三元组抽取</code>，指的是在特定的Schema约束下，从文本中抽取出符合条件的三元组。笔者当时以<code>2019语言与智能技术竞赛的三元组抽取比赛</code>为例，其数据集的三元组Schema为50种关系。</p><p>采用的模型为Pipeline模型，先用序列标注算法进行实体识别，再用关系分类模型进行关系分类，形成三元组，流程图如下：</p><figure><imgsrc="https://mmbiz.qpic.cn/mmbiz_png/cRWNtpP7icvFsBsCx5aF24hLdCH7V0PXNHJU2Vgg3dY7oCqictVhDJEhTpnvOpdE6VLNuVyWCibsBomG4xrEPtRQg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"alt="限定领域三元组抽取" /><figcaption aria-hidden="true">限定领域三元组抽取</figcaption></figure><h3 id="开放领域三元组抽取">开放领域三元组抽取</h3><p>所谓<code>开放领域三元组抽取</code>，指的是不限定Schema，从文本中抽取出有效的三元组。笔者当时以自己标注的三元组数据（主要为人物关系、头衔职务等）为例，数据集规模为3200条样本，采用的模型流程图如下：</p><figure><imgsrc="https://mmbiz.qpic.cn/mmbiz_png/cRWNtpP7icvH2PkLeUxHgzDq4WDW9sVr3mrJoqxPfq01jstXesJqMQd0BLfIU4g80ic9VibSnia6sU9cq416HEib3mA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"alt="开放领域三元组抽取" /><figcaption aria-hidden="true">开放领域三元组抽取</figcaption></figure><h3 id="知识图谱构建">知识图谱构建</h3><p>三元组抽取能够从非结构化数据（文本）中抽取出符合条件的(实体1, 关系,实体2)或(实体1, 属性,属性值)三元组，从而方便我们加工出知识图谱，因为知识图谱的基本单元就是三元组。</p><p>笔者以上述的<code>开放领域三元组抽取</code>为例，在文学作品《平凡的世界》、《白鹿原》、《神雕侠侣》、《明朝那些事儿》、《曾国藩》和政治新闻中抽取三元组，结合人工整理，形成有价值的知识图谱。</p><p>关于知识图谱构建的例子，可参考Github项目：<ahref="https://github.com/percent4/knowledge_graph_demo">knowledge_graph_demo</a>.</p><h2 id="数据集">数据集</h2><blockquote><p>时间已进入大模型时代，用大模型来进行开放领域三元组抽取，应当有更好的效果。本文即是笔者的进一步尝试。有了大模型，以往难做的开放领域三元组抽取就变得较为容易了，因为大模型的文本生成模式，基本可以完成以往所有的NLP任务，这无疑是一次NLP领域的重大革命。</p></blockquote><p>笔者在以往3200条关于开放领域三元组抽取样本的基础上，采用主动学习方法，将数据集扩充至5259条样本，涉及领域主要为人物关系、头衔职务等。数据集已上传至HuggingFace，网址为：<ahref="https://huggingface.co/datasets/jclian91/open_domain_triple_extraction">jclian91/open_domain_triple_extraction</a>.</p><p>对三元组数量进行统计分析，如下图所示：</p><figure><img src="https://s2.loli.net/2023/09/30/LjuKNwGW6D5scXg.png"alt="三元组数量分布图" /><figcaption aria-hidden="true">三元组数量分布图</figcaption></figure><p>我们构造了1680条无三元组的样本，这在数据集中十分重要，因为现实世界中的文本中包含有大量的无三元组的数据，因此，基于标注数据训练的模型需要有区分是否含有三元组的能力。</p><h2 id="可视化">可视化</h2><p>在介绍大模型微调三元组抽取前，我们先来看一下，微调后的模型在新样本的表现。</p><h3 id="例子1">例子1</h3><p>来源网站：<ahref="https://www.chinanews.com/cj/2023/09-25/10083719.shtml">https://www.chinanews.com/cj/2023/09-25/10083719.shtml</a></p><p>可视化页面抽取结果如下：</p><p><img src="https://s2.loli.net/2023/09/27/NMKr6adWeQh39XL.png" /></p><p>形成的知识图谱如下：</p><p><img src="https://s2.loli.net/2023/09/27/Xj1DHU2d7pLEKfJ.png" /></p><h3 id="例子2">例子2</h3><p>来源网站：<ahref="https://www.jjxw.cn/xinwen/jjsz/202309/t20230926_6225481.html">https://www.jjxw.cn/xinwen/jjsz/202309/t20230926_6225481.html</a></p><p>可视化页面抽取结果如下：</p><p><img src="https://s2.loli.net/2023/09/27/nEchIxVk6MAXf8S.png" /></p><p>形成的知识图谱如下：</p><p><img src="https://s2.loli.net/2023/09/27/7sxWpgQeF9JXwAT.png" /></p><h2 id="模型训练">模型训练</h2><p>本文采用<code>Firefly</code>框架和基座模型<code>Baichuan2-13B-Base</code>，在开放领域三元组抽取数据集上进行微调（SFT）。</p><p>只需要将数据加工成<code>Firefly</code>框架支持的对话格式，prompt构造如下：</p><blockquote><p>给定以下文本，请分析并提取其中的关系三元组。每个三元组应该包括主体（人物、组织或物体）、关系和客体（人物、地点或物体）。如果文本中没有明显的关系，请返回空字符串。："{content}"：- （主体，关系，客体）-（主体，关系，客体），请返回空字符串。</p></blockquote><p>训练参数如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;output_dir&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;output/firefly-baichuan2-13b-spo&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;model_name_or_path&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/workspace/Baichuan2-13B-Base&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;train_file&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;./data/spo.jsonl&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;num_train_epochs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">10</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;per_device_train_batch_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;gradient_accumulation_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;learning_rate&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1e-4</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;max_seq_length&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">550</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;logging_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">100</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;save_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">100</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;save_total_limit&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lr_scheduler_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;constant_with_warmup&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;warmup_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">300</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lora_rank&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">64</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lora_alpha&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">16</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lora_dropout&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.05</span><span class="hljs-punctuation">,</span><br><br>    <span class="hljs-attr">&quot;gradient_checkpointing&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;disable_tqdm&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;optim&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;paged_adamw_32bit&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;seed&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">42</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;fp16&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;report_to&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;tensorboard&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;dataloader_num_workers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;save_strategy&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;steps&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;weight_decay&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;max_grad_norm&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.3</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;remove_unused_columns&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h2 id="模型评估">模型评估</h2><p>对开放领域三元组抽取进行模型评估应当是一件困难的事情，因为三元组的Schema是不受约束的。但好在，笔者构建的数据集主要是从新闻、小说中采集的关于人物关系、头衔职务的数据，因此，笔者又收集了来自各个网站的新闻、小说中的三元组，共100条评估样本，文件为<code>evaluate_data.xlsx</code>，前几行如下：</p><table style="width:100%;"><thead><tr class="header"><th>文本</th><th>真实三元组</th><th>来源</th><th>网址</th></tr></thead><tbody><tr class="odd"><td>新华社杭州9月24日电（记者姬烨、董意行）国际奥委会主席巴赫23日在杭州出席了第19届亚运会开幕式，他称赞这场开幕式是数字创新和人文风采的完美结合。</td><td>(新华社，记者，姬烨)(新华社，记者，董意行)(国际奥委会，主席，巴赫)</td><td>新华网</td><td>https://www.news.cn/sports/2023-09/24/c_1212274341.htm</td></tr><tr class="even"><td>2022年11月，法国总统马克龙访问泰国，受到泰国国王哇集拉隆功接见。希里婉瓦丽出现在父亲身边。</td><td>(法国，总统，马克龙)(泰国，国王，哇集拉隆功)</td><td>网易新闻</td><td>https://www.163.com/dy/article/IFDIJR03051283GO.html</td></tr><tr class="odd"><td>“这位是红岸基地的雷志成政委。我是杨卫宁，基地的总工程师。离降落还有一个小时，你休息吧。”</td><td>（红岸基地，政委，雷志成）（基地，总工程师，杨卫宁）</td><td>鲲弩小说</td><td>https://www.kunnu.com/santi/26653.htm</td></tr></tbody></table><p>对三元组抽取的评估办法，笔者借鉴了苏神的思路，主要参考代码为 <ahref="https://github.com/bojone/bert4keras/blob/master/examples/task_relation_extraction.py">examples/task_relation_extraction.py</a>.</p><p>最终的评估结果为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">f1: 0.84831, precision: 0.90419, recall: 0.79894: : 100it<br></code></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>这几年来，笔者一直在思考如何在开放领域进行三元组抽取，但在BERT模型时代受限太大，基本就是传统的限定领域的关系抽取模型。</p><p>大模型的出现，无疑是现阶段解决开放领域三元组抽取的最佳方式，也算是了了笔者多年的一个夙愿。</p><p>当然，大模型在解决开放领域中三元组抽取的过程中并不是万能的，还有许多问题待解决，笔者尝试着列举如下：</p><ul><li>如何对抽取的三元组中的实体进行对齐</li><li>在抽取三元组过程中添加时间维度（即知识更新），形成时序知识图谱</li><li>如何避免抽取无效三元组</li><li>当数据涉及的领域变多后，如何保证模型的效果</li><li>如何在一本书籍中，将抽取出的三元组自动构建知识图谱</li><li>给出更多的知识图谱的构建例子</li><li>如何提升模型的推理速度</li><li>其它</li></ul><p>以上内容笔者已开源至Github，网址为：<ahref="https://github.com/percent4/llm_open_triplet_extraction">https://github.com/percent4/llm_open_triplet_extraction</a>，欢迎大家参考~</p><h4 id="推荐阅读">推荐阅读</h4><ul><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484571&amp;idx=1&amp;sn=2dda3e2cff031a3b038c45185e88bb6c&amp;chksm=fcb9bd0bcbce341db4f9f8fd1439fb44fc13c3552a7cee0df19ed7ac396c996bb477f21aa7cc&amp;payreadticket=HEEa57SV8Tl4yGiZAjcIeJ87x3M7phfxjXfmz2Zy-aor_Isc6erRbkMyEl1F-9tySvTHB-Y#rd">NLP（二十六）限定领域的三元组抽取的一次尝试</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484576&amp;idx=1&amp;sn=fc2bce1ec35381185209ea12eab3714d&amp;chksm=fcb9bd30cbce3426c69db55e13981b202674105529aac9d8389a950b275c8542d472f9ebe3cc&amp;payreadticket=HEVs_r75geHHd7WZ8GvbGtoTYrayU-ZhMzkU6x3nZEJzZb4tW0DJsNUkliboWT48nULHW1E#rd">NLP（二十七）开放领域的三元组抽取的一次尝试</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484535&amp;idx=1&amp;sn=9870bbe6e4eb48431f1b15fae41d0a7d&amp;chksm=fcb9bde7cbce34f19cb9a272a385a22e3845da353c8d57978abece07fa12d0e4cd21e842ce0e&amp;token=901693202&amp;lang=zh_CN#rd">知识图谱构建举例</a></li></ul>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>三元组抽取</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（七十四）使用LangChain和异步Web框架实现接口流式输出</title>
    <link href="/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8LangChain%E5%92%8C%E5%BC%82%E6%AD%A5Web%E6%A1%86%E6%9E%B6%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA/"/>
    <url>/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8LangChain%E5%92%8C%E5%BC%82%E6%AD%A5Web%E6%A1%86%E6%9E%B6%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="介绍">介绍</h2><p><code>openai</code>接口已经支持流式调用，再结合Web框架的流式响应功能，不难完成流式输出功能。</p><p>但LangChain对openai接口进行了深度包装，流式输出需要进行回调（<code>callback</code>）。LangChain的流式回调类为<code>StreamingStdOutCallbackHandler</code>，此为终端流式输出，不支持接口流式输出。</p><p>如果想要对LangChain的回答进行Web端流式输出，网络上有不少人已给出解决方案，大多数方法为继承<code>BaseCallbackHandler</code>类，进行改造：通常方法是借助队列，将新生成的token送入队列，在回复答案（另起一个新的线程）的同时，进行队列元素的获取，从而实现接口流式输出。</p><p>参考其中一种解决方案：https://gist.github.com/python273/563177b3ad5b9f74c0f8f3299ec13850.</p><p>本文的创新之处在于，借助异步Web框架sanic和FastAPI,和LangChain中的AsyncIteratorCallbackHandler，使用异步方法来实现调用LangChain，实现接口流式输出功能。</p><h2 id="sanic框架框架">Sanic框架框架</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: sanic_langchain_stream.py</span><br><span class="hljs-comment"># @time: 2023/9/19 18:18</span><br><span class="hljs-comment"># sanic==23.6.0</span><br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">from</span> sanic <span class="hljs-keyword">import</span> Sanic<br><span class="hljs-keyword">from</span> sanic.response <span class="hljs-keyword">import</span> text, json, ResponseStream<br><br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> langchain.schema <span class="hljs-keyword">import</span> HumanMessage<br><span class="hljs-keyword">from</span> langchain.callbacks.streaming_aiter <span class="hljs-keyword">import</span> AsyncIteratorCallbackHandler<br><br><br>app = Sanic(<span class="hljs-string">&quot;benchmark&quot;</span>)<br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/&quot;</span></span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">index</span>(<span class="hljs-params">request</span>):<br>    <span class="hljs-keyword">return</span> text(<span class="hljs-string">&quot;hello&quot;</span>)<br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/test&quot;</span>, methods=[<span class="hljs-string">&quot;POST&quot;</span>]</span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">answer</span>(<span class="hljs-params">request</span>):<br>    content = request.json[<span class="hljs-string">&quot;content&quot;</span>]<br>    <span class="hljs-keyword">return</span> json(&#123;<span class="hljs-string">&quot;text&quot;</span>: content&#125;)<br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/csv&quot;</span></span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">request</span>):<br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">sample_streaming_fn</span>(<span class="hljs-params">response</span>):<br>        <span class="hljs-keyword">await</span> response.write(<span class="hljs-string">&quot;foo,&quot;</span>)<br>        <span class="hljs-keyword">await</span> response.write(<span class="hljs-string">&quot;bar&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> ResponseStream(sample_streaming_fn, content_type=<span class="hljs-string">&quot;text/csv&quot;</span>)<br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/answer/async&quot;</span>, methods=[<span class="hljs-string">&quot;POST&quot;</span>]</span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">answer_async</span>(<span class="hljs-params">request</span>):<br>    content = request.json[<span class="hljs-string">&quot;content&quot;</span>]<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">response</span>):<br>        handler = AsyncIteratorCallbackHandler()<br>        model_message = [HumanMessage(content=content)]<br>        chat = ChatOpenAI(streaming=<span class="hljs-literal">True</span>,<br>                          callbacks=[handler],<br>                          temperature=<span class="hljs-number">0</span>,<br>                          openai_api_key=<span class="hljs-string">&quot;&quot;</span>)<br>        asyncio.create_task(chat.apredict_messages(model_message))<br>        <span class="hljs-keyword">async</span> <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> handler.aiter():<br>            <span class="hljs-keyword">await</span> response.write(<span class="hljs-string">f&quot;data: <span class="hljs-subst">&#123;token&#125;</span>\n\n&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> ResponseStream(predict, content_type=<span class="hljs-string">&quot;text/event-stream&quot;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    app.run(host=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, port=<span class="hljs-number">3000</span>, debug=<span class="hljs-literal">False</span>, access_log=<span class="hljs-literal">True</span>)<br><br></code></pre></td></tr></table></figure><figure><img src="https://s2.loli.net/2023/09/20/My5kqGgVtr87faW.gif"alt="sanic.gif" /><figcaption aria-hidden="true">sanic.gif</figcaption></figure><h2 id="fastapi框架">FastAPI框架</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai </span><br><span class="hljs-comment"># @file: fastapi_langchain_stream.py</span><br><span class="hljs-comment"># @time: 2023/9/20 17:36</span><br><span class="hljs-comment"># fastapi==0.101.1</span><br><span class="hljs-keyword">import</span> uvicorn<br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI<br><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel<br><span class="hljs-keyword">from</span> fastapi.responses <span class="hljs-keyword">import</span> StreamingResponse, JSONResponse<br><br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> langchain.schema <span class="hljs-keyword">import</span> HumanMessage<br><span class="hljs-keyword">from</span> langchain.callbacks.streaming_aiter <span class="hljs-keyword">import</span> AsyncIteratorCallbackHandler<br><br>app = FastAPI(description=<span class="hljs-string">&quot;langchain_streaming&quot;</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Item</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    text: <span class="hljs-built_in">str</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Question</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    text: <span class="hljs-built_in">str</span><br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">fake_video_streamer</span>():<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        <span class="hljs-keyword">yield</span> <span class="hljs-string">b&quot;some fake video bytes\n&quot;</span><br><br><br><span class="hljs-meta">@app.get(<span class="hljs-params"><span class="hljs-string">&quot;/&quot;</span></span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-keyword">return</span> StreamingResponse(fake_video_streamer())<br><br><br><span class="hljs-meta">@app.post(<span class="hljs-params"><span class="hljs-string">&quot;/test&quot;</span></span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">item: Item</span>):<br>    <span class="hljs-keyword">return</span> JSONResponse(&#123;<span class="hljs-string">&quot;content&quot;</span>: item.text&#125;)<br><br><br><span class="hljs-meta">@app.post(<span class="hljs-params"><span class="hljs-string">&quot;/answer/async&quot;</span></span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">answer_async</span>(<span class="hljs-params">q: Question</span>):<br>    content = q.text<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>():<br>        handler = AsyncIteratorCallbackHandler()<br>        model_message = [HumanMessage(content=content)]<br>        chat = ChatOpenAI(streaming=<span class="hljs-literal">True</span>,<br>                          callbacks=[handler],<br>                          temperature=<span class="hljs-number">0</span>,<br>                          openai_api_key=<span class="hljs-string">&quot;sk-xxx&quot;</span>)<br>        asyncio.create_task(chat.apredict_messages(model_message))<br>        <span class="hljs-keyword">async</span> <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> handler.aiter():<br>            <span class="hljs-keyword">yield</span> <span class="hljs-string">f&quot;data: <span class="hljs-subst">&#123;token&#125;</span>\n\n&quot;</span><br><br>    <span class="hljs-keyword">return</span> StreamingResponse(predict())<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    uvicorn.run(app, host=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, port=<span class="hljs-number">8000</span>, log_level=<span class="hljs-string">&quot;info&quot;</span>)<br><br></code></pre></td></tr></table></figure>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LangChain</tag>
      
      <tag>流式输出</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python异步编程入门（一）</title>
    <link href="/Python%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <url>/Python%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>协程：单线程；充分提升性能：多核 + 单线程</p><p>Python对<strong>协程</strong>的支持是通过<strong>generator</strong>实现的。</p><p>Python3.5开始引入了新的语法async和await，可以让coroutine的代码更简洁易读。</p><p>异步模块:</p><ul><li>IO: asyncio</li><li>HTTP: aiohttp</li></ul><h2 id="简单示例">简单示例</h2><ul><li>hello world</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">import</span> asyncio<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello world!&quot;</span>, datetime.now())<br>    r = <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello again!&quot;</span>, datetime.now())<br><br><span class="hljs-comment"># 获取EventLoop</span><br>loop = asyncio.get_event_loop()<br><span class="hljs-comment"># 执行coroutine</span><br>loop.run_until_complete(hello())<br>loop.close()<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">Hello world! 2023-09-18 11:14:14.840318<br>Hello again! 2023-09-18 11:14:15.840848<br></code></pre></td></tr></table></figure><blockquote><p>asyncio.sleep(1) 也是协程</p></blockquote><blockquote><p>python 3.7以后可以用asyncio.run()运行</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">import</span> asyncio<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello world!&quot;</span>, datetime.now())<br>    r = <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello again!&quot;</span>, datetime.now())<br><br>asyncio.run(hello())<br></code></pre></td></tr></table></figure><ul><li>任务组</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> randint<br><span class="hljs-keyword">import</span> threading<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello world!&quot;</span>, datetime.now(), threading.current_thread())<br>    sleep_time = randint(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;sleep time: <span class="hljs-subst">&#123;sleep_time&#125;</span>&quot;</span>, threading.current_thread())<br>    r = <span class="hljs-keyword">await</span> asyncio.sleep(sleep_time)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello again!&quot;</span>, datetime.now(), threading.current_thread())<br><br><span class="hljs-comment"># 获取EventLoop</span><br>loop = asyncio.get_event_loop()<br><span class="hljs-comment"># 执行coroutine</span><br>tasks = [hello(), hello(), hello(), hello()]<br>loop.run_until_complete(asyncio.wait(tasks))<br>loop.close()<br></code></pre></td></tr></table></figure><p>输出结果：</p><pre><code class="hljs">Hello world! 2023-09-18 14:40:17.230477 &lt;_MainThread(MainThread, started 8127873344)&gt;sleep time: 3 &lt;_MainThread(MainThread, started 8127873344)&gt;Hello world! 2023-09-18 14:40:17.230515 &lt;_MainThread(MainThread, started 8127873344)&gt;sleep time: 1 &lt;_MainThread(MainThread, started 8127873344)&gt;Hello world! 2023-09-18 14:40:17.230528 &lt;_MainThread(MainThread, started 8127873344)&gt;sleep time: 3 &lt;_MainThread(MainThread, started 8127873344)&gt;Hello world! 2023-09-18 14:40:17.230539 &lt;_MainThread(MainThread, started 8127873344)&gt;sleep time: 2 &lt;_MainThread(MainThread, started 8127873344)&gt;Hello again! 2023-09-18 14:40:18.231054 &lt;_MainThread(MainThread, started 8127873344)&gt;Hello again! 2023-09-18 14:40:19.231754 &lt;_MainThread(MainThread, started 8127873344)&gt;Hello again! 2023-09-18 14:40:20.231809 &lt;_MainThread(MainThread, started 8127873344)&gt;Hello again! 2023-09-18 14:40:20.231981 &lt;_MainThread(MainThread, started 8127873344)&gt;</code></pre><blockquote><p>使用asyncio.gather()运行任务组</p></blockquote><ul><li>gather的使用</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> randint<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello world!&quot;</span>, datetime.now())<br>    sleep_time = randint(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;sleep time: <span class="hljs-subst">&#123;sleep_time&#125;</span>&quot;</span>)<br>    r = <span class="hljs-keyword">await</span> asyncio.sleep(sleep_time)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello again!&quot;</span>, datetime.now())<br>    <span class="hljs-keyword">return</span> sleep_time<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">group_task</span>():<br>    tasks = [hello(), hello(), hello(), hello()]<br>    <span class="hljs-keyword">await</span> asyncio.gather(*tasks)<br><br><br>asyncio.run(group_task())<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Hello</span> world! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">36</span>:<span class="hljs-number">34</span>.<span class="hljs-number">779374</span><br><span class="hljs-attribute">sleep</span> time: <span class="hljs-number">2</span><br><span class="hljs-attribute">Hello</span> world! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">36</span>:<span class="hljs-number">34</span>.<span class="hljs-number">779417</span><br><span class="hljs-attribute">sleep</span> time: <span class="hljs-number">4</span><br><span class="hljs-attribute">Hello</span> world! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">36</span>:<span class="hljs-number">34</span>.<span class="hljs-number">779427</span><br><span class="hljs-attribute">sleep</span> time: <span class="hljs-number">1</span><br><span class="hljs-attribute">Hello</span> world! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">36</span>:<span class="hljs-number">34</span>.<span class="hljs-number">779433</span><br><span class="hljs-attribute">sleep</span> time: <span class="hljs-number">0</span><br><span class="hljs-attribute">Hello</span> again! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">36</span>:<span class="hljs-number">34</span>.<span class="hljs-number">779463</span><br><span class="hljs-attribute">Hello</span> again! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">36</span>:<span class="hljs-number">35</span>.<span class="hljs-number">780650</span><br><span class="hljs-attribute">Hello</span> again! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">36</span>:<span class="hljs-number">36</span>.<span class="hljs-number">780536</span><br><span class="hljs-attribute">Hello</span> again! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">36</span>:<span class="hljs-number">38</span>.<span class="hljs-number">780285</span><br></code></pre></td></tr></table></figure><p>使用<code>gather</code>还可以获取返回结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> randint<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello world!&quot;</span>, datetime.now())<br>    sleep_time = randint(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>)<br>    r = <span class="hljs-keyword">await</span> asyncio.sleep(sleep_time)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello again!&quot;</span>, datetime.now())<br>    <span class="hljs-keyword">return</span> sleep_time<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">group_task</span>():<br>    tasks = [hello(), hello(), hello(), hello()]<br>    result = <span class="hljs-keyword">await</span> asyncio.gather(*tasks)<br>    <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> result:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;result =&gt; <span class="hljs-subst">&#123;v&#125;</span>&quot;</span>)<br><br><br>asyncio.run(group_task())<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Hello</span> world! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">54</span>:<span class="hljs-number">38</span>.<span class="hljs-number">360411</span><br><span class="hljs-attribute">Hello</span> world! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">54</span>:<span class="hljs-number">38</span>.<span class="hljs-number">360461</span><br><span class="hljs-attribute">Hello</span> world! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">54</span>:<span class="hljs-number">38</span>.<span class="hljs-number">360469</span><br><span class="hljs-attribute">Hello</span> world! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">54</span>:<span class="hljs-number">38</span>.<span class="hljs-number">360475</span><br><span class="hljs-attribute">Hello</span> again! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">54</span>:<span class="hljs-number">39</span>.<span class="hljs-number">361758</span><br><span class="hljs-attribute">Hello</span> again! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">54</span>:<span class="hljs-number">40</span>.<span class="hljs-number">361681</span><br><span class="hljs-attribute">Hello</span> again! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">54</span>:<span class="hljs-number">41</span>.<span class="hljs-number">361665</span><br><span class="hljs-attribute">Hello</span> again! <span class="hljs-number">2023</span>-<span class="hljs-number">09</span>-<span class="hljs-number">19</span> <span class="hljs-number">13</span>:<span class="hljs-number">54</span>:<span class="hljs-number">42</span>.<span class="hljs-number">361748</span><br><span class="hljs-attribute">result</span> =&gt; <span class="hljs-number">3</span><br><span class="hljs-attribute">result</span> =&gt; <span class="hljs-number">2</span><br><span class="hljs-attribute">result</span> =&gt; <span class="hljs-number">4</span><br><span class="hljs-attribute">result</span> =&gt; <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><ul><li>超时</li></ul><p>wait_for提供了超时功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> asyncio<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">my_job</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;before sleep&#x27;</span>)<br>    <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">2</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;never print&#x27;</span>)<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">await</span> asyncio.wait_for(my_job(), timeout=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">except</span> asyncio.TimeoutError:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;timeout!&#x27;</span>)<br><br><br>asyncio.run(main())<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-keyword">before</span> sleep<br><span class="hljs-keyword">timeout</span>!<br></code></pre></td></tr></table></figure><ul><li>to_thread</li></ul><p>event loop 遇到执行时间特别长的代码，有没有 await 能让event loop转为执行其它工作时，就会造成event loop 阻塞</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">import</span> threading<br><br><span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> sleep, time<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hard_work</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;thread id:&#x27;</span>, threading.get_ident())<br>    sleep(<span class="hljs-number">10</span>)<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">do_async_job</span>():<br>    hard_work()<br>    <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;job done!&#x27;</span>)<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-built_in">print</span>(time())<br>    task1 = asyncio.create_task(do_async_job())<br>    task2 = asyncio.create_task(do_async_job())<br>    task3 = asyncio.create_task(do_async_job())<br>    <span class="hljs-keyword">await</span> asyncio.gather(task1, task2, task3)<br>    <span class="hljs-built_in">print</span>(time())<br><br><br>asyncio.run(main())<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">1695103401.266803<br>thread <span class="hljs-built_in">id</span>: 8127873344<br>thread <span class="hljs-built_in">id</span>: 8127873344<br>thread <span class="hljs-built_in">id</span>: 8127873344<br>job <span class="hljs-keyword">done</span>!<br>job <span class="hljs-keyword">done</span>!<br>job <span class="hljs-keyword">done</span>!<br>1695103432.283202<br></code></pre></td></tr></table></figure><p>为解决某些耗时执行的代码阻塞 event loop的问题，Python 3.9 提供asyncio.to_thread() 可以将耗时执行的代码丟至 event loop 以外的另 1 个thread 中执行，每呼叫 1 次就會在 1 个新的 thread.</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs css">import asyncio<br>import threading<br><br><span class="hljs-selector-tag">from</span> <span class="hljs-selector-tag">time</span> import sleep, <span class="hljs-selector-tag">time</span><br><br><br>def hard_work():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;thread id:&#x27;</span>, threading.<span class="hljs-built_in">get_ident</span>())<br>    <span class="hljs-built_in">sleep</span>(<span class="hljs-number">10</span>)<br><br><br>async def <span class="hljs-built_in">do_async_job</span>():<br>    await asyncio.<span class="hljs-built_in">to_thread</span>(hard_work)<br>    await asyncio.<span class="hljs-built_in">sleep</span>(<span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;job done!&#x27;</span>)<br><br><br>async def <span class="hljs-built_in">main</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">time</span>())<br>    task1 = asyncio.<span class="hljs-built_in">create_task</span>(<span class="hljs-built_in">do_async_job</span>())<br>    task2 = asyncio.<span class="hljs-built_in">create_task</span>(<span class="hljs-built_in">do_async_job</span>())<br>    task3 = asyncio.<span class="hljs-built_in">create_task</span>(<span class="hljs-built_in">do_async_job</span>())<br>    await asyncio.<span class="hljs-built_in">gather</span>(task1, task2, task3)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">time</span>())<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">1695103741.921301<br>thread <span class="hljs-built_in">id</span>: 6153449472<br>thread <span class="hljs-built_in">id</span>: 6170275840<br>thread <span class="hljs-built_in">id</span>: 6187102208<br>job <span class="hljs-keyword">done</span>!<br>job <span class="hljs-keyword">done</span>!<br>job <span class="hljs-keyword">done</span>!<br>1695103752.9301171<br></code></pre></td></tr></table></figure><ul><li>aiohttp</li></ul><p>https://example.com/ 为示例网站，用于演示HTTP请求。</p><p>同步请求：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> time<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_requests</span>():<br>    resp = requests.get(<span class="hljs-string">&#x27;https://example.com&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;example.com =&gt;&#x27;</span>, resp.status_code)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>):<br>        make_requests()<br><br><br>s_time = time.time()<br>main()<br><span class="hljs-built_in">print</span>(time.time() - s_time)<br><br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">example</span>.com =&gt; <span class="hljs-number">200</span><br><span class="hljs-attribute">example</span>.com =&gt; <span class="hljs-number">200</span><br><span class="hljs-attribute">example</span>.com =&gt; <span class="hljs-number">200</span><br><span class="hljs-attribute">example</span>.com =&gt; <span class="hljs-number">200</span><br><span class="hljs-attribute">example</span>.com =&gt; <span class="hljs-number">200</span><br><span class="hljs-attribute">5</span>.<span class="hljs-number">089737892150879</span><br></code></pre></td></tr></table></figure><p>使用aiohttp完成HTTP异步请求：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> aiohttp<br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">import</span> time<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_requests</span>(<span class="hljs-params">session</span>):<br>    <span class="hljs-keyword">return</span> session.get(<span class="hljs-string">&#x27;https://example.com&#x27;</span>)<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> aiohttp.ClientSession() <span class="hljs-keyword">as</span> session:<br>        tasks = []<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>):<br>            tasks.append(make_requests(session))<br><br>        results = <span class="hljs-keyword">await</span> asyncio.gather(*tasks)<br>        <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> results:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;example.com =&gt;&#x27;</span>, r.status)<br><br><br>s_time = time.time()<br>asyncio.run(main())<br><span class="hljs-built_in">print</span>(time.time() - s_time)<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">example</span>.com =&gt; <span class="hljs-number">200</span><br><span class="hljs-attribute">example</span>.com =&gt; <span class="hljs-number">200</span><br><span class="hljs-attribute">example</span>.com =&gt; <span class="hljs-number">200</span><br><span class="hljs-attribute">example</span>.com =&gt; <span class="hljs-number">200</span><br><span class="hljs-attribute">example</span>.com =&gt; <span class="hljs-number">200</span><br><span class="hljs-attribute">0</span>.<span class="hljs-number">8919808864593506</span><br></code></pre></td></tr></table></figure><ul><li>异步生成器</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># SuperFastPython.com</span><br><span class="hljs-comment"># example of asynchronous generator with async for loop</span><br><span class="hljs-keyword">import</span> asyncio<br><br><br><span class="hljs-comment"># define an asynchronous generator</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">async_generator</span>():<br>    <span class="hljs-comment"># normal loop</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        <span class="hljs-comment"># block to simulate doing work</span><br>        <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># yield the result</span><br>        <span class="hljs-keyword">yield</span> i<br><br><br><span class="hljs-comment"># main coroutine</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-comment"># loop over async generator with async for loop</span><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> async_generator():<br>        <span class="hljs-built_in">print</span>(item)<br><br><br><span class="hljs-comment"># execute the asyncio program</span><br>asyncio.run(main())<br><br></code></pre></td></tr></table></figure><h2 id="参考网站">参考网站</h2><ol type="1"><li><a href="https://myapollo.com.tw/blog/begin-to-asyncio/">Pythonasyncio 從不會到上路</a></li><li><ahref="https://www.liaoxuefeng.com/wiki/1016959663602400/1017968846697824">协程</a></li><li><ahref="https://www.maxlist.xyz/2020/03/29/python-coroutine/">【Python教學】淺談Coroutine 協程使用方法</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>异步编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（七十三）从BERT模型训练到量化、蒸馏之路</title>
    <link href="/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%B8%89%EF%BC%89%E4%BB%8EBERT%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%88%B0%E9%87%8F%E5%8C%96%E3%80%81%E8%92%B8%E9%A6%8F%E4%B9%8B%E8%B7%AF/"/>
    <url>/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%B8%89%EF%BC%89%E4%BB%8EBERT%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%88%B0%E9%87%8F%E5%8C%96%E3%80%81%E8%92%B8%E9%A6%8F%E4%B9%8B%E8%B7%AF/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍笔者从BERT模型训练到模型量化、蒸馏的旅程，通过一系列文章的回顾，不难掌握模型训练和模型压缩的技能。</p></blockquote><p>在工业界中，常见的模型压缩方法有<strong>知识蒸馏</strong>（KnowledgeDistillation，KD）、<strong>剪枝</strong>（Pruning）、<strong>量化</strong>（Quantization）等。</p><p>以往，笔者只注重模型训练，而忽略了模型压缩的办法。不知不觉间，在这一段时间内，笔者研究了BERT分类模型训练、量化、知识蒸馏相关内容，形成了一系列文章。</p><p>本文希望通过对以往历史文章的回顾，来更好地梳理从模型训练到模型量化、蒸馏的发展阶段，理清模型训练和推理性能之间的平衡方法，形成自己的方法论。</p><h2 id="模型训练">模型训练</h2><p>对于<strong>模型训练</strong>，大家都接触过著名的<code>HuggingFace</code>社区的<code>Transformers</code>模块。在<code>Transformers</code>模块中，模型训练的优雅解法应该是使用<code>Trainer</code>类，其强大的功能足以完成我们绝大部分的BERT系列模型的NLP任务，且十分高效、简洁，代码操作也较为统一、优雅。</p><p>关于使用<code>Trainer</code>类进行BERT模型文本分类任务，可以参考下面的文章，模型训练、推理的代码十分简洁。</p><p><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485508&amp;idx=1&amp;sn=77a6fef8cfb11a604e19de303576539f&amp;chksm=fcb9b1d4cbce38c24cd92793bcc734684a8a5bc6c4a94d4473328158a5f7e95373f1da4ce2e2&amp;token=1635177260&amp;lang=zh_CN#rd">NLP（六十六）使用HuggingFace中的Trainer进行BERT模型微调</a></p><p>如果需要对模型进行自动化参数优化，<code>Optuna</code>会是你理想的工具，一个很好的例子见诸下文：</p><p><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485678&amp;idx=1&amp;sn=e46f781dae394bd7a9381e20eedb04ab&amp;chksm=fcb9b17ecbce38689d6453d4f5b2d0b3cb89a8bcf33135d995c9ad92ff8bd6817fe70087e9ee&amp;token=1635177260&amp;lang=zh_CN#rd">PyTorch入门（八）Optuna的使用</a></p><h2 id="模型量化">模型量化</h2><p><strong>模型量化</strong>是指通过将神经网络模型中的部分参数的数据类型从FP32或FP16转化为INT8或UINT8，在损失部分模型效果的前提下，缩小量化后模型大小，提升量化后推理性能。</p><p>PyTorch自身提供了模型训练后动态量化（Post Training DynamicQuantization, PTDQ），参考文章如下：</p><p><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485516&amp;idx=1&amp;sn=79b9e17d05335f9283a2d4e0b5632456&amp;chksm=fcb9b1dccbce38ca8d35b27c33f7411499437d53ef32cd989c210495e4c9f42c155845245da8&amp;token=1635177260&amp;lang=zh_CN#rd">NLP（六十七）BERT模型训练后动态量化（PTDQ）</a></p><p>HuggingFace社区也提供了好用的第三方量化工具：<code>Optimum</code>，关于使用<code>Optimum</code>来更方便地进行模型量化，可参考：</p><p><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485536&amp;idx=1&amp;sn=249981abe460822a997e4461c56d903a&amp;chksm=fcb9b1f0cbce38e6add3b44e0db721c21c3e4b57590f268dd4f853c11977c00ec74bb9e35818&amp;token=1635177260&amp;lang=zh_CN#rd">NLP（六十八）使用Optimum进行模型量化</a></p><h2 id="知识蒸馏">知识蒸馏</h2><p><strong>知识蒸馏</strong>同样也是模型压缩办法，它通过Teacher模型（一般为复杂的大模型）来指导小模型的方法，提升小模型的表现能力，使用小模型进行推理，从而加速模型推理。关于<strong>知识蒸馏</strong>的基本概念、原理和代码实现，下面的文章值得一读：</p><p><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;tempkey=MTIzNV8rRXQwM21jVEI1VVZXRFVZYzRmUzB3WTdFdnU4Z25SR2xVOU9nVE9OZ25JQTliWE5pVEJ1dmFvZWI5WGhQb0d4b1lmYzU2eVB1WlBYVVNLdm9oMWVWSndZWGF1WVFPUm0waHR2eGVHSlAxbDZOUU15YUlJQ1p6WlVGeDFpdjM0a3R2OU94QmhwZFM4Zm93eTZfSjV4bDk4eWNqcW8ycktYRmFpNU53fn4%3D&amp;chksm=fcb9b08ccbce399ae641e04d487e991c377f502f0cc54ad871cf5c5272c3cae1e88b6fb95bd1&amp;token=1635177260&amp;lang=zh_CN#rd">NLP（七十二）使用知识蒸馏提升模型推理性能</a></p><h2 id="推理性能提升">推理性能提升</h2><p>综上所述，我们整理出一个模型推理性能提升的表格：</p><blockquote><p>实验的数据集为sougou分类小数据集，基座模型采用bert-base-chinese（Teacher模型），文本最大长度为128。量化工具使用Optimum，自动化参数优化框架采用Optuna，知识蒸馏（<strong>KD</strong>）的小模型（Student模型）采用ckiplab/bert-tiny-chinese。</p></blockquote><blockquote><p>下表中的推理性能衡量指标为测试数据集上的平均推理时间，单位ms,推理效果为测试数据集上的weightedF1值。</p></blockquote><table><thead><tr class="header"><th>模型压缩方案</th><th>推理性能</th><th>推理效果</th><th>模型大小</th></tr></thead><tbody><tr class="odd"><td>原始BERT模型</td><td>341.6</td><td>0.9737</td><td>~412MB</td></tr><tr class="even"><td>量化</td><td>215.1</td><td>0.9737</td><td>~152MB</td></tr><tr class="odd"><td>KD</td><td>45.55</td><td>0.9454</td><td>~46MB</td></tr><tr class="even"><td>KD+量化</td><td>35.4</td><td>0.9475</td><td>~12MB</td></tr></tbody></table><h2 id="总结">总结</h2><p>笔者的研究起于整理之前的模型量化的笔记，经过这一段时间的探索，形成了这一系列的文章，差不多完成了从模型训练、推理到模型压缩的完整链路。因此，BERT模型方面的探索将暂告一段落，后续将开始开始探索大模型（LLM）。</p><p><strong>在不久的将来，BERT系列模型将缓缓退出历史舞台，LLM粉墨登场，引领风骚，成为下一个时代的弄潮儿。旧王退位，新王登基，一个崭新的时代已经曙光初现，于惊鸿一瞥中展现了它迷人的身姿和无穷的魅力，未来它的光芒将照耀每一个人。</strong></p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模型量化</tag>
      
      <tag>知识蒸馏</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（七十二）使用知识蒸馏提升模型推理性能</title>
    <link href="/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%BA%8C%EF%BC%89%E4%BD%BF%E7%94%A8%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%80%A7%E8%83%BD/"/>
    <url>/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%BA%8C%EF%BC%89%E4%BD%BF%E7%94%A8%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%80%A7%E8%83%BD/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍模型压缩方法——知识蒸馏，通过对训练后的BERT模型在小模型上进行蒸馏，在小模型上提到推理性能的极大提升，同时也不会过多损失模型效果。</p></blockquote><p>在深度学习中， <ahref="https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch17_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2.md">模型压缩</a>是指利用数据集对已经训练好的深度模型进行精简，进而得到一个轻量且准确率相当的网络，压缩后的网络具有更小的结构和更少的参数，可以有效降低计算和存储开销，便于部署在受限的硬件环境中。</p><p>在工业界中，常见的模型压缩方法有<strong>知识蒸馏</strong>（KnowledgeDistillation，KD）、<strong>剪枝</strong>（Pruning）、<strong>量化</strong>（Quantization）等。</p><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485516&amp;idx=1&amp;sn=79b9e17d05335f9283a2d4e0b5632456&amp;chksm=fcb9b1dccbce38ca8d35b27c33f7411499437d53ef32cd989c210495e4c9f42c155845245da8&amp;token=475225731&amp;lang=zh_CN#rd">NLP（六十七）BERT模型训练后动态量化（PTDQ）</a>和 文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485536&amp;idx=1&amp;sn=249981abe460822a997e4461c56d903a&amp;chksm=fcb9b1f0cbce38e6add3b44e0db721c21c3e4b57590f268dd4f853c11977c00ec74bb9e35818&amp;token=475225731&amp;lang=zh_CN#rd">NLP（六十八）使用Optimum进行模型量化</a>中，笔者已经介绍了<strong>模型量化</strong>相关的内容，本文将会介绍知识蒸馏（KD）。</p><p>那么，什么是<code>知识蒸馏</code>呢？</p><h2 id="知识蒸馏介绍">知识蒸馏介绍</h2><p>首先，我们先简单地了解下<ahref="https://zhuanlan.zhihu.com/p/353472061">知识蒸馏概念</a>。</p><blockquote><p>通常，大模型可能是一个复杂的网络或多个网络的组合，表现出优越的效果和泛化能力。而小模型由于其较小的规模，其表达能力可能受到限制。为了提高小模型的效果，我们可以借助大模型所学习到的知识来指导小模型的训练。这样，小模型在参数数量明显减少的情况下，也能够达到与大模型相似的效果。这种策略就是知识蒸馏在模型压缩中的实践应用。</p></blockquote><p><strong>Geoffrey Hinton</strong>及其团队在论文<ahref="https://arxiv.org/pdf/1503.02531.pdf">Distilling the Knowledge ina NeuralNetwork</a>中首次提出了“知识蒸馏”的思想，这是知识蒸馏中的开山之作，分量十足。其核心理念是首先训练一个大型复杂的网络，接着利用这个大网络的输出以及数据的真实标签来训练一个更轻量级的网络。在知识蒸馏的结构中，这个大型网络被称为“Teacher”模型，而轻量级网络则被称为“Student”模型。</p><p>现阶段，知识蒸馏已经有了长足的发展，方法繁多。常见的<strong>知识蒸馏</strong>可分为<strong>目标蒸馏</strong>和<strong>特征蒸馏</strong>。</p><ul><li><strong>目标蒸馏</strong>：Student模型只学习Teacher模型的Logits结果知识，一般为SoftLogits</li><li><strong>特征蒸馏</strong>：Student模型学习Teacher网络结构中的中间层特征，利用Teacher模型的信息更加充分，训练难度更大</li></ul><p>本文主要介绍<strong>目标蒸馏</strong>，一般的<ahref="https://intellabs.github.io/distiller/knowledge_distillation.html">目标蒸馏模型结构</a>如下图所示：</p><figure><imgsrc="https://intellabs.github.io/distiller/imgs/knowledge_distillation.png"alt="图1：知识蒸馏模型结构" /><figcaption aria-hidden="true">图1：知识蒸馏模型结构</figcaption></figure><p>步骤如下：</p><ol type="1"><li>在原有训练数据集中训练好<strong>Teacher模型</strong>，一般为复杂的（大）模型；</li><li>借助温度参数（Temperature，T）和Teacher模型的Logits结果，产生SoftLabels;</li><li>在相同训练集上训练小模型（<strong>Student模型</strong>），最终loss为<strong>两部分loss的权重和</strong>：大模型的SoftLabels和小模型的Soft Labels（Predictions）的K-Lloss；小模型在数据集上的交叉熵损失</li><li>使用训练好的小模型做最终的模型推理（Inference）</li></ol><p>让我们暂时脱离模型架构，来理解两个重要的概念：<strong>Logits</strong>和<strong>Temperature</strong>.</p><h2 id="logits">Logits</h2><p><strong>Logits</strong>指的是在分类模型结构中，最后的Softmax函数作用前，在各个标签上的分数z_i，称为Logits。当Softmax函数作用在Logits上，会得到各个标签上的概率值p_i，总和为1。</p><p>基于Logits概念，当我们的概率值中只有一个为1，其余为0，则称这些概率值分布为<strong>Hard-Target</strong>；其它情况为<strong>Soft-Target</strong>。一般，真实的标签表示方法（通常采用One-Hot表示法）为<strong>Hard-Target</strong>，只有命中的标签为1，其余标签为0；而模型训练产出的标签结果为<strong>Soft-Target</strong>，因为不存在概率为1的标签，只有无限接近于1的标签。</p><p>通过上述的知识蒸馏模型结构介绍，我们知道，Student模型会利用Teacher模型产生的<strong>Soft-Target</strong>。那么，<strong>Soft-Target</strong>有何用处呢？</p><p>我们来看个<ahref="https://medium.com/%E5%AD%B8%E4%BB%A5%E5%BB%A3%E6%89%8D/soft-label-hard-label-844445950aba">Soft-Target的例子</a>。</p><figure><imgsrc="https://miro.medium.com/v2/resize:fit:4800/format:webp/1*Iibl2UNT9HEm6-wDaF51KQ.png"alt="图2: Soft Target &amp; Hard Target" /><figcaption aria-hidden="true">图2: Soft Target &amp; HardTarget</figcaption></figure><p>观察上面的两个样本，他们的真实标签均为数字2，因此<strong>Hard-Target</strong>一致。但我们观察它们的<strong>Soft-Target</strong>，第一个值的预测结果为2，但在数字3上面的概率值会比其它数字更高，因为从图片中看这个数字2，有点像数字3；同理，第二个值在数字7上的概率比其它数字更高，有点像数字7，这从图片中也能得到反映。</p><p>因此，与<strong>Hard-Target</strong>相比，<strong>Soft-Target</strong>能够反映样本特征的更多信息，有其合理之处，这就是为什么我们要利用Teacher模型的<strong>Soft-Target</strong>，它在<strong>Hard-Target</strong>之外，还能告诉Student模型更多关于样本的特征信息，因此对Student模型有指导意义。</p><h2 id="temperature">Temperature</h2><p>那么，Teacher模型的<strong>Soft-Target</strong>对Student模型有指导意义，还能再加强<strong>Soft-Target</strong>的作用吗？参数<strong>Temperature</strong>便应运而生。</p><p>对于Softmax函数，我们有如下公式：</p><p><img src="https://s2.loli.net/2023/09/16/gjO6KGvfcT5xB24.png" /></p><p>其中，z_i为Logits值，p_i为概率值。我们将温度系数T作用在该公式中，得到：</p><p><img src="https://s2.loli.net/2023/09/16/Kn9dRT7yqX6ENZs.png" /></p><p>由上述公式，我们可得到：</p><ul><li>随着T的增大，各个概率值将趋向平滑（当T为无穷大时，概率值相同），其分布的熵越大，负标签携带的信息会被相对地放大，模型训练将更加关注负标签</li><li>随着T的减小，各个概率值将趋向陡峭，分布的熵越小，负标签携带的信息被相对放小，模型训练更少关注负标签</li></ul><p>我们来做个小小的实验，以原始Logits分布[-1, 1, 3, 2,0.5]为例，考察温度T对概率值分布的影响：</p><figure><img src="https://s2.loli.net/2023/09/16/bXp3Tq5jgWLGBQ1.png"alt="图3: 温度T对概率值分布的影响" /><figcaption aria-hidden="true">图3: 温度T对概率值分布的影响</figcaption></figure><p>Python实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> exp<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">logit_list</span>):<br>    s_sum = <span class="hljs-built_in">sum</span>([exp(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> logit_list])<br>    <span class="hljs-keyword">return</span> [exp(_)/s_sum <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> logit_list]<br><br><br>logits = [-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0.5</span>]<br><br><span class="hljs-keyword">for</span> i, T <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>([<span class="hljs-number">0.2</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-number">10</span>]):<br>    post_logits = softmax([_/T <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> logits])<br>    <span class="hljs-keyword">if</span> i &lt; <span class="hljs-number">3</span>:<br>        j = i + <span class="hljs-number">1</span><br>    <span class="hljs-keyword">elif</span> i == <span class="hljs-number">3</span>:<br>        j = i + <span class="hljs-number">2</span><br>    <span class="hljs-keyword">else</span>:<br>        j = i + <span class="hljs-number">3</span><br>    plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, j)<br>    plt.bar(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(post_logits)), post_logits, color=<span class="hljs-built_in">list</span>(<span class="hljs-string">&#x27;bbrbb&#x27;</span>))<br>    plt.title(<span class="hljs-string">f&quot;Temperature: <span class="hljs-subst">&#123;T&#125;</span>&quot;</span>)<br>    plt.xticks([])<br><br>plt.show()<br></code></pre></td></tr></table></figure><h2 id="理论介绍">理论介绍</h2><p>在<strong>知识蒸馏介绍</strong>章节中，我们已经介绍了知识蒸馏的模型结构图（图1）。同时，还介绍了知识蒸馏的步骤。</p><ol type="1"><li>在原有训练数据集中训练好<strong>Teacher模型</strong>，一般为复杂的（大）模型；</li><li>借助温度参数（Temperature，T）和Teacher模型的Logits结果，产生SoftLabels;</li><li>在相同训练集上训练小模型（<strong>Student模型</strong>），最终loss为<strong>两部分loss的权重和</strong>：大模型的SoftLabels和小模型的Soft Labels（Predictions）的K-Lloss；小模型在数据集上的交叉熵损失</li><li>使用训练好的小模型做最终的模型推理（Inference）</li></ol><p>第1步为常规的（大）模型训练，第2,3步被称为<strong>蒸馏</strong>。在2,3步中，最终的输出loss表示如下：</p><p><img src="https://s2.loli.net/2023/09/16/p6GvflMW2qtJSgw.png" /></p><p>其中，Teacher模型和Student模型的Soft Target如下：</p><p><img src="https://s2.loli.net/2023/09/16/dHWcrnASjeN9Khi.png" /></p><p>L_soft为Teacher模型和Student模型的Soft Target的KL-Loss,L_hard为Student模型在训练集真实标签上的交叉熵。最终Loss为两部分的权重和。</p><p>由于L_soft贡献的梯度大约为L_hard的1/(T<sup>2)，因此在同时使用Soft-target和Hard-target的时候，需要在L_soft的权重上乘以T</sup>2，这样才能保证Soft-target和Hard-target贡献的梯度量基本一致。</p><p>实验发现，当L_hard权重较小时，能产生最好的效果，这是一个经验性的结论。</p><h2 id="实验代码">实验代码</h2><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485678&amp;idx=1&amp;sn=e46f781dae394bd7a9381e20eedb04ab&amp;chksm=fcb9b17ecbce38689d6453d4f5b2d0b3cb89a8bcf33135d995c9ad92ff8bd6817fe70087e9ee&amp;token=475225731&amp;lang=zh_CN#rd">PyTorch入门（八）Optuna的使用</a>中，笔者介绍了ckiplab/bert-tiny-chinese模型在Sougou小样本数据集上的分类效果。</p><p>在本文中，数据集采用Sougou小样本数据集，Teacher模型采用BERT训练，模型名称为<strong>bert_base_sougou_trainer_128/checkpoint-96</strong>，Student模型采用<ahref="https://huggingface.co/ckiplab/bert-tiny-chinese">ckiplab/bert-tiny-chinese模型</a>。实验过程详细介绍如下：</p><ul><li>导入模型名称</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">student_id = <span class="hljs-string">&quot;ckiplab/bert-tiny-chinese&quot;</span><br>teacher_id = <span class="hljs-string">&quot;./bert_base_sougou_trainer_128/checkpoint-96&quot;</span><br></code></pre></td></tr></table></figure><ul><li>验证tokenizer</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br><span class="hljs-comment"># init tokenizer</span><br>teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_id)<br>student_tokenizer = AutoTokenizer.from_pretrained(student_id)<br><br><span class="hljs-comment"># sample input</span><br>sample = <span class="hljs-string">&quot;这是一个基本例子，使用不同的汉字进行测试。&quot;</span><br><br><span class="hljs-comment"># assert results</span><br><span class="hljs-built_in">print</span>(teacher_tokenizer(sample), student_tokenizer(sample))<br><span class="hljs-keyword">assert</span> teacher_tokenizer(sample) == student_tokenizer(sample), <span class="hljs-string">&quot;Tokenizers haven&#x27;t created the same output&quot;</span><br></code></pre></td></tr></table></figure><ul><li>加载数据集</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load dataset</span><br><span class="hljs-keyword">import</span> datasets<br>data_files = &#123;<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;./sougou/train.csv&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;./sougou/test.csv&quot;</span>&#125;<br>raw_datasets = datasets.load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="hljs-string">&quot;,&quot;</span>)<br></code></pre></td></tr></table></figure><ul><li>加载tokenizer并对文本进行tokenize</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>tokenizer = AutoTokenizer.from_pretrained(teacher_id)<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">sample</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(sample[<span class="hljs-string">&#x27;text&#x27;</span>], max_length=<span class="hljs-number">128</span>, truncation=<span class="hljs-literal">True</span>)<br>tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)<br><br>data_collator = DataCollatorWithPadding(tokenizer=tokenizer)<br></code></pre></td></tr></table></figure><ul><li>创造知识蒸馏网络的训练参数和Trainer</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments, Trainer<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DistillationTrainingArguments</span>(<span class="hljs-title class_ inherited__">TrainingArguments</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *args, alpha=<span class="hljs-number">0.5</span>, temperature=<span class="hljs-number">2.0</span>, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>().__init__(*args, **kwargs)<br><br>        self.alpha = alpha<br>        self.temperature = temperature<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DistillationTrainer</span>(<span class="hljs-title class_ inherited__">Trainer</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *args, teacher_model=<span class="hljs-literal">None</span>, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>().__init__(*args, **kwargs)<br>        self.teacher = teacher_model<br>        <span class="hljs-comment"># place teacher on same device as student</span><br>        self._move_model_to_device(self.teacher,self.model.device)<br>        self.teacher.<span class="hljs-built_in">eval</span>()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_loss</span>(<span class="hljs-params">self, model, inputs, return_outputs=<span class="hljs-literal">False</span></span>):<br><br>        <span class="hljs-comment"># compute student output</span><br>        outputs_student = model(**inputs)<br>        student_loss=outputs_student.loss<br>        <span class="hljs-comment"># compute teacher output</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>          outputs_teacher = self.teacher(**inputs)<br><br>        <span class="hljs-comment"># assert size</span><br>        <span class="hljs-keyword">assert</span> outputs_student.logits.size() == outputs_teacher.logits.size()<br><br>        <span class="hljs-comment"># Soften probabilities and compute distillation loss</span><br>        loss_function = nn.KLDivLoss(reduction=<span class="hljs-string">&quot;batchmean&quot;</span>)<br>        loss_logits = (loss_function(<br>            F.log_softmax(outputs_student.logits / self.args.temperature, dim=-<span class="hljs-number">1</span>),<br>            F.softmax(outputs_teacher.logits / self.args.temperature, dim=-<span class="hljs-number">1</span>)) * (self.args.temperature ** <span class="hljs-number">2</span>))<br>        <span class="hljs-comment"># Return weighted student loss</span><br>        loss = self.args.alpha * student_loss + (<span class="hljs-number">1.</span> - self.args.alpha) * loss_logits<br>        <span class="hljs-keyword">return</span> (loss, outputs_student) <span class="hljs-keyword">if</span> return_outputs <span class="hljs-keyword">else</span> loss<br></code></pre></td></tr></table></figure><ul><li>设置训练参数，加载模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification<br><br><span class="hljs-comment"># define training args</span><br>training_args = DistillationTrainingArguments(<br>    output_dir=<span class="hljs-string">&#x27;kd_sougou_trainer_128&#x27;</span>,<br>    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>    per_device_train_batch_size=<span class="hljs-number">32</span>,<br>    per_device_eval_batch_size=<span class="hljs-number">32</span>,<br>    learning_rate=<span class="hljs-number">5e-5</span>,<br>    num_train_epochs=<span class="hljs-number">5</span>,<br>    warmup_ratio=<span class="hljs-number">0.2</span>,<br>    logging_dir=<span class="hljs-string">&#x27;./sougou_train_logs&#x27;</span>,<br>    logging_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>    report_to=<span class="hljs-string">&quot;tensorboard&quot;</span>,<br>    <span class="hljs-comment"># distilation parameters</span><br>    alpha=<span class="hljs-number">0.5</span>,<br>    temperature=<span class="hljs-number">1.0</span><br>    )<br><br><span class="hljs-comment"># define model</span><br>teacher_model = AutoModelForSequenceClassification.from_pretrained(<br>    teacher_id,<br>    num_labels=<span class="hljs-number">5</span><br>)<br><br><span class="hljs-comment"># define student model</span><br>student_model = AutoModelForSequenceClassification.from_pretrained(<br>    student_id,<br>    num_labels=<span class="hljs-number">5</span><br>)<br></code></pre></td></tr></table></figure><ul><li>创造准确率计算指标</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score, precision_recall_fscore_support<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">pred</span>):<br>    labels = pred.label_ids<br>    preds = pred.predictions.argmax(-<span class="hljs-number">1</span>)<br>    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=<span class="hljs-string">&#x27;weighted&#x27;</span>)<br>    acc = accuracy_score(labels, preds)<br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&#x27;accuracy&#x27;</span>: acc,<br>        <span class="hljs-string">&#x27;f1&#x27;</span>: f1,<br>        <span class="hljs-string">&#x27;precision&#x27;</span>: precision,<br>        <span class="hljs-string">&#x27;recall&#x27;</span>: recall<br>    &#125;<br></code></pre></td></tr></table></figure><ul><li>Trainer类实例化，进行整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">trainer = DistillationTrainer(<br>    student_model,<br>    training_args,<br>    teacher_model=teacher_model,<br>    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>],<br>    data_collator=data_collator,<br>    tokenizer=tokenizer,<br>    compute_metrics=compute_metrics,<br>)<br><br>trainer.train()<br></code></pre></td></tr></table></figure><h2 id="实验结果">实验结果</h2><p>在上述的实验代码下，我们分别对单独Student模型训练、蒸馏过程、单独Student模型Optuna参数优化、蒸馏过程Optuna参数优化进行实验，统计在测试集上的WeightedF1值，如下：</p><table><thead><tr class="header"><th>模型</th><th>Weighted F1</th></tr></thead><tbody><tr class="odd"><td>Teacher模型（单独）</td><td>0.9737</td></tr><tr class="even"><td>Student模型（单独）</td><td>0.9050</td></tr><tr class="odd"><td>蒸馏</td><td>0.9050</td></tr><tr class="even"><td>Student模型（单独，参数优化）</td><td>0.9331</td></tr><tr class="odd"><td>蒸馏（参数优化）</td><td>0.9454</td></tr></tbody></table><p>在本地实验中，如果不进行参数优化，则蒸馏的效果不一定会比单独训练Student模型效果来得好；但进行参数优化后，蒸馏效果优于单独训练Student模型，且只比Teacher模型下降了2.8%。</p><p>对比蒸馏后的小模型和Teacher模型的平均推理时间，结果如下：</p><table><thead><tr class="header"><th>基座模型</th><th>推理时间（ms）</th><th>模型大小</th></tr></thead><tbody><tr class="odd"><td>bert-base-chinse</td><td>341.5</td><td>~412MB</td></tr><tr class="even"><td>bert-tiny-chinese（蒸馏后）</td><td>45.55</td><td>~46MB</td></tr></tbody></table><p>推理速度提升了7.5倍，这比量化策略的提升1.8倍强太多了。</p><h2 id="总结">总结</h2><p>本文篇幅较长，主要介绍了知识蒸馏的基本概念和原理，并通过笔者自己的亲身试验，验证了知识蒸馏的有效性，在稍微降低模型效果的前提下，模型的推理速度获得了极大提升。</p><p>本项目已开源至Github，网址为：<ahref="https://github.com/percent4/dynamic_quantization_on_bert">https://github.com/percent4/dynamic_quantization_on_bert</a>.</p><h4 id="推荐阅读">推荐阅读</h4><ul><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485678&amp;idx=1&amp;sn=e46f781dae394bd7a9381e20eedb04ab&amp;chksm=fcb9b17ecbce38689d6453d4f5b2d0b3cb89a8bcf33135d995c9ad92ff8bd6817fe70087e9ee&amp;token=475225731&amp;lang=zh_CN#rd">PyTorch入门（八）Optuna的使用</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485516&amp;idx=1&amp;sn=79b9e17d05335f9283a2d4e0b5632456&amp;chksm=fcb9b1dccbce38ca8d35b27c33f7411499437d53ef32cd989c210495e4c9f42c155845245da8&amp;token=475225731&amp;lang=zh_CN#rd">NLP（六十七）BERT模型训练后动态量化（PTDQ）</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485508&amp;idx=1&amp;sn=77a6fef8cfb11a604e19de303576539f&amp;chksm=fcb9b1d4cbce38c24cd92793bcc734684a8a5bc6c4a94d4473328158a5f7e95373f1da4ce2e2&amp;token=475225731&amp;lang=zh_CN#rd">NLP（六十六）使用HuggingFace中的Trainer进行BERT模型微调</a></li><li><ahref="https://www.philschmid.de/knowledge-distillation-bert-transformers">Task-specificknowledge distillation for BERT using Transformers &amp; AmazonSageMaker</a></li></ul>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>知识蒸馏</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（七十一）大模型微调RACE数据集的进一步实验</title>
    <link href="/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%B8%80%EF%BC%89%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83RACE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%AE%9E%E9%AA%8C/"/>
    <url>/NLP%EF%BC%88%E4%B8%83%E5%8D%81%E4%B8%80%EF%BC%89%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83RACE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%AE%9E%E9%AA%8C/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485636&amp;idx=1&amp;sn=bee1e493374be774b0ca357dcd2ae9da&amp;chksm=fcb9b154cbce384294cdbc8e0329604292b5f4a731ed3f44c03f5db177e44b5aa95880ada68b&amp;token=475225731&amp;lang=zh_CN#rd">NLP（七十）使用LLAMA2模型微调Multiple Choice MRC</a>中，笔者介绍了RACE数据集，以及如何使用LLAMA2模型对该数据集进行微调，较以往的BERT系列模型取得了长足进步。</p></blockquote><p>本文将继续上述实验。</p><h2 id="实验">实验</h2><p>我们的实验使用<code>Firefly</code>大模型训练框架，数据集为RACEmiddle数据集，训练参数在<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485636&amp;idx=1&amp;sn=bee1e493374be774b0ca357dcd2ae9da&amp;chksm=fcb9b154cbce384294cdbc8e0329604292b5f4a731ed3f44c03f5db177e44b5aa95880ada68b&amp;token=475225731&amp;lang=zh_CN#rd">NLP（七十）使用LLAMA2模型微调Multiple Choice MRC</a> 中已经给出。</p><p>微调方式采用<code>大模型 + qlora</code>, 对数据集进行SFT(SupervisedFine-Tuning)。针对不同的模型、模型尺寸、学习率、最大长度等参数进行调试（其余参数不变），实验结果如下：</p><table><thead><tr class="header"><th>模型</th><th>学习率</th><th>训练轮数</th><th>最大长度</th><th>准确率</th></tr></thead><tbody><tr class="odd"><td>LLAMA-2-7B</td><td>1e-4</td><td>3</td><td>384</td><td>0.8691</td></tr><tr class="even"><td>LLAMA-2-7B</td><td>1e-4</td><td>3</td><td>320</td><td>0.8593</td></tr><tr class="odd"><td>LLAMA-2-7B</td><td>1e-4</td><td>5</td><td>384</td><td>0.8545</td></tr><tr class="even"><td>LLAMA-2-7B</td><td>1e-4</td><td>5</td><td>320</td><td>0.8538</td></tr><tr class="odd"><td>LLAMA-2-13B</td><td>1e-4</td><td>3</td><td>384</td><td>0.8844</td></tr><tr class="even"><td>Baichuan-7B</td><td>2e-4</td><td>3</td><td>384</td><td>0.8357</td></tr><tr class="odd"><td>Baichuan-13B-Chat</td><td>1e-4</td><td>3</td><td>384</td><td>0.8726</td></tr><tr class="even"><td>Baichuan2-13B-Base</td><td>2e-4</td><td>3</td><td>384</td><td><strong>0.8948</strong></td></tr><tr class="odd"><td>XVERSE-13B</td><td>1e-4</td><td>3</td><td>384</td><td>0.8718</td></tr></tbody></table><p>在上述实验中，<code>LLAMA-2-13B</code>,<code>Baichuan-13B-Chat</code>, <code>Baichuan2-13B-Base</code>,<code>XVERSE-13B</code>模型取得了不错的效果，尤其<code>Baichuan2-13B-Base</code>效果最好，accuracy达到了89.48%。</p><p>我们对<code>LLAMA-2-13B + Baichuan2-13B-Base + XVERSE-13B</code>进行模型集成（取预测结果中的次数最大值，如果都相同，则以Baichuan2-13B-Base的结果为准），accuracy为90.25%！</p><p>使用全量RACE数据中的训练集进行训练，使用LLAMA-2-13B，学习率1e-4，轮数3，最大长度384，测试结果如下：</p><table><thead><tr class="header"><th>测试集</th><th>准确率</th></tr></thead><tbody><tr class="odd"><td>middle</td><td>0.9283</td></tr><tr class="even"><td>high</td><td>0.8413</td></tr><tr class="odd"><td>all</td><td>0.8666</td></tr></tbody></table><p>我们再回过头来看看，在以往BERT时代，<ahref="https://paperswithcode.com/sota/reading-comprehension-on-race">RACE数据集排行榜</a>：</p><p><img src="https://s2.loli.net/2023/09/10/9LMe2PdmZNKcCbo.png" /></p><h2 id="可视化">可视化</h2><p>我们使用<code>Gradio</code>模块，对文章、问题、选项进行可视化问答，页面效果：</p><p><img src="https://s2.loli.net/2023/09/15/BYWr4KSoG8lfwIQ.png" /></p><p>实现的Python代码可以参考如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><span class="hljs-keyword">import</span> torch<br><br><br><span class="hljs-keyword">import</span> sys<br>sys.path.append(<span class="hljs-string">&quot;../../&quot;</span>)<br><span class="hljs-keyword">from</span> component.utils <span class="hljs-keyword">import</span> ModelUtils<br><br><span class="hljs-comment"># 使用合并后的模型进行推理</span><br>model_name_or_path = <span class="hljs-string">&#x27;/home/jclian91/experiment/Firefly/script/checkpoint/firefly-llama2-7b-qlora-sft-race-merge&#x27;</span><br><span class="hljs-comment"># 生成超参配置</span><br>max_new_tokens = <span class="hljs-number">1</span><br>top_p = <span class="hljs-number">0.9</span><br>temperature = <span class="hljs-number">0.01</span><br>repetition_penalty = <span class="hljs-number">1.0</span><br>device = <span class="hljs-string">&#x27;cuda:0&#x27;</span><br><span class="hljs-comment"># 加载模型</span><br>model = ModelUtils.load_model(<br>    model_name_or_path,<br>    load_in_4bit=<span class="hljs-literal">False</span>,<br>    adapter_name_or_path=<span class="hljs-literal">None</span><br>).<span class="hljs-built_in">eval</span>()<br>tokenizer = AutoTokenizer.from_pretrained(<br>    model_name_or_path,<br>    trust_remote_code=<span class="hljs-literal">True</span>,<br>    <span class="hljs-comment"># llama不支持fast</span><br>    use_fast=<span class="hljs-literal">False</span> <span class="hljs-keyword">if</span> model.config.model_type == <span class="hljs-string">&#x27;llama&#x27;</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">True</span><br>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;load model: <span class="hljs-subst">&#123;model_name_or_path&#125;</span>&quot;</span>)<br><br><br><span class="hljs-comment"># Gradio app</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">passage, question, options</span>):<br><span class="hljs-comment"># make prompt</span><br>    prefix = <span class="hljs-string">&#x27;Read the following passage and questions, then choose the right answer from options, &#x27;</span> \<br>             <span class="hljs-string">&#x27;the answer should be one of A, B, C, D.\n\n&#x27;</span><br>    passage = <span class="hljs-string">f&#x27;&lt;passage&gt;:\n<span class="hljs-subst">&#123;passage&#125;</span>\n\n&#x27;</span><br>    question = <span class="hljs-string">f&#x27;&lt;question&gt;:\n<span class="hljs-subst">&#123;question&#125;</span>\n\n&#x27;</span><br>    option1, option2, option3, option3 = options.split(<span class="hljs-string">&quot;\n&quot;</span>)<br>    option = <span class="hljs-string">f&#x27;&lt;options&gt;:\n<span class="hljs-subst">&#123;option1.strip()&#125;</span>\n<span class="hljs-subst">&#123;option2.strip()&#125;</span>\n<span class="hljs-subst">&#123;option3.strip()&#125;</span>\n<span class="hljs-subst">&#123;option3.strip()&#125;</span>\n\n&#x27;</span><br>    suffix = <span class="hljs-string">f&quot;&lt;answer&gt;:\n&quot;</span><br>    prompt = <span class="hljs-string">&#x27;&#x27;</span>.join([prefix, passage, question, option, suffix])<br>    <span class="hljs-comment"># get input ids</span><br>    input_ids = tokenizer(prompt, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, add_special_tokens=<span class="hljs-literal">False</span>).input_ids.to(device)<br>    bos_token_id = torch.tensor([[tokenizer.bos_token_id]], dtype=torch.long).to(device)<br>    eos_token_id = torch.tensor([[tokenizer.eos_token_id]], dtype=torch.long).to(device)<br>    input_ids = torch.concat([bos_token_id, input_ids, eos_token_id], dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># model predict</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        outputs = model.generate(<br>            input_ids=input_ids, max_new_tokens=max_new_tokens, do_sample=<span class="hljs-literal">True</span>,<br>            top_p=top_p, temperature=temperature, repetition_penalty=repetition_penalty,<br>            eos_token_id=tokenizer.eos_token_id<br>        )<br>    outputs = outputs.tolist()[<span class="hljs-number">0</span>][<span class="hljs-built_in">len</span>(input_ids[<span class="hljs-number">0</span>]):]<br>    response = tokenizer.decode(outputs)<br>    response = response.strip().replace(tokenizer.eos_token, <span class="hljs-string">&quot;&quot;</span>).strip()<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;The answer is <span class="hljs-subst">&#123;response&#125;</span>.&quot;</span><br><br><br><span class="hljs-keyword">with</span> gr.Blocks() <span class="hljs-keyword">as</span> demo:<br>    <span class="hljs-comment"># 设置输入组件</span><br>    gr_passage = gr.Textbox(lines=<span class="hljs-number">3</span>, placeholder=<span class="hljs-string">&quot;Passage&quot;</span>, label=<span class="hljs-string">&quot;Passage&quot;</span>)<br>    gr_question = gr.Textbox(lines=<span class="hljs-number">1</span>, placeholder=<span class="hljs-string">&quot;question&quot;</span>, label=<span class="hljs-string">&quot;question&quot;</span>)<br>    gr_options = gr.Textbox(lines=<span class="hljs-number">4</span>, placeholder=<span class="hljs-string">&quot;options&quot;</span>, label=<span class="hljs-string">&quot;options&quot;</span>)<br>    <span class="hljs-comment"># 设置输出组件</span><br>    answer = gr.Textbox(label=<span class="hljs-string">&quot;Answer&quot;</span>)<br>    <span class="hljs-comment"># 设置按钮</span><br>    greet_btn = gr.Button(<span class="hljs-string">&quot;Show me the answer&quot;</span>)<br>    <span class="hljs-comment"># 设置按钮点击事件</span><br>    greet_btn.click(fn=predict,<br>                    inputs=[gr_passage, gr_question, gr_options],<br>                    outputs=answer)<br><br>demo.launch(share=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>本文并无太多新意，只是在之前文章的基础上进行大量测试，考察不同模型，模型尺寸在SFT上的效果差异，同时也验证了，大模型时代中LLM的强大之处，<strong>在效果上几乎横扫以往所有的NLP模型</strong>，且<strong>将以往的NLP任务做到了统一</strong>，这才是LLM的可怕之处！</p><p>本文的代码及实验结果已开放至Github，网址为 <ahref="https://github.com/percent4/llama-2-multiple-choice-mrc">https://github.com/percent4/llama-2-multiple-choice-mrc</a>.</p><p>本人博客网站为 <ahref="https://percent4.github.io/">https://percent4.github.io/</a>，欢迎大家访问~</p><h4 id="推荐阅读">推荐阅读</h4><ul><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485636&amp;idx=1&amp;sn=bee1e493374be774b0ca357dcd2ae9da&amp;chksm=fcb9b154cbce384294cdbc8e0329604292b5f4a731ed3f44c03f5db177e44b5aa95880ada68b&amp;token=475225731&amp;lang=zh_CN#rd">NLP（七十）使用LLAMA2模型微调Multiple Choice MRC</a></li></ul>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>RACE数据集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python代码整洁之道及代码注释</title>
    <link href="/Python%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93%E5%8F%8A%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/"/>
    <url>/Python%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93%E5%8F%8A%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="代码规范">代码规范</h2><p>Python代码规范遵循<a href="https://peps.python.org/pep-0008/">PEP8风格</a>。</p><p>以下是Python代码不遵循规范的例子：</p><ul><li>同时导入两个模块</li><li>函数参数赋值时，=两边空格</li><li>代码中存在;</li><li>函数前只空了一行</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys, os<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">complex</span>(<span class="hljs-params">real, imag = <span class="hljs-number">0.0</span></span>):<br>    <span class="hljs-keyword">return</span> magic(r = real, i = imag)<br>    <br>a = <span class="hljs-number">1</span>; b =<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>可以使用第三方模块进行代码规范化，使得代码遵循规范。常见的第三方工具有<code>autopep8</code>,<code>yapf</code>等。</p><p>在PyCharm设置中，选择Tools中的External Tools,点击右边的+号进行外部工具配置。配置如下：</p><figure><img src="https://s2.loli.net/2023/09/15/g2sp4fOeyvxlzSW.png"alt="python_comment1_2.png" /><figcaption aria-hidden="true">python_comment1_2.png</figcaption></figure><p>此时，在PyCharm的工具栏上方，选择Tools --&gt; External Tools --&gt;autopep8，即可对上述代码进行规范化，效果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> os<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">complex</span>(<span class="hljs-params">real, imag=<span class="hljs-number">0.0</span></span>):<br>    <span class="hljs-keyword">return</span> magic(r=real, i=imag)<br><br><br>a = <span class="hljs-number">1</span><br>b = <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><h2 id="代码注释">代码注释</h2><p>Python代码注释的5种常见风格：</p><ul><li>Plain</li><li>Epytest</li><li>reStructuredText</li><li>Numpy</li><li>Google</li></ul><p>各种代码注释的风格如下所示。</p><p>Plain风格：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a: <span class="hljs-built_in">int</span>, b: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    c = a + b<br>    <span class="hljs-keyword">return</span> c<br></code></pre></td></tr></table></figure><p>Epytest风格：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a: <span class="hljs-built_in">int</span>, b: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    @param a: </span><br><span class="hljs-string">    @param b: </span><br><span class="hljs-string">    @return: </span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    c = a + b<br>    <span class="hljs-keyword">return</span> c<br></code></pre></td></tr></table></figure><p>reStructuredText风格：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a: <span class="hljs-built_in">int</span>, b: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param a: </span><br><span class="hljs-string">    :param b: </span><br><span class="hljs-string">    :return: </span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    c = a + b<br>    <span class="hljs-keyword">return</span> c<br></code></pre></td></tr></table></figure><p>Numpy风格：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a: <span class="hljs-built_in">int</span>, b: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    Parameters</span><br><span class="hljs-string">    ----------</span><br><span class="hljs-string">    a</span><br><span class="hljs-string">    b</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Returns</span><br><span class="hljs-string">    -------</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    c = a + b<br>    <span class="hljs-keyword">return</span> c<br></code></pre></td></tr></table></figure><p>Google风格：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a: <span class="hljs-built_in">int</span>, b: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        a:</span><br><span class="hljs-string">        b:</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    c = a + b<br>    <span class="hljs-keyword">return</span> c<br></code></pre></td></tr></table></figure><p>在PyCharm中设置Python代码风格如下，之后在函数中输入三个英文引号，按下Enter键，即可看到上述的代码注释。</p><figure><img src="https://s2.loli.net/2023/09/15/R9fw56L1CDxlon3.png"alt="Python代码注释" /><figcaption aria-hidden="true">Python代码注释</figcaption></figure>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch入门（八）Optuna的使用</title>
    <link href="/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AB%EF%BC%89Optuna%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AB%EF%BC%89Optuna%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍机器学习领域的自动化超参优化软件框架——<code>Optuna</code>，它能在很大程度上让我们专注于模型实现，因为它让超参优化变得更加简洁、高效！</p></blockquote><h2 id="optuna-介绍">Optuna 介绍</h2><p><a href="https://optuna.org/">Optuna</a>是一个特别为机器学习设计的开源的自动超参数优化软件框架（hyperparameteroptimization framework）。它具有命令式的, define-by-run 风格的API。由于这种 API 的存在, 用 Optuna 编写的代码模块化程度很高, Optuna的用户因此也可以动态地构造超参数的搜索空间。</p><p><imgsrc="https://raw.githubusercontent.com/optuna/optuna/master/docs/image/optuna-logo.png" /></p><p><code>Optuna</code>的优点如下：</p><ul><li><p>轻量级、多功能和跨平台架构：只需少量依赖,简单安装完成后便可处理各种任务.</p></li><li><p>Python 式的搜索空间：利用熟悉的 Python 语法,如条件语句和循环来定义搜索空间.</p></li><li><p>高效的优化算法：采用了最先进的超参数采样和最有效的对无望 trial进行剪枝的算法.</p></li><li><p>易用的并行优化：仅需少量甚至无需代码修改便可将 study扩展到数十甚至数百个 worker 上.</p></li><li><p>便捷的可视化：查询优化记录.</p></li></ul><p><code>Optuna</code>轻松支持多种深度学习工具，比如PyTorch, TensorFlow,Keras, MXNet, Scikit-Learn, Chainer, LightGBM等。</p><p><code>Optuna</code>中的基本概念有objective（目标函数）、trail（单次实验）、study（研究）。objective是优化程序的目标函数，一般取最大化（maximize）或最小化（minimize），支持单目标或多目标函数；trail是目标函数的单次执行过程，也就是一次单独的实验；study是基于目标函数的优化过程。</p><p>下面我们将介绍三个基本的例子，来体会<code>Optuna</code>的强大之处！</p><h2 id="简单例子">简单例子</h2><p>在这个例子中，我们优化函数f(x)=x*x-2*x+1,其中x的取值范围为-3到3的浮点数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 简单例子</span><br><span class="hljs-keyword">import</span> optuna<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">objective</span>(<span class="hljs-params">trial</span>):<br>    x = trial.suggest_float(<span class="hljs-string">&#x27;x&#x27;</span>, -<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>    <span class="hljs-keyword">return</span> x ** <span class="hljs-number">2</span> - <span class="hljs-number">2</span> * x + <span class="hljs-number">1</span><br><br><span class="hljs-comment"># create_study函数有参数direction，取值minimize, maximize, 默认取值为minimize</span><br>study = optuna.create_study()<br>study.optimize(objective, n_trials=<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure><p>取目标函数进行最小化优化，查看最优参数和最优值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>study.best_params<br>&#123;<span class="hljs-string">&#x27;x&#x27;</span>: <span class="hljs-number">0.8293099933595993</span>&#125;<br><span class="hljs-meta">&gt;&gt;&gt; </span>study.best_value<br><span class="hljs-number">0.02913507836689999</span><br></code></pre></td></tr></table></figure><p>查看10次实验过程，表格如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Create a dataframe from the study.</span><br>df = study.trials_dataframe()<br>df<br></code></pre></td></tr></table></figure><figure><img src="https://s2.loli.net/2023/09/13/shEqYGxBrpZtneA.png"alt="实验结果" /><figcaption aria-hidden="true">实验结果</figcaption></figure><p>如果我们在create_study中将目标函数的优化方向（direction）改为最大化，此时查看最优参数和最优值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">study = optuna.create_study(direction=<span class="hljs-string">&quot;maximize&quot;</span>)<br>study.optimize(objective, n_trials=<span class="hljs-number">10</span>)<br><br><span class="hljs-meta">&gt;&gt;&gt; </span>study.best_params<br>&#123;<span class="hljs-string">&#x27;x&#x27;</span>: -<span class="hljs-number">2.911470602812437</span>&#125;<br><span class="hljs-meta">&gt;&gt;&gt; </span>study.best_value<br><span class="hljs-number">15.299602276665889</span><br></code></pre></td></tr></table></figure><h2 id="机器学习例子">机器学习例子</h2><p><code>Optuna</code>可支持在机器学习中进行超参优化，如下面的例子，我们对<code>iris</code>数据集，使用SVC和RandomForest进行分类模型的参数优化，优化的目标函数为K折划分后的验证集的预测准确率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># scikit-learn, 机器学习例子</span><br><span class="hljs-keyword">import</span> optuna<br><br><span class="hljs-keyword">import</span> sklearn.datasets<br><span class="hljs-keyword">import</span> sklearn.ensemble<br><span class="hljs-keyword">import</span> sklearn.model_selection<br><span class="hljs-keyword">import</span> sklearn.svm<br><br><br><span class="hljs-comment"># FYI: Objective functions can take additional arguments</span><br><span class="hljs-comment"># (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">objective</span>(<span class="hljs-params">trial</span>):<br>    iris = sklearn.datasets.load_iris()<br>    x, y = iris.data, iris.target<br><br>    classifier_name = trial.suggest_categorical(<span class="hljs-string">&quot;classifier&quot;</span>, [<span class="hljs-string">&quot;SVC&quot;</span>, <span class="hljs-string">&quot;RandomForest&quot;</span>])<br>    <span class="hljs-keyword">if</span> classifier_name == <span class="hljs-string">&quot;SVC&quot;</span>:<br>        svc_c = trial.suggest_float(<span class="hljs-string">&quot;svc_c&quot;</span>, <span class="hljs-number">1e-10</span>, <span class="hljs-number">1e10</span>, log=<span class="hljs-literal">True</span>)<br>        classifier_obj = sklearn.svm.SVC(C=svc_c, gamma=<span class="hljs-string">&quot;auto&quot;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        rf_max_depth = trial.suggest_int(<span class="hljs-string">&quot;rf_max_depth&quot;</span>, <span class="hljs-number">2</span>, <span class="hljs-number">32</span>, log=<span class="hljs-literal">True</span>)<br>        classifier_obj = sklearn.ensemble.RandomForestClassifier(<br>            max_depth=rf_max_depth, n_estimators=<span class="hljs-number">10</span><br>        )<br><br>    score = sklearn.model_selection.cross_val_score(classifier_obj, x, y, n_jobs=-<span class="hljs-number">1</span>, cv=<span class="hljs-number">3</span>)<br>    accuracy = score.mean()<br>    <span class="hljs-keyword">return</span> accuracy<br><br>study = optuna.create_study(direction=<span class="hljs-string">&quot;maximize&quot;</span>)<br>study.optimize(objective, n_trials=<span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure><p>查看最好的实验记录：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>study.best_trial<br>FrozenTrial(number=<span class="hljs-number">43</span>, state=TrialState.COMPLETE, values=[<span class="hljs-number">0.9866666666666667</span>], datetime_start=datetime.datetime(<span class="hljs-number">2023</span>, <span class="hljs-number">9</span>, <span class="hljs-number">13</span>, <span class="hljs-number">1</span>, <span class="hljs-number">32</span>, <span class="hljs-number">49</span>, <span class="hljs-number">300321</span>), datetime_complete=datetime.datetime(<span class="hljs-number">2023</span>, <span class="hljs-number">9</span>, <span class="hljs-number">13</span>, <span class="hljs-number">1</span>, <span class="hljs-number">32</span>, <span class="hljs-number">49</span>, <span class="hljs-number">329775</span>), params=&#123;<span class="hljs-string">&#x27;classifier&#x27;</span>: <span class="hljs-string">&#x27;SVC&#x27;</span>, <span class="hljs-string">&#x27;svc_c&#x27;</span>: <span class="hljs-number">4.63942008536747</span>&#125;, user_attrs=&#123;&#125;, system_attrs=&#123;&#125;, intermediate_values=&#123;&#125;, distributions=&#123;<span class="hljs-string">&#x27;classifier&#x27;</span>: CategoricalDistribution(choices=(<span class="hljs-string">&#x27;SVC&#x27;</span>, <span class="hljs-string">&#x27;RandomForest&#x27;</span>)), <span class="hljs-string">&#x27;svc_c&#x27;</span>: FloatDistribution(high=<span class="hljs-number">10000000000.0</span>, log=<span class="hljs-literal">True</span>, low=<span class="hljs-number">1e-10</span>, step=<span class="hljs-literal">None</span>)&#125;, trial_id=<span class="hljs-number">43</span>, value=<span class="hljs-literal">None</span>)<br></code></pre></td></tr></table></figure><p><code>Optuna</code>也支持可视化，提供了可视化工具<ahref="https://optuna-dashboard.readthedocs.io/en/latest/getting-started.html">optunadashboard</a>。我们只需对上面的代码做些许改造，将实验结果储存在sqlite数据库中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">study = optuna.create_study(study_name=<span class="hljs-string">&#x27;iris&#x27;</span>,direction=<span class="hljs-string">&quot;maximize&quot;</span>,storage=<span class="hljs-string">&#x27;sqlite:///db.sqlite3&#x27;</span>)<br>study.optimize(objective, n_trials=<span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure><p>运行完毕后，输入命令行<code>optuna-dashboard sqlite:///db.sqlite3</code>，在浏览器中输入<strong>127.0.0.1:8080</strong>，即可在页面中可视化地查看实验中的各项数据。</p><p>也可以在<a href="https://optuna.github.io/optuna-dashboard/">Optunadashboard官方可视化页面中查看</a>，只需要将sqlite3文件上传即可，页面如下：</p><figure><img src="https://s2.loli.net/2023/09/13/kgVWbJXsOlUSFKo.png"alt="可视化结果" /><figcaption aria-hidden="true">可视化结果</figcaption></figure><h2 id="nlp模型例子">NLP模型例子</h2><p>PyTorch也提供了对<code>Optuna</code>很好的支持，除了上述的objective,trail模式，PyTorch还提供了内置代码支持<code>Optuna</code>。</p><p>我们以文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485508&amp;idx=1&amp;sn=77a6fef8cfb11a604e19de303576539f&amp;chksm=fcb9b1d4cbce38c24cd92793bcc734684a8a5bc6c4a94d4473328158a5f7e95373f1da4ce2e2&amp;token=475225731&amp;lang=zh_CN#rd">NLP（六十六）使用HuggingFace中的Trainer进行BERT模型微调</a>中的文本分类模型训练为例，介绍在PyToch中如何支持<code>Optuna</code>。</p><blockquote><p>预训练模型改为 <ahref="https://huggingface.co/ckiplab/bert-tiny-chinese">ckiplab/bert-tiny-chinese</a>.</p></blockquote><ul><li>首先加载数据集，tokenizer和模型。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># pytorch支持</span><br><br><span class="hljs-comment"># load dataset, tokenizer, model</span><br><span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding<br><br><br>checkpoint = <span class="hljs-string">&#x27;ckiplab/bert-tiny-chinese&#x27;</span><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br><br>data_files = &#123;<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;./sougou/train.csv&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;./sougou/test.csv&quot;</span>&#125;<br>raw_datasets = datasets.load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="hljs-string">&quot;,&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">sample</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(sample[<span class="hljs-string">&#x27;text&#x27;</span>], max_length=<span class="hljs-number">128</span>, truncation=<span class="hljs-literal">True</span>)<br>tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)<br><br>data_collator = DataCollatorWithPadding(tokenizer=tokenizer)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification<br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">5</span>)<br></code></pre></td></tr></table></figure><ul><li>指定训练参数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer, TrainingArguments<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score, precision_recall_fscore_support<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">pred</span>):<br>    labels = pred.label_ids<br>    preds = pred.predictions.argmax(-<span class="hljs-number">1</span>)<br>    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=<span class="hljs-string">&#x27;weighted&#x27;</span>)<br>    acc = accuracy_score(labels, preds)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;f1&#x27;</span>: f1&#125;<br><br>training_args = TrainingArguments(output_dir=<span class="hljs-string">&#x27;bert_tiny_sougou_trainer_128&#x27;</span>, <span class="hljs-comment"># 指定输出文件夹，没有会自动创建</span><br>                                 evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>                                 per_device_train_batch_size=<span class="hljs-number">32</span>,<br>                                 per_device_eval_batch_size=<span class="hljs-number">32</span>,<br>                                 learning_rate=<span class="hljs-number">5e-5</span>,<br>                                 num_train_epochs=<span class="hljs-number">5</span>,<br>                                 warmup_ratio=<span class="hljs-number">0.2</span>,<br>                                 logging_dir=<span class="hljs-string">&#x27;./sougou_train_logs&#x27;</span>,<br>                                 logging_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>                                 save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>                                 report_to=<span class="hljs-string">&quot;tensorboard&quot;</span>) <br><br></code></pre></td></tr></table></figure><ul><li>设置模型和超参优化空间，进行超参搜索实验</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">hp_space</span>(<span class="hljs-params">trial</span>):<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;num_train_epochs&quot;</span>: trial.suggest_int(<span class="hljs-string">&quot;num_train_epochs&quot;</span>, <span class="hljs-number">2</span>, <span class="hljs-number">10</span>),<br>            <span class="hljs-string">&quot;learning_rate&quot;</span>: trial.suggest_float(<span class="hljs-string">&quot;learning_rate&quot;</span>, <span class="hljs-number">1e-6</span>, <span class="hljs-number">1e-3</span> ,log=<span class="hljs-literal">True</span>)&#125;<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model_init</span>():<br>    <span class="hljs-keyword">return</span> AutoModelForSequenceClassification.from_pretrained(<br>        checkpoint,<br>        num_labels=<span class="hljs-number">5</span><br>    )<br><br>trainer = Trainer(<br>    model_init=model_init,<br>    args=training_args,<br>    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>],<br>    data_collator=data_collator,<br>    tokenizer=tokenizer,<br>    compute_metrics=compute_metrics,<br>)<br><br>best_run = trainer.hyperparameter_search(n_trials=<span class="hljs-number">50</span>,<br>                                         direction=<span class="hljs-string">&quot;maximize&quot;</span>,<br>                                         hp_space=hp_space)<br></code></pre></td></tr></table></figure><p>bert_run是PyTorch中的<code>transformers.trainer_utils</code>中的<code>BestRun</code>，参数为run_id,objective, hyperparameters, 查看结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> best_run.hyperparameters.items():<br><span class="hljs-meta">&gt;&gt;&gt; </span>   <span class="hljs-built_in">print</span>(k, v)<br>num_train_epochs <span class="hljs-number">10</span><br>learning_rate <span class="hljs-number">8.26383331124286e-05</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>best_run.run_id<br><span class="hljs-number">5</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>best_run.objective<br><span class="hljs-number">0.933096723776579</span><br></code></pre></td></tr></table></figure><p>由上可知，在第5次实验中，num_train_epochs 和 learning_rate的参数取值使得模型的指标最好，F1为0.9331。</p><h2 id="总结">总结</h2><h4 id="推荐阅读">推荐阅读</h4><ul><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485508&amp;idx=1&amp;sn=77a6fef8cfb11a604e19de303576539f&amp;chksm=fcb9b1d4cbce38c24cd92793bcc734684a8a5bc6c4a94d4473328158a5f7e95373f1da4ce2e2&amp;token=475225731&amp;lang=zh_CN#rd">NLP（六十六）使用HuggingFace中的Trainer进行BERT模型微调</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485262&amp;idx=1&amp;sn=360652e6471d831d7d1ace79e3da8399&amp;chksm=fcb9bedecbce37c860856dbd883503a0bc6c44e8ecbc26d6ee8640dab8df39a6a3a48a46d617&amp;token=475225731&amp;lang=zh_CN#rd">PyTorch入门（七）TensorBoard的使用</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485261&amp;idx=1&amp;sn=d8e8a4fce4bb1ff19dd739bca020bd84&amp;chksm=fcb9beddcbce37cbebfaad75fb2ed337a7c4ac48a2642c651051e0c6cd51b4b397fcca49b4e6&amp;payreadticket=HBaOUydQ3igU3XkxAYNeSKyWZlkwyEZVeNznI01M6y7E63vt1R4mTMxuAvNPhSP7Ronlbhk#rd">PyTorch入门（六）使用Transformer模型进行中文文本分类</a></li></ul>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Optuna</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Apollo配置中心及Python连接</title>
    <link href="/Apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E5%8F%8APython%E8%BF%9E%E6%8E%A5/"/>
    <url>/Apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E5%8F%8APython%E8%BF%9E%E6%8E%A5/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何启动Apollo，在Apollo中配置参数，以及如何使用Python连接Apollo.</p></blockquote><h2 id="apollo介绍">Apollo介绍</h2><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485073&amp;idx=1&amp;sn=b120ac202781f482393d5420d5adba02&amp;chksm=fcb9bf01cbce3617d36a13d25330928586e937e3a440191f57344b799c6da7deb20ddbccfcae&amp;token=633459163&amp;lang=zh_CN#rd">Python之读取配置文件</a>和文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485073&amp;idx=1&amp;sn=b120ac202781f482393d5420d5adba02&amp;chksm=fcb9bf01cbce3617d36a13d25330928586e937e3a440191f57344b799c6da7deb20ddbccfcae&amp;token=633459163&amp;lang=zh_CN#rd">Python之配置文件处理</a>中，笔者分别介绍了如何使用Python来处理ini,yaml,conf等配置文件。这种配置方式比较方便本地加载，但囿于项目的复杂性、安全性、稳定性等角度考虑，我们需要借助其它的配置工具来实现更高效、高可靠的参数配置，其中之一便是<code>Apollo</code>。</p><p><imgsrc="https://cdn.jsdelivr.net/gh/apolloconfig/apollo@master/doc/images/logo/logo-simple.png" /></p><p><ahref="https://www.apolloconfig.com/#/zh/README">Apollo（阿波罗）</a>是一款可靠的分布式配置管理中心，诞生于携程框架研发部，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。服务端基于SpringBoot和SpringCloud开发，打包后可以直接运行，不需要额外安装Tomcat等应用容器。</p><p>Apollo的优点如下：</p><ul><li>部署简单</li><li>灰度发布</li><li>版本发布管理</li><li>提供开放平台API</li><li>客户端配置信息监控</li><li>提供Java和.Net原生客户端</li><li>配置修改实时生效（热发布）</li><li>权限管理、发布审核、操作审计</li><li>统一管理不同环境、不同集群的配置</li></ul><h2 id="apollo启动">Apollo启动</h2><p>我们采用<code>Docker-Compose</code>方式来启动<code>Apollo</code>，参考Github项目<ahref="https://github.com/apolloconfig/apollo-quick-start">apollo-quick-start</a>中给出的介绍，可以方便地在本地启动<code>Apollo</code>。</p><p>如果使用的是 arm 架构的机器，例如 macm1，需要下载docker-compose-arm64.yml。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker-compose -f docker-compose-arm64.yml up -d<br></code></pre></td></tr></table></figure><p>如果是其他架构的机器，如x86，则直接启动：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker-compose up -d<br></code></pre></td></tr></table></figure><h2 id="apollo配置">Apollo配置</h2><p>启动成功后，在浏览器中输入网址<strong>localhost:8070</strong>打开Apollo配置页面，账号apollo，密码admin，环境选择<strong>DEV</strong>，创建应用<strong>ai_service_1</strong>，appid 为<strong>ai_test</strong>，配置参数如下：</p><figure><img src="https://s2.loli.net/2023/09/12/IsoiW2tZbjweUAv.png"alt="参数配置" /><figcaption aria-hidden="true">参数配置</figcaption></figure><p>在管理秘钥中创建秘钥，点击发布按钮即可发布配置好的变量。</p><h2 id="python连接apollo">Python连接Apollo</h2><p><code>Apollo</code>天然支持Java,Net连接，支持度较好，对于Python，也有热心的开发者创建了支持度较好的第三方模块，这里使用<ahref="https://github.com/BruceWW/pyapollo">pyapollo</a>。该模块的安装方式为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install apollo-client==2.1.2<br></code></pre></td></tr></table></figure><p>使用Python连接<code>Apollo</code>的示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> pyapollo.apollo_client <span class="hljs-keyword">import</span> ApolloClient<br><br>app_id = <span class="hljs-string">&quot;ai_test&quot;</span><br>config_server_url = <span class="hljs-string">&quot;http://127.0.0.1:8090&quot;</span><br>authorization = <span class="hljs-string">&quot;3a7d769835ef43e3ae2af1cb1f861795&quot;</span><br>cache_file_path = <span class="hljs-string">&#x27;my_apollo_config&#x27;</span><br>env = <span class="hljs-string">&#x27;DEV&#x27;</span><br>namespace = <span class="hljs-string">&#x27;application&#x27;</span><br>client = ApolloClient(<br>            app_id=app_id,<br>            cluster=<span class="hljs-string">&quot;default&quot;</span>,<br>            config_server_url=config_server_url,<br>            authorization=authorization,<br>            cache_file_path=cache_file_path,<br>            env=env<br>        )<br>client.start()<br><span class="hljs-comment"># print(client.__dict__)</span><br><br><span class="hljs-comment"># get config from apollo</span><br>host = client.get_value(key=<span class="hljs-string">&quot;host&quot;</span>, default_val=<span class="hljs-string">&quot;*&quot;</span>, namespace=namespace)<br>port = client.get_value(key=<span class="hljs-string">&quot;port&quot;</span>, default_val=<span class="hljs-string">&quot;**&quot;</span>, namespace=namespace)<br>key = client.get_value(key=<span class="hljs-string">&quot;key&quot;</span>, default_val=<span class="hljs-string">&quot;***&quot;</span>, namespace=namespace)<br>name = client.get_value(key=<span class="hljs-string">&quot;name&quot;</span>, default_val=<span class="hljs-string">&quot;****&quot;</span>, namespace=namespace)<br><span class="hljs-built_in">print</span>(host, <span class="hljs-built_in">type</span>(host))<br><span class="hljs-built_in">print</span>(port, <span class="hljs-built_in">type</span>(port))<br><span class="hljs-built_in">print</span>(key, <span class="hljs-built_in">type</span>(key))<br><span class="hljs-built_in">print</span>(name, <span class="hljs-built_in">type</span>(name))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">0.0.0.0 &lt;class <span class="hljs-string">&#x27;str&#x27;</span>&gt;<br>80 &lt;class <span class="hljs-string">&#x27;str&#x27;</span>&gt;<br>abc &lt;class <span class="hljs-string">&#x27;str&#x27;</span>&gt;<br>**** &lt;class <span class="hljs-string">&#x27;str&#x27;</span>&gt;<br></code></pre></td></tr></table></figure><p>同时在本地的my_apollo_config目录下，也会有缓存的配置文件。</p><p>在上面的示例代码中，host, port,key变量都正常获取，但name变量不存在<code>Apollo</code>中，因为取默认值。如果在<code>Apollo</code>中配置该参数，则也能正常获取。</p><h2 id="总结">总结</h2><p>本文是笔者在实际工作中的一次总结，主要介绍了Apollo的启动、配置，以及如何使用Python来连接Apollo。</p><p>笔者已开通个人博客网址：<ahref="https://percent4.github.io/">https://percent4.github.io/</a>，欢迎大家访问~</p><h4 id="推荐阅读">推荐阅读</h4><ul><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485073&amp;idx=1&amp;sn=b120ac202781f482393d5420d5adba02&amp;chksm=fcb9bf01cbce3617d36a13d25330928586e937e3a440191f57344b799c6da7deb20ddbccfcae&amp;token=633459163&amp;lang=zh_CN#rd">Python之读取配置文件</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485073&amp;idx=1&amp;sn=b120ac202781f482393d5420d5adba02&amp;chksm=fcb9bf01cbce3617d36a13d25330928586e937e3a440191f57344b799c6da7deb20ddbccfcae&amp;token=633459163&amp;lang=zh_CN#rd">Python之配置文件处理</a></li></ul><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Apollo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（七十）使用LLAMA-2模型微调Multiple-Choice-MRC</title>
    <link href="/NLP%EF%BC%88%E4%B8%83%E5%8D%81%EF%BC%89%E4%BD%BF%E7%94%A8LLAMA-2%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83Multiple-Choice-MRC/"/>
    <url>/NLP%EF%BC%88%E4%B8%83%E5%8D%81%EF%BC%89%E4%BD%BF%E7%94%A8LLAMA-2%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83Multiple-Choice-MRC/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将介绍如何在Firefly大模型训练框架中，使用LLAMA-27B模型，对多项选择阅读理解数据集RACEmiddle进行微调，最终效果提升明显。</p></blockquote><h2 id="mrc">MRC</h2><p><code>机器阅读理解（Machine Reading Comprehension, MRC）</code>属于NLP任务中的问答任务（QuestionAnswering,QA），是NLP领域中基础且重要的一项任务。所谓的机器阅读理解就是给定一篇文章，以及基于文章的一个问题，让机器在阅读文章后对问题进行作答。</p><p>根据任务形式的不同，可划分为：</p><figure><img src="https://s2.loli.net/2023/09/10/hJL4uqE7pl1aOWS.png"alt="四种MRC任务" /><figcaption aria-hidden="true">四种MRC任务</figcaption></figure><ul><li><p>完形填空（ClozeTests）：将文章中的某些单词隐去，让模型根据上下文判断被隐去的单词最可能是哪个。</p></li><li><p>多项选择（MultipleChoice）：给定一篇文章和一个问题，让模型从多个备选答案中选择一个最有可能是正确答案的选项。</p></li><li><p>片段抽取（SpanExtraction）：给定一篇文章和一个问题，让模型从文章中抽取连续的单词序列，并使得该序列尽可能的作为该问题的答案。</p></li><li><p>自由作答（FreeAnswering）：给定一篇文章和一个问题，让模型生成一个单词序列，并使得该序列尽可能的作为该问题的答案。与片段抽取任务不同的是，该序列不再限制于是文章中的句子。</p></li></ul><p>其中，<code>完形填空</code>是BERT模型中的其中一项预训练任务MLM，因此，BERT系列的模型天然支持完形填空。</p><p><code>片段抽取</code>即抽取式阅读理解，是我们在NLP任务中最常见的阅读理解的形式，一般情况下的阅读理解也指的是这种形式。使用BERT系列模型也能很好地完成该任务。该任务的经典数据集有<ahref="https://huggingface.co/datasets/squad">SQUAD</a>, <ahref="https://huggingface.co/datasets/squad_v2">SQUAD 2</a>等。</p><p><code>自由作答</code>不限定回复的答案来自于原始文章，因此难度最大，一般采用生成式模型解决，以前的NLP模型在这方面的表现不佳。而大模型（LLM）的出现，让该任务有了很大改观，效果有了较强的阅读性，属于革命性的变化。</p><p><code>多项选择</code>即我们在英语考试中的阅读理解，阅读文章，给定问题，从固定的选项中选出正确答案。经典的多项选择阅读理解数据集有<ahref="https://huggingface.co/datasets/race">RACE</a> , <ahref="https://huggingface.co/datasets/swag">SWAG</a>等。本文将会具体介绍多项选择阅读理解中的RACE数据集，以及LLAMA-2在该数据集上的微调效果。</p><h2 id="race数据集">RACE数据集</h2><p><code>RACE</code>数据集是多项选择阅读理解（Multi ChoiceMRC）中的经典数据集，<ahref="https://www.cs.cmu.edu/~glai1/data/race/">RACE官方网址</a>中的介绍为：</p><blockquote><p>Race is a large-scale reading comprehension dataset with more than28,000 passages and nearly 100,000 questions. The dataset is collectedfrom English examinations in China, which are designed for middle schooland high school students. The dataset can be served as the training andtest sets for machine comprehension.</p></blockquote><p>RACE数据集又分为middle（初中）和high（高中）两部分，如下：</p><table><thead><tr class="header"><th>数据集</th><th>train</th><th>dev</th><th>test</th></tr></thead><tbody><tr class="odd"><td>middle</td><td>25421</td><td>1436</td><td>1436</td></tr><tr class="even"><td>high</td><td>62445</td><td>3451</td><td>3498</td></tr><tr class="odd"><td>total</td><td>87866</td><td>4887</td><td>4934</td></tr></tbody></table><p>由于数据规模原因和训练时间原因，本文只对middle数据集进行微调。随机从middle数据集中的训练集挑选一条样本，如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>&#x27;example_id&#x27;<span class="hljs-punctuation">:</span> &#x27;middle4558.txt&#x27;<span class="hljs-punctuation">,</span><br> &#x27;article&#x27;<span class="hljs-punctuation">:</span> &#x27;<span class="hljs-string">&quot;I planted a seed. Finally grow fruits. Today is a great day. Pick off the star for you. Pick off the moon for you. Let it rise for you every day. Become candles burning myself. Just light you up, hey!... You are my little little apple. How much I love you, still no enough.&quot;</span>\nThis words are from the popular song You Are My Little Dear Apple. Bae Seul-Ki acted as the leading dancer in the MV of the song. She loves dancing. She became crazy about hip-hop when she was a school girl.\nBai Seul-Ki was born on September <span class="hljs-number">27</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1986.</span> She is a South Korean singer and dancer. She is <span class="hljs-number">168</span>cm tall. She loves cooking. Her favourite food is spicy and salty. She like pink and red most. There are five members in her family---father<span class="hljs-punctuation">,</span> mother<span class="hljs-punctuation">,</span> two younger brothers and herself. She isn\&#x27;t married.\nAfter her father and mother broke up<span class="hljs-punctuation">,</span> she lived with her mother and new daddy. She enjoys being alone.&#x27;<span class="hljs-punctuation">,</span><br> &#x27;answer&#x27;<span class="hljs-punctuation">:</span> &#x27;B&#x27;<span class="hljs-punctuation">,</span><br> &#x27;question&#x27;<span class="hljs-punctuation">:</span> &#x27;Bae Seul-Ki   _   in the MV of the song according to the passage.&#x27;<span class="hljs-punctuation">,</span><br> &#x27;options&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>&#x27;sang&#x27;<span class="hljs-punctuation">,</span> &#x27;danced&#x27;<span class="hljs-punctuation">,</span> &#x27;cried&#x27;<span class="hljs-punctuation">,</span> &#x27;laughed&#x27;<span class="hljs-punctuation">]</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h2 id="构建prompt">构建Prompt</h2><p>本文针对RACE数据集，构建的Prompt如下：</p><pre><code class="hljs">Read the following passage and questions, then choose the right answer from options, the answer should be one of A, B, C, D.&lt;passage&gt;:&quot;I planted a seed. Finally grow fruits. Today is a great day. Pick off the star for you. Pick off the moon for you. Let it rise for you every day. Become candles burning myself. Just light you up, hey!... You are my little little apple. How much I love you, still no enough.&quot;This words are from the popular song You Are My Little Dear Apple. Bae Seul-Ki acted as the leading dancer in the MV of the song. She loves dancing. She became crazy about hip-hop when she was a school girl.Bai Seul-Ki was born on September 27, 1986. She is a South Korean singer and dancer. She is 168cm tall. She loves cooking. Her favourite food is spicy and salty. She like pink and red most. There are five members in her family---father, mother, two younger brothers and herself. She isn&#39;t married.After her father and mother broke up, she lived with her mother and new daddy. She enjoys being alone.&lt;question&gt;:Bae Seul-Ki   _   in the MV of the song according to the passage.&lt;options&gt;:A sangB dancedC criedD laughed&lt;answer&gt;:</code></pre><blockquote><p><strong>Trick</strong>:可以借助大模型，比如GPT-4构建能好的Prompt以提升微调效果。</p></blockquote><h2 id="llama-2模型微调">LLAMA-2模型微调</h2><p>在大模型领域，<ahref="https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/"><code>LLAMA</code></a>系列模型可谓大名鼎鼎，其本身及衍生的模型有几十个，真让人眼花缭乱，而且效果都很不错，是大模型领域真正的一代宗师。我们有机会再介绍LLAMA系列模型，本文不再详述。</p><p>本文使用刚开源的<ahref="https://about.fb.com/news/2023/07/llama-2/"><code>LLAMA 2</code>模型</a>，7B版本，在<code>Firefly</code>框架下，对RACEmiddle数据集进行微调。微调的参数如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;output_dir&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;output/firefly-llama2-7b-race-middle&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;model_name_or_path&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/home/jclian91/Llama-2-7b-hf&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;train_file&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;./data/race_train.jsonl&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;num_train_epochs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;per_device_train_batch_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">8</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;gradient_accumulation_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;learning_rate&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1e-4</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;max_seq_length&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">384</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;logging_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">100</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;save_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">100</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;save_total_limit&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lr_scheduler_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;constant_with_warmup&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;warmup_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">100</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lora_rank&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">64</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lora_alpha&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">16</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lora_dropout&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.05</span><span class="hljs-punctuation">,</span><br><br>    <span class="hljs-attr">&quot;gradient_checkpointing&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;disable_tqdm&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;optim&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;paged_adamw_32bit&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;seed&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">42</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;fp16&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;report_to&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;tensorboard&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;dataloader_num_workers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">10</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;save_strategy&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;steps&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;weight_decay&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;max_grad_norm&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.3</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;remove_unused_columns&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485454&amp;idx=1&amp;sn=efe98ac6bef1d06518958918405719ab&amp;chksm=fcb9b19ecbce3888a57b9c7c8bc7852a7e051774ee897f5caa0a03d3afb0adf1aedc5bc5c11b&amp;payreadticket=HNZHAsM-Bua8lK8PnmTkk4-3mVg_01kmjA_KfhvBvh0iIMm1Tlz2woLFkuX8-weOLoMxOUU#rd">NLP（六十三）使用Baichuan-7b模型微调人物关系分类任务</a>，我们已经详细介绍了Firefly模型微调、评估、WEB服务等步骤，这里也不再详述。也可以参考Github项目<ahref="https://github.com/percent4/llama-2-multiple-choice-mrc">llama-2-multiple-choice-mrc</a>.</p><p>在RACE test数据集上的准确率为<code>86.91%</code>!效果可谓惊人，而这只是LLAMA2没有经过参数调整的结果，效果不可谓不佳。笔者之前用<ahref="https://github.com/percent4/keras_bert_multiple_choice_MRC">BERT模型同样在RACEmiddle数据集上进行微调</a>，评估结果一般只有72%左右，BERTLarge模型才不过75%，这还是训练数据采用了middle + high的结果。</p><p><ahref="https://paperswithcode.com/sota/reading-comprehension-on-race">RACE数据集排行榜</a>如下：</p><figure><img src="https://s2.loli.net/2023/09/10/9LMe2PdmZNKcCbo.png"alt="RACE数据集排行榜" /><figcaption aria-hidden="true">RACE数据集排行榜</figcaption></figure><h2 id="模型效果评估">模型效果评估</h2><p>最后，我们在新的文章上进行评估。我们从网上随机选取<ahref="https://yingyu.xdf.cn/201901/10843790.html">一篇初中英语阅读理解文章</a>，如下：</p><pre><code class="hljs">Edward rose early on the New-year morning. He looked in every room and wished a Happy New Year to his family. Then he ran into the street to repeat that to those he might meet.When he came back, his father gave him two bright, new silver dollars.His face lighted up as he took them. He had wished for a long time to buy some pretty books that he had seen at the bookstore.He left the house with a light heart, expecting to buy the books. As he ran down the street, he saw a poor family.“I wish you a Happy New Year.” said Edward, as he was passing on. The man shook his head.“You are not from this country.” said Edward. The man again shook his head, for he could not understand or speak his language. But he pointed to his mouth and to the children shaking with cold, as if (好像) to say, “These little ones have had nothing to eat for a long time.”Edward quickly understood that these poor people were in trouble. He took out his dollars and gave one to the man, and the other to his wife.They were excited and said something in their language, which doubtless meant, “We thank you so much that we will remember you all the time.”When Edward came home, his father asked what books he had bought. He hung his head a moment, but quickly looked up.“I have bought no books”, said he. “I gave my money to some poor people, who seemed to be very hungry then.” He went on, “I think I can wait for my books till next New Year.”“My dear boy,” said his father, “here are some books for you, more as a prize for your goodness of heart than as a New-year gift”“I saw you give the money cheerfully to the poor German family. It was nice for a little boy to do so. Be always ready to help others and every year of your life will be to you a Happy New Year.”</code></pre><p>四个问题如下：</p><pre><code class="hljs">48. Edward expected to _________ with the money he got from his father.A. help the poor family B. buy something to eatC. buy some pretty books D. learn another language49. Why did the poor man shake his head when Edward spoke to him?A. He couldn’t understand the boy B. He wouldn’t accept the moneyC. He didn’t like the boy’s language D. He was too cold to say anything50. How much did Edward give the poor family?A. One dollar B. Two dollars C. Three dollars D. Four dollars51. We know that Edward_________ from the passage?A. got a prize for his kind heart B. had to buy his books next yearC. bought the books at the bookstore D. got more money from his father</code></pre><p>微调模型给出的答案为<strong>CABA</strong>，与参考答案一致！</p><h2 id="总结">总结</h2><p>多项选择阅读理解一直是笔者这几年来关注的人物，而之前的BERT时代，BERT模型的效果并不太好，<ahref="https://huggingface.co/docs/transformers/model_doc/megatron-bert">Megatron-BERT</a>将指标提升至90%左右，这中间付出了太多努力，效果也不太好复现。笔者一直都在做这方面的努力，而囿于机器资源或模型参数，都未能成功。LLAMA系列模型的出现，让这一切变得如此轻松写意，虽然效果还不是SOTA，但效果无疑是让人满意的。大模型无疑是未来人工智能的潮流，是当今时代的弄潮儿！</p><p>本文主要介绍了MRC及RACE数据集，同时介绍了如何在Firefly训练框架下，采用LLAMA2模型进行微调，并取得了满意的效果。</p><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>MRC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（六十九）智能文档助手升级</title>
    <link href="/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B9%9D%EF%BC%89%E6%99%BA%E8%83%BD%E6%96%87%E6%A1%A3%E5%8A%A9%E6%89%8B%E5%8D%87%E7%BA%A7/"/>
    <url>/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B9%9D%EF%BC%89%E6%99%BA%E8%83%BD%E6%96%87%E6%A1%A3%E5%8A%A9%E6%89%8B%E5%8D%87%E7%BA%A7/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文在笔者之前研发的<ahref="https://github.com/percent4/document_qa_with_llm">大模型智能文档问答项目</a>中，开发更进一步，支持多种类型文档和URL链接，支持多种大模型接入，且使用更方便、高效。</p></blockquote><h2 id="项目介绍">项目介绍</h2><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485425&amp;idx=1&amp;sn=bd85ddfce82d77ceec5a66cb96835400&amp;chksm=fcb9be61cbce37773109f9703c2b6c4256d5037c8bf4497dfb9ad0f296ce0ee4065255954c1c&amp;token=385301904&amp;lang=zh_CN#rd">NLP（六十一）使用Baichuan-13B-Chat模型构建智能文档</a>中，笔者详细介绍了如何使用<code>Baichuan-13B-Chat</code>模型来构建智能文档问答助手。</p><p>一般，使用大模型来实现文档问答功能的流程图如下：</p><figure><img src="/img/nlp60_5.jpeg" alt="LangChain文档问答流程" /><figcaption aria-hidden="true">LangChain文档问答流程</figcaption></figure><p>本次，笔者在之前的项目中更进一步，支持的功能如下：</p><ul><li>支持多种格式文档（包括txt, pdf, docx）和URL链接</li><li>问答可视化页面</li><li>问答可追溯，加入高亮显示</li><li>单/多模型调用</li><li>模型效果对比</li></ul><p>说明如下：</p><ol type="1"><li>支持的文档格式由<code>LangChain</code>提供，URL链接的解析由<code>LangChain</code>中的<strong>selenium</strong> 和<strong>unstructured</strong>，可支持JavaScript渲染的页面。但网页解析（或者说爬虫）是一项复杂而艰巨的任务，不可能在本项目中实现所有的网页解析。</li><li>可视化问答页面由Gradio模块实现</li><li>支持单模型或多模型调用，并且可以提供问答溯源。同时，还支持不同模型回答结果的比对，该想法来源于<ahref="https://opencompass.org.cn/">OpenCompass</a> .</li></ol><p>在工程开发上，加入的特性（features）如下：</p><ul><li>丰富使用文档</li><li>加入配置文件</li><li>增加日志调用</li><li>ES分词器支持用户词典</li><li>Milvus支持初步筛选的阈值配置</li></ul><p>本项目已开源至Github，代码实现可参考<ahref="https://github.com/percent4/document_qa_with_llm">document_qa_with_llm</a>，这里不再讲解代码细节。</p><h2 id="支持文档格式">支持文档格式</h2><p>本项目原先只支持txt格式，现在已支持多种格式文档（包括txt, pdf,docx）和URL链接，这得益于<code>LangChain</code>框架中的<ahref="https://python.langchain.com/docs/integrations/document_loaders/">文档加载模块</a>，使得各种格式的文档加载变得更加统一、简洁、高效。</p><p>本项目中的文件解析脚本如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> TextLoader, PyPDFLoader, Docx2txtLoader, SeleniumURLLoader<br><br><span class="hljs-keyword">from</span> utils.logger <span class="hljs-keyword">import</span> logger<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FileParser</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, file_path</span>):<br>        self.file_path = file_path<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">txt_loader</span>(<span class="hljs-params">self</span>):<br>        documents = TextLoader(self.file_path, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>).load()<br>        <span class="hljs-keyword">return</span> documents<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">pdf_loader</span>(<span class="hljs-params">self</span>):<br>        loader = PyPDFLoader(self.file_path)<br>        documents = loader.load_and_split()<br>        <span class="hljs-keyword">return</span> documents<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">docx_loader</span>(<span class="hljs-params">self</span>):<br>        loader = Docx2txtLoader(self.file_path)<br>        documents = loader.load()<br>        <span class="hljs-keyword">return</span> documents<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">url_loader</span>(<span class="hljs-params">self</span>):<br>        loader = SeleniumURLLoader(urls=[self.file_path])<br>        documents = loader.load()<br>        <span class="hljs-keyword">return</span> documents<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">parse</span>(<span class="hljs-params">self</span>):<br>        logger.info(<span class="hljs-string">f&#x27;parse file: <span class="hljs-subst">&#123;self.file_path&#125;</span>&#x27;</span>)<br>        <span class="hljs-keyword">if</span> self.file_path.endswith(<span class="hljs-string">&quot;.txt&quot;</span>):<br>            <span class="hljs-keyword">return</span> self.txt_loader()<br>        <span class="hljs-keyword">elif</span> self.file_path.endswith(<span class="hljs-string">&quot;.pdf&quot;</span>):<br>            <span class="hljs-keyword">return</span> self.pdf_loader()<br>        <span class="hljs-keyword">elif</span> self.file_path.endswith(<span class="hljs-string">&quot;.docx&quot;</span>):<br>            <span class="hljs-keyword">return</span> self.docx_loader()<br>        <span class="hljs-keyword">elif</span> <span class="hljs-string">&quot;http&quot;</span> <span class="hljs-keyword">in</span> self.file_path:<br>            <span class="hljs-keyword">return</span> self.url_loader()<br>        <span class="hljs-keyword">else</span>:<br>            logger.error(<span class="hljs-string">&quot;unsupported document type!&quot;</span>)<br>            <span class="hljs-keyword">return</span> []<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    txt_file_path = <span class="hljs-string">&quot;/Users/admin/PycharmProjects/document_qa_with_llm/files/gdp.txt&quot;</span><br>    content = FileParser(txt_file_path).parse()<br>    <span class="hljs-built_in">print</span>(content)<br><br>    pdf_file_path = <span class="hljs-string">&quot;/Users/admin/PycharmProjects/document_qa_with_llm/files/oppo_n3_flip.pdf&quot;</span><br>    content = FileParser(pdf_file_path).parse()<br>    <span class="hljs-built_in">print</span>(content)<br><br>    docx_file_path = <span class="hljs-string">&quot;/Users/admin/PycharmProjects/document_qa_with_llm/files/haicaihua.docx&quot;</span><br>    content = FileParser(docx_file_path).parse()<br>    <span class="hljs-built_in">print</span>(content)<br><br>    url = <span class="hljs-string">&quot;https://gaokao.xdf.cn/202303/12967078.html&quot;</span><br>    url = <span class="hljs-string">&quot;https://www.hntv.tv/50rd/article/1/1700396378818207745?v=1.0&quot;</span><br>    content = FileParser(url).parse()<br>    <span class="hljs-built_in">print</span>(content)<br></code></pre></td></tr></table></figure><h2 id="问答测试">问答测试</h2><p>文档上传页面如下，支持多种格式文档上传和URL解析（依赖于页面解析能力），页面较为粗糙。</p><figure><img src="/img/nlp69_1.png" alt="文件上传页面" /><figcaption aria-hidden="true">文件上传页面</figcaption></figure><p>上传后的文件会放至files文件夹上，示例文档可在Github项目中files文件夹中参考。</p><ul><li>txt文件</li></ul><p>我们以<code>files/dengyue.txt</code>为例，问答如下：</p><blockquote><p>你知道格里芬的职务吗？ 格里芬的职务是美国宇航局局长。</p></blockquote><blockquote><p>格里芬发表演说时讲了什么？根据文档知识，格里芬发表演说时讲了如下内容：他认为如果中国人愿意，2020年他们可以实现载人登月工程。此外，叶培建院士也曾发表自己的观点，认为2025年比较合适。然而，根据中国科学院编制的50年长远规划，中国要实现载人登月工程是2030年。</p></blockquote><ul><li>pdf文件</li></ul><p>我们以<code>files/oppo_n3_flip.pdf</code>为例，回答如下：</p><blockquote><p>OPPO最新款折叠屏手机叫什么？ OPPO最新款折叠屏手机是OPPO Find N3Flip。</p></blockquote><blockquote><p>腾讯有发布自研的大模型吗，什么时候发布的？是的，腾讯已经发布了自研的大语言模型，名为 “ 混元大模型 ” 。它在 2023年腾讯全球数字生态大会上正式对外亮相。具体时间为 9 月 7 日。</p></blockquote><ul><li>docx文件</li></ul><p>我们以<code>files/haicaihua.docx</code>为例，回答如下：</p><blockquote><p>海菜花对生长环境有什么要求？海菜花对生长环境要求极高，只能在水体洁净、透明度较高的水体中生长，被誉为水质的“试金石”。</p></blockquote><ul><li>URL链接</li></ul><p>我们以<code>https://gaokao.xdf.cn/202303/12967078.html</code>为例，回答如下：</p><blockquote><p>电子科技大学2022年招生多少人？电子科技大学2022年招生总计划是5030人，其中“电子科技大学”将面向全国招生3300余人，“电子科技大学(沙河校区)”将面向部分省份招生1700余人。</p></blockquote><blockquote><p>电子科技大学的官网？电子科技大学的官网是：http://www.zs.uestc.edu.cn/</p></blockquote><h2 id="可视化问答">可视化问答</h2><p>除了之前的API调用，本项目还支持可视化问答。该功能由<code>Gradio</code>模块实现，支持在页面上进行可视化问答，同时还支持多模型调用，支持的大模型如下：</p><ul><li>Baichuan-13B-Chat: 百川智能发布的模型，现已更新至Baichuan2</li><li>LLAMA-2-Chinese-13b-Chat: 在LLAMA2模型上进行微调得到的中文对话模型</li><li>internlm-chat-7b：上海人工智能实验室发布的书生（InternLM）对话模型</li></ul><p>这些都是中文大模型。理论上，支持的模型由<ahref="https://github.com/lm-sys/FastChat">FastChat</a> 和部署的GPU型号、数量决定，本项目只考虑以上三种。</p><p>该页面支持多模型或单模型的问答。<strong>多模型</strong>问答时，可比较不同模型在相同的Prompt下的回答效果，作为模型评估的一种方式。</p><figure><img src="/img/nlp69_2.png" alt="单模型问答" /><figcaption aria-hidden="true">单模型问答</figcaption></figure><figure><img src="/img/nlp69_3.png" alt="多模型问答" /><figcaption aria-hidden="true">多模型问答</figcaption></figure><p>同时，该页面还支持问答溯源，可追踪文档问答得到的答案所需的引用文本和对用的数据来源。</p><figure><img src="/img/nlp69_4.png" alt="问答溯源" /><figcaption aria-hidden="true">问答溯源</figcaption></figure><h2 id="问答溯源中的文本高亮">问答溯源中的文本高亮</h2><p>由于<code>Gradio</code>中的表格不支持单元格内文本高亮，因此，我们所用它自带的高亮文本控件对问答溯源中的引用文本进行文本高亮，方便我们对回答内容在原文中的位置进行确认，避免大模型幻觉问题。</p><p>问答溯源中的文本高亮算法如下：</p><ol type="1"><li>找到问答所在的引用文本列表，由ES和Milvus产生</li><li>对引用文本拆分成列表</li><li>得到与回答相似度最高的文本，相似度采用Jaccard系数</li><li>将相似度最高文本中与回答重合的部分，进行高亮显示</li></ol><figure><img src="/img/nlp69_5.png" alt="问答溯源中的文本高亮" /><figcaption aria-hidden="true">问答溯源中的文本高亮</figcaption></figure><h2 id="总结">总结</h2><p>本项目在之前开源的基础上，加入了更丰富的功能，包括支持多种格式文档解析和URL解析，支持问答可视化页面，支持单/多模型调用，支持多模型效果对比。</p><p>本项目已开源至Github，代码实现可参考<ahref="https://github.com/percent4/document_qa_with_llm">document_qa_with_llm</a>。</p><h4 id="推荐阅读">推荐阅读</h4><ul><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485425&amp;idx=1&amp;sn=bd85ddfce82d77ceec5a66cb96835400&amp;chksm=fcb9be61cbce37773109f9703c2b6c4256d5037c8bf4497dfb9ad0f296ce0ee4065255954c1c&amp;token=385301904&amp;lang=zh_CN#rd">NLP（六十一）使用Baichuan-13B-Chat模型构建智能文档</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247485495&amp;idx=1&amp;sn=be35afc0d6fb7f6159af6ad13fda6f93&amp;chksm=fcb9b1a7cbce38b1f86fd3264d58ef15c565c3c1e4bb60204ab819f3a987d69c9ee3ef527491&amp;token=385301904&amp;lang=zh_CN#rd">Gradio入门（1）输入输出、表格、文本高亮</a></li></ul><p>引用链接</p><p>[1] 大模型智能文档问答项目:https://github.com/percent4/document_qa_with_llm</p><p>[2] OpenCompass: https://opencompass.org.cn/</p><p>[3] document_qa_with_llm:https://github.com/percent4/document_qa_with_llm</p><p>[4] 文档加载模块:https://python.langchain.com/docs/integrations/document_loaders/</p><p>[5] FastChat: https://github.com/lm-sys/FastChat</p><p>[6] document_qa_with_llm:https://github.com/percent4/document_qa_with_llm</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文档问答</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于token的编辑距离计算</title>
    <link href="/%E5%9F%BA%E4%BA%8Etoken%E7%9A%84%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97/"/>
    <url>/%E5%9F%BA%E4%BA%8Etoken%E7%9A%84%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>字符串的<strong>编辑距离</strong>是我们都知道的，事实上，编辑距离的计算，本质上是对列表元素的操作，那么，自然也可以是token列表。本文的想法正是基于此。</p></blockquote><h2 id="字符串的编辑距离">字符串的编辑距离</h2><p>在文章<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484130&amp;idx=1&amp;sn=dc34277848f23f6a80077d970eb0af2f&amp;chksm=fcb9bb72cbce3264c9e08f26be4b2d07ddd3d57bc060d8d5819c12fd4d121fbe811674125199&amp;token=385301904&amp;lang=zh_CN#rd">动态规划法算法之编辑距离</a>中，笔者详细介绍了字符串的编辑距离定义及使用动态规划法（DynamicProgramming, DP）来解决。</p><p>我们再来看看字符串的编辑距离的定义。什么是两个字符串的<strong>编辑距离（editdistance）</strong>？给定字符串s1和s2，以及在s1上的如下操作：</p><ul><li><code>插入</code>（Insert）一个字符</li><li><code>移除</code>（Remove）一个字符</li><li><code>替换</code>（Replace）一个字符</li></ul><p>试问最小需要多少次这样的操作才能使得s1转换为s2？</p><p>在leetcode网站中，这是题目中的<ahref="https://leetcode.cn/problems/edit-distance/">第72题</a>，难度为hard。</p><p>笔者当时使用动态规划算法，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">string_edit_distance</span>(<span class="hljs-params">s1, s2</span>):<br>    n = <span class="hljs-built_in">len</span>(s1)<br>    m = <span class="hljs-built_in">len</span>(s2)<br><br>    <span class="hljs-comment"># 有一个字符串为空串</span><br>    <span class="hljs-keyword">if</span> n * m == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> n + m<br><br>    <span class="hljs-comment"># DP 数组</span><br>    D = [[<span class="hljs-number">0</span>] * (m + <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n + <span class="hljs-number">1</span>)]<br><br>    <span class="hljs-comment"># 边界状态初始化</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n + <span class="hljs-number">1</span>):<br>        D[i][<span class="hljs-number">0</span>] = i<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m + <span class="hljs-number">1</span>):<br>        D[<span class="hljs-number">0</span>][j] = j<br><br>    <span class="hljs-comment"># 计算所有 DP 值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n + <span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, m + <span class="hljs-number">1</span>):<br>            left = D[i - <span class="hljs-number">1</span>][j] + <span class="hljs-number">1</span><br>            down = D[i][j - <span class="hljs-number">1</span>] + <span class="hljs-number">1</span><br>            left_down = D[i - <span class="hljs-number">1</span>][j - <span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">if</span> s1[i - <span class="hljs-number">1</span>] != s2[j - <span class="hljs-number">1</span>]:<br>                left_down += <span class="hljs-number">1</span><br>            D[i][j] = <span class="hljs-built_in">min</span>(left, down, left_down)<br><br>    <span class="hljs-keyword">return</span> D[n][m]<br></code></pre></td></tr></table></figure><blockquote><p>该算法是字符串编辑距离的常规优化算法。</p></blockquote><h2 id="基于token的编辑距离">基于token的编辑距离</h2><p>不难发现，上述的字符串编辑距离的算法，可以扩展至一切列表元素的编辑距离。在这里，我们选择token列表。</p><p>我们使用<code>tiktoken</code>将字符串转化为token列表。</p><p>基于token的编辑距离代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tiktoken<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">token_edit_distance</span>(<span class="hljs-params">s1, s2</span>):<br>    enc = tiktoken.get_encoding(<span class="hljs-string">&quot;cl100k_base&quot;</span>)<br>    token_list1 = enc.encode(s1)<br>    token_list2 = enc.encode(s2)<br>    <span class="hljs-built_in">print</span>(token_list1)<br>    <span class="hljs-built_in">print</span>(token_list2)<br>    <span class="hljs-keyword">return</span> string_edit_distance(token_list1, token_list2)<br></code></pre></td></tr></table></figure><p>我们选取两个例子进行测试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># case 1</span><br>    text1 = <span class="hljs-string">&quot;tiktoken is good&quot;</span><br>    text2 = <span class="hljs-string">&quot;tiktoken is great&quot;</span><br>    <span class="hljs-built_in">print</span>(string_edit_distance(text1, text2))<br>    <span class="hljs-built_in">print</span>(token_edit_distance(text1, text2))<br><br>    <span class="hljs-comment"># case 2</span><br>    text1 = <span class="hljs-string">&quot;iPhone手机很棒！&quot;</span><br>    text2 = <span class="hljs-string">&quot;华为手机很棒！&quot;</span><br>    <span class="hljs-built_in">print</span>(string_edit_distance(text1, text2))<br>    <span class="hljs-built_in">print</span>(token_edit_distance(text1, text2))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">4<br>[83, 1609, 5963, 374, 1695]<br>[83, 1609, 5963, 374, 2294]<br>1<br>6<br>[45840, 59505, 17599, 230, 77062, 240, 6447]<br>[86461, 18184, 59505, 17599, 230, 77062, 240, 6447]<br>2<br></code></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>本文的想法较为简单，是将字符串的<strong>编辑距离</strong>推广至token列表的编辑距离，可以作为一种衡量字符串相似度的指标。</p><p><code>其它想法</code>如下：</p><ol type="1"><li>不仅字符串，token可以作为字符串相似度的衡量标准，在文本纠错中，拼音也可作为标准</li><li>edit distance本质上是两个列表的编辑距离</li><li>利用预训练模型进行文本纠错，实质上是对token进行纠错</li><li>在中英文混合场景也许有用</li></ol><h4 id="推荐阅读">推荐阅读</h4><ul><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484130&amp;idx=1&amp;sn=dc34277848f23f6a80077d970eb0af2f&amp;chksm=fcb9bb72cbce3264c9e08f26be4b2d07ddd3d57bc060d8d5819c12fd4d121fbe811674125199&amp;token=385301904&amp;lang=zh_CN#rd">动态规划法算法之编辑距离</a></li><li><ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484135&amp;idx=1&amp;sn=803081aa7940bb81a67e7310a912d4db&amp;chksm=fcb9bb77cbce3261e6a291b432376aad1ae2c93929cb8f6cc711728efda8f651506fd6809db8&amp;token=385301904&amp;lang=zh_CN#rd">单词纠错</a></li></ul><hr /><p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/8562f60caee45918bf34261bba008c77.jpeg" style="width:100px;"></p><p>欢迎关注我的公众号“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/6a816b105c18ca778a6a0b6cbb0879fc.jpeg" style="width:100px;"></p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编辑距离</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（六十八）使用Optimum进行模型量化</title>
    <link href="/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8Optimum%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/"/>
    <url>/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8Optimum%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会介绍如何使用HuggingFace的<code>Optimum</code>，来对微调后的BERT模型进行量化（Quantization）。</p><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%83%EF%BC%89BERT%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%90%8E%E5%8A%A8%E6%80%81%E9%87%8F%E5%8C%96%EF%BC%88PTDQ%EF%BC%89/">NLP（六十七）BERT模型训练后动态量化（PTDQ）</a>中，我们使用PyTorch自带的PTDQ（PostTraining DynamicQuantization）量化策略对微调后的BERT模型进行量化，取得了模型推理性能的提升（大约1.5倍）。本文将尝试使用<code>Optimum</code>量化工具。</p><h3 id="optimum介绍">Optimum介绍</h3><p><code>Optimum</code> 是 <code>Transformers</code>的扩展，它提供了一组性能优化工具，可以在目标硬件上以最高效率训练和运行模型。</p><p><code>Optimum</code>针对不同的硬件，提供了不同的优化方案，如下表：</p><table><thead><tr class="header"><th>硬件</th><th>安装命令</th></tr></thead><tbody><tr class="odd"><td>ONNX runtime</td><td>python -m pip install optimum[onnxruntime]</td></tr><tr class="even"><td>Intel Neural Compressor (INC)</td><td>python -m pip install optimum[neural-compressor]</td></tr><tr class="odd"><td>Intel OpenVINO</td><td>python -m pip install optimum[openvino,nncf]</td></tr><tr class="even"><td>Graphcore IPU</td><td>python -m pip install optimum[graphcore]</td></tr><tr class="odd"><td>Habana Gaudi Processor (HPU)</td><td>python -m pip install optimum[habana]</td></tr><tr class="even"><td>GPU</td><td>python -m pip install optimum[onnxruntime-gpu]</td></tr></tbody></table><p>本文将会介绍基于ONNX的模型量化技术。ONNX（英语：Open Neural NetworkExchange）是一种针对机器学习所设计的开放式的文件格式，用于存储训练好的模型。它使得不同的人工智能框架（如Pytorch、MXNet）可以采用相同格式存储模型数据并交互。</p><h3 id="模型量化">模型量化</h3><p>我们使用的微调后的BERT模型采用文章<ahref="https://percent4.github.io/2023/09/02/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8HuggingFace%E4%B8%AD%E7%9A%84Trainer%E8%BF%9B%E8%A1%8CBERT%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/">https://percent4.github.io/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8HuggingFace%E4%B8%AD%E7%9A%84Trainer%E8%BF%9B%E8%A1%8CBERT%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/</a>中给出的文本分类模型。</p><p>首先，我们先加载PyTorch中的设备（CPU）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load device</span><br><span class="hljs-keyword">import</span> torch<br><br>device = torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br></code></pre></td></tr></table></figure><p>接着，我们使用<code>optimum.onnxruntime</code>模块加载模型和tokenizer，并将模型保存为onnx格式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTModelForSequenceClassification<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><span class="hljs-keyword">import</span> torch<br><br>model_id = <span class="hljs-string">&quot;./sougou_test_trainer_256/checkpoint-96&quot;</span><br>onnx_path = <span class="hljs-string">&quot;./sougou_test_trainer_256/onnx_256&quot;</span><br><br><span class="hljs-comment"># load vanilla transformers and convert to onnx</span><br>model = ORTModelForSequenceClassification.from_pretrained(model_id, from_transformers=<span class="hljs-literal">True</span>)<br>tokenizer = AutoTokenizer.from_pretrained(model_id)<br><br><span class="hljs-comment"># save onnx checkpoint and tokenizer</span><br>model.save_pretrained(onnx_path)<br>tokenizer.save_pretrained(onnx_path)<br></code></pre></td></tr></table></figure><p>此时，会多出onnx_256文件夹，保存模型为model.onnx。</p><figure><img src="/img/nlp68_1.png" alt="保存为onnx模型" /><figcaption aria-hidden="true">保存为onnx模型</figcaption></figure><p>输出结果为：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs scheme">(<span class="hljs-symbol">&#x27;./sougou_test_trainer_256/onnx_256</span>\\tokenizer_config.json&#x27;,<br> <span class="hljs-symbol">&#x27;./sougou_test_trainer_256/onnx_256</span>\\special_tokens_map.json&#x27;,<br> <span class="hljs-symbol">&#x27;./sougou_test_trainer_256/onnx_256</span>\\vocab.txt&#x27;,<br> <span class="hljs-symbol">&#x27;./sougou_test_trainer_256/onnx_256</span>\\added_tokens.json&#x27;,<br> <span class="hljs-symbol">&#x27;./sougou_test_trainer_256/onnx_256</span>\\tokenizer.json&#x27;)<br></code></pre></td></tr></table></figure><p>使用<code>transfomers</code>中的pipeline对模型进行快速推理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>vanilla_clf = pipeline(<span class="hljs-string">&quot;text-classification&quot;</span>, model=model, tokenizer=tokenizer)<br>vanilla_clf(<span class="hljs-string">&quot;这期节目继续关注中国篮球的话题。众所周知，我们已经结束了男篮世界杯的所有赛程，一胜四负的一个成绩，甚至比上一届的世界杯成绩还要差。因为这一次我们连奥运会落选赛也都没有资格参加，所以，连续两次错过了巴黎奥运会的话，对于中国篮协，还有对于姚明来说，确实成为了他任职的一个最大的败笔。对于球迷非常关注的一个话题，乔尔杰维奇是否下课，可能对于这个悬念来说也都是暂时有答案了。&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[&#123;<span class="hljs-symbol">&#x27;label</span><span class="hljs-symbol">&#x27;:</span> <span class="hljs-symbol">&#x27;LABEL_0</span>&#x27;, <span class="hljs-symbol">&#x27;score</span><span class="hljs-symbol">&#x27;:</span> <span class="hljs-number">0.9963239431381226</span>&#125;]<br></code></pre></td></tr></table></figure><p>对ONNX模型进行优化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTOptimizer<br><span class="hljs-keyword">from</span> optimum.onnxruntime.configuration <span class="hljs-keyword">import</span> OptimizationConfig<br><br><span class="hljs-comment"># create ORTOptimizer and define optimization configuration</span><br>optimizer = ORTOptimizer.from_pretrained(model)<br>optimization_config = OptimizationConfig(optimization_level=<span class="hljs-number">99</span>) <span class="hljs-comment"># enable all optimizations</span><br><br><span class="hljs-comment"># apply the optimization configuration to the model</span><br>optimizer.optimize(<br>    save_dir=onnx_path,<br>    optimization_config=optimization_config,<br>)<br></code></pre></td></tr></table></figure><p>此时，优化后的模型为model_optimized.onnx。</p><p>对优化后的模型进行推理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br><span class="hljs-comment"># load optimized model</span><br>optimized_model = ORTModelForSequenceClassification.from_pretrained(onnx_path, file_name=<span class="hljs-string">&quot;model_optimized.onnx&quot;</span>)<br><br><span class="hljs-comment"># create optimized pipeline</span><br>optimized_clf = pipeline(<span class="hljs-string">&quot;text-classification&quot;</span>, model=optimized_model, tokenizer=tokenizer)<br>optimized_clf(<span class="hljs-string">&quot;今年7月，教育部等四部门联合印发了《关于在深化非学科类校外培训治理中加强艺考培训规范管理的通知》（以下简称《通知》）。《通知》针对近年来校外艺术培训的状况而发布，并从源头就校外艺术培训机构的“培训主体、从业人员、招生行为、安全底线”等方面进行严格规范。校外艺术培训之所以火热，主要在于高中阶段艺术教育发展迟滞于学生需求。分析教育部数据，2021年艺术学科在校生占比为9.84%，高于2020年的9.73%；2020至2021年艺术学科在校生的年增长率为5.04%，远高于4.28%的总在校生年增长率。增长的数据，是近年来艺考招生连年火热的缩影，在未来一段时间内，艺考或将在全国范围内继续保持高热度。&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[&#123;<span class="hljs-symbol">&#x27;label</span><span class="hljs-symbol">&#x27;:</span> <span class="hljs-symbol">&#x27;LABEL_3</span>&#x27;, <span class="hljs-symbol">&#x27;score</span><span class="hljs-symbol">&#x27;:</span> <span class="hljs-number">0.9926980137825012</span>&#125;]<br></code></pre></td></tr></table></figure><p>对优化后的ONNX模型再进行量化，代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTQuantizer<br><span class="hljs-keyword">from</span> optimum.onnxruntime.configuration <span class="hljs-keyword">import</span> AutoQuantizationConfig<br><br><span class="hljs-comment"># create ORTQuantizer and define quantization configuration</span><br>dynamic_quantizer = ORTQuantizer.from_pretrained(optimized_model)<br>dqconfig = AutoQuantizationConfig.avx2(is_static=<span class="hljs-literal">False</span>, per_channel=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># apply the quantization configuration to the model</span><br>model_quantized_path = dynamic_quantizer.quantize(<br>    save_dir=onnx_path,<br>    quantization_config=dqconfig,<br>)<br></code></pre></td></tr></table></figure><p>此时量化后的模型为model_optimized_quantized.onnx。比较量化前后的模型大小，代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># get model file size</span><br>size = os.path.getsize(os.path.join(onnx_path, <span class="hljs-string">&quot;model_optimized.onnx&quot;</span>))/(<span class="hljs-number">1024</span>*<span class="hljs-number">1024</span>)<br>quantized_model = os.path.getsize(os.path.join(onnx_path, <span class="hljs-string">&quot;model_optimized_quantized.onnx&quot;</span>))/(<span class="hljs-number">1024</span>*<span class="hljs-number">1024</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Model file size: <span class="hljs-subst">&#123;size:<span class="hljs-number">.2</span>f&#125;</span> MB&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Quantized Model file size: <span class="hljs-subst">&#123;quantized_model:<span class="hljs-number">.2</span>f&#125;</span> MB&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Model</span> file size: <span class="hljs-number">390</span>.<span class="hljs-number">17</span> MB<br><span class="hljs-attribute">Quantized</span> Model file size: <span class="hljs-number">97</span>.<span class="hljs-number">98</span> MB<br></code></pre></td></tr></table></figure><p>最后，加载量化后的模型，代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load quantization model</span><br><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTModelForSequenceClassification<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline, AutoTokenizer<br><br>quantized_model = ORTModelForSequenceClassification.from_pretrained(onnx_path, file_name=<span class="hljs-string">&quot;model_optimized_quantized.onnx&quot;</span>).to(device)<br>tokenizer = AutoTokenizer.from_pretrained(onnx_path)<br></code></pre></td></tr></table></figure><h3 id="推理实验">推理实验</h3><p>在进行模型推理实验前，先加载测试数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>test_df = pd.read_csv(<span class="hljs-string">&quot;./data/sougou/test.csv&quot;</span>)<br></code></pre></td></tr></table></figure><p>使用量化前的模型进行推理，记录推理时间，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># original model evaluate</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> time<br><br>cost_time_list = []<br>s_time = time.time()<br>true_labels, pred_labels = [], [] <br><span class="hljs-keyword">for</span> i, row <span class="hljs-keyword">in</span> test_df.iterrows():<br>    row_s_time = time.time()<br>    true_labels.append(row[<span class="hljs-string">&quot;label&quot;</span>])<br>    encoded_text = tokenizer(row[<span class="hljs-string">&#x27;text&#x27;</span>], max_length=<span class="hljs-number">256</span>, truncation=<span class="hljs-literal">True</span>, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>)<br>    <span class="hljs-comment"># print(encoded_text)</span><br>    logits = model(**encoded_text)<br>    label_id = np.argmax(logits[<span class="hljs-number">0</span>].detach().numpy(), axis=<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]<br>    pred_labels.append(label_id)<br>    cost_time_list.append((time.time() - row_s_time) * <span class="hljs-number">1000</span>)<br>    <span class="hljs-keyword">if</span> i % <span class="hljs-number">100</span>:<br>    <span class="hljs-built_in">print</span>(i, (time.time() - row_s_time) * <span class="hljs-number">1000</span>, label_id)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;avg time:&quot;</span>, (time.time() - s_time) * <span class="hljs-number">1000</span> / test_df.shape[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;P50 time:&quot;</span>, np.percentile(np.array(cost_time_list), <span class="hljs-number">50</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;P95 time:&quot;</span>, np.percentile(np.array(cost_time_list), <span class="hljs-number">95</span>))<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">0</span> <span class="hljs-number">710</span>.<span class="hljs-number">2577686309814</span> <span class="hljs-number">0</span><br><span class="hljs-attribute">100</span> <span class="hljs-number">477</span>.<span class="hljs-number">72765159606934</span> <span class="hljs-number">1</span><br><span class="hljs-attribute">200</span> <span class="hljs-number">616</span>.<span class="hljs-number">3530349731445</span> <span class="hljs-number">2</span><br><span class="hljs-attribute">300</span> <span class="hljs-number">509</span>.<span class="hljs-number">63783264160156</span> <span class="hljs-number">3</span><br><span class="hljs-attribute">400</span> <span class="hljs-number">531</span>.<span class="hljs-number">57639503479</span> <span class="hljs-number">4</span><br><br><span class="hljs-attribute">avg</span> time: <span class="hljs-number">501</span>.<span class="hljs-number">0757282526806</span><br><span class="hljs-attribute">P50</span> time: <span class="hljs-number">504</span>.<span class="hljs-number">6522617340088</span><br><span class="hljs-attribute">P95</span> time: <span class="hljs-number">623</span>.<span class="hljs-number">9353895187337</span><br><br></code></pre></td></tr></table></figure><p>对输出结果进行指标评级，代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br><span class="hljs-built_in">print</span>(classification_report(true_labels, pred_labels, digits=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><p>重复上述代码，将模型替换为量化前ONNX模型（model.onnx），优化后ONNX模型（model_oprimized.onnx），量化后ONNX模型（model_optimized_quantized.onnx），进行推理时间（单位：ms）统计和推理指标评估，结果见下表：</p><table><thead><tr class="header"><th>模型</th><th>平均推理时间</th><th>P95推理时间</th><th>weighted F1</th></tr></thead><tbody><tr class="odd"><td>量化前ONNX模型</td><td>501.1</td><td>623.9</td><td>0.9717</td></tr><tr class="even"><td>优化后ONNX模型</td><td>484.6</td><td>629.6</td><td>0.9717</td></tr><tr class="odd"><td>量化后ONNX模型</td><td>361.5</td><td>426.9</td><td>0.9738</td></tr></tbody></table><p>对比文章<ahref="https://percent4.github.io/2023/09/03/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%83%EF%BC%89BERT%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%90%8E%E5%8A%A8%E6%80%81%E9%87%8F%E5%8C%96%EF%BC%88PTDQ%EF%BC%89/">NLP（六十七）BERT模型训练后动态量化（PTDQ）</a>中的推理结果，原始模型的平均推理时间为666.6ms，weightedF1值为0.9717，我们有如下结论：</p><ul><li><p>ONNX模型不影响推理效果，但在平均推理时间上提速约1.33倍</p></li><li><p>优化ONNX模型不影响推理效果，但在平均推理时间上提速约1.38倍</p></li><li><p>量化后的ONNX模型影响推理效果，一般会略有下降，本次实验结果为提升，但在平均推理时间上提速约1.84倍，由于PyTorch的PTDQ（模型训练后动态量化）</p></li><li><h3 id="总结">总结</h3><p>本文介绍了如何使用HuggingFace的<code>Optimum</code>，来对微调后的BERT模型进行量化（Quantization），在<code>optimum.onnxruntime</code>模块中，平均推理时间提速约1.8倍。</p><p>本文已开源至Github，网址为：<ahref="https://github.com/percent4/dynamic_quantization_on_bert">https://github.com/percent4/dynamic_quantization_on_bert</a>。</p><p>本文已开通个人博客，欢迎大家访问：<ahref="https://percent4.github.io/">https://percent4.github.io/</a>。</p><p>欢迎你关注我的微信公众号，每周我都会在这里更新文章。</p></li></ul><figure><img src="/img/weixin_gzh.png" alt="个人微信公众号" /><figcaption aria-hidden="true">个人微信公众号</figcaption></figure><h3 id="参考文献">参考文献</h3><ol type="1"><li>NLP（六十六）使用HuggingFace中的Trainer进行BERT模型微调：<ahref="https://percent4.github.io/2023/09/02/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8HuggingFace%E4%B8%AD%E7%9A%84Trainer%E8%BF%9B%E8%A1%8CBERT%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/">https://percent4.github.io/2023/09/02/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8HuggingFace%E4%B8%AD%E7%9A%84Trainer%E8%BF%9B%E8%A1%8CBERT%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/</a></li><li>NLP（六十七）BERT模型训练后动态量化（PTDQ）：<ahref="https://percent4.github.io/2023/09/03/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%83%EF%BC%89BERT%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%90%8E%E5%8A%A8%E6%80%81%E9%87%8F%E5%8C%96%EF%BC%88PTDQ%EF%BC%89/">https://percent4.github.io/2023/09/03/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%83%EF%BC%89BERT%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%90%8E%E5%8A%A8%E6%80%81%E9%87%8F%E5%8C%96%EF%BC%88PTDQ%EF%BC%89/</a></li><li>Optimum: <ahref="https://huggingface.co/docs/optimum/index">https://huggingface.co/docs/optimum/index</a></li><li>Optimizing Transformers with Hugging Face Optimum: <ahref="https://www.philschmid.de/optimizing-transformers-with-optimum">https://www.philschmid.de/optimizing-transformers-with-optimum</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BERT</tag>
      
      <tag>模型量化</tag>
      
      <tag>Optimum</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（六十七）BERT模型训练后动态量化（PTDQ）</title>
    <link href="/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%83%EF%BC%89BERT%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%90%8E%E5%8A%A8%E6%80%81%E9%87%8F%E5%8C%96%EF%BC%88PTDQ%EF%BC%89/"/>
    <url>/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%83%EF%BC%89BERT%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%90%8E%E5%8A%A8%E6%80%81%E9%87%8F%E5%8C%96%EF%BC%88PTDQ%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会介绍BERT模型训练后动态量化（Post Training DynamicQuantization，PTDQ）。</p><h3 id="量化">量化</h3><p>在深度学习中，量化（Quantization）指的是使用更少的bit来存储原本以浮点数存储的tensor，以及使用更少的bit来完成原本以浮点数完成的计算。这么做的好处主要有如下几点：</p><ul><li><p>更少的模型体积，接近4倍的减少</p></li><li><p>可以更快地计算，由于更少的内存访问和更快的int8计算，可以快2~4倍</p><p>PyTorch中的模型参数默认以FP32精度储存。对于量化后的模型，其部分或者全部的tensor操作会使用int类型来计算，而不是使用量化之前的float类型。当然，量化还需要底层硬件支持，x86CPU(支持AVX2)、ARM CPU、Google TPU、Nvidia Volta/Turing/Ampere、QualcommDSP这些主流硬件都对量化提供了支持。</p></li></ul><figure><img src="/img/nlp67_1.png" alt="模型量化示例图片" /><figcaption aria-hidden="true">模型量化示例图片</figcaption></figure><h3 id="ptdq">PTDQ</h3><p>PyTorch对量化的支持目前有如下三种方式：</p><ul><li>Post Training Dynamic Quantization：模型训练完毕后的动态量化</li><li>Post Training Static Quantization：模型训练完毕后的静态量化</li><li>QAT (Quantization Aware Training)：模型训练中开启量化</li></ul><p><code>本文仅介绍Post Training Dynamic Quantization（PTDQ）</code>。</p><p>对训练后的模型权重执行动态量化，将浮点模型转换为动态量化模型，<code>仅对模型权重进行量化，偏置不会量化</code>。默认情况下，仅对Linear和RNN变体量化(因为这些layer的参数量很大，收益更高)。 　　 &gt;torch.quantization.quantize_dynamic(model, qconfig_spec=None,dtype=torch.qint8, mapping=None, inplace=False)</p><p>参数解释：</p><ul><li>model：模型（默认为FP32）</li><li>qconfig_spec：</li></ul><ol type="1"><li>集合：比如： qconfig_spec={nn.LSTM, nn.Linear}。列出要量化的神经网络模块。</li><li>字典： qconfig_spec = {nn.Linear: default_dynamic_qconfig, nn.LSTM:default_dynamic_qconfig}</li></ol><ul><li>dtype： float16 或 qint8</li><li>mapping：就地执行模型转换，原始模块发生变异</li><li>inplace：将子模块的类型映射到需要替换子模块的相应动态量化版本的类型</li></ul><p>例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># 动态量化模型，只量化权重</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DemoModel</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(DemoModel, self).__init__()<br>        self.conv = nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">1</span>, kernel_size=<span class="hljs-number">1</span>)<br>        self.relu = nn.ReLU()<br>        self.fc = torch.nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.conv(x)<br>        x = self.relu(x)<br>        x = self.fc(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    model_fp32 = DemoModel()<br>    <span class="hljs-comment"># 创建一个量化的模型实例</span><br>    model_int8 = torch.quantization.quantize_dynamic(model=model_fp32,  <span class="hljs-comment"># 原始模型</span><br>                                                     qconfig_spec=&#123;torch.nn.Linear&#125;,  <span class="hljs-comment"># 要动态量化的算子</span><br>                                                     dtype=torch.qint8)  <span class="hljs-comment"># 将权重量化为：qint8</span><br><br>    <span class="hljs-built_in">print</span>(model_fp32)<br>    <span class="hljs-built_in">print</span>(model_int8)<br><br>    <span class="hljs-comment"># 运行模型</span><br>    input_fp32 = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>    output_fp32 = model_fp32(input_fp32)<br>    <span class="hljs-built_in">print</span>(output_fp32)<br><br>    output_int8 = model_int8(input_fp32)<br>    <span class="hljs-built_in">print</span>(output_int8)<br><br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">DemoModel(<br>  (conv): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))<br>  (relu): ReLU()<br>  (<span class="hljs-built_in">fc</span>): Linear(in_features=2, out_features=2, bias=True)<br>)<br>DemoModel(<br>  (conv): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))<br>  (relu): ReLU()<br>  (<span class="hljs-built_in">fc</span>): DynamicQuantizedLinear(in_features=2, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)<br>)<br>tensor([[[[0.3120, 0.3042],<br>          [0.3120, 0.3042]]]], grad_fn=&lt;AddBackward0&gt;)<br>tensor([[[[0.3120, 0.3042],<br>          [0.3120, 0.3042]]]])<br></code></pre></td></tr></table></figure><h3 id="模型量化策略">模型量化策略</h3><p>当前，由于量化算子的覆盖有限，因此，对于不同的深度学习模型，其量化策略不同，见下表：</p><table><thead><tr class="header"><th>模型</th><th>量化策略</th><th>原因</th></tr></thead><tbody><tr class="odd"><td>LSTM/RNN</td><td>Dynamic Quantization</td><td>模型吞吐量由权重的计算/内存带宽决定</td></tr><tr class="even"><td>BERT/Transformer</td><td>Dynamic Quantization</td><td>模型吞吐量由权重的计算/内存带宽决定</td></tr><tr class="odd"><td>CNN</td><td>Static Quantization</td><td>模型吞吐量由激活函数的内存带宽决定</td></tr><tr class="even"><td>CNN</td><td>Quantization Aware Training</td><td>模型准确率不能由Static Quantization获取的情况</td></tr></tbody></table><p>下面对BERT模型进行训练后动态量化，分析模型在量化前后，推理效果和推理性能的变化。</p><h3 id="实验">实验</h3><p>我们使用的训练后的模型为中文文本分类模型，其训练过程可以参考文章：<ahref="https://blog.csdn.net/jclian91/article/details/132642662">NLP（六十六）使用HuggingFace中的Trainer进行BERT模型微调</a>。</p><p>训练后的BERT模型动态量化实验的设置如下：</p><ol type="1"><li><p>base model: <ahref="https://huggingface.co/bert-base-chinese">bert-base-chinese</a></p></li><li><p>CPU info: x86-64, Intel(R) Core(TM) i5-10210U CPU @1.60GHz</p></li><li><p>batch size: 1</p></li><li><p>thread: 1</p><p><strong>具体的实验过程如下</strong>：</p></li></ol><ul><li>加载模型及tokenizer</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification<br><br>MAX_LENGTH = <span class="hljs-number">128</span><br>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>checkpoint = <span class="hljs-string">f&quot;./sougou_test_trainer_<span class="hljs-subst">&#123;MAX_LENGTH&#125;</span>/checkpoint-96&quot;</span><br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint).to(device)<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding<br><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br></code></pre></td></tr></table></figure><ul><li>测试数据集</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>test_df = pd.read_csv(<span class="hljs-string">&quot;./data/sougou/test.csv&quot;</span>)<br><br>test_df.head()<br></code></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th></th><th>text</th><th>label</th></tr></thead><tbody><tr><th>0</th><td>届数比赛时间比赛地点参加国家和地区冠军亚军决赛成绩第一届1956-1957英国11美国丹麦6...</td><td>0</td></tr><tr><th>1</th><td>商品属性材质软橡胶带加浮雕工艺+合金彩色队徽吊牌规格162mm数量这一系列产品不限量发行图案...</td><td>0</td></tr><tr><th>2</th><td>今天下午，沈阳金德和长春亚泰队将在五里河相遇。在这两支球队中沈阳籍球员居多，因此这场比赛实际...</td><td>0</td></tr><tr><th>3</th><td>本报讯中国足协准备好了与特鲁西埃谈判的合同文本，也在北京给他预订好了房间，但特鲁西埃爽约了！...</td><td>0</td></tr><tr><th>4</th><td>网友点击发表评论祝贺中国队夺得五连冠搜狐体育讯北京时间5月6日，2006年尤伯杯羽毛球赛在日...</td><td>0</td></tr></tbody></table></div><ul><li>量化前模型的推理时间及评估指标</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> time<br><br>s_time = time.time()<br>true_labels, pred_labels = [], [] <br><span class="hljs-keyword">for</span> i, row <span class="hljs-keyword">in</span> test_df.iterrows():<br>    row_s_time = time.time()<br>    true_labels.append(row[<span class="hljs-string">&quot;label&quot;</span>])<br>    encoded_text = tokenizer(row[<span class="hljs-string">&#x27;text&#x27;</span>], max_length=MAX_LENGTH, truncation=<span class="hljs-literal">True</span>, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).to(device)<br>    <span class="hljs-comment"># print(encoded_text)</span><br>    logits = model(**encoded_text)<br>    label_id = np.argmax(logits[<span class="hljs-number">0</span>].detach().cpu().numpy(), axis=<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]<br>    pred_labels.append(label_id)<br>    <span class="hljs-built_in">print</span>(i, (time.time() - row_s_time)*<span class="hljs-number">1000</span>, label_id)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;avg time: &quot;</span>, (time.time() - s_time) * <span class="hljs-number">1000</span> / test_df.shape[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><pre><code class="hljs">0 229.3872833251953 0100 362.0314598083496 1200 311.16747856140137 2300 324.13792610168457 3400 406.9099426269531 4avg time:  352.44047810332944</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br><span class="hljs-built_in">print</span>(classification_report(true_labels, pred_labels, digits=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><pre><code class="hljs">              precision    recall  f1-score   support           0     0.9900    1.0000    0.9950        99           1     0.9691    0.9495    0.9592        99           2     0.9900    1.0000    0.9950        99           3     0.9320    0.9697    0.9505        99           4     0.9895    0.9495    0.9691        99    accuracy                         0.9737       495   macro avg     0.9741    0.9737    0.9737       495weighted avg     0.9741    0.9737    0.9737       495</code></pre><ul><li>设置量化后端</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型量化</span><br>cpu_device = torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.backends.quantized.supported_engines<br></code></pre></td></tr></table></figure><pre><code class="hljs">[&#39;none&#39;, &#39;onednn&#39;, &#39;x86&#39;, &#39;fbgemm&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.backends.quantized.engine = <span class="hljs-string">&#x27;x86&#x27;</span><br></code></pre></td></tr></table></figure><ul><li>量化后模型的推理时间及评估指标</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 8-bit 量化</span><br>quantized_model = torch.quantization.quantize_dynamic(<br>    model, &#123;torch.nn.Linear&#125;, dtype=torch.qint8<br>).to(cpu_device)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">q_s_time = time.time()<br>q_true_labels, q_pred_labels = [], [] <br><br><span class="hljs-keyword">for</span> i, row <span class="hljs-keyword">in</span> test_df.iterrows():<br>    row_s_time = time.time()<br>    q_true_labels.append(row[<span class="hljs-string">&quot;label&quot;</span>])<br>    encoded_text = tokenizer(row[<span class="hljs-string">&#x27;text&#x27;</span>], max_length=MAX_LENGTH, truncation=<span class="hljs-literal">True</span>, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).to(cpu_device)<br>    logits = quantized_model(**encoded_text)<br>    label_id = np.argmax(logits[<span class="hljs-number">0</span>].detach().numpy(), axis=<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]<br>    q_pred_labels.append(label_id)<br>    <span class="hljs-built_in">print</span>(i, (time.time() - row_s_time) * <span class="hljs-number">1000</span>, label_id)<br>    <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;avg time: &quot;</span>, (time.time() - q_s_time) * <span class="hljs-number">1000</span> / test_df.shape[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><pre><code class="hljs">0 195.47462463378906 0100 247.33805656433105 1200 219.41304206848145 2300 206.44831657409668 3400 187.4992847442627 4avg time:  217.63229466447928</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br><span class="hljs-built_in">print</span>(classification_report(q_true_labels, q_pred_labels, digits=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><pre><code class="hljs">              precision    recall  f1-score   support           0     0.9900    1.0000    0.9950        99           1     0.9688    0.9394    0.9538        99           2     0.9900    1.0000    0.9950        99           3     0.9320    0.9697    0.9505        99           4     0.9896    0.9596    0.9744        99    accuracy                         0.9737       495   macro avg     0.9741    0.9737    0.9737       495weighted avg     0.9741    0.9737    0.9737       495</code></pre><ul><li>量化前后模型大小对比</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_size_of_model</span>(<span class="hljs-params">model</span>):<br>    torch.save(model.state_dict(), <span class="hljs-string">&quot;temp.p&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Size (MB): &quot;</span>, os.path.getsize(<span class="hljs-string">&quot;temp.p&quot;</span>)/<span class="hljs-number">1e6</span>)<br>    os.remove(<span class="hljs-string">&quot;temp.p&quot;</span>)<br><br>print_size_of_model(model)<br>print_size_of_model(quantized_model)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Size (MB):  409.155273Size (MB):  152.627621</code></pre><p>量化后端（Quantizationbackend）取决于CPU架构，不同计算机的CPU架构不同，因此，默认的动态量化不一定在所有的CPU上都能生效，需根据自己计算机的CPU架构设置好对应的量化后端。另外，不同的量化后端也有些许差异。Linux服务器使用<code>uname -a</code>可查看CPU信息。</p><p>重复上述实验过程，以模型的最大输入长度为变量，取值为128,256,384，每种情况各做3次实验，结果如下：</p><table><thead><tr class="header"><th>实验</th><th>最大长度</th><th>量化前平均推理时间(ms)</th><th>量化前weighted F1值</th><th>量化前平均推理时间(ms)</th><th>量化前weighted F1值</th></tr></thead><tbody><tr class="odd"><td>实验1</td><td>384</td><td>1066</td><td>0.9797</td><td>686</td><td>0.9838</td></tr><tr class="even"><td>实验2</td><td>384</td><td>1047.6</td><td>0.9899</td><td>738.1</td><td>0.9879</td></tr><tr class="odd"><td>实验3</td><td>384</td><td>1020.9</td><td>0.9817</td><td>714.0</td><td>0.9838</td></tr><tr class="even"><td>实验1</td><td>256</td><td>668.7</td><td>0.9717</td><td>431.4</td><td>0.9718</td></tr><tr class="odd"><td>实验2</td><td>256</td><td>675.1</td><td>0.9717</td><td>449.9</td><td>0.9718</td></tr><tr class="even"><td>实验3</td><td>256</td><td>656.0</td><td>0.9717</td><td>446.5</td><td>0.9718</td></tr><tr class="odd"><td>实验1</td><td>128</td><td>335.8</td><td>0.9737</td><td>200.5</td><td>0.9737</td></tr><tr class="even"><td>实验2</td><td>128</td><td>336.5</td><td>0.9737</td><td>227.2</td><td>0.9737</td></tr><tr class="odd"><td>实验3</td><td>128</td><td>352.4</td><td>0.9737</td><td>217.6</td><td>0.9737</td></tr></tbody></table><p>综上所述，对于训练后的BERT模型（文本分类模型）进行动态量化，其结论如下：</p><ul><li>模型推理效果：量化前后基本相同，量化后略有下降</li><li>模型推理时间：量化后平均提速约1.52倍</li></ul><h3 id="总结">总结</h3><p>本文介绍了量化基本概念，PyTorch模型量化方式，以及对BERT模型训练后进行动态量化后在推理效果和推理性能上的实验。</p><p>本文项目已开源至Github项目：<ahref="https://github.com/percent4/dynamic_quantization_on_bert">https://github.com/percent4/dynamic_quantization_on_bert</a>。</p><p>本人已开通个人博客网站，网址为：<ahref="https://percent4.github.io/">https://percent4.github.io/</a>，欢迎大家访问~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模型量化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（六十六）使用HuggingFace中的Trainer进行BERT模型微调</title>
    <link href="/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8HuggingFace%E4%B8%AD%E7%9A%84Trainer%E8%BF%9B%E8%A1%8CBERT%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/"/>
    <url>/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8HuggingFace%E4%B8%AD%E7%9A%84Trainer%E8%BF%9B%E8%A1%8CBERT%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>以往，我们在使用HuggingFace在训练BERT模型时，代码写得比较复杂，涉及到数据处理、token编码、模型编码、模型训练等步骤，从事NLP领域的人都有这种切身感受。事实上，HugggingFace中提供了<code>datasets</code>模块（数据处理）和Trainer函数，使得我们的模型训练较为方便。关于<code>datasets</code>模块，可参考文章<ahref="https://percent4.github.io/2023/07/24/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%BA%8C%EF%BC%89HuggingFace%E4%B8%AD%E7%9A%84Datasets%E4%BD%BF%E7%94%A8/">NLP（六十二）HuggingFace中的Datasets使用</a>。</p><p>本文将会介绍如何使用HuggingFace中的Trainer对BERT模型微调。</p><h3 id="trainer">Trainer</h3><p>Trainer是HuggingFace中的模型训练函数，其网址为：<ahref="https://huggingface.co/docs/transformers/main_classes/trainer">https://huggingface.co/docs/transformers/main_classes/trainer</a>。</p><p>Trainer的传入参数如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">model: typing.<span class="hljs-type">Union</span>[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = <span class="hljs-literal">None</span><br>args: TrainingArguments = <span class="hljs-literal">None</span><br>data_collator: typing.<span class="hljs-type">Optional</span>[DataCollator] = <span class="hljs-literal">None</span><br>train_dataset: typing.<span class="hljs-type">Optional</span>[torch.utils.data.dataset.Dataset] = <span class="hljs-literal">None</span><br>eval_dataset: typing.<span class="hljs-type">Union</span>[torch.utils.data.dataset.Dataset, typing.<span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, torch.utils.data.dataset.Dataset], NoneType] = <span class="hljs-literal">None</span><br>tokenizer: typing.<span class="hljs-type">Optional</span>[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = <span class="hljs-literal">None</span><br>model_init: typing.<span class="hljs-type">Union</span>[typing.<span class="hljs-type">Callable</span>[[], transformers.modeling_utils.PreTrainedModel], NoneType] = <span class="hljs-literal">None</span><br>compute_metrics: typing.<span class="hljs-type">Union</span>[typing.<span class="hljs-type">Callable</span>[[transformers.trainer_utils.EvalPrediction], typing.<span class="hljs-type">Dict</span>], NoneType] = <span class="hljs-literal">None</span><br>callbacks: typing.<span class="hljs-type">Optional</span>[typing.<span class="hljs-type">List</span>[transformers.trainer_callback.TrainerCallback]] = <span class="hljs-literal">None</span><br>optimizers: typing.<span class="hljs-type">Tuple</span>[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (<span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>)<br>preprocess_logits_for_metrics: typing.<span class="hljs-type">Union</span>[typing.<span class="hljs-type">Callable</span>[[torch.Tensor, torch.Tensor], torch.Tensor], NoneType] = <span class="hljs-literal">None</span> )<br></code></pre></td></tr></table></figure><p>参数解释：</p><ul><li><p><code>model</code>为预训练模型</p></li><li><p><code>args</code>为TrainingArguments（训练参数）类</p></li><li><p><code>data_collator</code>会将数据集中的元素组成一个batch，默认使用default_data_collator()，如果tokenizer没有提供，则使用<code>DataCollatorWithPadding</code></p></li><li><p><code>train_dataset</code>,<code>eval_dataset</code>为训练集，验证集</p></li><li><p><code>tokenizer</code>为模型训练使用的tokenizer</p></li><li><p><code>model_init</code>为模型初始化</p></li><li><p><code>compute_metrics</code>为验证集的评估指标计算函数</p></li><li><p><code>callbacks</code>为训练过程中的callback列表</p></li><li><p><code>optimizers</code>为模型训练中的优化器</p></li><li><p><code>preprocess_logits_for_metrics</code>为模型评估阶段前对logits的预处理</p><p>TrainingArguments为训练参数类，其网址为：<ahref="https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments">https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments</a>，传入参数非常多（transformers版本4.32.1中有98个参数！），我们在这里只介绍几个常见的：</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">output_dir: stroverwrite_output_dir: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span><br>evaluation_strategy: typing.<span class="hljs-type">Union</span>[transformers.trainer_utils.IntervalStrategy, <span class="hljs-built_in">str</span>] = <span class="hljs-string">&#x27;no&#x27;</span><br>per_gpu_train_batch_size: typing.<span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span><br>per_gpu_eval_batch_size: typing.<span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span><br>learning_rate: <span class="hljs-built_in">float</span> = <span class="hljs-number">5e-05</span><br>num_train_epochs: <span class="hljs-built_in">float</span> = <span class="hljs-number">3.0</span><br>logging_dir: typing.<span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span><br>logging_strategy: typing.<span class="hljs-type">Union</span>[transformers.trainer_utils.IntervalStrategy, <span class="hljs-built_in">str</span>] = <span class="hljs-string">&#x27;steps&#x27;</span><br>save_strategy: typing.<span class="hljs-type">Union</span>[transformers.trainer_utils.IntervalStrategy, <span class="hljs-built_in">str</span>] = <span class="hljs-string">&#x27;steps&#x27;</span>save_steps: <span class="hljs-built_in">float</span> = <span class="hljs-number">500</span><br>report_to: typing.<span class="hljs-type">Optional</span>[typing.<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><p>参数解释：</p><ul><li><code>output_dir</code>为模型输出目录</li><li><code>evaluation_strategy</code>为模型评估策略</li></ul><ol type="1"><li>“no": 不做模型评估</li><li>"steps": 按训练步数（steps）进行评估，需指定步数</li><li>"epoch": 每个epoch训练完后进行评估</li></ol><ul><li><p><code>per_gpu_train_batch_size</code>,<code>per_gpu_eval_batch_size</code>为每个GPU上训练集和测试集的batchsize，也有CPU上的对应参数</p></li><li><p><code>learning_rate</code>为学习率</p></li><li><p><code>logging_dir</code>为日志输出目录</p></li><li><p><code>logging_strategy</code>为日志输出策略，同样有no, steps,epoch三种，意义同上</p></li><li><p><code>save_strategy</code>为模型保存策略，同样有no, steps,epoch三种，意义同上</p></li><li><p><code>report_to</code>为模型训练、评估中的重要指标（如loss,accurace）输出之处，可选择azure_ml, clearml, codecarbon, comet_ml,dagshub, flyte, mlflow, neptune, tensorboard,wandb，使用all会输出到所有的地方，使用no则不会输出。</p><p>下面我们使用Trainer进行BERT模型微调，给出英语、中文数据集上文本分类的示例代码。</p></li><li><h3 id="bert微调">BERT微调</h3><p>使用<code>datasets</code>模块导入imdb数据集（英语影评数据集，常用于文本分类），加载预训练模型<code>bert-base-cased</code>的tokenizer。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding<br><span class="hljs-keyword">import</span> datasets<br><br>checkpoint = <span class="hljs-string">&#x27;bert-base-cased&#x27;</span><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br>raw_datasets = datasets.load_dataset(<span class="hljs-string">&#x27;imdb&#x27;</span>)<br></code></pre></td></tr></table></figure><p>查看数据集，有train（训练集）、test（测试集）、unsupervised（非监督）三部分，我们这里使用训练集和测试集，各自有25000个样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">raw_datasets<br></code></pre></td></tr></table></figure><pre><code class="hljs">DatasetDict(&#123;    train: Dataset(&#123;        features: [&#39;text&#39;, &#39;label&#39;],        num_rows: 25000    &#125;)    test: Dataset(&#123;        features: [&#39;text&#39;, &#39;label&#39;],        num_rows: 25000    &#125;)    unsupervised: Dataset(&#123;        features: [&#39;text&#39;, &#39;label&#39;],        num_rows: 50000    &#125;)&#125;)</code></pre><p>创建数据tokenize函数，对文本进行tokenize，最大长度设置为300，同时使用data_collector为DataCollatorWithPadding。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">sample</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(sample[<span class="hljs-string">&#x27;text&#x27;</span>], max_length=<span class="hljs-number">300</span>, truncation=<span class="hljs-literal">True</span>)<br>tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)<br><br>data_collator = DataCollatorWithPadding(tokenizer=tokenizer)<br></code></pre></td></tr></table></figure><p>加载分类模型，输出类别为2.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification<br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>设置compute_metrics函数，在评估过程中输出accuracy, f1, precision,recall四个指标。设置训练参数TrainingArguments类，设置Trainer。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer, TrainingArguments<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score, precision_recall_fscore_support<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">pred</span>):<br>    labels = pred.label_ids<br>    preds = pred.predictions.argmax(-<span class="hljs-number">1</span>)<br>    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=<span class="hljs-string">&#x27;weighted&#x27;</span>)<br>    acc = accuracy_score(labels, preds)<br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&#x27;accuracy&#x27;</span>: acc,<br>        <span class="hljs-string">&#x27;f1&#x27;</span>: f1,<br>        <span class="hljs-string">&#x27;precision&#x27;</span>: precision,<br>        <span class="hljs-string">&#x27;recall&#x27;</span>: recall<br>    &#125;<br><br>training_args = TrainingArguments(output_dir=<span class="hljs-string">&#x27;imdb_test_trainer&#x27;</span>, <span class="hljs-comment"># 指定输出文件夹，没有会自动创建</span><br>                                 evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>                                 per_device_train_batch_size=<span class="hljs-number">32</span>,<br>                                 per_device_eval_batch_size=<span class="hljs-number">32</span>,<br>                                 learning_rate=<span class="hljs-number">5e-5</span>,<br>                                 num_train_epochs=<span class="hljs-number">3</span>,<br>                                 warmup_ratio=<span class="hljs-number">0.2</span>,<br>                                 logging_dir=<span class="hljs-string">&#x27;./imdb_train_logs&#x27;</span>,<br>                                 logging_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>                                 save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>                                 report_to=<span class="hljs-string">&quot;tensorboard&quot;</span>) <br><br>trainer = Trainer(<br>    model,<br>    training_args,<br>    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>],<br>    data_collator=data_collator,  <span class="hljs-comment"># 在定义了tokenizer之后，其实这里的data_collator就不用再写了，会自动根据tokenizer创建</span><br>    tokenizer=tokenizer,<br>    compute_metrics=compute_metrics<br>)<br></code></pre></td></tr></table></figure></p><p>开启模型训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">trainer.train()<br></code></pre></td></tr></table></figure><table border="1" class="dataframe"><thead><tr style="text-align: left;"><th>Epoch</th><th>Training Loss</th><th>Validation Loss</th><th>Accuracy</th><th>F1</th><th>Precision</th><th>Recall</th></tr></thead><tbody><tr><td>1</td><td>0.364300</td><td>0.223223</td><td>0.910600</td><td>0.910509</td><td>0.912276</td><td>0.910600</td></tr><tr><td>2</td><td>0.164800</td><td>0.204420</td><td>0.923960</td><td>0.923941</td><td>0.924375</td><td>0.923960</td></tr><tr><td>3</td><td>0.071000</td><td>0.241350</td><td>0.925520</td><td>0.925510</td><td>0.925759</td><td>0.925520</td></tr></tbody></table><p>以上为英语数据集的文本分类模型微调。</p><p>中文数据集使用sougou-mini数据集（训练集4000个样本，测试集495个样本，共5个输出类别），预训练模型采用bert-base-chinese。代码基本与英语数据集差不多，只要修改预训练模型，数据集加载 和最大长度为128，输出类别。以下是不同的代码之处：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding<br><span class="hljs-keyword">import</span> datasets<br><br>checkpoint = <span class="hljs-string">&#x27;bert-base-chinese&#x27;</span><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br><br>data_files = &#123;<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;./data/sougou/train.csv&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;./data/sougou/test.csv&quot;</span>&#125;<br>raw_datasets = datasets.load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="hljs-string">&quot;,&quot;</span>)<br>...<br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">5</span>)<br>...<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><table border="1" class="dataframe"><thead><tr><th>Epoch</th><th>Training Loss</th><th>Validation Loss</th><th>Accuracy</th><th>F1</th><th>Precision</th><th>Recall</th></tr></thead><tbody><tr><td>1</td><td>0.849200</td><td>0.115189</td><td>0.969697</td><td>0.969449</td><td>0.970073</td><td>0.969697</td></tr><tr><td>2</td><td>0.106900</td><td>0.093987</td><td>0.973737</td><td>0.973770</td><td>0.975372</td><td>0.973737</td></tr><tr><td>3</td><td>0.047800</td><td>0.078861</td><td>0.973737</td><td>0.973740</td><td>0.974117</td><td>0.973737</td></tr></tbody></table><h3 id="模型评估">模型评估</h3><p>在上述模型评估过程中，已经有了模型评估的各项指标。</p><p>本文也给出单独做模型评估的代码，方便后续对模型做量化时（后续介绍BERT模型的动态量化）获取量化前后模型推理的各项指标。</p><p>中文数据集文本分类模型评估代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification<br><br>MAX_LENGTH = <span class="hljs-number">128</span><br>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>checkpoint = <span class="hljs-string">f&quot;./sougou_test_trainer_<span class="hljs-subst">&#123;MAX_LENGTH&#125;</span>/checkpoint-96&quot;</span><br>model = AutoModelForSequenceClassification.from_pretrained(checkpoint).to(device)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding<br><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>test_df = pd.read_csv(<span class="hljs-string">&quot;./data/sougou/test.csv&quot;</span>)<br>test_df.head()<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th></th><th>text</th><th>label</th></tr></thead><tbody><tr><th>0</th><td>届数比赛时间比赛地点参加国家和地区冠军亚军决赛成绩第一届1956-1957英国11美国丹麦6...</td><td>0</td></tr><tr><th>1</th><td>商品属性材质软橡胶带加浮雕工艺+合金彩色队徽吊牌规格162mm数量这一系列产品不限量发行图案...</td><td>0</td></tr><tr><th>2</th><td>今天下午，沈阳金德和长春亚泰队将在五里河相遇。在这两支球队中沈阳籍球员居多，因此这场比赛实际...</td><td>0</td></tr><tr><th>3</th><td>本报讯中国足协准备好了与特鲁西埃谈判的合同文本，也在北京给他预订好了房间，但特鲁西埃爽约了！...</td><td>0</td></tr><tr><th>4</th><td>网友点击发表评论祝贺中国队夺得五连冠搜狐体育讯北京时间5月6日，2006年尤伯杯羽毛球赛在日...</td><td>0</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> time<br><br>s_time = time.time()<br>true_labels, pred_labels = [], [] <br><span class="hljs-keyword">for</span> i, row <span class="hljs-keyword">in</span> test_df.iterrows():<br>    row_s_time = time.time()<br>    true_labels.append(row[<span class="hljs-string">&quot;label&quot;</span>])<br>    encoded_text = tokenizer(row[<span class="hljs-string">&#x27;text&#x27;</span>], max_length=MAX_LENGTH, truncation=<span class="hljs-literal">True</span>, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).to(device)<br>    <span class="hljs-comment"># print(encoded_text)</span><br>    logits = model(**encoded_text)<br>    label_id = np.argmax(logits[<span class="hljs-number">0</span>].detach().cpu().numpy(), axis=<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]<br>    pred_labels.append(label_id)<br>    <span class="hljs-keyword">if</span> i % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>    <span class="hljs-built_in">print</span>(i, (time.time() - row_s_time)*<span class="hljs-number">1000</span>, label_id)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;avg time: &quot;</span>, (time.time() - s_time) * <span class="hljs-number">1000</span> / test_df.shape[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><blockquote><p>0 229.3872833251953 0 100 362.0314598083496 1 200 311.167478561401372 300 324.13792610168457 3 400 406.9099426269531 4 avg time:352.44047810332944</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">true_labels[:<span class="hljs-number">10</span>]<br></code></pre></td></tr></table></figure><blockquote><p>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pred_labels[:<span class="hljs-number">10</span>]<br></code></pre></td></tr></table></figure><blockquote><p>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br><span class="hljs-built_in">print</span>(classification_report(true_labels, pred_labels, digits=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs apache">              <span class="hljs-attribute">precision</span>    recall  f1-score   support<br><br>           <span class="hljs-attribute">0</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9900</span>    <span class="hljs-number">1</span>.<span class="hljs-number">0000</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9950</span>        <span class="hljs-number">99</span><br>           <span class="hljs-attribute">1</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9691</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9495</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9592</span>        <span class="hljs-number">99</span><br>           <span class="hljs-attribute">2</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9900</span>    <span class="hljs-number">1</span>.<span class="hljs-number">0000</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9950</span>        <span class="hljs-number">99</span><br>           <span class="hljs-attribute">3</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9320</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9697</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9505</span>        <span class="hljs-number">99</span><br>           <span class="hljs-attribute">4</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9895</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9495</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9691</span>        <span class="hljs-number">99</span><br><br>    <span class="hljs-attribute">accuracy</span>                         <span class="hljs-number">0</span>.<span class="hljs-number">9737</span>       <span class="hljs-number">495</span><br>   <span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9741</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9737</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9737</span>       <span class="hljs-number">495</span><br><span class="hljs-attribute">weighted</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9741</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9737</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9737</span>       <span class="hljs-number">495</span><br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本文介绍了如何使用HuggingFace中的Trainer对BERT模型微调。可以看到，使用Trainer进行模型微调，代码较为简洁，且支持功能丰富，是理想的模型训练方式。</p><p>本文项目代码已开源至Github，网址为：<ahref="https://github.com/percent4/PyTorch_Learning/tree/master/huggingface_learning">https://github.com/percent4/PyTorch_Learning/tree/master/huggingface_learning</a>。</p><p>本人已开通个人博客网站，网址为：<ahref="https://percent4.github.io/">https://percent4.github.io/</a>，欢迎大家访问~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BERT</tag>
      
      <tag>文本分类</tag>
      
      <tag>HuggingFace</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Gradio入门（1）输入输出、表格、文本高亮</title>
    <link href="/Gradio%E5%85%A5%E9%97%A8%EF%BC%881%EF%BC%89%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E3%80%81%E8%A1%A8%E6%A0%BC%E3%80%81%E6%96%87%E6%9C%AC%E9%AB%98%E4%BA%AE/"/>
    <url>/Gradio%E5%85%A5%E9%97%A8%EF%BC%881%EF%BC%89%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E3%80%81%E8%A1%A8%E6%A0%BC%E3%80%81%E6%96%87%E6%9C%AC%E9%AB%98%E4%BA%AE/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会介绍gradio的入门使用，并结合大模型（LLM），给出三个使用例子。</p><p><code>Gradio</code> 是通过友好的 Web界面演示机器学习模型的最快方式，以便任何人都可以在任何地方使用它。其官网网址为：<ahref="https://www.gradio.app/">https://www.gradio.app/</a>，Github网址为：<ahref="https://github.com/gradio-app/gradio">https://github.com/gradio-app/gradio</a>。</p><h3 id="输入与输出">输入与输出</h3><p>一个简单的Web页面的输入、输出代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet</span>(<span class="hljs-params">name</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello &quot;</span> + name + <span class="hljs-string">&quot;!&quot;</span><br><br><br>demo = gr.Interface(<br>    fn=greet,<br>    <span class="hljs-comment"># 自定义输入框</span><br>    inputs=gr.Textbox(lines=<span class="hljs-number">3</span>, placeholder=<span class="hljs-string">&quot;Name Here...&quot;</span>, label=<span class="hljs-string">&quot;my input&quot;</span>),<br>    outputs=<span class="hljs-string">&quot;text&quot;</span>,<br>)<br><br>demo.launch()<br></code></pre></td></tr></table></figure><p>页面如下：</p><figure><img src="/img/gradio1_1.png" alt="简单的输入、输出" /><figcaption aria-hidden="true">简单的输入、输出</figcaption></figure><p>我们使用<code>openai</code>的<code>gpt-3.5-turbo</code>模型进行问答，结合Gradio，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">import</span> openai<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model_completion</span>(<span class="hljs-params">prompt</span>):<br>    openai.api_type = <span class="hljs-string">&quot;open_ai&quot;</span><br>    openai.api_base = <span class="hljs-string">&quot;https://api.openai.com/v1&quot;</span><br>    openai.api_version = <span class="hljs-literal">None</span><br>    openai.api_key = <span class="hljs-string">&quot;sk-xxx&quot;</span><br><br>    response = openai.ChatCompletion.create(<br>        model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>        messages=[<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>&#125;,<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: prompt&#125;<br>        ],<br>        max_tokens=<span class="hljs-number">100</span><br>    )<br><br>    <span class="hljs-keyword">return</span> response[<span class="hljs-string">&#x27;choices&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;message&#x27;</span>][<span class="hljs-string">&#x27;content&#x27;</span>]<br><br><br>demo = gr.Interface(<br>    fn=model_completion,<br>    inputs=gr.Textbox(lines=<span class="hljs-number">3</span>, placeholder=<span class="hljs-string">&quot;your question here...&quot;</span>, label=<span class="hljs-string">&quot;Question&quot;</span>),<br>    outputs=<span class="hljs-string">&quot;text&quot;</span>,<br>)<br><br>demo.launch()<br></code></pre></td></tr></table></figure><p>页面如下：</p><figure><img src="/img/gradio1_2.png" alt="大模型问答页面" /><figcaption aria-hidden="true">大模型问答页面</figcaption></figure><h3 id="表格展示">表格展示</h3><p>一个简单的表格展示的示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_list</span>(<span class="hljs-params">input_str</span>):<br>    <span class="hljs-keyword">return</span> [_.split(<span class="hljs-string">&#x27;,&#x27;</span>) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> input_str.split(<span class="hljs-string">&#x27;\n&#x27;</span>)]<br><br><br>demo = gr.Interface(<br>    fn=make_list,<br>    <span class="hljs-comment"># 自定义输入框</span><br>    inputs=gr.Textbox(lines=<span class="hljs-number">3</span>, placeholder=<span class="hljs-string">&quot;String Here...&quot;</span>, label=<span class="hljs-string">&quot;input&quot;</span>),<br>    <span class="hljs-comment"># 设置输出组件</span><br>    outputs=gr.DataFrame(label=<span class="hljs-string">&#x27;Table&#x27;</span>,<br>                         interactive=<span class="hljs-literal">True</span>,<br>                         wrap=<span class="hljs-literal">True</span>)<br>)<br><br>demo.launch()<br></code></pre></td></tr></table></figure><p>页面如下：</p><figure><img src="/img/gradio1_3.png" alt="简单的表格应用" /><figcaption aria-hidden="true">简单的表格应用</figcaption></figure><p>我们使用<code>openai</code>中的<code>gpt-3.5-turbo</code>模型进行文本分类，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">import</span> openai<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">input_str</span>):<br>    openai.api_type = <span class="hljs-string">&quot;open_ai&quot;</span><br>    openai.api_base = <span class="hljs-string">&quot;https://api.openai.com/v1&quot;</span><br>    openai.api_version = <span class="hljs-literal">None</span><br>    openai.api_key = <span class="hljs-string">&quot;sk-xxx&quot;</span><br><br>    output_list = []<br>    <span class="hljs-keyword">for</span> prompt <span class="hljs-keyword">in</span> input_str.split(<span class="hljs-string">&#x27;\n&#x27;</span>):<br>        response = openai.ChatCompletion.create(<br>            model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>            messages=[<br>                &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Classify the text into Positive, Negative, Neural.&quot;</span>&#125;,<br>                &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: prompt&#125;<br>            ],<br>            max_tokens=<span class="hljs-number">5</span><br>        )<br>        output = response[<span class="hljs-string">&#x27;choices&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;message&#x27;</span>][<span class="hljs-string">&#x27;content&#x27;</span>]<br>        output_list.append([prompt, output])<br><br>    <span class="hljs-keyword">return</span> output_list<br><br><br>demo = gr.Interface(<br>    fn=predict,<br>    <span class="hljs-comment"># 自定义输入框</span><br>    inputs=gr.Textbox(lines=<span class="hljs-number">3</span>, placeholder=<span class="hljs-string">&quot;Documents...&quot;</span>, label=<span class="hljs-string">&quot;Documents&quot;</span>),<br>    <span class="hljs-comment"># 设置输出组件</span><br>    outputs=gr.DataFrame(label=<span class="hljs-string">&#x27;Predict Result&#x27;</span>,<br>                         headers=[<span class="hljs-string">&quot;document&quot;</span>, <span class="hljs-string">&quot;class&quot;</span>],<br>                         datatype=[<span class="hljs-string">&quot;str&quot;</span>, <span class="hljs-string">&quot;str&quot;</span>],<br>                         interactive=<span class="hljs-literal">True</span>,<br>                         wrap=<span class="hljs-literal">True</span>)<br>)<br><br>demo.launch()<br></code></pre></td></tr></table></figure><p>页面如下：</p><figure><img src="/img/gradio1_4.png" alt="在Gradio中实现文本分类" /><figcaption aria-hidden="true">在Gradio中实现文本分类</figcaption></figure><h3 id="文本高亮">文本高亮</h3><p><code>Gradio</code>给出了基于文本比对的文本高亮的例子，文本比对使用difflib模块，示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">from</span> difflib <span class="hljs-keyword">import</span> Differ<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">diff_texts</span>(<span class="hljs-params">text1, text2</span>):<br>    d = Differ()<br>    output = [(token[<span class="hljs-number">2</span>:], token[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> token[<span class="hljs-number">0</span>] != <span class="hljs-string">&quot; &quot;</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>) <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> d.compare(text1, text2)]<br>    <span class="hljs-keyword">return</span> output<br><br><br>demo = gr.Interface(<br>    fn=diff_texts,<br>    inputs=[<br>            gr.Textbox(<br>                label=<span class="hljs-string">&quot;Text 1&quot;</span>,<br>                info=<span class="hljs-string">&quot;Initial text&quot;</span>,<br>                lines=<span class="hljs-number">3</span>,<br>                value=<span class="hljs-string">&quot;The quick brown fox jumped over the lazy dogs.&quot;</span>,<br>            ),<br>            gr.Textbox(<br>                label=<span class="hljs-string">&quot;Text 2&quot;</span>,<br>                info=<span class="hljs-string">&quot;Text to compare&quot;</span>,<br>                lines=<span class="hljs-number">3</span>,<br>                value=<span class="hljs-string">&quot;The fast brown fox jumps over lazy dogs.&quot;</span>,<br>            ),<br>           ],<br>    outputs=gr.HighlightedText(label=<span class="hljs-string">&quot;Diff&quot;</span>,<br>                               combine_adjacent=<span class="hljs-literal">True</span>,<br>                               show_legend=<span class="hljs-literal">True</span><br>                               ).style(color_map=&#123;<span class="hljs-string">&quot;+&quot;</span>: <span class="hljs-string">&quot;red&quot;</span>, <span class="hljs-string">&quot;-&quot;</span>: <span class="hljs-string">&quot;green&quot;</span>&#125;),<br>    theme=gr.themes.Base()<br>)<br><br><br>demo.launch()<br></code></pre></td></tr></table></figure><p>页面如下：</p><figure><img src="/img/gradio1_5.png" alt="简单的文本高亮例子" /><figcaption aria-hidden="true">简单的文本高亮例子</figcaption></figure><p>我们使用文本高亮来显示文本纠错结果，文本纠错工具我们使用<code>pycorrector</code>模块，其Github网址为：<ahref="https://github.com/shibing624/pycorrector">https://github.com/shibing624/pycorrector</a>。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">import</span> pycorrector<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">corrector</span>(<span class="hljs-params">text</span>):<br>    corrected_text, detail = pycorrector.correct(text)<br>    index_list = []<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> detail:<br>        index_list.extend(<span class="hljs-built_in">range</span>(_[<span class="hljs-number">2</span>], _[<span class="hljs-number">3</span>]))<br>    output = [(char, <span class="hljs-string">&#x27;+&#x27;</span> <span class="hljs-keyword">if</span> i <span class="hljs-keyword">in</span> index_list <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>)<span class="hljs-keyword">for</span> i, char <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(corrected_text)]<br>    <span class="hljs-keyword">return</span> output<br><br><br>demo = gr.Interface(<br>    fn=corrector,<br>    inputs=gr.Textbox(lines=<span class="hljs-number">3</span>, placeholder=<span class="hljs-string">&quot;Text...&quot;</span>, label=<span class="hljs-string">&quot;Text&quot;</span>),<br>    outputs=gr.HighlightedText(label=<span class="hljs-string">&quot;Diff&quot;</span>,<br>                               combine_adjacent=<span class="hljs-literal">True</span>,<br>                               show_legend=<span class="hljs-literal">True</span><br>                               ).style(color_map=&#123;<span class="hljs-string">&quot;+&quot;</span>: <span class="hljs-string">&quot;yellow&quot;</span>&#125;),<br>    theme=gr.themes.Base()<br>)<br><br><br>demo.launch()<br></code></pre></td></tr></table></figure><p>页面如下：</p><figure><img src="/img/gradio1_6.png" alt="使用文本高亮来展示文本接错结果" /><figcaptionaria-hidden="true">使用文本高亮来展示文本接错结果</figcaption></figure><h3 id="总结">总结</h3><p>本文介绍了机器学习领域中一个很好用的前端展示工具Gradio，分别就输入和输出、表格、文本高亮三个功能上给出了简单示例和大模型方面的应用。</p><p>本人个人博客网站为 <ahref="https://percent4.github.io/">https://percent4.github.io/</a>，欢迎大家访问~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Gradio</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>测试工具coverage的高阶使用</title>
    <link href="/%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7coverage%E7%9A%84%E9%AB%98%E9%98%B6%E4%BD%BF%E7%94%A8/"/>
    <url>/%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7coverage%E7%9A%84%E9%AB%98%E9%98%B6%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在文章<ahref="https://blog.csdn.net/jclian91/article/details/123833933">Python之单元测试使用的一点心得</a>中，笔者介绍了自己在使用Python测试工具<code>coverge</code>的一点心得，包括：</p><ol type="1"><li>使用coverage模块计算代码测试覆盖率</li><li>使用coverage api计算代码测试覆盖率</li><li>coverage配置文件的使用</li><li>coverage badge的生成</li></ol><p>本文在此基础上，将会介绍coverage的高阶使用，包括：</p><ul><li><p>Flask API测试</p></li><li><p>coverage多文件测试</p></li><li><p>coverage的Gitlab CI/CD集成</p></li><li><p>coverage badge生成</p><p>本文中使用coverage的版本均为7.3.0。</p></li><li><h3 id="flask-api测试">Flask API测试</h3><p>在unittest测试框架如果对FlaskAPI进行测试时使用HTTP请求，那么将无法得到代码覆盖率。</p><p>我们有如下的示例Flask服务：</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><br>app = Flask(__name__)<br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">index</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello index&quot;</span><br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/test&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello test&quot;</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    app.run(host=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, port=<span class="hljs-number">5000</span>, debug=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>正确的测试代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> unittest<br><br><span class="hljs-keyword">from</span> flask_app <span class="hljs-keyword">import</span> app<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AppTestCase</span>(unittest.TestCase):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">setUp</span>(<span class="hljs-params">self</span>):<br>        self.ctx = app.app_context()<br>        self.ctx.push()<br>        self.client = app.test_client()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">tearDown</span>(<span class="hljs-params">self</span>):<br>        self.ctx.pop()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_case1</span>(<span class="hljs-params">self</span>):<br>        response = self.client.get(<span class="hljs-string">&quot;/&quot;</span>)<br>        self.assertEqual(response.status_code, <span class="hljs-number">200</span>)<br>        self.assertEqual(response.text, <span class="hljs-string">&quot;Hello index&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_case2</span>(<span class="hljs-params">self</span>):<br>        response = self.client.get(<span class="hljs-string">&quot;/test&quot;</span>)<br>        self.assertEqual(response.status_code, <span class="hljs-number">200</span>)<br>        self.assertEqual(response.text, <span class="hljs-string">&quot;Hello test&quot;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    suite = unittest.TestSuite()<br>    suite.addTest(AppTestCase(<span class="hljs-string">&#x27;test_case1&#x27;</span>))<br>    suite.addTest(AppTestCase(<span class="hljs-string">&#x27;test_case2&#x27;</span>))<br>    run = unittest.TextTestRunner()<br>    run.run(suite)<br></code></pre></td></tr></table></figure><h3 id="coverage多文件测试">coverage多文件测试</h3><p>我们有如下的实现两个变量相加的代码（<code>func_add.py</code>）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(a, <span class="hljs-built_in">str</span>) <span class="hljs-keyword">and</span> <span class="hljs-built_in">isinstance</span>(b, <span class="hljs-built_in">str</span>):<br>        <span class="hljs-keyword">return</span> a + <span class="hljs-string">&#x27;+&#x27;</span> + b<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(a, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">and</span> <span class="hljs-built_in">isinstance</span>(b, <span class="hljs-built_in">list</span>):<br>        <span class="hljs-keyword">return</span> a + b<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(a, (<span class="hljs-built_in">int</span>, <span class="hljs-built_in">float</span>)) <span class="hljs-keyword">and</span> <span class="hljs-built_in">isinstance</span>(b, (<span class="hljs-built_in">int</span>, <span class="hljs-built_in">float</span>)):<br>        <span class="hljs-keyword">return</span> a + b<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><p>两个测试文件<code>test_func_add1.py</code>和<code>test_func_add2.py</code>，内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> unittest<br><br><span class="hljs-keyword">from</span> func_add <span class="hljs-keyword">import</span> add<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TestAdd</span>(unittest.TestCase):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">setUp</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">pass</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_add_case1</span>(<span class="hljs-params">self</span>):<br>        a = <span class="hljs-string">&quot;Hello&quot;</span><br>        b = <span class="hljs-string">&quot;World&quot;</span><br>        res = add(a, b)<br>        <span class="hljs-built_in">print</span>(res)<br>        self.assertEqual(res, <span class="hljs-string">&quot;Hello+World&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_add_case2</span>(<span class="hljs-params">self</span>):<br>        a = <span class="hljs-number">1</span><br>        b = <span class="hljs-number">2</span><br>        res = add(a, b)<br>        <span class="hljs-built_in">print</span>(res)<br>        self.assertEqual(res, <span class="hljs-number">3</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br><br>    <span class="hljs-comment"># 部分用例测试</span><br>    <span class="hljs-comment"># 构造一个容器用来存放我们的测试用例</span><br>    suite = unittest.TestSuite()<br>    <span class="hljs-comment"># 添加类中的测试用例</span><br>    suite.addTest(TestAdd(<span class="hljs-string">&#x27;test_add_case1&#x27;</span>))<br>    suite.addTest(TestAdd(<span class="hljs-string">&#x27;test_add_case2&#x27;</span>))<br>    run = unittest.TextTestRunner()<br>    run.run(suite)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> unittest<br><br><span class="hljs-keyword">from</span> func_add <span class="hljs-keyword">import</span> add<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TestAdd</span>(unittest.TestCase):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">setUp</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">pass</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_add_case3</span>(<span class="hljs-params">self</span>):<br>        a = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]<br>        b = [<span class="hljs-number">3</span>]<br>        res = add(a, b)<br>        <span class="hljs-built_in">print</span>(res)<br>        self.assertEqual(res, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_add_case4</span>(<span class="hljs-params">self</span>):<br>        a = <span class="hljs-number">2</span><br>        b = <span class="hljs-string">&quot;3&quot;</span><br>        res = add(a, b)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-literal">None</span>)<br>        self.assertEqual(res, <span class="hljs-literal">None</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br><br>    <span class="hljs-comment"># 部分用例测试</span><br>    <span class="hljs-comment"># 构造一个容器用来存放我们的测试用例</span><br>    suite = unittest.TestSuite()<br>    <span class="hljs-comment"># 添加类中的测试用例</span><br>    suite.addTest(TestAdd(<span class="hljs-string">&#x27;test_add_case3&#x27;</span>))<br>    suite.addTest(TestAdd(<span class="hljs-string">&#x27;test_add_case4&#x27;</span>))<br>    run = unittest.TextTestRunner()<br>    run.run(suite)<br></code></pre></td></tr></table></figure><p>使用命令进行测试：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">coverage run test_func_add1.py<br>coverage run test_func_add2.py<br>coverage report<br></code></pre></td></tr></table></figure><p>生成的代码测试覆盖率如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">Name          Stmts   Miss  Cover<br>---------------------------------<br>func_add.py       8      2    75%<br>---------------------------------<br>TOTAL             8      2    75%<br></code></pre></td></tr></table></figure><p>这是不符合我们预期的，因为在这两个测试文件中我们对所有的代码都进行了测试，理论上测试覆盖率应该为100%，之所以这样，是因为<code>coverage run</code>命令运行时每一次都会覆盖掉之前的测试。正确的测试命令（以文件追加的形式）如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">coverage run test_func_add1.py<br>coverage run --append test_func_add2.py<br>coverage report<br></code></pre></td></tr></table></figure><p>此时代码覆盖率如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">Name          Stmts   Miss  Cover<br>---------------------------------<br>func_add.py       8      0   100%<br>---------------------------------<br>TOTAL             8      0   100%<br></code></pre></td></tr></table></figure><h3 id="coverage的gitlab-cicd集成">coverage的Gitlab CI/CD集成</h3><p>在文章<ahref="https://blog.csdn.net/jclian91/article/details/131258147">GitlabCI/CD入门（一）Python项目的CI演示</a>中，笔者介绍了GitlabCI/CD的入门。在此基础上，我们将集成coverage。</p><p>首先我们的test目录如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">.<br>├── __init__.py<br>├── func_add.py<br>└── test_func_add.py<br></code></pre></td></tr></table></figure><p><code>func_add.py</code>为实现两个变量相加的代码，如前述。<code>test_func_add.py</code>为测试代码，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> unittest<br><br><span class="hljs-keyword">from</span> func_add <span class="hljs-keyword">import</span> add<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TestAdd</span>(unittest.TestCase):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">setUp</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">pass</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_add_case1</span>(<span class="hljs-params">self</span>):<br>        a = <span class="hljs-string">&quot;Hello&quot;</span><br>        b = <span class="hljs-string">&quot;World&quot;</span><br>        res = add(a, b)<br>        <span class="hljs-built_in">print</span>(res)<br>        self.assertEqual(res, <span class="hljs-string">&quot;Hello+World&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_add_case2</span>(<span class="hljs-params">self</span>):<br>        a = <span class="hljs-number">1</span><br>        b = <span class="hljs-number">2</span><br>        res = add(a, b)<br>        <span class="hljs-built_in">print</span>(res)<br>        self.assertEqual(res, <span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_add_case3</span>(<span class="hljs-params">self</span>):<br>        a = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]<br>        b = [<span class="hljs-number">3</span>]<br>        res = add(a, b)<br>        <span class="hljs-built_in">print</span>(res)<br>        self.assertEqual(res, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_add_case4</span>(<span class="hljs-params">self</span>):<br>        a = <span class="hljs-number">2</span><br>        b = <span class="hljs-string">&quot;3&quot;</span><br>        res = add(a, b)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-literal">None</span>)<br>        self.assertEqual(res, <span class="hljs-literal">None</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br><br>    <span class="hljs-comment"># 部分用例测试</span><br>    <span class="hljs-comment"># 构造一个容器用来存放我们的测试用例</span><br>    suite = unittest.TestSuite()<br>    <span class="hljs-comment"># 添加类中的测试用例</span><br>    suite.addTest(TestAdd(<span class="hljs-string">&#x27;test_add_case1&#x27;</span>))<br>    suite.addTest(TestAdd(<span class="hljs-string">&#x27;test_add_case2&#x27;</span>))<br>    suite.addTest(TestAdd(<span class="hljs-string">&#x27;test_add_case3&#x27;</span>))<br>    suite.addTest(TestAdd(<span class="hljs-string">&#x27;test_add_case4&#x27;</span>))<br>    run = unittest.TextTestRunner()<br>    run.run(suite)<br></code></pre></td></tr></table></figure><p>CI/CD依赖<code>.gitlab-ci.yml</code>，配置如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">stages:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">build</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">unittest</span><br><br><span class="hljs-attr">build-job:</span><br>  <span class="hljs-attr">stage:</span> <span class="hljs-string">build</span><br>  <span class="hljs-attr">script:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">echo</span> <span class="hljs-string">`date`</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">echo</span> <span class="hljs-string">&quot;Hello, $GITLAB_USER_LOGIN!&quot;</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">echo</span> <span class="hljs-string">&quot;This job deploys something from the $CI_COMMIT_BRANCH branch.&quot;</span><br><br><span class="hljs-attr">unit_test_job:</span><br>  <span class="hljs-attr">stage:</span> <span class="hljs-string">unittest</span><br>  <span class="hljs-attr">image:</span> <span class="hljs-string">python:3.9-alpine3.17</span><br>  <span class="hljs-attr">script:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">pip3</span> <span class="hljs-string">install</span> <span class="hljs-string">coverage==7.3.0</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">coverage</span> <span class="hljs-string">run</span> <span class="hljs-string">test/test_func_add.py</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">coverage</span> <span class="hljs-string">report</span><br>  <span class="hljs-attr">coverage:</span> <span class="hljs-string">&#x27;/TOTAL.*\s+(\d+%)$/&#x27;</span><br></code></pre></td></tr></table></figure><p>运行CI/CD，结果如下图：</p><figure><img src="/img/coverage1_1.png" alt="unittest_job运行结果" /><figcaption aria-hidden="true">unittest_job运行结果</figcaption></figure><p>在Gitlab项目中的<code>Settings -&gt; CI/CD -&gt; General pipelines</code>中点击Expand，会显示CI/CD已内置<code>Pipeline status, Coverage report, Latest release</code>，其中<code>Coverage repor</code>如下图：</p><figure><img src="/img/coverage1_2.png" alt="Coverage report" /><figcaption aria-hidden="true">Coverage report</figcaption></figure><p>最后我们要在项目中加入coveragebadge（徽章），在Gitlab项目中的<code>Settings -&gt; General -&gt; Badge</code>中点击Expand，再点击Addbadge，coverage徽章的配置如下：</p><figure><img src="/img/coverage1_3.png" alt="Add badge" /><figcaption aria-hidden="true">Add badge</figcaption></figure><p>本项目中只有main分支，因此不需要设置变量，实际在使用过程中，需要配置变量如default_branch等。</p><p>以上配置完毕后，项目徽章显示如下：</p><figure><img src="/img/coverage1_4.png" alt="成功加入徽章！" /><figcaption aria-hidden="true">成功加入徽章！</figcaption></figure><p>以上配置过程已开源，项目网址为：<ahref="https://gitlab.com/jclian91/gitlab_ci_test">https://gitlab.com/jclian91/gitlab_ci_test</a>。</p><h3 id="coverage-badge生成">coverage badge生成</h3><p>coverage badge生成方式分为静态和动态。</p><p>动态的话，可使用<code>coverage-badge</code>或者<code>genbadge</code>模块。</p><p>静态的话，可使用网站：<ahref="https://shields.io/badges/static-badge">https://shields.io/badges/static-badge</a>.</p><p>比如我们生成编程语言的徽章，如下图：</p><figure><img src="/img/coverage1_5.png" alt="示例徽章生成" /><figcaption aria-hidden="true">示例徽章生成</figcaption></figure><p>之后我们就可以用该网址访问徽章了。</p><h3 id="总结">总结</h3><p>本文介绍了测试工具coverage的高阶使用，希望能对读者有所启发~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>单元测试</tag>
      
      <tag>coverage</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>tensorflow（1）基础入门</title>
    <link href="/tensorflow%EF%BC%881%EF%BC%89%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"/>
    <url>/tensorflow%EF%BC%881%EF%BC%89%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="tensorflow-is-coming-part-1">TensorFlow Is Coming ( Part 1)</h2><h3 id="目录">目录</h3><ol type="1"><li>TensorFlow简介</li><li>TensorFlow基本概念</li><li>Using TensorFlow</li><li>Optimization &amp; Linear Regression &amp; Logistic Regression</li></ol><h3 id="tensorflow简介">1. TensorFlow简介</h3><p>TensorFlow由Google的Brain Team创立，于2015年11月9日开源。</p><p>TensorFlow中文社区网站：http://www.tensorfly.cn 。</p><p>TensorFlow, 其含义为 Tensor + Flow, 具体说来：</p><ul><li>Tensor（张量）：N维数组</li><li>Flow（流图）： 基于数据流图（Data Flow Graph）的计算</li></ul><p><a href="http://www.tensorfly.cn/">TensorFlow的特征</a>：</p><ol type="1"><li>高度的灵活性</li><li>真正的可移植性（Portability）</li><li>将科研和产品联系在一起</li><li>自动求微分</li><li>多语言支持</li><li>性能最优化</li></ol><p>TensorFlow Python API在数据结构和基于多维数组的计算与NumPy有许多相似之处，其安装方式：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> tensorflow<br></code></pre></td></tr></table></figure><p>一个简单的例子："Hello world" with TensorFlow</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>h = tf.constant(<span class="hljs-string">&quot;Hello&quot;</span>)<br>w = tf.constant(<span class="hljs-string">&quot; World!&quot;</span>)<br>hw = h + w<br><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>    ans = sess.run(hw)<br><span class="hljs-built_in">print</span> (ans)<br></code></pre></td></tr></table></figure><h3 id="tensorflow基本概念">2. TensorFlow基本概念</h3><p>本节目录：</p><ol type="1"><li>Constant</li><li>Tensor</li><li>Computation Graphs</li><li>Variables</li><li>Placeholder Variables</li></ol><h4 id="constant">Constant</h4><p>TensorFlow中的常量用constant()函数构造。</p><h4 id="tensor">Tensor</h4><p><img src="/img/tf1_1.png" /> <img src="/img/tf1_2.png" /></p><p>Tensor的创建：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">a = tf.constant(<span class="hljs-number">2</span>)        <span class="hljs-comment"># 标量</span><br>b = tf.constant([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])    <span class="hljs-comment"># 一维向量</span><br>c = tf.constant([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],<br>                 [<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]])  <span class="hljs-comment"># 二维向量</span><br></code></pre></td></tr></table></figure><p>也可以指定维度（shape）以及数据类型(dtype)。比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">a = tf.constant(np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]), shape=(<span class="hljs-number">3</span>,<span class="hljs-number">2</span>),dtype=tf.int64)<br>a = tf.constant(np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],<br>                          [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]]),<br>                          shape=(<span class="hljs-number">3</span>,<span class="hljs-number">2</span>),<br>                          dtype=tf.float64)<br></code></pre></td></tr></table></figure><figure><img src="/img/tf1_3.png" alt="数据类型" /><figcaption aria-hidden="true">数据类型</figcaption></figure><h4 id="computation-graphs">Computation Graphs</h4><p>Generally, the typical workflow in TensorFlow can be summarized asfollows:</p><ul><li>Build a computational graph</li><li>Start a new session to evaluate the graph<ol type="1"><li>Initialize variables</li><li>Execute the operations in the compiled graph</li></ol></li></ul><p>例1：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>a = tf.constant(<span class="hljs-number">5</span>)<br>b = tf.constant(<span class="hljs-number">2</span>)<br>c = tf.constant(<span class="hljs-number">3</span>)<br><br>d = tf.multiply(a,b)<br>e = tf.add(c,b)<br>f = tf.subtract(d,e)<br><br><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>    res = sess.run(f)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;f is %s&#x27;</span>%res)<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">f is 5<br></code></pre></td></tr></table></figure><p>在上述程序中，Computation Graph 示意图如下：</p><p><img src="/img/tf1_4.png" /></p><p>在TensorBoard中，Computation Graph如下：</p><p><img src="/img/tf1_5.png" /></p><p>常用的TensorFlow运算函数：</p><p><img src="/img/tf1_6.png" /></p><p>例2：使用Graph及Session</p><p>未使用Session</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.constant([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>,<span class="hljs-number">6.</span>]], dtype=tf.float64)<br>    col_sum = tf.reduce_sum(tf_x, axis=<span class="hljs-number">0</span>) <span class="hljs-comment"># 按列求和</span><br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;tf_x:\n&#x27;</span>, tf_x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;col_sum:\n&#x27;</span>, col_sum)<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">tf_x:<br> Tensor(<span class="hljs-string">&quot;Const:0&quot;</span>, shape=(3, 2), dtype=float64)<br>col_sum:<br> Tensor(<span class="hljs-string">&quot;Sum:0&quot;</span>, shape=(2,), dtype=float64)<br></code></pre></td></tr></table></figure><p>使用Session（获取计算结果）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.constant([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>,<span class="hljs-number">6.</span>]], dtype=tf.float64)<br>    col_sum = tf.reduce_sum(tf_x, axis=<span class="hljs-number">0</span>) <span class="hljs-comment"># 按列求和</span><br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    mat, csum = sess.run([tf_x, col_sum])<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;tf_x:\n&#x27;</span>, mat)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;col_sum:\n&#x27;</span>, csum)<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">tf_x:<br> [[1. 2.]<br>  [3. 4.]<br>  [5. 6.]]<br>col_sum:<br> [ 9. 12.]<br></code></pre></td></tr></table></figure><p>TensorFlow背后的运行原理图：</p><figure><img src="/img/tf1_7.png" alt="运行原理图" /><figcaption aria-hidden="true">运行原理图</figcaption></figure><p>为什么要采用Computation Graphs？</p><ul><li>TensorFlow optimizes its computations based on the graph’sconnectivity.</li><li>Each graph has its own set of node dependencies.Being able to locatedependencies between units of our model allows us to both distributecomputations across available resources and avoid performing redundantcomputations of irrelevant subsets, resulting in a faster and moreefficient way of computing things.</li></ul><p><img src="/img/tf1_8.png" /></p><h4 id="variables">Variables</h4><p>Variables are constructs in TensorFlow that allows us to store andupdate parameters of our models in the current session during training.To define a “variable” tensor, we use TensorFlow’s Variable()constructor. to execute a computational graph that contains variables,we must initialize all variables in the active session first (usingtf.global_variables_initializer()).</p><p>例1：使用Variables</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]], dtype=tf.float32)<br>    x = tf.constant(<span class="hljs-number">1.</span>, dtype=tf.float32)<br><br>    <span class="hljs-comment"># add a constant to the matrix:</span><br>    tf_x = tf_x + x<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    result = sess.run(tf_x)<br><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[2. 3.]<br> [4. 5.]<br> [6. 7.]]<br></code></pre></td></tr></table></figure><p>例2： 运行两遍？</p><p>运行两遍， 存在的问题：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]], dtype=tf.float32)<br>    x = tf.constant(<span class="hljs-number">1.</span>, dtype=tf.float32)<br><br>    <span class="hljs-comment"># add a constant to the matrix:</span><br>    tf_x = tf_x + x<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    result = sess.run(tf_x)<br>    result = sess.run(tf_x) <span class="hljs-comment"># 运行两遍</span><br><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[2. 3.]<br> [4. 5.]<br> [6. 7.]]<br></code></pre></td></tr></table></figure><p>解决办法？ 使用tf.assign()函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]], dtype=tf.float32)<br>    x = tf.constant(<span class="hljs-number">1.</span>, dtype=tf.float32)<br><br>    <span class="hljs-comment"># add a constant to the matrix:</span><br>    update_tf_x = tf.assign(tf_x, tf_x + x)<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    result = sess.run(update_tf_x)<br>    result = sess.run(update_tf_x) <span class="hljs-comment"># 运行两遍</span><br><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>此时的输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[3. 4.]<br> [5. 6.]<br> [7. 8.]]<br></code></pre></td></tr></table></figure><h4 id="placeholder-variables">Placeholder Variables</h4><p><strong>Placeholder variables</strong> allow us to feed thecomputational graph with numerical values in an active session atruntime. <strong>Placeholders</strong> have an optional shape argument.If a shape is not fed or is passed as <strong>None</strong>, then theplaceholder can be fed with data of any size.</p><p>例：矩阵相乘</p><p>指定行数与列数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.placeholder(dtype=tf.float32,shape=(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>))<br><br>    output = tf.matmul(tf_x, tf.transpose(tf_x)) <span class="hljs-comment"># 矩阵乘以它的转置</span><br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    <span class="hljs-comment"># 创建3*2矩阵</span><br>    np_ary = np.array([[<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                       [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>],<br>                       [<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>]])<br><br>    <span class="hljs-built_in">print</span>(sess.run(output, &#123;tf_x: np_ary&#125;))<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[ 25.  39.  53.]<br> [ 39.  61.  83.]<br> [ 53.  83. 113.]]<br></code></pre></td></tr></table></figure><p>指定列数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.placeholder(dtype=tf.float32,shape=(<span class="hljs-literal">None</span>, <span class="hljs-number">2</span>))<br><br>    output = tf.matmul(tf_x, tf.transpose(tf_x)) <span class="hljs-comment"># 矩阵乘以它的转置</span><br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    <span class="hljs-comment"># 创建3*2矩阵</span><br>    np_ary1 = np.array([[<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                       [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>],<br>                       [<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>]])<br><br>    <span class="hljs-built_in">print</span>(sess.run(output, &#123;tf_x: np_ary1&#125;))<br><br>    <span class="hljs-comment"># 创建4*2矩阵</span><br>    np_ary2 = np.array([[<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>],<br>                        [<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>],<br>                        [<span class="hljs-number">9.</span>,<span class="hljs-number">10.</span>]])<br><br>    <span class="hljs-built_in">print</span>(sess.run(output, &#123;tf_x: np_ary2&#125;))<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[ 25.  39.  53.]<br> [ 39.  61.  83.]<br> [ 53.  83. 113.]]<br>[[ 25.  39.  53.  67.]<br> [ 39.  61.  83. 105.]<br> [ 53.  83. 113. 143.]<br> [ 67. 105. 143. 181.]]<br></code></pre></td></tr></table></figure><p>未指定shape</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    tf_x = tf.placeholder(dtype=tf.float32)<br><br>    output = tf.matmul(tf_x, tf.transpose(tf_x)) <span class="hljs-comment"># 矩阵乘以它的转置</span><br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    <span class="hljs-comment"># 创建3*3矩阵</span><br>    np_ary1 = np.array([[<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>, <span class="hljs-number">5.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">7.</span>],<br>                        [<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>, <span class="hljs-number">9.</span>]])<br><br>    <span class="hljs-built_in">print</span>(sess.run(output, &#123;tf_x: np_ary1&#125;))<br><br>    <span class="hljs-comment"># 创建4*2矩阵</span><br>    np_ary2 = np.array([[<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>],<br>                        [<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>],<br>                        [<span class="hljs-number">9.</span>,<span class="hljs-number">10.</span>]])<br><br>    <span class="hljs-built_in">print</span>(sess.run(output, &#123;tf_x: np_ary2&#125;))<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[ 50.  74.  98.]<br> [ 74. 110. 146.]<br> [ 98. 146. 194.]]<br>[[ 25.  39.  53.  67.]<br> [ 39.  61.  83. 105.]<br> [ 53.  83. 113. 143.]<br> [ 67. 105. 143. 181.]]<br></code></pre></td></tr></table></figure><h4 id="using-tensorflow">3. Using TensorFlow</h4><p>本节目录:</p><ul><li>Saving and Restoring Models</li><li>Naming TensorFlow Objects</li><li>CPU and GPU</li><li>Control Flow</li><li>TensorBoard</li></ul><h5 id="saving-and-restoring-models">Saving and Restoring Models</h5><p>例：</p><p><strong>Saving Models</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br><br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]], dtype=tf.float32)<br>    x = tf.constant(<span class="hljs-number">1.</span>, dtype=tf.float32)<br><br>    update_tf_x = tf.assign(tf_x, tf_x + x)<br><br>    <span class="hljs-comment"># initialize a Saver, which gets all variables</span><br>    <span class="hljs-comment"># within this computation graph context</span><br>    saver = tf.train.Saver()<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br>    result = sess.run(update_tf_x)<br><br>    <span class="hljs-comment"># save the model</span><br>    saver.save(sess, save_path=<span class="hljs-string">&#x27;E://flag/my-model.ckpt&#x27;</span>)<br></code></pre></td></tr></table></figure><p>保存的文件：</p><figure><img src="/img/tf1_9.png" alt="保存的文件" /><figcaption aria-hidden="true">保存的文件</figcaption></figure><p>The file my-model.ckpt.data-00000-of-00001 saves our main variablevalues, the .index file keeps track of the data structures, and the.meta file describes the structure of our computational graph that weexecuted.</p><p><strong>Restoring Models:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br><br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]], dtype=tf.float32)<br>    x = tf.constant(<span class="hljs-number">1.</span>, dtype=tf.float32)<br><br>    update_tf_x = tf.assign(tf_x, tf_x + x)<br><br>    <span class="hljs-comment"># initialize a Saver, which gets all variables</span><br>    <span class="hljs-comment"># within this computation graph context</span><br>    saver = tf.train.Saver()<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    saver.restore(sess, save_path=<span class="hljs-string">&#x27;E://flag/my-model.ckpt&#x27;</span>)<br>    result = sess.run(update_tf_x)<br>    <span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[3. 4.]<br> [5. 6.]<br> [7. 8.]]<br></code></pre></td></tr></table></figure><h4 id="naming-tensorflow-objects">Naming TensorFlow Objects</h4><p>Each Tensor object also has an identifying name. This name is anintrinsic string name, not to be confused with the name of the variable.As with dtype, we can use the .name attribute to see the name of theobject:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    c1 = tf.constant(<span class="hljs-number">4</span>, dtype=tf.float64, name=<span class="hljs-string">&#x27;c&#x27;</span>)<br>    c2 = tf.constant(<span class="hljs-number">4</span>, dtype=tf.int32, name=<span class="hljs-string">&#x27;c&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(c1.name)<br><span class="hljs-built_in">print</span>(c2.name)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">c:0<br>c_1:0<br></code></pre></td></tr></table></figure><p><strong>Name scopes</strong></p><p>Sometimes when dealing with a large, complicated graph, we would liketo create some node grouping to make it easier to follow and manage. Forthat we can hierarchically group nodes together by name. We do so byusing tf.name_scope("prefix") together with the useful with clauseagain:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    c1 = tf.constant(<span class="hljs-number">4</span>, dtype=tf.float64, name=<span class="hljs-string">&#x27;c&#x27;</span>)<br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&quot;prefix_name&quot;</span>):<br>        c2 = tf.constant(<span class="hljs-number">4</span>, dtype=tf.int32, name=<span class="hljs-string">&#x27;c&#x27;</span>)<br>        c3 = tf.constant(<span class="hljs-number">4</span>, dtype=tf.float64, name=<span class="hljs-string">&#x27;c&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(c1.name)<br><span class="hljs-built_in">print</span>(c2.name)<br><span class="hljs-built_in">print</span>(c3.name)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">c:0<br>prefix_name/c:0<br>prefix_name/c_1:0<br></code></pre></td></tr></table></figure><h4 id="cpu-and-gpu">CPU and GPU</h4><p>All TensorFlow operations in general, can be executed on a<strong>CPU</strong>. If you have a <strong>GPU</strong> version ofTensorFlow installed, TensorFlow will automatically execute thoseoperations that have <strong>GPU</strong> support on GPUs and use yourmachine’s <strong>CPU</strong>, otherwise.</p><h4 id="control-flow">Control Flow</h4><p>例： if-else结构</p><p>简单的if-else语句</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>addition = <span class="hljs-literal">True</span><br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    x = tf.placeholder(dtype=tf.float32, shape=<span class="hljs-literal">None</span>)<br>    <span class="hljs-keyword">if</span> addition:<br>        y = x + <span class="hljs-number">1.</span><br>    <span class="hljs-keyword">else</span>:<br>        y = x - <span class="hljs-number">1.</span><br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    result = sess.run(y, feed_dict=&#123;x: <span class="hljs-number">1.</span>&#125;)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Result:\n&#x27;</span>, result)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">Result:<br> 2.0<br></code></pre></td></tr></table></figure><p>使用tf.cond()代替上面的if-else语句</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br>    addition = tf.placeholder(dtype=tf.<span class="hljs-built_in">bool</span>, shape=<span class="hljs-literal">None</span>)<br>    x = tf.placeholder(dtype=tf.float32, shape=<span class="hljs-literal">None</span>)<br><br>    y = tf.cond(addition,<br>                true_fn=<span class="hljs-keyword">lambda</span>: tf.add(x, <span class="hljs-number">1.</span>),<br>                false_fn=<span class="hljs-keyword">lambda</span>: tf.subtract(x, <span class="hljs-number">1.</span>))<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    result = sess.run(y, feed_dict=&#123;addition:<span class="hljs-literal">True</span>,x: <span class="hljs-number">1.</span>&#125;)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Result:\n&#x27;</span>, result)<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">Result:<br> 2.0<br></code></pre></td></tr></table></figure><h4 id="tensorboard">TensorBoard</h4><p>TensorBoard is one of the coolest features of TensorFlow, whichprovides us with a suite of tools to visualize our computational graphsand operations before and during runtime.</p><p>例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>g = tf.Graph()<br><span class="hljs-keyword">with</span> g.as_default() <span class="hljs-keyword">as</span> g:<br><br>    tf_x = tf.Variable([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>                        [<span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>],<br>                        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]],<br>                        name=<span class="hljs-string">&#x27;tf_x_0&#x27;</span>,<br>                        dtype=tf.float32)<br><br>    tf_y = tf.Variable([[<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>],<br>                        [<span class="hljs-number">9.</span>, <span class="hljs-number">10.</span>],<br>                        [<span class="hljs-number">11.</span>, <span class="hljs-number">12.</span>]],<br>                        name=<span class="hljs-string">&#x27;tf_y_0&#x27;</span>,<br>                        dtype=tf.float32)<br><br>    output = tf_x + tf_y<br>    output = tf.matmul(tf.transpose(tf_x), output)<br><br><span class="hljs-keyword">with</span> tf.Session(graph=g) <span class="hljs-keyword">as</span> sess:<br>    sess.run(tf.global_variables_initializer())<br><br>    <span class="hljs-comment"># create FileWrite object that writes the logs</span><br>    file_writer = tf.summary.FileWriter(logdir=<span class="hljs-string">&#x27;E://flag/logs/1&#x27;</span>, graph=g)<br>    result = sess.run(output)<br>    <span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">[[124. 142.]<br> [160. 184.]]<br></code></pre></td></tr></table></figure><p>使用Tensorboard查看Computation Graph:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tensorboard --logdir E://flag/logs/1<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">C:\Users\HP&gt;tensorboard --logdir E://flag/logs/1<br>TensorBoard 1.10.0 at http://DESKTOP-28K2SLS:6006 (Press CTRL+C to quit)<br></code></pre></td></tr></table></figure><p>在浏览器中输入http://DESKTOP-28K2SLS:6006即可查看ComputationGraph，截图如下：</p><p><img src="/img/tf1_10.png" /></p><h3 id="optimization-linear-regression-logistic-regression">4.Optimization &amp; Linear Regression &amp; Logistic Regression</h3><p><strong>Optimization Steps:</strong></p><ol type="1"><li>Defining a model</li><li>Defining loss function</li><li>Optimizer(The gradient descent)</li><li>Try to predict</li></ol><p>Gradient Descent的三种形式：</p><table><thead><tr class="header"><th>描述</th><th>GD</th><th>Minth-Batches GD</th><th>SGD</th></tr></thead><tbody><tr class="odd"><td>单次迭代样本数</td><td>整个训练集</td><td>训练集的子集</td><td>单个样本</td></tr><tr class="even"><td>算法复杂度</td><td>高</td><td>一般</td><td>低</td></tr><tr class="odd"><td>运行速度</td><td>慢</td><td>较快</td><td>快</td></tr><tr class="even"><td>收敛性</td><td>稳定</td><td>较稳定</td><td>不稳定</td></tr><tr class="odd"><td>陷入局部最优点的可能性</td><td>大</td><td>较大</td><td>小</td></tr></tbody></table><p><strong>Linear Regression</strong></p><ol type="1"><li>Model</li></ol><p><span class="math display">\[y = \sum\limits_{i=1}^{n}w_{i}x_{i} +b\]</span></p><ol start="2" type="1"><li>Loss function: MSE</li></ol><p><span class="math display">\[loss =\frac{1}{2m}\sum\limits_{i=1}^{m}(y_{true} -(\sum\limits_{i=1}^{n}w_{i}x_{i}+b))^{2}\]</span></p><ol start="3" type="1"><li>The gradient descent optimizer(SGD)</li></ol><p>指定 loss function 和 learning_rate</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = tf.train.GradientDescentOptimizer(learning_rate)<br>train = optimizer.minimize(loss)<br></code></pre></td></tr></table></figure><ol start="4" type="1"><li>predict on new sample</li></ol><p>Linear Regression的例子：</p><p>数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">x_data = np.random.randn(<span class="hljs-number">200</span>, <span class="hljs-number">3</span>)<br>w_real = [<span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.1</span>]<br>b_real = -<span class="hljs-number">0.2</span><br>noise = np.random.randn(<span class="hljs-number">1</span>, <span class="hljs-number">200</span>)*<span class="hljs-number">0.1</span><br>y_data = np.matmul(w_real, x_data.T) + b_real + noise<br></code></pre></td></tr></table></figure><p>示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> linear_model<br><br><span class="hljs-comment"># 样本数据集</span><br>x_data = np.random.randn(<span class="hljs-number">200</span>, <span class="hljs-number">3</span>)<br>w_real = [<span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.1</span>]<br>b_real = -<span class="hljs-number">0.2</span><br>noise = np.random.randn(<span class="hljs-number">1</span>, <span class="hljs-number">200</span>)*<span class="hljs-number">0.1</span><br>y_data = np.matmul(w_real, x_data.T) + b_real + noise<br><br><span class="hljs-comment"># 使用Sklearn进行一元线性回归建模</span><br>regr = linear_model.LinearRegression()<br><br><span class="hljs-comment"># Train the model using the data</span><br>regr.fit(x_data, y_data.transpose())<br><br><span class="hljs-comment"># The coefficients</span><br>w, b = regr.coef_[<span class="hljs-number">0</span>], regr.intercept_<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;用Sklearn计算得到的线性回归系数:\n w:%s\tb:%s&#x27;</span>%(w, b))<br><br>NUM_STEPS = <span class="hljs-number">100</span>                                         <span class="hljs-comment"># 循环次数</span><br>g = tf.Graph()                                          <span class="hljs-comment"># 创建图</span><br>wb_ = []                                                <span class="hljs-comment"># 记录结果的列表</span><br><br><span class="hljs-keyword">with</span> g.as_default():<br>    x = tf.placeholder(tf.float32, shape=[<span class="hljs-literal">None</span>,<span class="hljs-number">3</span>])       <span class="hljs-comment"># 样本中的x值</span><br>    y_true = tf.placeholder(tf.float32, shape=<span class="hljs-literal">None</span>)      <span class="hljs-comment"># 样本中的真实的y值</span><br><br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&#x27;inference&#x27;</span>) <span class="hljs-keyword">as</span> scope:<br>        w = tf.Variable([[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]], dtype=tf.float32, name=<span class="hljs-string">&#x27;weights&#x27;</span>)  <span class="hljs-comment"># w系数</span><br>        b = tf.Variable(<span class="hljs-number">0</span>, dtype=tf.float32, name=<span class="hljs-string">&#x27;bias&#x27;</span>)             <span class="hljs-comment"># 截距b</span><br>        y_pred = tf.matmul(w, tf.transpose(x)) + b                    <span class="hljs-comment"># y的预测值</span><br><br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&#x27;loss&#x27;</span>) <span class="hljs-keyword">as</span> scope:                              <span class="hljs-comment"># 定义损失函数</span><br>        loss = tf.reduce_mean(tf.square(y_true-y_pred))<br><br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&#x27;train&#x27;</span>) <span class="hljs-keyword">as</span> scope:                             <span class="hljs-comment">#定义optimization</span><br>        learning_rate = <span class="hljs-number">0.5</span><br>        optimizer = tf.train.GradientDescentOptimizer(learning_rate)<br>        train = optimizer.minimize(loss)<br><br>        <span class="hljs-comment"># Before starting, initialize the variables. We will &#x27;run&#x27; this first.</span><br>        init = tf.global_variables_initializer()<br><br>        <span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>            sess.run(init)<br>            <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_STEPS):<br>                sess.run(train, &#123;x: x_data, y_true: y_data&#125;)<br>            wb_.append(sess.run([w, b]))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;用TensorFlow计算得到的线性回归系数:\n&quot;</span>)<br><span class="hljs-built_in">print</span>(wb_)<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">用Sklearn计算得到的线性回归系数:<br> w:[0.29638914 0.49420393 0.096624  ]b:[-0.21690145]<br>用TensorFlow计算得到的线性回归系数:<br>[[array([[0.29638913, 0.49420393, 0.096624  ]], dtype=float32), -0.21690145]]<br></code></pre></td></tr></table></figure><p><strong>Logistic Regression</strong></p><ol type="1"><li>Model</li></ol><p><span class="math display">\[\ln{(\frac{p}{1-p})} =\sum\limits_{i=1}^{n}w_{i}x_{i} + b\]</span></p><ol start="2" type="1"><li>Loss function: Cross Entropy (OR log loss function)</li></ol><p><span class="math display">\[loss = H(p,q) = \sum\limits_{x} p(x)\log{q(x)}\]</span></p><ol start="3" type="1"><li>The gradient descent optimizer(SGD)</li></ol><p>指定 loss function 和 learning_rate</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = tf.train.GradientDescentOptimizer(learning_rate)<br>train = optimizer.minimize(loss)<br></code></pre></td></tr></table></figure><ol start="4" type="1"><li>predict on new samples</li></ol><p>例子：</p><p>样本数据集：</p><p>https://github.com/percent4/tensorflow_js_learning/blob/master/USA_vote.csv</p><p>Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><br><span class="hljs-comment">#read data from other places, e.g. csv</span><br><span class="hljs-comment">#drop_list: variables that are not used</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_data</span>(<span class="hljs-params">file_path, drop_list=[]</span>):<br>    dataSet = pd.read_csv(file_path,sep=<span class="hljs-string">&#x27;,&#x27;</span>)<br>    <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> drop_list:<br>        dataSet = dataSet.drop(col,axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> dataSet<br><br><span class="hljs-comment"># CSV文件存放目录</span><br>path = <span class="hljs-string">&#x27;E://USA_vote.csv&#x27;</span><br><span class="hljs-comment"># 读取CSV文件中的数据</span><br>dataSet = read_data(path)<br><br><span class="hljs-comment"># 利用sklearn中的LogisticRegression模型进行建模</span><br>clf = LogisticRegression(C=<span class="hljs-number">1e9</span>)<br>X, y = dataSet.iloc[:,<span class="hljs-number">0</span>:-<span class="hljs-number">1</span>], dataSet.iloc[:, -<span class="hljs-number">1</span>]<br>clf.fit(X,y)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Sklearn中的逻辑回归模型计算结果：&#x27;</span>)<br><span class="hljs-built_in">print</span>(clf.coef_)<br><span class="hljs-built_in">print</span>(clf.intercept_)<br><br>y_samples = np.array(y)    <span class="hljs-comment"># 样本中的y标签</span><br>x_samples = np.array(X)    <span class="hljs-comment"># 样本中的x标签</span><br>samples_num, var_num = x_samples.shape<br><br>NUM_STEPS = <span class="hljs-number">20000</span>    <span class="hljs-comment"># 总的训练次数</span><br>g = tf.Graph()<br>wb_ = []<br><br><br><span class="hljs-comment"># tensorflow训练模型</span><br><span class="hljs-keyword">with</span> g.as_default():<br>    x = tf.placeholder(tf.float32, shape=[<span class="hljs-literal">None</span>, var_num])<br>    y_true = tf.placeholder(tf.float32, shape=<span class="hljs-literal">None</span>)<br><br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&#x27;inference&#x27;</span>) <span class="hljs-keyword">as</span> scope:<br>        w = tf.Variable([[-<span class="hljs-number">1</span>]*var_num], dtype=tf.float32, name=<span class="hljs-string">&#x27;weights&#x27;</span>)<br>        b = tf.Variable(<span class="hljs-number">0</span>, dtype=tf.float32, name=<span class="hljs-string">&#x27;bias&#x27;</span>)<br>        y_pred = tf.matmul(w, tf.transpose(x)) + b<br><br>    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&#x27;train&#x27;</span>) <span class="hljs-keyword">as</span> scope:<br>        <span class="hljs-comment"># labels: ture output of y, i.e. 0 and 1, logits: the model&#x27;s linear prediction</span><br>        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)<br>        loss = tf.reduce_mean(cross_entropy)<br><br>        learning_rate = <span class="hljs-number">0.5</span><br>        optimizer = tf.train.GradientDescentOptimizer(learning_rate)<br>        train = optimizer.minimize(loss)<br><br>        <span class="hljs-comment"># Before starting, initialize the variables. We will &#x27;run&#x27; this first.</span><br>        init = tf.global_variables_initializer()<br><br>        <span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>            sess.run(init)<br><br>            <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_STEPS):<br>                sess.run(train, &#123;x: x_samples, y_true: y_samples&#125;)<br>                <span class="hljs-keyword">if</span> (step % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>):<br>                    <span class="hljs-comment"># print(step, sess.run([w, b]))</span><br>                    wb_.append(sess.run([w, b]))<br><br>            <span class="hljs-built_in">print</span>(NUM_STEPS, sess.run([w, b]))<br>            sess.close()<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">Sklearn中的逻辑回归模型计算结果：<br>[[ 0.34827234 -1.23053489 -2.74406079  6.85275877 -0.95313362 -0.47709861<br>   1.36435858 -1.85956934 -1.3986284   1.54663297 -3.14095297  0.78882048<br>   0.15680863  0.37217971 -1.44617613  0.59043785]]<br>[-1.56742975]<br>TensorFlow的计算结果：<br>20000 [array([[ 0.3481937 , -1.2305422 , -2.743876  ,  6.8526907 , -0.95355535,<br>        -0.47679362,  1.3641126 , -1.8595191 , -1.3984671 ,  1.5464842 ,<br>        -3.1406438 ,  0.7888262 ,  0.15678449,  0.37208068, -1.4461256 ,<br>         0.5904298 ]], dtype=float32), -1.56729]<br></code></pre></td></tr></table></figure><h3 id="homework">Homework</h3><p>尝试着用Ridge Regression（岭回归）解决一个线性回归问题，关于RidgeRegression,可以参考网址：https://blog.csdn.net/u012102306/article/details/52988660</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>tensorflow</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《文治时代：五代十国、两宋》摘抄</title>
    <link href="/%E3%80%8A%E6%96%87%E6%B2%BB%E6%97%B6%E4%BB%A3%EF%BC%9A%E4%BA%94%E4%BB%A3%E5%8D%81%E5%9B%BD%E3%80%81%E4%B8%A4%E5%AE%8B%E3%80%8B%E6%91%98%E6%8A%84/"/>
    <url>/%E3%80%8A%E6%96%87%E6%B2%BB%E6%97%B6%E4%BB%A3%EF%BC%9A%E4%BA%94%E4%BB%A3%E5%8D%81%E5%9B%BD%E3%80%81%E4%B8%A4%E5%AE%8B%E3%80%8B%E6%91%98%E6%8A%84/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="/pdfjs/web/viewer.html?file=/pdf/《文治时代：五代十国、两宋》摘抄.pdf">PDF全屏浏览（PDF View in FullScreen）</a></p><iframe src='/pdfjs/web/viewer.html?file=/pdf/《文治时代：五代十国、两宋》摘抄.pdf' width="100%" height="800px"></iframe>]]></content>
    
    
    <categories>
      
      <category>书籍摘抄</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍摘抄</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《在工作中，看到中国》摘抄</title>
    <link href="/%E3%80%8A%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%EF%BC%8C%E7%9C%8B%E5%88%B0%E4%B8%AD%E5%9B%BD%E3%80%8B%E6%91%98%E6%8A%84/"/>
    <url>/%E3%80%8A%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%EF%BC%8C%E7%9C%8B%E5%88%B0%E4%B8%AD%E5%9B%BD%E3%80%8B%E6%91%98%E6%8A%84/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="/pdfjs/web/viewer.html?file=/pdf/《在工作中，看到中国》摘抄.pdf">PDF全屏浏览（PDF View in FullScreen）</a></p><iframe src='/pdfjs/web/viewer.html?file=/pdf/《在工作中，看到中国》摘抄.pdf' width="100%" height="800px"></iframe>]]></content>
    
    
    <categories>
      
      <category>书籍摘抄</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍摘抄</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（六十五）LangChain中的重连（retry）机制</title>
    <link href="/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%BA%94%EF%BC%89LangChain%E4%B8%AD%E7%9A%84%E9%87%8D%E8%BF%9E%EF%BC%88retry%EF%BC%89%E6%9C%BA%E5%88%B6/"/>
    <url>/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%BA%94%EF%BC%89LangChain%E4%B8%AD%E7%9A%84%E9%87%8D%E8%BF%9E%EF%BC%88retry%EF%BC%89%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>关于LangChain入门，读者可参考文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E5%85%AD%EF%BC%89LangChain%E5%85%A5%E9%97%A8/">NLP（五十六）LangChain入门</a>。</p><p>本文将会介绍LangChain中的重连机制，并尝试给出定制化重连方案。</p><p>本文以LangChain中的对话功能（<code>ChatOpenAI</code>）为例。</p><h3 id="langchain中的重连机制">LangChain中的重连机制</h3><p>查看LangChain中对话功能（<code>ChatOpenAI</code>）的重连机制（retry），其源代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ChatOpenAI</span>(<span class="hljs-title class_ inherited__">BaseChatModel</span>):<br>...<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_create_retry_decorator</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-type">Callable</span>[[<span class="hljs-type">Any</span>], <span class="hljs-type">Any</span>]:<br>        <span class="hljs-keyword">import</span> openai<br><br>        min_seconds = <span class="hljs-number">1</span><br>        max_seconds = <span class="hljs-number">60</span><br>        <span class="hljs-comment"># Wait 2^x * 1 second between each retry starting with</span><br>        <span class="hljs-comment"># 4 seconds, then up to 10 seconds, then 10 seconds afterwards</span><br>        <span class="hljs-keyword">return</span> retry(<br>            reraise=<span class="hljs-literal">True</span>,<br>            stop=stop_after_attempt(self.max_retries),<br>            wait=wait_exponential(multiplier=<span class="hljs-number">1</span>, <span class="hljs-built_in">min</span>=min_seconds, <span class="hljs-built_in">max</span>=max_seconds),<br>            retry=(<br>                retry_if_exception_type(openai.error.Timeout)<br>                | retry_if_exception_type(openai.error.APIError)<br>                | retry_if_exception_type(openai.error.APIConnectionError)<br>                | retry_if_exception_type(openai.error.RateLimitError)<br>                | retry_if_exception_type(openai.error.ServiceUnavailableError)<br>            ),<br>            before_sleep=before_sleep_log(logger, logging.WARNING),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">completion_with_retry</span>(<span class="hljs-params">self, **kwargs: <span class="hljs-type">Any</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>        <span class="hljs-string">&quot;&quot;&quot;Use tenacity to retry the completion call.&quot;&quot;&quot;</span><br>        retry_decorator = self._create_retry_decorator()<br><br><span class="hljs-meta">        @retry_decorator</span><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">_completion_with_retry</span>(<span class="hljs-params">**kwargs: <span class="hljs-type">Any</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>            <span class="hljs-keyword">return</span> self.client.create(**kwargs)<br><br>        <span class="hljs-keyword">return</span> _completion_with_retry(**kwargs)<br></code></pre></td></tr></table></figure><p>可以看到，其编码方式为硬编码（hardcore），采用<code>tenacity</code>模块实现重连机制，对于支持的报错情形，比如<code>openai.error.Timeout,  openai.error.APIError</code>等，会尝试重连，最小等待时间为1s，最大等待时间为60s，每次重连等待时间会乘以2。</p><h3 id="简单重连">简单重连</h3><p>我们尝试用一个错误的OpenAI key进行对话，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat_bot</span>(<span class="hljs-params">input_text: <span class="hljs-built_in">str</span></span>):<br>    llm = ChatOpenAI(temperature=<span class="hljs-number">0</span>,<br>                     model_name=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>                     openai_api_key=<span class="hljs-string">&quot;sk-xxx&quot;</span>,<br>                     max_retries=<span class="hljs-number">5</span>)<br>    <span class="hljs-keyword">return</span> llm.predict(input_text)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    text = <span class="hljs-string">&#x27;中国的首都是哪里？&#x27;</span><br>    <span class="hljs-built_in">print</span>(chat_bot(text))<br></code></pre></td></tr></table></figure><p>尽管我们在代码中设置了重连最大次数（<code>max_retries</code>），代码运行时会直接报错，不会重连，原因是LangChain中的对话功能重连机制没有支持<code>openai.error.AuthenticationError</code>。输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openai.error.AuthenticationError: Incorrect API key provided: sk-xxx. You can find your API key at https://platform.openai.com/account/api-keys.<br></code></pre></td></tr></table></figure><p>此时，我们尝试在源代码的基础上做简单的定制，使得其支持<code>openai.error.AuthenticationError</code>错误类型，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> openai<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Callable</span>, <span class="hljs-type">Any</span><br><span class="hljs-keyword">from</span> tenacity <span class="hljs-keyword">import</span> (<br>    before_sleep_log,<br>    retry,<br>    retry_if_exception_type,<br>    stop_after_attempt,<br>    wait_exponential,<br>)<br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">import</span> logging<br><br><br>logger = logging.getLogger(__name__)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyChatOpenAI</span>(<span class="hljs-title class_ inherited__">ChatOpenAI</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_create_retry_decorator</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-type">Callable</span>[[<span class="hljs-type">Any</span>], <span class="hljs-type">Any</span>]:<br>        min_seconds = <span class="hljs-number">1</span><br>        max_seconds = <span class="hljs-number">60</span><br>        <span class="hljs-comment"># Wait 2^x * 1 second between each retry starting with</span><br>        <span class="hljs-comment"># 4 seconds, then up to 10 seconds, then 10 seconds after wards</span><br>        <span class="hljs-keyword">return</span> retry(<br>            reraise=<span class="hljs-literal">True</span>,<br>            stop=stop_after_attempt(self.max_retries),<br>            wait=wait_exponential(multiplier=<span class="hljs-number">1</span>, <span class="hljs-built_in">min</span>=min_seconds, <span class="hljs-built_in">max</span>=max_seconds),<br>            retry=(<br>                retry_if_exception_type(openai.error.Timeout)<br>                | retry_if_exception_type(openai.error.APIError)<br>                | retry_if_exception_type(openai.error.APIConnectionError)<br>                | retry_if_exception_type(openai.error.RateLimitError)<br>                | retry_if_exception_type(openai.error.ServiceUnavailableError)<br>                <span class="hljs-comment"># add new error</span><br>                | retry_if_exception_type(openai.error.AuthenticationError)<br>            ),<br>            before_sleep=before_sleep_log(logger, logging.WARNING),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">completion_with_retry</span>(<span class="hljs-params">self, **kwargs: <span class="hljs-type">Any</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>        <span class="hljs-string">&quot;&quot;&quot;Use tenacity to retry the completion call.&quot;&quot;&quot;</span><br>        retry_decorator = self._create_retry_decorator()<br><br><span class="hljs-meta">        @retry_decorator</span><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">_completion_with_retry</span>(<span class="hljs-params">**kwargs: <span class="hljs-type">Any</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>            <span class="hljs-keyword">return</span> self.client.create(**kwargs)<br><br>        <span class="hljs-keyword">return</span> _completion_with_retry(**kwargs)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat_bot</span>(<span class="hljs-params">input_text: <span class="hljs-built_in">str</span></span>):<br>    llm = MyChatOpenAI(temperature=<span class="hljs-number">0</span>,<br>                       model_name=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>                       openai_api_key=<span class="hljs-string">&quot;sk-xxx&quot;</span>,<br>                       max_retries=<span class="hljs-number">5</span>)<br>    <span class="hljs-keyword">return</span> llm.predict(input_text)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    text = <span class="hljs-string">&#x27;中国的首都是哪里？&#x27;</span><br>    <span class="hljs-built_in">print</span>(chat_bot(text))<br></code></pre></td></tr></table></figure><p>分析上述代码，我们在继承ChatOpenAI类的基础上重新创建MyChatOpenAI类，在_create_retry_decorator中的重连错误情形中加入了<code>openai.error.AuthenticationError</code>错误类型，此时代码输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">Retrying __main__.MyChatOpenAI.completion_with_retry.&lt;locals&gt;._completion_with_retry <span class="hljs-keyword">in</span> 1.0 seconds as it raised AuthenticationError: Incorrect API key provided: sk-xxx. You can find your API key at https://platform.openai.com/account/api-keys..<br>Retrying __main__.MyChatOpenAI.completion_with_retry.&lt;locals&gt;._completion_with_retry <span class="hljs-keyword">in</span> 2.0 seconds as it raised AuthenticationError: Incorrect API key provided: sk-xxx. You can find your API key at https://platform.openai.com/account/api-keys..<br>Retrying __main__.MyChatOpenAI.completion_with_retry.&lt;locals&gt;._completion_with_retry <span class="hljs-keyword">in</span> 4.0 seconds as it raised AuthenticationError: Incorrect API key provided: sk-xxx. You can find your API key at https://platform.openai.com/account/api-keys..<br>Retrying __main__.MyChatOpenAI.completion_with_retry.&lt;locals&gt;._completion_with_retry <span class="hljs-keyword">in</span> 8.0 seconds as it raised AuthenticationError: Incorrect API key provided: sk-xxx. You can find your API key at https://platform.openai.com/account/api-keys..<br>Traceback (most recent call last):<br>    ......<br>openai.error.AuthenticationError: Incorrect API key provided: sk-xxx. You can find your API key at https://platform.openai.com/account/api-keys.<br></code></pre></td></tr></table></figure><p>从输出结果中，我们可以看到，该代码确实对<code>openai.error.AuthenticationError</code>错误类型进行了重连，按照源代码的方式进行重连，一共尝试了5次重连，每次重连等待时间是上一次的两倍。</p><h3 id="定制化重连">定制化重连</h3><p>LangChain中的重连机制也支持定制化。</p><p>假设我们的使用场景：某个OpenAIkey在调用过程中失效了，那么在重连时希望能快速切换至某个能正常使用的OpenAIkey，以下为示例代码（仅需要修改<code>completion_with_retry</code>函数）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">completion_with_retry</span>(<span class="hljs-params">self, **kwargs: <span class="hljs-type">Any</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;Use tenacity to retry the completion call.&quot;&quot;&quot;</span><br>    retry_decorator = self._create_retry_decorator()<br><br><span class="hljs-meta">    @retry_decorator</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_completion_with_retry</span>(<span class="hljs-params">**kwargs: <span class="hljs-type">Any</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>    <span class="hljs-comment"># 重连机制定制化(custom retry)</span><br>        kwargs[<span class="hljs-string">&#x27;api_key&#x27;</span>] = <span class="hljs-string">&#x27;right openai key&#x27;</span><br>        <span class="hljs-keyword">return</span> self.client.create(**kwargs)<br><br>    <span class="hljs-keyword">return</span> _completion_with_retry(**kwargs)<br></code></pre></td></tr></table></figure><p>此时就能进行正常的对话功能了。</p><h3 id="总结">总结</h3><p>本文介绍了LangChain中的重连机制，并尝试给出定制化重连方案，希望能对读者有所帮助。</p><p>笔者的个人博客网址为：<ahref="https://percent4.github.io/">https://percent4.github.io/</a>,欢迎大家访问~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>LangChain</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（六十四）使用FastChat计算LLaMA-2模型的token长度</title>
    <link href="/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8FastChat%E8%AE%A1%E7%AE%97LLaMA-2%E6%A8%A1%E5%9E%8B%E7%9A%84token%E9%95%BF%E5%BA%A6/"/>
    <url>/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8FastChat%E8%AE%A1%E7%AE%97LLaMA-2%E6%A8%A1%E5%9E%8B%E7%9A%84token%E9%95%BF%E5%BA%A6/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="llama-2模型部署">LLaMA-2模型部署</h3><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%B9%9D%EF%BC%89%E4%BD%BF%E7%94%A8FastChat%E9%83%A8%E7%BD%B2%E7%99%BE%E5%B7%9D%E5%A4%A7%E6%A8%A1%E5%9E%8B/">NLP（五十九）使用FastChat部署百川大模型</a>中，笔者介绍了<code>FastChat</code>框架，以及如何使用<code>FastChat</code>来部署百川模型。</p><p>本文将会部署LLaMA-270B模型，使得其兼容OpenAI的调用风格。部署的<code>Dockerfile</code>文件如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">FROM</span> <span class="hljs-string">nvidia/cuda:11.7.1-runtime-ubuntu20.04</span><br><br><span class="hljs-string">RUN</span> <span class="hljs-string">apt-get</span> <span class="hljs-string">update</span> <span class="hljs-string">-y</span> <span class="hljs-string">&amp;&amp;</span> <span class="hljs-string">apt-get</span> <span class="hljs-string">install</span> <span class="hljs-string">-y</span> <span class="hljs-string">python3.9</span> <span class="hljs-string">python3.9-distutils</span> <span class="hljs-string">curl</span><br><span class="hljs-string">RUN</span> <span class="hljs-string">curl</span> <span class="hljs-string">https://bootstrap.pypa.io/get-pip.py</span> <span class="hljs-string">-o</span> <span class="hljs-string">get-pip.py</span><br><span class="hljs-string">RUN</span> <span class="hljs-string">python3.9</span> <span class="hljs-string">get-pip.py</span><br><span class="hljs-string">RUN</span> <span class="hljs-string">pip3</span> <span class="hljs-string">install</span> <span class="hljs-string">fschat</span><br></code></pre></td></tr></table></figure><p><code>Docker-compose.yml</code>文件如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.9&quot;</span><br><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">fastchat-controller:</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">.</span><br>      <span class="hljs-attr">dockerfile:</span> <span class="hljs-string">Dockerfile</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">fastchat:latest</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;21001:21001&quot;</span><br>    <span class="hljs-attr">entrypoint:</span> [<span class="hljs-string">&quot;python3.9&quot;</span>, <span class="hljs-string">&quot;-m&quot;</span>, <span class="hljs-string">&quot;fastchat.serve.controller&quot;</span>, <span class="hljs-string">&quot;--host&quot;</span>, <span class="hljs-string">&quot;0.0.0.0&quot;</span>, <span class="hljs-string">&quot;--port&quot;</span>, <span class="hljs-string">&quot;21001&quot;</span>]<br><br>  <span class="hljs-attr">fastchat-model-worker:</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">.</span><br>      <span class="hljs-attr">dockerfile:</span> <span class="hljs-string">Dockerfile</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./model:/root/model</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">fastchat:latest</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;21002:21002&quot;</span><br>    <span class="hljs-attr">deploy:</span><br>      <span class="hljs-attr">resources:</span><br>        <span class="hljs-attr">reservations:</span><br>          <span class="hljs-attr">devices:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">driver:</span> <span class="hljs-string">nvidia</span><br>              <span class="hljs-attr">device_ids:</span> [<span class="hljs-string">&#x27;0&#x27;</span>, <span class="hljs-string">&#x27;1&#x27;</span>]<br>              <span class="hljs-attr">capabilities:</span> [<span class="hljs-string">gpu</span>]<br>    <span class="hljs-attr">entrypoint:</span> [<span class="hljs-string">&quot;python3.9&quot;</span>, <span class="hljs-string">&quot;-m&quot;</span>, <span class="hljs-string">&quot;fastchat.serve.model_worker&quot;</span>, <span class="hljs-string">&quot;--model-names&quot;</span>, <span class="hljs-string">&quot;llama2-70b-chat&quot;</span>, <span class="hljs-string">&quot;--model-path&quot;</span>, <span class="hljs-string">&quot;/root/model/llama2/Llama-2-70b-chat-hf&quot;</span>, <span class="hljs-string">&quot;--num-gpus&quot;</span>, <span class="hljs-string">&quot;2&quot;</span>, <span class="hljs-string">&quot;--gpus&quot;</span>,  <span class="hljs-string">&quot;0,1&quot;</span>, <span class="hljs-string">&quot;--worker-address&quot;</span>, <span class="hljs-string">&quot;http://fastchat-model-worker:21002&quot;</span>, <span class="hljs-string">&quot;--controller-address&quot;</span>, <span class="hljs-string">&quot;http://fastchat-controller:21001&quot;</span>, <span class="hljs-string">&quot;--host&quot;</span>, <span class="hljs-string">&quot;0.0.0.0&quot;</span>, <span class="hljs-string">&quot;--port&quot;</span>, <span class="hljs-string">&quot;21002&quot;</span>]<br><br>  <span class="hljs-attr">fastchat-api-server:</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">.</span><br>      <span class="hljs-attr">dockerfile:</span> <span class="hljs-string">Dockerfile</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">fastchat:latest</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;8000:8000&quot;</span><br>    <span class="hljs-attr">entrypoint:</span> [<span class="hljs-string">&quot;python3.9&quot;</span>, <span class="hljs-string">&quot;-m&quot;</span>, <span class="hljs-string">&quot;fastchat.serve.openai_api_server&quot;</span>, <span class="hljs-string">&quot;--controller-address&quot;</span>, <span class="hljs-string">&quot;http://fastchat-controller:21001&quot;</span>, <span class="hljs-string">&quot;--host&quot;</span>, <span class="hljs-string">&quot;0.0.0.0&quot;</span>, <span class="hljs-string">&quot;--port&quot;</span>, <span class="hljs-string">&quot;8000&quot;</span>]<br></code></pre></td></tr></table></figure><p>部署成功后，会占用2张A100，每张A100占用约66G显存。</p><p>测试模型是否部署成功：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/models<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;list&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;data&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;llama2-70b-chat&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;model&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1691504717</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;owned_by&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;fastchat&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;root&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;llama2-70b-chat&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;parent&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;permission&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;modelperm-3XG6nzMAqfEkwfNqQ52fdv&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;model_permission&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1691504717</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_create_engine&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_sampling&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_logprobs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_search_indices&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_view&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_fine_tuning&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;organization&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;*&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;group&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;is_blocking&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>部署LLaMA-2 70B模型成功！</p><h3 id="prompt-token长度计算">Prompt token长度计算</h3><p>在<code>FastChat</code>的Github开源项目中，项目提供了计算Prompt的token长度的API，文件路径为：fastchat/serve/model_worker.py，调用方法为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs curl">curl --location &#x27;localhost:21002/count_token&#x27; \<br>--header &#x27;Content-Type: application/json&#x27; \<br>--data &#x27;&#123;&quot;prompt&quot;: &quot;What is your name?&quot;&#125;&#x27;<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;count&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">6</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;error_code&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="conversation-token长度计算">Conversation token长度计算</h3><p>在<code>FastChat</code>中计算Conversation（对话）的token长度较为麻烦。</p><p>首先我们需要获取LLaMA-270B模型的<code>对话配置</code>，调用API如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl --location --request POST <span class="hljs-string">&#x27;http://localhost:21002/worker_get_conv_template&#x27;</span><br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>&#x27;conv&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>&#x27;messages&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>          &#x27;name&#x27;<span class="hljs-punctuation">:</span> &#x27;llama<span class="hljs-number">-2</span>&#x27;<span class="hljs-punctuation">,</span><br>          &#x27;offset&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>          &#x27;roles&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>&#x27;<span class="hljs-punctuation">[</span>INST<span class="hljs-punctuation">]</span>&#x27;<span class="hljs-punctuation">,</span> &#x27;<span class="hljs-punctuation">[</span>/INST<span class="hljs-punctuation">]</span>&#x27;<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>          &#x27;sep&#x27;<span class="hljs-punctuation">:</span> &#x27; &#x27;<span class="hljs-punctuation">,</span><br>          &#x27;sep2&#x27;<span class="hljs-punctuation">:</span> &#x27; &lt;/s&gt;&lt;s&gt;&#x27;<span class="hljs-punctuation">,</span><br>          &#x27;sep_style&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-number">7</span><span class="hljs-punctuation">,</span><br>          &#x27;stop_str&#x27;<span class="hljs-punctuation">:</span> None<span class="hljs-punctuation">,</span><br>          &#x27;stop_token_ids&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>          &#x27;system_message&#x27;<span class="hljs-punctuation">:</span> &#x27;You are a helpful<span class="hljs-punctuation">,</span> respectful and honest &#x27;<br>                            &#x27;assistant. Always answer as helpfully as &#x27;<br>                            &#x27;possible<span class="hljs-punctuation">,</span> while being safe. Your answers should &#x27;<br>                            &#x27;not include any harmful<span class="hljs-punctuation">,</span> unethical<span class="hljs-punctuation">,</span> racist<span class="hljs-punctuation">,</span> &#x27;<br>                            &#x27;sexist<span class="hljs-punctuation">,</span> toxic<span class="hljs-punctuation">,</span> dangerous<span class="hljs-punctuation">,</span> or illegal content. &#x27;<br>                            &#x27;Please ensure that your responses are socially &#x27;<br>                            &#x27;unbiased and positive in nature.\n&#x27;<br>                            &#x27;\n&#x27;<br>                            &#x27;If a question does not make any sense<span class="hljs-punctuation">,</span> or is not &#x27;<br>                            &#x27;factually coherent<span class="hljs-punctuation">,</span> explain why instead of &#x27;<br>                            <span class="hljs-string">&quot;answering something not correct. If you don&#x27;t &quot;</span><br>                            <span class="hljs-string">&quot;know the answer to a question, please don&#x27;t share &quot;</span><br>                            &#x27;<span class="hljs-literal"><span class="hljs-keyword">false</span></span> information.&#x27;<span class="hljs-punctuation">,</span><br>          &#x27;system_template&#x27;<span class="hljs-punctuation">:</span> &#x27;<span class="hljs-punctuation">[</span>INST<span class="hljs-punctuation">]</span> &lt;&lt;SYS&gt;&gt;\n<span class="hljs-punctuation">&#123;</span>system_message<span class="hljs-punctuation">&#125;</span>\n&lt;&lt;/SYS&gt;&gt;\n\n&#x27;<span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>在<code>FastChat</code>中的对话文件（fastchat/conversation.py）中，提供了对话加工的代码，这里不再展示，使用时直接复制整个文件即可，该文件不依赖任何第三方模块。</p><p>我们需要将对话按照OpenAI的方式加工成对应的Prompt，输入的对话（messages）如下：</p><blockquote><p>messages = [{"role": "system", "content": "You are Jack, you are 20years old, answer questions with humor."}, {"role": "user", "content":"What is your name?"},{"role": "assistant", "content": " Well, well,well! Look who's asking the questions now! My name is Jack, but you cancall me the king of the castle, the lord of the rings, or the prince ofthe pizza party. Whatever floats your boat, my friend!"}, {"role":"user", "content": "How old are you?"}, {"role": "assistant", "content":" Oh, you want to know my age? Well, let's just say I'm older than abottle of wine but younger than a bottle of whiskey. I'm like a finecheese, getting better with age, but still young enough to party likeit's 1999!"}, {"role": "user", "content": "Where is yourhometown?"}]</p></blockquote><p>Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai </span><br><span class="hljs-comment"># @file: prompt.py</span><br><span class="hljs-comment"># @time: 2023/8/8 19:24</span><br><span class="hljs-keyword">from</span> conversation <span class="hljs-keyword">import</span> Conversation, SeparatorStyle<br><br>messages = [&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are Jack, you are 20 years old, answer questions with humor.&quot;</span>&#125;, &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;What is your name?&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot; Well, well, well! Look who&#x27;s asking the questions now! My name is Jack, but you can call me the king of the castle, the lord of the rings, or the prince of the pizza party. Whatever floats your boat, my friend!&quot;</span>&#125;, &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;How old are you?&quot;</span>&#125;, &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot; Oh, you want to know my age? Well, let&#x27;s just say I&#x27;m older than a bottle of wine but younger than a bottle of whiskey. I&#x27;m like a fine cheese, getting better with age, but still young enough to party like it&#x27;s 1999!&quot;</span>&#125;, &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Where is your hometown?&quot;</span>&#125;]<br><br>llama2_conv = &#123;<span class="hljs-string">&quot;conv&quot;</span>:&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;llama-2&quot;</span>,<span class="hljs-string">&quot;system_template&quot;</span>:<span class="hljs-string">&quot;[INST] &lt;&lt;SYS&gt;&gt;\n&#123;system_message&#125;\n&lt;&lt;/SYS&gt;&gt;\n\n&quot;</span>,<span class="hljs-string">&quot;system_message&quot;</span>:<span class="hljs-string">&quot;You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don&#x27;t know the answer to a question, please don&#x27;t share false information.&quot;</span>,<span class="hljs-string">&quot;roles&quot;</span>:[<span class="hljs-string">&quot;[INST]&quot;</span>,<span class="hljs-string">&quot;[/INST]&quot;</span>],<span class="hljs-string">&quot;messages&quot;</span>:[],<span class="hljs-string">&quot;offset&quot;</span>:<span class="hljs-number">0</span>,<span class="hljs-string">&quot;sep_style&quot;</span>:<span class="hljs-number">7</span>,<span class="hljs-string">&quot;sep&quot;</span>:<span class="hljs-string">&quot; &quot;</span>,<span class="hljs-string">&quot;sep2&quot;</span>:<span class="hljs-string">&quot; &lt;/s&gt;&lt;s&gt;&quot;</span>,<span class="hljs-string">&quot;stop_str&quot;</span>:<span class="hljs-literal">None</span>,<span class="hljs-string">&quot;stop_token_ids&quot;</span>:[<span class="hljs-number">2</span>]&#125;&#125;<br>conv = llama2_conv[<span class="hljs-string">&#x27;conv&#x27;</span>]<br><br>conv = Conversation(<br>        name=conv[<span class="hljs-string">&quot;name&quot;</span>],<br>        system_template=conv[<span class="hljs-string">&quot;system_template&quot;</span>],<br>        system_message=conv[<span class="hljs-string">&quot;system_message&quot;</span>],<br>        roles=conv[<span class="hljs-string">&quot;roles&quot;</span>],<br>        messages=<span class="hljs-built_in">list</span>(conv[<span class="hljs-string">&quot;messages&quot;</span>]),  <span class="hljs-comment"># prevent in-place modification</span><br>        offset=conv[<span class="hljs-string">&quot;offset&quot;</span>],<br>        sep_style=SeparatorStyle(conv[<span class="hljs-string">&quot;sep_style&quot;</span>]),<br>        sep=conv[<span class="hljs-string">&quot;sep&quot;</span>],<br>        sep2=conv[<span class="hljs-string">&quot;sep2&quot;</span>],<br>        stop_str=conv[<span class="hljs-string">&quot;stop_str&quot;</span>],<br>        stop_token_ids=conv[<span class="hljs-string">&quot;stop_token_ids&quot;</span>],<br>    )<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(messages, <span class="hljs-built_in">str</span>):<br>    prompt = messages<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-keyword">for</span> message <span class="hljs-keyword">in</span> messages:<br>        msg_role = message[<span class="hljs-string">&quot;role&quot;</span>]<br>        <span class="hljs-keyword">if</span> msg_role == <span class="hljs-string">&quot;system&quot;</span>:<br>            conv.set_system_message(message[<span class="hljs-string">&quot;content&quot;</span>])<br>        <span class="hljs-keyword">elif</span> msg_role == <span class="hljs-string">&quot;user&quot;</span>:<br>            conv.append_message(conv.roles[<span class="hljs-number">0</span>], message[<span class="hljs-string">&quot;content&quot;</span>])<br>        <span class="hljs-keyword">elif</span> msg_role == <span class="hljs-string">&quot;assistant&quot;</span>:<br>            conv.append_message(conv.roles[<span class="hljs-number">1</span>], message[<span class="hljs-string">&quot;content&quot;</span>])<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;Unknown role: <span class="hljs-subst">&#123;msg_role&#125;</span>&quot;</span>)<br><br>    <span class="hljs-comment"># Add a blank message for the assistant.</span><br>    conv.append_message(conv.roles[<span class="hljs-number">1</span>], <span class="hljs-literal">None</span>)<br>    prompt = conv.get_prompt()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">repr</span>(prompt))<br></code></pre></td></tr></table></figure><p>加工后的Prompt如下：</p><figure class="highlight smalltalk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk"><span class="hljs-comment">&quot;[INST] &lt;&lt;SYS&gt;&gt;\nYou are Jack, you are 20 years old, answer questions with humor.\n&lt;&lt;/SYS&gt;&gt;\n\nWhat is your name?[/INST]  Well, well, well! Look who&#x27;s asking the questions now! My name is Jack, but you can call me the king of the castle, the lord of the rings, or the prince of the pizza party. Whatever floats your boat, my friend! &lt;/s&gt;&lt;s&gt;[INST] How old are you? [/INST]  Oh, you want to know my age? Well, let&#x27;s just say I&#x27;m older than a bottle of wine but younger than a bottle of whiskey. I&#x27;m like a fine cheese, getting better with age, but still young enough to party like it&#x27;s 1999! &lt;/s&gt;&lt;s&gt;[INST] Where is your hometown? [/INST]&quot;</span><br></code></pre></td></tr></table></figure><p>最后再调用计算Prompt的API（参考上节的Prompttoken长度计算），输出该对话的token长度为199.</p><p>我们使用<code>FastChat</code>提供的对话补充接口（v1/chat/completions）<code>验证</code>输入的对话token长度，请求命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl --location <span class="hljs-string">&#x27;http://localhost:8000/v1/chat/completions&#x27;</span> \<br>--header <span class="hljs-string">&#x27;Content-Type: application/json&#x27;</span> \<br>--data <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">    &quot;model&quot;: &quot;llama2-70b-chat&quot;,</span><br><span class="hljs-string">    &quot;messages&quot;: [&#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are Jack, you are 20 years old, answer questions with humor.&quot;&#125;, &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is your name?&quot;&#125;,&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot; Well, well, well! Look who&#x27;</span>\<span class="hljs-string">&#x27;&#x27;</span>s asking the questions now! My name is Jack, but you can call me the king of the castle, the lord of the rings, or the prince of the pizza party. Whatever floats your boat, my friend!<span class="hljs-string">&quot;&#125;, &#123;&quot;</span>role<span class="hljs-string">&quot;: &quot;</span>user<span class="hljs-string">&quot;, &quot;</span>content<span class="hljs-string">&quot;: &quot;</span>How old are you?<span class="hljs-string">&quot;&#125;, &#123;&quot;</span>role<span class="hljs-string">&quot;: &quot;</span>assistant<span class="hljs-string">&quot;, &quot;</span>content<span class="hljs-string">&quot;: &quot;</span> Oh, you want to know my age? Well, <span class="hljs-built_in">let</span><span class="hljs-string">&#x27;\&#x27;</span><span class="hljs-string">&#x27;s just say I&#x27;</span>\<span class="hljs-string">&#x27;&#x27;</span>m older than a bottle of wine but younger than a bottle of whiskey. I<span class="hljs-string">&#x27;\&#x27;</span><span class="hljs-string">&#x27;m like a fine cheese, getting better with age, but still young enough to party like it&#x27;</span>\<span class="hljs-string">&#x27;&#x27;</span>s 1999!<span class="hljs-string">&quot;&#125;, &#123;&quot;</span>role<span class="hljs-string">&quot;: &quot;</span>user<span class="hljs-string">&quot;, &quot;</span>content<span class="hljs-string">&quot;: &quot;</span>Where is your hometown?<span class="hljs-string">&quot;&#125;]</span><br><span class="hljs-string">&#125;&#x27;</span><br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;chatcmpl-mQxcaQcNSNMFahyHS7pamA&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;chat.completion&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1691506768</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;llama2-70b-chat&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;choices&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;index&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;message&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot; Ha! My hometown? Well, that&#x27;s a tough one. I&#x27;m like a bird, I don&#x27;t have a nest, I just fly around and land wherever the wind takes me. But if you really want to know, I&#x27;m from a place called \&quot;The Internet\&quot;. It&#x27;s a magical land where memes and cat videos roam free, and the Wi-Fi is always strong. It&#x27;s a beautiful place, you should visit sometime!&quot;</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;finish_reason&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;stop&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;usage&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;prompt_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">199</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;total_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">302</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;completion_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">103</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>注意，输出的prompt_tokens为199，这与我们刚才计算的对话token长度的结果是一致的！</p><h3 id="总结">总结</h3><p>本文主要介绍了如何在FastChat中部署LLaMA-2 70B模型，并详细介绍了Prompttoken长度计算以及对话（conversation）的token长度计算。希望能对读者有所帮助~</p><p>笔者的一点心得是：阅读源码真的很重要。</p><p>笔者的个人博客网址为：<ahref="https://percent4.github.io/">https://percent4.github.io/</a>,欢迎大家访问~</p><h3 id="参考网址">参考网址</h3><ol type="1"><li><p>NLP（五十九）使用FastChat部署百川大模型: <ahref="https://percent4.github.io/2023/07/11/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%B9%9D%EF%BC%89%E4%BD%BF%E7%94%A8FastChat%E9%83%A8%E7%BD%B2%E7%99%BE%E5%B7%9D%E5%A4%A7%E6%A8%A1%E5%9E%8B/">https://blog.csdn.net/jclian91/article/details/131650918</a></p></li><li><p>FastChat: <ahref="https://github.com/lm-sys/FastChat">https://github.com/lm-sys/FastChat</a></p></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>AIGC</tag>
      
      <tag>FastChat</tag>
      
      <tag>LLaMA-2</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Keras入门（八）K折交叉验证</title>
    <link href="/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AB%EF%BC%89K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/"/>
    <url>/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AB%EF%BC%89K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在文章<ahref="https://percent4.github.io/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E6%90%AD%E5%BB%BA%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88DNN%EF%BC%89%E8%A7%A3%E5%86%B3%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/">Keras入门（一）搭建深度神经网络（DNN）解决多分类问题</a>中，笔者介绍了如何搭建DNN模型来解决IRIS数据集的多分类问题。</p><p>本文将在此基础上介绍如何在Keras中实现K折交叉验证。</p><h3 id="什么是k折交叉验证">什么是K折交叉验证？</h3><p>K折交叉验证是机器学习中的一个专业术语，它指的是将原始数据随机分成K份，每次选择K-1份作为训练集，剩余的1份作为测试集。交叉验证重复K次，取K次准确率的平均值作为最终模型的评价指标。一般取K=10，即10折交叉验证，如下图所示：</p><figure><img src="/img/keras8_1.png" alt="10折交叉验证" /><figcaption aria-hidden="true">10折交叉验证</figcaption></figure><p>用交叉验证的目的是为了得到可靠稳定的模型。K折交叉验证能够有效提高模型的学习能力，类似于增加了训练样本数量，使得学习的模型更加稳健，鲁棒性更强。选择合适的K值能够有效避免过拟合。</p><h3 id="keras实现k折交叉验证">Keras实现K折交叉验证</h3><p>我们仍采用文章<ahref="https://percent4.github.io/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E6%90%AD%E5%BB%BA%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88DNN%EF%BC%89%E8%A7%A3%E5%86%B3%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/">Keras入门（一）搭建深度神经网络（DNN）解决多分类问题</a>中的模型，如下：</p><figure><img src="/img/keras8_2.png" alt="DNN模型结构图" /><figcaption aria-hidden="true">DNN模型结构图</figcaption></figure><p>同时，我们对IRIS数据集采用10折交叉验证，完整的实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># model_train.py</span><br><span class="hljs-comment"># Python 3.6.8, TensorFlow 2.3.0, Keras 2.4.3</span><br><span class="hljs-comment"># 导入模块</span><br><span class="hljs-keyword">import</span> keras <span class="hljs-keyword">as</span> K<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold<br><br><br><span class="hljs-comment"># 读取CSV数据集</span><br><span class="hljs-comment"># 该函数的传入参数为csv_file_path: csv文件路径</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">sv_file_path</span>):<br>    iris = pd.read_csv(sv_file_path)<br>    target_var = <span class="hljs-string">&#x27;class&#x27;</span>  <span class="hljs-comment"># 目标变量</span><br>    <span class="hljs-comment"># 数据集的特征</span><br>    features = <span class="hljs-built_in">list</span>(iris.columns)<br>    features.remove(target_var)<br>    <span class="hljs-comment"># 目标变量的类别</span><br>    Class = iris[target_var].unique()<br>    <span class="hljs-comment"># 目标变量的类别字典</span><br>    Class_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(Class, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(Class))))<br>    <span class="hljs-comment"># 增加一列target, 将目标变量转化为类别变量</span><br>    iris[<span class="hljs-string">&#x27;target&#x27;</span>] = iris[target_var].apply(<span class="hljs-keyword">lambda</span> x: Class_dict[x])<br><br>    <span class="hljs-keyword">return</span> features, <span class="hljs-string">&#x27;target&#x27;</span>, iris<br><br><br><span class="hljs-comment"># 创建模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_model</span>():<br>    init = K.initializers.glorot_uniform(seed=<span class="hljs-number">1</span>)<br>    simple_adam = K.optimizers.Adam()<br>    model = K.models.Sequential()<br>    model.add(K.layers.Dense(units=<span class="hljs-number">5</span>, input_dim=<span class="hljs-number">4</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br>    model.add(K.layers.Dense(units=<span class="hljs-number">6</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br>    model.add(K.layers.Dense(units=<span class="hljs-number">3</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>))<br>    model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;sparse_categorical_crossentropy&#x27;</span>, optimizer=simple_adam, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-comment"># 1. 读取CSV数据集</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Loading Iris data into memory&quot;</span>)<br>    n_split = <span class="hljs-number">10</span><br>    features, target, data = load_data(<span class="hljs-string">&quot;./iris_data.csv&quot;</span>)<br>    x = data[features]<br>    y = data[target]<br>    avg_accuracy = <span class="hljs-number">0</span><br>    avg_loss = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> train_index, test_index <span class="hljs-keyword">in</span> KFold(n_split).split(x):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;test index: &quot;</span>, test_index)<br>        x_train, x_test = x.iloc[train_index], x.iloc[test_index]<br>        y_train, y_test = y.iloc[train_index], y.iloc[test_index]<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;create model and train model&quot;</span>)<br>        model = create_model()<br>        model.fit(x_train, y_train, batch_size=<span class="hljs-number">1</span>, epochs=<span class="hljs-number">80</span>, verbose=<span class="hljs-number">0</span>)<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Model evaluation: &#x27;</span>, model.evaluate(x_test, y_test))<br>        avg_accuracy += model.evaluate(x_test, y_test)[<span class="hljs-number">1</span>]<br>        avg_loss += model.evaluate(x_test, y_test)[<span class="hljs-number">0</span>]<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;K fold average accuracy: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(avg_accuracy / n_split))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;K fold average accuracy: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(avg_loss / n_split))<br><br><br>main()<br></code></pre></td></tr></table></figure><p>模型的输出结果如下： |Iteration|loss|accuracy| |---|---|---||1|0.00056|1.0| |2|0.00021|1.0| |3|0.00022|1.0| |4|0.00608|1.0||5|0.21925|0.8667| |6|0.52390|0.8667| |7|0.00998|1.0| |8|0.04431|1.0||9|0.14590|1.0| |10|0.21286|0.8667| |avg|0.11633|0.9600|10折交叉验证的平均loss为0.11633,平均准确率为96.00%。</p><h3 id="总结">总结</h3><p>本文代码已存放至Github，网址为：https://github.com/percent4/Keras-K-fold-test。</p><p>感谢大家的阅读~</p><p>2020.1.24于上海浦东</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Keras</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Keras入门（七）使用Flask+Keras-bert构建模型预测服务</title>
    <link href="/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%83%EF%BC%89%E4%BD%BF%E7%94%A8Flask-Keras-bert%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E6%9C%8D%E5%8A%A1/"/>
    <url>/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%83%EF%BC%89%E4%BD%BF%E7%94%A8Flask-Keras-bert%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E6%9C%8D%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在文章<ahref="https://percent4.github.io/2023/07/10/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/">NLP（三十四）使用keras-bert实现序列标注任务</a>中，我们介绍了如何使用keras-bert模块，利用BERT中文预训练模型来实现序列标注任务的模型训练、模型评估和模型预测。其中，模型预测是通过加载生成的h5文件来实现的。</p><p>本文将会介绍如何使用Flask构建模型预测的HTTP服务。</p><p>我们遵循正常的思路，即先使用Keras加载保存后的h5模型文件，利用Flask对新输入的文本进行模型预测，最后给出预测结果。我们对人民日报命名实体实体数据集进行模型训练，采用文章<ahref="https://percent4.github.io/2023/07/10/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/">NLP（三十四）使用keras-bert实现序列标注任务</a>中的模型，训练后得到example_ner.h5文件，模型预测的HTTP服务脚本如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> traceback<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> get_custom_objects<br><span class="hljs-keyword">from</span> keras_contrib.layers <span class="hljs-keyword">import</span> CRF<br><span class="hljs-keyword">from</span> keras_contrib.losses <span class="hljs-keyword">import</span> crf_loss<br><span class="hljs-keyword">from</span> keras_contrib.metrics <span class="hljs-keyword">import</span> crf_accuracy<br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request<br><br><span class="hljs-keyword">from</span> model_train <span class="hljs-keyword">import</span> PreProcessInputData, id_label_dict<br><br><br><span class="hljs-comment"># 将BIO标签转化为方便阅读的json格式</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">bio_to_json</span>(<span class="hljs-params">string, tags</span>):<br>    item = &#123;<span class="hljs-string">&quot;string&quot;</span>: string, <span class="hljs-string">&quot;entities&quot;</span>: []&#125;<br>    entity_name = <span class="hljs-string">&quot;&quot;</span><br>    entity_start = <span class="hljs-number">0</span><br>    iCount = <span class="hljs-number">0</span><br>    entity_tag = <span class="hljs-string">&quot;&quot;</span><br><br>    <span class="hljs-keyword">for</span> c_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">min</span>(<span class="hljs-built_in">len</span>(string), <span class="hljs-built_in">len</span>(tags))):<br>        c, tag = string[c_idx], tags[c_idx]<br>        <span class="hljs-keyword">if</span> c_idx &lt; <span class="hljs-built_in">len</span>(tags)-<span class="hljs-number">1</span>:<br>            tag_next = tags[c_idx+<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">else</span>:<br>            tag_next = <span class="hljs-string">&#x27;&#x27;</span><br><br>        <span class="hljs-keyword">if</span> tag[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;B&#x27;</span>:<br>            entity_tag = tag[<span class="hljs-number">2</span>:]<br>            entity_name = c<br>            entity_start = iCount<br>            <span class="hljs-keyword">if</span> tag_next[<span class="hljs-number">2</span>:] != entity_tag:<br>                item[<span class="hljs-string">&quot;entities&quot;</span>].append(&#123;<span class="hljs-string">&quot;word&quot;</span>: c, <span class="hljs-string">&quot;start&quot;</span>: iCount, <span class="hljs-string">&quot;end&quot;</span>: iCount + <span class="hljs-number">1</span>, <span class="hljs-string">&quot;type&quot;</span>: tag[<span class="hljs-number">2</span>:]&#125;)<br>        <span class="hljs-keyword">elif</span> tag[<span class="hljs-number">0</span>] == <span class="hljs-string">&quot;I&quot;</span>:<br>            <span class="hljs-keyword">if</span> tag[<span class="hljs-number">2</span>:] != tags[c_idx-<span class="hljs-number">1</span>][<span class="hljs-number">2</span>:] <span class="hljs-keyword">or</span> tags[c_idx-<span class="hljs-number">1</span>][<span class="hljs-number">2</span>:] == <span class="hljs-string">&#x27;O&#x27;</span>:<br>                tags[c_idx] = <span class="hljs-string">&#x27;O&#x27;</span><br>                <span class="hljs-keyword">pass</span><br>            <span class="hljs-keyword">else</span>:<br>                entity_name = entity_name + c<br>                <span class="hljs-keyword">if</span> tag_next[<span class="hljs-number">2</span>:] != entity_tag:<br>                    item[<span class="hljs-string">&quot;entities&quot;</span>].append(&#123;<span class="hljs-string">&quot;word&quot;</span>: entity_name, <span class="hljs-string">&quot;start&quot;</span>: entity_start, <span class="hljs-string">&quot;end&quot;</span>: iCount + <span class="hljs-number">1</span>, <span class="hljs-string">&quot;type&quot;</span>: entity_tag&#125;)<br>                    entity_name = <span class="hljs-string">&#x27;&#x27;</span><br>        iCount += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> item<br><br><br>app = Flask(__name__)<br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/model/ner&quot;</span>, methods=[<span class="hljs-string">&quot;GET&quot;</span>, <span class="hljs-string">&quot;POST&quot;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_geo</span>():<br>    return_result = &#123;<span class="hljs-string">&quot;code&quot;</span>: <span class="hljs-number">200</span>, <span class="hljs-string">&quot;message&quot;</span>: <span class="hljs-string">&quot;success&quot;</span>, <span class="hljs-string">&quot;data&quot;</span>: []&#125;<br>    <span class="hljs-keyword">try</span>:<br>        text = request.get_json()[<span class="hljs-string">&quot;text&quot;</span>].replace(<span class="hljs-string">&quot; &quot;</span>, <span class="hljs-string">&quot;&quot;</span>)<br>        word_labels, seq_types = PreProcessInputData([text])<br><br>        <span class="hljs-comment"># 模型预测</span><br>        predicted = ner_model.predict([word_labels, seq_types])<br>        y = np.argmax(predicted[<span class="hljs-number">0</span>], axis=<span class="hljs-number">1</span>)<br>        tag = [id_label_dict[_] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> y]<br><br>        <span class="hljs-comment"># 输出预测结果</span><br>        result = bio_to_json(text, tag[<span class="hljs-number">1</span>:-<span class="hljs-number">1</span>])<br>        return_result[<span class="hljs-string">&quot;data&quot;</span>] = result<br><br>    <span class="hljs-keyword">except</span> Exception:<br>        return_result[<span class="hljs-string">&quot;code&quot;</span>] = <span class="hljs-number">400</span><br>        return_result[<span class="hljs-string">&quot;message&quot;</span>] = traceback.format_exc()<br><br>    <span class="hljs-keyword">return</span> json.dumps(return_result, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">2</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># 加载训练好的模型</span><br>    custom_objects = get_custom_objects()<br>    <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> &#123;<span class="hljs-string">&#x27;CRF&#x27;</span>: CRF, <span class="hljs-string">&#x27;crf_loss&#x27;</span>: crf_loss, <span class="hljs-string">&#x27;crf_accuracy&#x27;</span>: crf_accuracy&#125;.items():<br>        custom_objects[key] = value<br>    ner_model = load_model(<span class="hljs-string">&quot;example_ner.h5&quot;</span>, custom_objects=custom_objects)<br>    <span class="hljs-comment"># 启动HTTP服务</span><br>    app.run(host=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, port=<span class="hljs-number">25000</span>)<br></code></pre></td></tr></table></figure><p>看上去上面的服务并没有什么问题，但当我们进行HTTP请求时，报错如下：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-built_in">File</span> <span class="hljs-string">&quot;/home/jclian91/.conda/envs/py3-lmj/lib/python3.6/site-packages/tensorflow/python/framework/ops.py&quot;</span>, line <span class="hljs-number">3875</span>, <span class="hljs-function">in _as_graph_element_locked</span><br><span class="hljs-function">    raise <span class="hljs-title">ValueError</span><span class="hljs-params">(<span class="hljs-string">&quot;Tensor %s is not an element of this graph.&quot;</span> % obj)</span></span><br><span class="hljs-function">ValueError: Tensor Tensor(<span class="hljs-string">&quot;crf_1/cond/Merge:0&quot;</span>, shape=</span>(?, ?, <span class="hljs-number">7</span>), dtype=float32) is <span class="hljs-keyword">not</span> an element of <span class="hljs-keyword">this</span> graph.<br></code></pre></td></tr></table></figure><p>上网搜资料，发现这种错误非常常见，其中一种解决方法如下：</p><p>导入模块：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> keras.backend <span class="hljs-keyword">import</span> set_session<br></code></pre></td></tr></table></figure><p>在加载模型（load_model）的代码前，加几行代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">sess = tf.Session()<br>   graph = tf.get_default_graph()<br>   set_session(sess)<br></code></pre></td></tr></table></figure><p>同时在HTTP服务的模型预测（ner_model.predict）前，加几行代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型预测</span><br><span class="hljs-keyword">global</span> sess<br><span class="hljs-keyword">global</span> graph<br><span class="hljs-keyword">with</span> graph.as_default():<br>    set_session(sess)<br>    predicted = ner_model.predict([word_labels, seq_types])<br></code></pre></td></tr></table></figure><p>这样再次启动模型预测HTTP脚本，可以发现模型预测的HTTP请求是正常的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl --location --request POST <span class="hljs-string">&#x27;http://192.168.1.193:25000/model/ner&#x27;</span> \<br>&gt; --header <span class="hljs-string">&#x27;Content-Type: application/json&#x27;</span> \<br>&gt; --data-raw <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">&gt;     &quot;text&quot;: &quot;美国卫生部长阿扎尔辞职 原因曝光&quot;</span><br><span class="hljs-string">&gt; &#125;&#x27;</span><br>&#123;<br>  <span class="hljs-string">&quot;code&quot;</span>: 200,<br>  <span class="hljs-string">&quot;message&quot;</span>: <span class="hljs-string">&quot;success&quot;</span>,<br>  <span class="hljs-string">&quot;data&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;string&quot;</span>: <span class="hljs-string">&quot;美国卫生部长阿扎尔辞职原因曝光&quot;</span>,<br>    <span class="hljs-string">&quot;entities&quot;</span>: [<br>      &#123;<br>        <span class="hljs-string">&quot;word&quot;</span>: <span class="hljs-string">&quot;美国卫生部&quot;</span>,<br>        <span class="hljs-string">&quot;start&quot;</span>: 0,<br>        <span class="hljs-string">&quot;end&quot;</span>: 5,<br>        <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;ORG&quot;</span><br>      &#125;,<br>      &#123;<br>        <span class="hljs-string">&quot;word&quot;</span>: <span class="hljs-string">&quot;阿扎尔&quot;</span>,<br>        <span class="hljs-string">&quot;start&quot;</span>: 6,<br>        <span class="hljs-string">&quot;end&quot;</span>: 9,<br>        <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;PER&quot;</span><br>      &#125;<br>    ]<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>该脚本已上传至Github，网址为：<ahref="https://github.com/percent4/keras_bert_sequence_labeling/blob/master/model_server.py">https://github.com/percent4/keras_bert_sequence_labeling/blob/master/model_server.py</a>。</p><p>感谢阅读~</p><p>2021年1月16日于上海浦东</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Keras-bert</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Keras入门（六）模型训练实时可视化</title>
    <link href="/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AD%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%AE%9E%E6%97%B6%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    <url>/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AD%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%AE%9E%E6%97%B6%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在北京做某个项目的时候，客户要求能够对数据进行训练、预测，同时能导出模型，还有在页面上显示训练的进度。前面的几个要求都不难实现，但在页面上显示训练进度当时笔者并没有实现。</p><p>本文将会分享如何在Keras中将模型训练的过程实时可视化。</p><p>幸运的是，已经有人帮我们做好了这件事，这个项目名叫hualos，Github的访问网址为：https://github.com/fchollet/hualos，作者为François Chollet和EderSantana，前面的作者就是Keras的创造者，同时也是书籍《Deep Learning withPython》的作者。</p><p>大神的工作大大地方便了我们的使用。调用该项目仅需要三行代码，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> callbacks<br>remote = callbacks.RemoteMonitor(root=<span class="hljs-string">&#x27;http://localhost:9000&#x27;</span>)<br><br>model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, validation_data=(X_test, Y_test), callbacks=[remote])<br></code></pre></td></tr></table></figure><p>该项目使用Python2写的，用到的第三方模块为Flask,gevent，其中Flask为网页端框架，gevent用于并发。用到的JavaScript的第三方模块为D3.js和C3.js。该项目使用起来非常方便，只需要切换至hualos项目所在文件夹，然后<code>python api.py</code>即可。</p><p>下面将介绍其使用方法，我们的项目结构如下：</p><figure><img src="/img/keras6_1.png" alt="项目结构" /><figcaption aria-hidden="true">项目结构</figcaption></figure><p>其中hualos可以从Github上直接clone下来，笔者对代码和HTML网页稍作了修改，便于自己使用。model_train.py为Keras模型训练脚本，iris.csv为著名的鸢尾花数据集。</p><p>model_train.py中利用Keras搭建了简单的DNN模型对鸢尾花数据集进行训练及预测，该模型的介绍已经在文章<ahref="https://percent4.github.io/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E6%90%AD%E5%BB%BA%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88DNN%EF%BC%89%E8%A7%A3%E5%86%B3%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/">Keras入门（一）搭建深度神经网络（DNN）解决多分类问题</a>中给出，其完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入模块</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> keras <span class="hljs-keyword">as</span> K<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelBinarizer<br><span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> callbacks<br><br><br><span class="hljs-comment"># 读取CSV数据集，并拆分为训练集和测试集</span><br><span class="hljs-comment"># 该函数的传入参数为CSV_FILE_PATH: csv文件路径</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">CSV_FILE_PATH</span>):<br>    IRIS = pd.read_csv(CSV_FILE_PATH)<br>    target_var = <span class="hljs-string">&#x27;class&#x27;</span>  <span class="hljs-comment"># 目标变量</span><br>    <span class="hljs-comment"># 数据集的特征</span><br>    features = <span class="hljs-built_in">list</span>(IRIS.columns)<br>    features.remove(target_var)<br>    <span class="hljs-comment"># 目标变量的类别</span><br>    Class = IRIS[target_var].unique()<br>    <span class="hljs-comment"># 目标变量的类别字典</span><br>    Class_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(Class, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(Class))))<br>    <span class="hljs-comment"># 增加一列target, 将目标变量进行编码</span><br>    IRIS[<span class="hljs-string">&#x27;target&#x27;</span>] = IRIS[target_var].apply(<span class="hljs-keyword">lambda</span> x: Class_dict[x])<br>    <span class="hljs-comment"># 对目标变量进行0-1编码(One-hot Encoding)</span><br>    lb = LabelBinarizer()<br>    lb.fit(<span class="hljs-built_in">list</span>(Class_dict.values()))<br>    transformed_labels = lb.transform(IRIS[<span class="hljs-string">&#x27;target&#x27;</span>])<br>    y_bin_labels = []  <span class="hljs-comment"># 对多分类进行0-1编码的变量</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(transformed_labels.shape[<span class="hljs-number">1</span>]):<br>        y_bin_labels.append(<span class="hljs-string">&#x27;y&#x27;</span> + <span class="hljs-built_in">str</span>(i))<br>        IRIS[<span class="hljs-string">&#x27;y&#x27;</span> + <span class="hljs-built_in">str</span>(i)] = transformed_labels[:, i]<br>    <span class="hljs-comment"># 将数据集分为训练集和测试集</span><br>    train_x, test_x, train_y, test_y = train_test_split(IRIS[features], IRIS[y_bin_labels], \<br>                                                        train_size=<span class="hljs-number">0.7</span>, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span> train_x, test_x, train_y, test_y, Class_dict<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br><br>    <span class="hljs-comment"># 0. 开始</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nIris dataset using Keras&quot;</span>)<br>    np.random.seed(<span class="hljs-number">4</span>)<br>    tf.set_random_seed(<span class="hljs-number">13</span>)<br><br>    <span class="hljs-comment"># 1. 读取CSV数据集</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Loading Iris data into memory&quot;</span>)<br>    CSV_FILE_PATH = <span class="hljs-string">&#x27;iris.csv&#x27;</span><br>    train_x, test_x, train_y, test_y, Class_dict = load_data(CSV_FILE_PATH)<br><br>    <span class="hljs-comment"># 2. 定义模型</span><br>    init = K.initializers.glorot_uniform(seed=<span class="hljs-number">1</span>)<br>    simple_adam = K.optimizers.Adam()<br>    model = K.models.Sequential()<br>    model.add(K.layers.Dense(units=<span class="hljs-number">5</span>, input_dim=<span class="hljs-number">4</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br>    model.add(K.layers.Dense(units=<span class="hljs-number">6</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br>    model.add(K.layers.Dense(units=<span class="hljs-number">3</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>))<br>    model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=simple_adam, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br>    <span class="hljs-comment"># 3. 训练模型</span><br>    b_size = <span class="hljs-number">1</span><br>    max_epochs = <span class="hljs-number">100</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Starting training &quot;</span>)<br>    remote = callbacks.RemoteMonitor(root=<span class="hljs-string">&#x27;http://localhost:9000&#x27;</span>)<br>    h = model.fit(train_x, train_y, validation_data=(test_x, test_y), batch_size=b_size, epochs=max_epochs,<br>                  shuffle=<span class="hljs-literal">True</span>, verbose=<span class="hljs-number">1</span>, callbacks=[remote])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Training finished \n&quot;</span>)<br><br>    <span class="hljs-comment"># 4. 评估模型</span><br>    <span class="hljs-built_in">eval</span> = model.evaluate(test_x, test_y, verbose=<span class="hljs-number">0</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Evaluation on test data: loss = %0.6f accuracy = %0.2f%% \n&quot;</span> \<br>          % (<span class="hljs-built_in">eval</span>[<span class="hljs-number">0</span>], <span class="hljs-built_in">eval</span>[<span class="hljs-number">1</span>] * <span class="hljs-number">100</span>) )<br><br>    <span class="hljs-comment"># 5. 使用模型进行预测</span><br>    np.set_printoptions(precision=<span class="hljs-number">4</span>)<br>    unknown = np.array([[<span class="hljs-number">6.1</span>, <span class="hljs-number">3.1</span>, <span class="hljs-number">5.1</span>, <span class="hljs-number">1.1</span>]], dtype=np.float32)<br>    predicted = model.predict(unknown)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Using model to predict species for features: &quot;</span>)<br>    <span class="hljs-built_in">print</span>(unknown)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nPredicted softmax vector is: &quot;</span>)<br>    <span class="hljs-built_in">print</span>(predicted)<br>    species_dict = &#123;v:k <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> Class_dict.items()&#125;<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nPredicted species is: &quot;</span>)<br>    <span class="hljs-built_in">print</span>(species_dict[np.argmax(predicted)])<br></code></pre></td></tr></table></figure><p>我们切换至hualos文件夹，运行<code>python api.py</code>，然后再用Python3运行model_train.py文件，在浏览器中输入网址：http://localhost:9000，即可看到在网页中显示的模型训练的实施可视化的结果，图像如下：</p><p><img src="/img/keras6_2.png" /></p><p>因为这里无法给出视频，需要观看视频的读者可以移步网址：<ahref="https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484522&amp;idx=1&amp;sn=dab46a55945baf2411e30bd109cee76f&amp;chksm=fcb9bdfacbce34ec02f3e958988e9b400676d29f88c1efad5ce01fb1f4ce2f5f96ccf0e4af66&amp;token=1377830530&amp;lang=zh_CN#rd">https://mp.weixin.qq.com/s?__biz=MzU2NTYyMDk5MQ==&amp;mid=2247484522&amp;idx=1&amp;sn=dab46a55945baf2411e30bd109cee76f&amp;chksm=fcb9bdfacbce34ec02f3e958988e9b400676d29f88c1efad5ce01fb1f4ce2f5f96ccf0e4af66&amp;token=1377830530&amp;lang=zh_CN#rd</a>。</p><p>本项目的Github地址为：<ahref="https://github.com/percent4/keras_train_visualization">https://github.com/percent4/keras_train_visualization</a>。</p><p>本期分享到此结束，感谢大家阅读~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Keras</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Keras入门（五）搭建ResNet对CIFAR-10进行图像分类</title>
    <link href="/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%94%EF%BC%89%E6%90%AD%E5%BB%BAResNet%E5%AF%B9CIFAR-10%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    <url>/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%94%EF%BC%89%E6%90%AD%E5%BB%BAResNet%E5%AF%B9CIFAR-10%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会介绍如何利用Keras来搭建著名的ResNet神经网络模型，在CIFAR-10数据集进行图像分类。</p><h3 id="数据集介绍">数据集介绍</h3><p>CIFAR-10数据集是已经标注好的图像数据集，由Alex Krizhevsky, VinodNair, and GeoffreyHinton三人收集，其访问网址为：https://www.cs.toronto.edu/~kriz/cifar.html。</p><p>CIFAR-10数据集包含60000张尺寸为32x32的彩色图片，共分成10个分类（类别之间互相独立），每个类别一共6000张图片。该数据集划分为训练集和测试集，其中训练集5000张图片，测试集10000张图片。</p><p>该数据集分为5个训练批次和1个测试批次，每个批次一共10000张图片。测试批次包含从每个分类中随机选取的1000张图片。训练批次包含剩下的图片，但是每个训练批次的某些类别的图片会比其他类别多。</p><p>下图为从每个类别中选取的10张示例图片：</p><figure><img src="/img/keras5_1.png" alt="每个类别的示例图片" /><figcaption aria-hidden="true">每个类别的示例图片</figcaption></figure><p>本文中选用的CIFAR-10数据集下载网址为：https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz，文件夹内容如下：</p><figure><img src="/img/keras5_2.png" alt="CIFAR-10数据集Python版本" /><figcaption aria-hidden="true">CIFAR-10数据集Python版本</figcaption></figure><p>我们尝试着用Python程序读取里面的图片（图片可视化），Python程序代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> pickle<br><br><span class="hljs-comment"># 读取文件</span><br>fpath = <span class="hljs-string">&#x27;cifar-10-batches-py/data_batch_1&#x27;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(fpath, <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    d = pickle.load(f, encoding=<span class="hljs-string">&#x27;bytes&#x27;</span>)<br><br>data = d[<span class="hljs-string">b&#x27;data&#x27;</span>]<br>labels = d[<span class="hljs-string">b&#x27;labels&#x27;</span>]<br>data = data.reshape(data.shape[<span class="hljs-number">0</span>], <span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>).transpose(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># 保存第image_no张图片</span><br>strings=[<span class="hljs-string">&#x27;airplane&#x27;</span>, <span class="hljs-string">&#x27;automobile&#x27;</span>, <span class="hljs-string">&#x27;bird&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>, <span class="hljs-string">&#x27;deer&#x27;</span>,<br>         <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;frog&#x27;</span>, <span class="hljs-string">&#x27;horse&#x27;</span>, <span class="hljs-string">&#x27;ship&#x27;</span>, <span class="hljs-string">&#x27;truck&#x27;</span>]<br>image_no = <span class="hljs-number">1000</span><br>label = strings[labels[image_no]]<br>image = data[image_no,:,:,:]<br>cv2.imwrite(<span class="hljs-string">&#x27;%s.jpg&#x27;</span> % label, image)<br></code></pre></td></tr></table></figure><p>运行结果如下：</p><figure><img src="/img/keras5_3.png" alt="保存后的图片" /><figcaption aria-hidden="true">保存后的图片</figcaption></figure><p>图片虽然比较模糊，但还是可以看出这是一辆车，属于truck类别。</p><h3 id="resnet模型">ResNet模型</h3><p>图像分类中的经典模型为CNN，但CNN随着层数的增加，显示出<code>退化问题</code>，即深层次的网络反而不如稍浅层次的网络性能；这并非是过拟合导致的，因为在训练集上就显示出退化差距。而ResNet能较好地解决这个问题。</p><p>ResNet全名ResidualNetwork，中文名为残差神经网络，曾获得2015年ImageNet的冠军。ResNet的主要思想在于残差块，KaimingHe等设计了一种skip connection（或者shortcutconnections）结构，使得网络具有更强的identitymapping（恒等映射）的能力，从而拓展了网络的深度，同时也提升了网络的性能。残差块的结构如下：</p><figure><img src="/img/keras5_4.png" alt="残差块结构" /><figcaption aria-hidden="true">残差块结构</figcaption></figure><p>F(x)=H(x)−x，x为浅层的输出，H(x)为深层的输出,F(x)为夹在二者中间的的两层代表的变换，当浅层的x代表的特征已经足够成熟，如果任何对于特征x的改变都会让loss变大的话，F(x)会自动趋向于学习成为0，x则从恒等映射的路径继续传递。这样就在不增加计算成本的情况下实现了一开始的目的：在前向过程中，当浅层的输出已经足够成熟（optimal），让深层网络后面的层能够实现恒等映射的作用。</p><p>示例的残差块如下图：</p><figure><img src="/img/keras5_5.png" alt="示例残差块" /><figcaption aria-hidden="true">示例残差块</figcaption></figure><p>左边针对的是ResNet34浅层网络，右边针对的是ResNet50/101/152深层网络，右边这个又被叫做bottleneck。bottleneck 很好地减少了参数数量。</p><p>以上是关于ResNet的一些简单介绍，更多细节有待于研究。</p><h3 id="模型训练">模型训练</h3><p>我们利用Keras官方网站给出的ResNet模型对CIFAR-10进行图片分类。</p><p>项目结构如下图：</p><figure><img src="/img/keras5_6.png" alt="项目结构" /><figcaption aria-hidden="true">项目结构</figcaption></figure><p>其中load_data.py脚本将数据集导入进来，分为训练集和测试集，完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> keras<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Dense, Conv2D, BatchNormalization, Activation<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> AveragePooling2D, Input, Flatten<br><span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> Adam<br><span class="hljs-keyword">from</span> keras.callbacks <span class="hljs-keyword">import</span> ModelCheckpoint, LearningRateScheduler<br><span class="hljs-keyword">from</span> keras.callbacks <span class="hljs-keyword">import</span> ReduceLROnPlateau<br><span class="hljs-keyword">from</span> keras.preprocessing.image <span class="hljs-keyword">import</span> ImageDataGenerator<br><span class="hljs-keyword">from</span> keras.regularizers <span class="hljs-keyword">import</span> l2<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># 使用GPU,自己根据机器配置调整,默认不开启</span><br><span class="hljs-comment"># os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;4,5,6,7,8&quot;</span><br><br><span class="hljs-keyword">from</span> load_data <span class="hljs-keyword">import</span> load_data<br><br><span class="hljs-comment"># Training parameters</span><br>batch_size = <span class="hljs-number">32</span><br>epochs = <span class="hljs-number">100</span><br>num_classes = <span class="hljs-number">10</span><br><br><span class="hljs-comment"># Subtracting pixel mean improves accuracy</span><br>subtract_pixel_mean = <span class="hljs-literal">True</span><br><br>n = <span class="hljs-number">3</span><br><br><span class="hljs-comment"># Model version</span><br><span class="hljs-comment"># Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)</span><br>version = <span class="hljs-number">1</span><br><br><span class="hljs-comment"># Computed depth from supplied model parameter n</span><br>depth = n * <span class="hljs-number">6</span> + <span class="hljs-number">2</span><br><br><span class="hljs-comment"># Model name, depth and version</span><br>model_type = <span class="hljs-string">&#x27;ResNet%dv%d&#x27;</span> % (depth, version)<br><br><span class="hljs-comment"># Load the CIFAR10 data.</span><br>(x_train, y_train), (x_test, y_test) = load_data()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;load data successfully!&#x27;</span>)<br><br><span class="hljs-comment"># Input image dimensions.</span><br>input_shape = x_train.shape[<span class="hljs-number">1</span>:]<br><br><span class="hljs-comment"># Normalize data.</span><br>x_train = x_train.astype(<span class="hljs-string">&#x27;float32&#x27;</span>) / <span class="hljs-number">255</span><br>x_test = x_test.astype(<span class="hljs-string">&#x27;float32&#x27;</span>) / <span class="hljs-number">255</span><br><br><span class="hljs-comment"># If subtract pixel mean is enabled</span><br><span class="hljs-keyword">if</span> subtract_pixel_mean:<br>    x_train_mean = np.mean(x_train, axis=<span class="hljs-number">0</span>)<br>    x_train -= x_train_mean<br>    x_test -= x_train_mean<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;x_train shape:&#x27;</span>, x_train.shape)<br><span class="hljs-built_in">print</span>(x_train.shape[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;train samples&#x27;</span>)<br><span class="hljs-built_in">print</span>(x_test.shape[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;test samples&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;y_train shape:&#x27;</span>, y_train.shape)<br><br><span class="hljs-comment"># Convert class vectors to binary class matrices.</span><br>y_train = keras.utils.to_categorical(y_train, num_classes)<br>y_test = keras.utils.to_categorical(y_test, num_classes)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Begin model training...&#x27;</span>)<br><br><br><span class="hljs-comment"># Learning Rate Schedule</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lr_schedule</span>(<span class="hljs-params">epoch</span>):<br>    lr = <span class="hljs-number">1e-3</span><br>    <span class="hljs-keyword">if</span> epoch &gt; <span class="hljs-number">180</span>:<br>        lr *= <span class="hljs-number">0.5e-3</span><br>    <span class="hljs-keyword">elif</span> epoch &gt; <span class="hljs-number">160</span>:<br>        lr *= <span class="hljs-number">1e-3</span><br>    <span class="hljs-keyword">elif</span> epoch &gt; <span class="hljs-number">120</span>:<br>        lr *= <span class="hljs-number">1e-2</span><br>    <span class="hljs-keyword">elif</span> epoch &gt; <span class="hljs-number">80</span>:<br>        lr *= <span class="hljs-number">1e-1</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Learning rate: &#x27;</span>, lr)<br>    <span class="hljs-keyword">return</span> lr<br><br><br><span class="hljs-comment"># resnet layer</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet_layer</span>(<span class="hljs-params">inputs,</span><br><span class="hljs-params">                 num_filters=<span class="hljs-number">16</span>,</span><br><span class="hljs-params">                 kernel_size=<span class="hljs-number">3</span>,</span><br><span class="hljs-params">                 strides=<span class="hljs-number">1</span>,</span><br><span class="hljs-params">                 activation=<span class="hljs-string">&#x27;relu&#x27;</span>,</span><br><span class="hljs-params">                 batch_normalization=<span class="hljs-literal">True</span>,</span><br><span class="hljs-params">                 conv_first=<span class="hljs-literal">True</span></span>):<br><br>    conv = Conv2D(num_filters,<br>                  kernel_size=kernel_size,<br>                  strides=strides,<br>                  padding=<span class="hljs-string">&#x27;same&#x27;</span>,<br>                  kernel_initializer=<span class="hljs-string">&#x27;he_normal&#x27;</span>,<br>                  kernel_regularizer=l2(<span class="hljs-number">1e-4</span>))<br><br>    x = inputs<br>    <span class="hljs-keyword">if</span> conv_first:<br>        x = conv(x)<br>        <span class="hljs-keyword">if</span> batch_normalization:<br>            x = BatchNormalization()(x)<br>        <span class="hljs-keyword">if</span> activation <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            x = Activation(activation)(x)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">if</span> batch_normalization:<br>            x = BatchNormalization()(x)<br>        <span class="hljs-keyword">if</span> activation <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            x = Activation(activation)(x)<br>        x = conv(x)<br>    <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet_v1</span>(<span class="hljs-params">input_shape, depth, num_classes=<span class="hljs-number">10</span></span>):<br>    <span class="hljs-comment"># ResNet Version 1 Model builder [a]</span><br>    <span class="hljs-keyword">if</span> (depth - <span class="hljs-number">2</span>) % <span class="hljs-number">6</span> != <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;depth should be 6n+2 (eg 20, 32, 44 in [a])&#x27;</span>)<br>    <span class="hljs-comment"># Start model definition.</span><br>    num_filters = <span class="hljs-number">16</span><br>    num_res_blocks = <span class="hljs-built_in">int</span>((depth - <span class="hljs-number">2</span>) / <span class="hljs-number">6</span>)<br><br>    inputs = Input(shape=input_shape)<br>    x = resnet_layer(inputs=inputs)<br>    <span class="hljs-comment"># Instantiate the stack of residual units</span><br>    <span class="hljs-keyword">for</span> stack <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>        <span class="hljs-keyword">for</span> res_block <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_res_blocks):<br>            strides = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> stack &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> res_block == <span class="hljs-number">0</span>:  <span class="hljs-comment"># first layer but not first stack</span><br>                strides = <span class="hljs-number">2</span>  <span class="hljs-comment"># downsample</span><br>            y = resnet_layer(inputs=x,<br>                             num_filters=num_filters,<br>                             strides=strides)<br>            y = resnet_layer(inputs=y,<br>                             num_filters=num_filters,<br>                             activation=<span class="hljs-literal">None</span>)<br>            <span class="hljs-keyword">if</span> stack &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> res_block == <span class="hljs-number">0</span>:  <span class="hljs-comment"># first layer but not first stack</span><br>                <span class="hljs-comment"># linear projection residual shortcut connection to match</span><br>                <span class="hljs-comment"># changed dims</span><br>                x = resnet_layer(inputs=x,<br>                                 num_filters=num_filters,<br>                                 kernel_size=<span class="hljs-number">1</span>,<br>                                 strides=strides,<br>                                 activation=<span class="hljs-literal">None</span>,<br>                                 batch_normalization=<span class="hljs-literal">False</span>)<br>            x = keras.layers.add([x, y])<br>            x = Activation(<span class="hljs-string">&#x27;relu&#x27;</span>)(x)<br>        num_filters *= <span class="hljs-number">2</span><br><br>    <span class="hljs-comment"># Add classifier on top.</span><br>    <span class="hljs-comment"># v1 does not use BN after last shortcut connection-ReLU</span><br>    x = AveragePooling2D(pool_size=<span class="hljs-number">8</span>)(x)<br>    y = Flatten()(x)<br>    outputs = Dense(num_classes,<br>                    activation=<span class="hljs-string">&#x27;softmax&#x27;</span>,<br>                    kernel_initializer=<span class="hljs-string">&#x27;he_normal&#x27;</span>)(y)<br><br>    <span class="hljs-comment"># Instantiate model.</span><br>    model = Model(inputs=inputs, outputs=outputs)<br>    <span class="hljs-keyword">return</span> model<br><br><br>model = resnet_v1(input_shape=input_shape, depth=depth, num_classes=num_classes)<br>model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>,<br>              optimizer=Adam(lr=lr_schedule(<span class="hljs-number">0</span>)),<br>              metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br>model.summary()<br><span class="hljs-built_in">print</span>(model_type)<br><br><span class="hljs-comment"># Prepare model model saving directory.</span><br>save_dir = os.path.join(os.getcwd(), <span class="hljs-string">&#x27;saved_models&#x27;</span>)<br>model_name = <span class="hljs-string">&#x27;garbage_%s_model.&#123;epoch:03d&#125;.h5&#x27;</span> % model_type<br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.isdir(save_dir):<br>    os.makedirs(save_dir)<br>filepath = os.path.join(save_dir, model_name)<br><br><span class="hljs-comment"># Prepare callbacks for model saving and for learning rate adjustment.</span><br>checkpoint = ModelCheckpoint(filepath=filepath,<br>                             monitor=<span class="hljs-string">&#x27;val_acc&#x27;</span>,<br>                             verbose=<span class="hljs-number">1</span>,<br>                             save_best_only=<span class="hljs-literal">True</span>)<br><br>lr_scheduler = LearningRateScheduler(lr_schedule)<br><br>lr_reducer = ReduceLROnPlateau(factor=np.sqrt(<span class="hljs-number">0.1</span>),<br>                               cooldown=<span class="hljs-number">0</span>,<br>                               patience=<span class="hljs-number">5</span>,<br>                               min_lr=<span class="hljs-number">0.5e-6</span>)<br><br>callbacks = [checkpoint, lr_reducer, lr_scheduler]<br><br><span class="hljs-comment"># Run training, with data augmentation.</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Using real-time data augmentation.&#x27;</span>)<br><span class="hljs-comment"># This will do preprocessing and realtime data augmentation:</span><br>datagen = ImageDataGenerator(<br>        <span class="hljs-comment"># set input mean to 0 over the dataset</span><br>        featurewise_center=<span class="hljs-literal">False</span>,<br>        <span class="hljs-comment"># set each sample mean to 0</span><br>        samplewise_center=<span class="hljs-literal">False</span>,<br>        <span class="hljs-comment"># divide inputs by std of dataset</span><br>        featurewise_std_normalization=<span class="hljs-literal">False</span>,<br>        <span class="hljs-comment"># divide each input by its std</span><br>        samplewise_std_normalization=<span class="hljs-literal">False</span>,<br>        <span class="hljs-comment"># apply ZCA whitening</span><br>        zca_whitening=<span class="hljs-literal">False</span>,<br>        <span class="hljs-comment"># epsilon for ZCA whitening</span><br>        zca_epsilon=<span class="hljs-number">1e-06</span>,<br>        <span class="hljs-comment"># randomly rotate images in the range (deg 0 to 180)</span><br>        rotation_range=<span class="hljs-number">0</span>,<br>        <span class="hljs-comment"># randomly shift images horizontally</span><br>        width_shift_range=<span class="hljs-number">0.1</span>,<br>        <span class="hljs-comment"># randomly shift images vertically</span><br>        height_shift_range=<span class="hljs-number">0.1</span>,<br>        <span class="hljs-comment"># set range for random shear</span><br>        shear_range=<span class="hljs-number">0.</span>,<br>        <span class="hljs-comment"># set range for random zoom</span><br>        zoom_range=<span class="hljs-number">0.</span>,<br>        <span class="hljs-comment"># set range for random channel shifts</span><br>        channel_shift_range=<span class="hljs-number">0.</span>,<br>        <span class="hljs-comment"># set mode for filling points outside the input boundaries</span><br>        fill_mode=<span class="hljs-string">&#x27;nearest&#x27;</span>,<br>        <span class="hljs-comment"># value used for fill_mode = &quot;constant&quot;</span><br>        cval=<span class="hljs-number">0.</span>,<br>        <span class="hljs-comment"># randomly flip images</span><br>        horizontal_flip=<span class="hljs-literal">True</span>,<br>        <span class="hljs-comment"># randomly flip images</span><br>        vertical_flip=<span class="hljs-literal">False</span>,<br>        <span class="hljs-comment"># set rescaling factor (applied before any other transformation)</span><br>        rescale=<span class="hljs-literal">None</span>,<br>        <span class="hljs-comment"># set function that will be applied on each input</span><br>        preprocessing_function=<span class="hljs-literal">None</span>,<br>        <span class="hljs-comment"># image data format, either &quot;channels_first&quot; or &quot;channels_last&quot;</span><br>        data_format=<span class="hljs-literal">None</span>,<br>        <span class="hljs-comment"># fraction of images reserved for validation (strictly between 0 and 1)</span><br>        validation_split=<span class="hljs-number">0.0</span>)<br><br><span class="hljs-comment"># Compute quantities required for featurewise normalization</span><br><span class="hljs-comment"># (std, mean, and principal components if ZCA whitening is applied).</span><br>datagen.fit(x_train)<br><br><span class="hljs-comment"># Fit the model on the batches generated by datagen.flow().</span><br>model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),<br>                    steps_per_epoch=<span class="hljs-built_in">len</span>(x_train) // batch_size,<br>                    validation_data=(x_test, y_test),<br>                    epochs=epochs, verbose=<span class="hljs-number">1</span>, workers=<span class="hljs-number">4</span>,<br>                    callbacks=callbacks)<br><br><span class="hljs-comment"># Score trained model.</span><br>scores = model.evaluate(x_test, y_test, verbose=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Test loss:&#x27;</span>, scores[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Test accuracy:&#x27;</span>, scores[<span class="hljs-number">1</span>])<br></code></pre></td></tr></table></figure><p>输出的模型结构如下：</p><figure><img src="/img/keras5_7.png" alt="模型结构" /><figcaption aria-hidden="true">模型结构</figcaption></figure><p>在GPU上进行模型训练，训练结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">Test loss: 0.4439272038936615<br>Test accuracy: 0.9128<br></code></pre></td></tr></table></figure><figure><img src="/img/keras5_8.png" alt="训练过程输出" /><figcaption aria-hidden="true">训练过程输出</figcaption></figure><h3 id="总结">总结</h3><p>本项目已经开源，Github地址为：https://github.com/percent4/resnet_4_cifar10。</p><p>感谢大家阅读，有问题请批评指正~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Keras</tag>
      
      <tag>ResNet</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Keras入门（四）利用CNN模型轻松破解网站验证码</title>
    <link href="/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E5%9B%9B%EF%BC%89%E5%88%A9%E7%94%A8CNN%E6%A8%A1%E5%9E%8B%E8%BD%BB%E6%9D%BE%E7%A0%B4%E8%A7%A3%E7%BD%91%E7%AB%99%E9%AA%8C%E8%AF%81%E7%A0%81/"/>
    <url>/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E5%9B%9B%EF%BC%89%E5%88%A9%E7%94%A8CNN%E6%A8%A1%E5%9E%8B%E8%BD%BB%E6%9D%BE%E7%A0%B4%E8%A7%A3%E7%BD%91%E7%AB%99%E9%AA%8C%E8%AF%81%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="项目简介">项目简介</h3><p>在之前的文章<ahref="https://www.jianshu.com/p/b653c0781073">keras入门（三）搭建CNN模型破解网站验证码</a>中，笔者介绍介绍了如何用Keras来搭建CNN模型来破解网站的验证码，其中验证码含有字母和数字。</p><p>让我们一起回顾一下<ahref="https://www.jianshu.com/p/b653c0781073">keras入门（三）搭建CNN模型破解网站验证码</a>的处理思路：</p><ul><li><p>利用OpenCV对图像进行单个字符的切割，大概400多张图片；</p></li><li><p>对切割好的单个字符进行人工手动标记；</p></li><li><p>搭建合适的CNN模型，对标记好的数据集进行训练；</p></li><li><p>对于新的验证码，先切割单个字符，再对单个字符进行预测，组成总的预测结果。</p><p>这一次，笔者将会换种思路，使用CNN模型来破解网站的验证码。我们的数据集如下：</p></li></ul><p><img src="/img/keras4_1.png" /></p><p>一共是946张图片，这里只展示了一部分，可以看到，这些验证码全部由数字组成。那么，新的破解验证码的思路是什么呢？如下：</p><ul><li>直接对验证码进行标记，标记的结果见上图；</li><li>搭建合适的CNN模型对标记好的数据集进行训练；</li><li>对新验证码进行预测。</li></ul><p>这种思路的好处是，不需要对验证码进行繁琐的预处理，只需要简单的数据标记即可。</p><p>下面，笔者将会具体展示这个过程。</p><h3 id="数据标记">数据标记</h3><p>数据标记绝对是个累活，当我想到要对946张图片进行标记并重命名，而且还要保证标记的准确性的时候，我开始是有点拒绝的心态，毕竟这项工作费时费力，而且能不能保证识别的效果还是个未知数。</p><p>就这么纠结了一段时间，原本年前就想做的项目一直拖到了现在，后来我想，能不能写个脚本，能够帮助我快速地进行数据标注，并自动保存呢？这么想着，我就动手自己做了一个由Tornado实现的前端页面，可以帮助我快速地标记数据并保存图片，页面如下：</p><figure><img src="/img/keras4_2.png" alt="数据标记界面.png" /><figcaption aria-hidden="true">数据标记界面.png</figcaption></figure><p>界面虽然简陋，却能帮助我很好地提升数据标记的速度，只需要在value文本框中输入自己识别的结果，程序就能自动保存标记好的图片，并切换至下一张未标记的验证码。有了如此好的工具，结果我用了不到一小时就标记完了这946张验证码（其实是1000张，因为标记好的结果会有重复）。有机会笔者会介绍这个验证码标记的项目～</p><h3 id="模型训练">模型训练</h3><p>标记完验证码后，我们就利用这946张验证码作为训练数据，训练CNN模型。我们使用Keras框架，CNN模型的结构图如下：</p><p><img src="/img/keras4_3.png" /></p><p>模型训练的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># CNN模型训练</span><br><br><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> callbacks<br><br>characters = <span class="hljs-string">&#x27;0123456789&#x27;</span><br>width, height, n_len, n_class = <span class="hljs-number">50</span>, <span class="hljs-number">22</span>, <span class="hljs-number">4</span>, <span class="hljs-number">10</span><br><br><span class="hljs-comment"># 产生训练的一批图片，默认是32张图片</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gen</span>(<span class="hljs-params"><span class="hljs-built_in">dir</span>, batch_size=<span class="hljs-number">32</span></span>):<br>    X = np.zeros((batch_size, height, width, <span class="hljs-number">3</span>), dtype=np.uint8)<br>    y = [np.zeros((batch_size, n_class), dtype=np.uint8) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_len)]<br>    files = os.listdir(<span class="hljs-built_in">dir</span>)<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_size):<br>            path = random.choice(files)<br>            imagePixel = cv2.imread(<span class="hljs-built_in">dir</span>+<span class="hljs-string">&#x27;/&#x27;</span>+path, <span class="hljs-number">1</span>)<br>            filename = path[:<span class="hljs-number">4</span>]<br>            X[i] = imagePixel<br>            <span class="hljs-keyword">for</span> j, ch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(filename):<br>                y[j][i, :] = <span class="hljs-number">0</span><br>                y[j][i, characters.find(ch)] = <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">yield</span> X, y<br><br><br>input_tensor = Input((height, width, <span class="hljs-number">3</span>))<br>x = input_tensor<br><br><span class="hljs-comment"># 产生有四个block的卷积神经网络</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>    <span class="hljs-comment"># 卷积层</span><br>    x = Conv2D(<span class="hljs-number">32</span> * <span class="hljs-number">2</span> ** i, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">&#x27;relu&#x27;</span>, padding=<span class="hljs-string">&#x27;same&#x27;</span>)(x)<br>    x = Conv2D(<span class="hljs-number">32</span> * <span class="hljs-number">2</span> ** i, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">&#x27;relu&#x27;</span>, padding=<span class="hljs-string">&#x27;same&#x27;</span>)(x)<br>    <span class="hljs-comment"># 池化层</span><br>    x = MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))(x)<br><br>x = Flatten()(x)<br>x = Dropout(<span class="hljs-number">0.25</span>)(x)<br><br><span class="hljs-comment"># 多输出模型，使用了4个&#x27;softmax&#x27;來分别预测4個字母的输出</span><br>x = [Dense(n_class, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>, name=<span class="hljs-string">&#x27;c%d&#x27;</span> % (i + <span class="hljs-number">1</span>))(x) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)]<br>model = Model(inputs=input_tensor, outputs=x)<br>model.summary()<br><br><span class="hljs-comment"># 保存模型结构图</span><br><span class="hljs-keyword">from</span> keras.utils.vis_utils <span class="hljs-keyword">import</span> plot_model<br>plot_model(model, to_file=<span class="hljs-string">&quot;./model.png&quot;</span>, show_shapes=<span class="hljs-literal">True</span>)<br><br>model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>,<br>              optimizer=<span class="hljs-string">&#x27;adadelta&#x27;</span>,<br>              metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br><span class="hljs-comment"># 保存效果最好的模型</span><br>cbks = [callbacks.ModelCheckpoint(<span class="hljs-string">&quot;best_model.h5&quot;</span>, save_best_only=<span class="hljs-literal">True</span>)]<br><br><span class="hljs-built_in">dir</span> = <span class="hljs-string">&#x27;./result&#x27;</span><br>history = model.fit_generator(gen(<span class="hljs-built_in">dir</span>, batch_size=<span class="hljs-number">8</span>),      <span class="hljs-comment"># 每次生成器会产生8张小批量的图片</span><br>                    steps_per_epoch=<span class="hljs-number">120</span>,    <span class="hljs-comment"># 每次的epoch要训练120批图片</span><br>                    epochs=<span class="hljs-number">50</span>,                <span class="hljs-comment"># 总共训练50次</span><br>                    callbacks=cbks,          <span class="hljs-comment"># 保存最好的模型</span><br>                    validation_data=gen(<span class="hljs-built_in">dir</span>),   <span class="hljs-comment"># 验证数据也是用生成器來产生</span><br>                    validation_steps=<span class="hljs-number">10</span>      <span class="hljs-comment"># 用10组图片来进行验证</span><br>                   )<br><br><span class="hljs-comment"># 绘制损失值图像</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_train_history</span>(<span class="hljs-params">history, train_metrics, val_metrics</span>):<br>    plt.plot(history.history.get(train_metrics), <span class="hljs-string">&#x27;-o&#x27;</span>)<br>    plt.plot(history.history.get(val_metrics), <span class="hljs-string">&#x27;-o&#x27;</span>)<br>    plt.ylabel(train_metrics)<br>    plt.xlabel(<span class="hljs-string">&#x27;Epochs&#x27;</span>)<br>    plt.legend([<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;validation&#x27;</span>])<br><br><br><span class="hljs-comment"># 打印整体的loss与val_loss，并保存图片</span><br>plot_train_history(history, <span class="hljs-string">&#x27;loss&#x27;</span>, <span class="hljs-string">&#x27;val_loss&#x27;</span>)<br>plt.savefig(<span class="hljs-string">&#x27;./all_loss.png&#x27;</span>)<br><br>plt.figure(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">4</span>))<br><br><span class="hljs-comment"># 第一个数字的正确率</span><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>plot_train_history(history, <span class="hljs-string">&#x27;c1_acc&#x27;</span>, <span class="hljs-string">&#x27;val_c1_acc&#x27;</span>)<br><br><span class="hljs-comment"># 第二个数字的正确率</span><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>plot_train_history(history, <span class="hljs-string">&#x27;c2_acc&#x27;</span>, <span class="hljs-string">&#x27;val_c2_acc&#x27;</span>)<br><br><span class="hljs-comment"># 第三個数字的正確率</span><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>plot_train_history(history, <span class="hljs-string">&#x27;c3_acc&#x27;</span>, <span class="hljs-string">&#x27;val_c3_acc&#x27;</span>)<br><br><span class="hljs-comment"># 第四個数字的正确率</span><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>)<br>plot_train_history(history, <span class="hljs-string">&#x27;c4_acc&#x27;</span>, <span class="hljs-string">&#x27;val_c4_acc&#x27;</span>)<br><br><span class="hljs-comment"># 保存图片</span><br>plt.savefig(<span class="hljs-string">&#x27;./train.png&#x27;</span>)<br></code></pre></td></tr></table></figure><p>在这个代码中，我们总共训练了50个epoch，每个epoch共120次批次，每个批次是8张验证码，每张验证码的大小为50*22。</p><p>运行该训练模型，后几个epoch的输出结果如下：</p><p><img src="/img/keras4_4.png" /></p><p>总的损失值图像如下：</p><p><img src="/img/keras4_5.png" /></p><p>四个数字每个数字的损失值图像如下：</p><p><img src="/img/keras4_6.png" /></p><p>训练完后，程序会将训练效果最好的epoch保存为best_model.h5文件，便于后续的模型预测。由输出的结果及图像来看，该CNN模型的训练效果应该是相当好的，下面，我们来看看对新验证码的预测效果。</p><h3 id="模型预测">模型预测</h3><p>新的验证码共有20张，如下：</p><p><img src="/img/keras4_7.png" /></p><p>模型预测的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用训练好的CNN模型对新图片进行预测</span><br><br><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 导入训练好的模型</span><br>model = load_model(<span class="hljs-string">&#x27;best_model.h5&#x27;</span>)<br><br>batch_size = <span class="hljs-number">20</span><br>width, height, n_len, n_class = <span class="hljs-number">50</span>, <span class="hljs-number">22</span>, <span class="hljs-number">4</span>, <span class="hljs-number">10</span><br><br><span class="hljs-comment"># 导入验证码数据并进行预测</span><br>X = np.zeros((batch_size, height, width, <span class="hljs-number">3</span>), dtype=np.uint8)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_size):<br>    X_test = cv2.imread(<span class="hljs-string">&#x27;./new_image/code%d.png&#x27;</span> %(i+<span class="hljs-number">1</span>), <span class="hljs-number">1</span>)<br>    X[i] = X_test<br><br>y_pred = model.predict(X)<br>y_pred = np.argmax(y_pred, axis=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 输出每张验证码的预测结果</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_size):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;第%d张验证码的识别结果为：&#x27;</span> %(i+<span class="hljs-number">1</span>), end=<span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;&#x27;</span>.join(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">str</span>, y_pred[:, i].tolist())))<br></code></pre></td></tr></table></figure><p>运行该模型，得到的输出结果如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs">第1张验证码的识别结果为：3568<br>第2张验证码的识别结果为：5402<br>第3张验证码的识别结果为：6051<br>第4张验证码的识别结果为：6769<br>第5张验证码的识别结果为：2675<br>第6张验证码的识别结果为：2450<br>第7张验证码的识别结果为：2364<br>第8张验证码的识别结果为：6879<br>第9张验证码的识别结果为：3702<br>第10张验证码的识别结果为：3459<br>第11张验证码的识别结果为：5895<br>第12张验证码的识别结果为：8042<br>第13张验证码的识别结果为：6897<br>第14张验证码的识别结果为：6558<br>第15张验证码的识别结果为：9428<br>第16张验证码的识别结果为：5662<br>第17张验证码的识别结果为：5431<br>第18张验证码的识别结果为：4981<br>第19张验证码的识别结果为：0567<br>第20张验证码的识别结果为：5239<br></code></pre></td></tr></table></figure><p>对这20张新的验证码，预测完全正确！不得不说，CNN模型的识别效果非常好！</p><h3 id="总结">总结</h3><p>本文采用了一种新的思路，搭建CNN模型来实现验证码的识别，取得了不错的识别效果，而且识别的验证码是从网页中下载下来的，具有实际背景，增强了该项目的应用性。</p><p>本项目已放至Github，地址为：<ahref="https://github.com/percent4/CAPTCHA-Recognizition">https://github.com/percent4/CAPTCHA-Recognizition</a>。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Keras</tag>
      
      <tag>CNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>keras入门（三）搭建CNN模型破解网站验证码</title>
    <link href="/keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%E6%90%AD%E5%BB%BACNN%E6%A8%A1%E5%9E%8B%E7%A0%B4%E8%A7%A3%E7%BD%91%E7%AB%99%E9%AA%8C%E8%AF%81%E7%A0%81/"/>
    <url>/keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%E6%90%AD%E5%BB%BACNN%E6%A8%A1%E5%9E%8B%E7%A0%B4%E8%A7%A3%E7%BD%91%E7%AB%99%E9%AA%8C%E8%AF%81%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="项目介绍">项目介绍</h3><p>在文章<ahref="https://www.jianshu.com/p/0287bcd24f78">CNN大战验证码</a>中，我们利用TensorFlow搭建了简单的CNN模型来破解某个网站的验证码。验证码如下：</p><p><img src="/img/keras3_1.png" /></p><p>在本文中，我们将会用Keras来搭建一个稍微复杂的CNN模型来破解以上的验证码。</p><h3 id="数据集">数据集</h3><p>对于验证码图片的处理过程在本文中将不再具体叙述，有兴趣的读者可以参考文章<ahref="https://www.jianshu.com/p/0287bcd24f78">CNN大战验证码</a>。</p><p>在这个项目中，我们现在的样本一共是1668个样本，每个样本都是一个字符图片，字符图片的大小为16*20。样本的特征为字符图片的像素，0代表白色，1代表黑色，每个样本为320个特征，取值为0或1，特征变量名称为v1到v320，样本的类别标签即为该字符。整个数据集的部分如下：</p><p><img src="/img/keras3_2.png" /></p><h3 id="cnn模型">CNN模型</h3><p>利用Keras可以快速方便地搭建CNN模型，本文搭建的CNN模型如下：</p><p><img src="/img/keras3_3.png" /></p><p>将数据集分为训练集和测试集，占比为8：2，该模型训练的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> np_utils, plot_model<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential<br><span class="hljs-keyword">from</span> keras.layers.core <span class="hljs-keyword">import</span> Dense, Dropout, Activation, Flatten<br><span class="hljs-keyword">from</span> keras.callbacks <span class="hljs-keyword">import</span> EarlyStopping<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Conv2D, MaxPooling2D<br><br><span class="hljs-comment"># 读取数据</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;F://verifycode_data/data.csv&#x27;</span>)<br><br><span class="hljs-comment"># 标签值</span><br>vals = <span class="hljs-built_in">range</span>(<span class="hljs-number">31</span>)<br>keys = [<span class="hljs-string">&#x27;1&#x27;</span>,<span class="hljs-string">&#x27;2&#x27;</span>,<span class="hljs-string">&#x27;3&#x27;</span>,<span class="hljs-string">&#x27;4&#x27;</span>,<span class="hljs-string">&#x27;5&#x27;</span>,<span class="hljs-string">&#x27;6&#x27;</span>,<span class="hljs-string">&#x27;7&#x27;</span>,<span class="hljs-string">&#x27;8&#x27;</span>,<span class="hljs-string">&#x27;9&#x27;</span>,<span class="hljs-string">&#x27;A&#x27;</span>,<span class="hljs-string">&#x27;B&#x27;</span>,<span class="hljs-string">&#x27;C&#x27;</span>,<span class="hljs-string">&#x27;D&#x27;</span>,<span class="hljs-string">&#x27;E&#x27;</span>,<span class="hljs-string">&#x27;F&#x27;</span>,<span class="hljs-string">&#x27;G&#x27;</span>,<span class="hljs-string">&#x27;H&#x27;</span>,<span class="hljs-string">&#x27;J&#x27;</span>,<span class="hljs-string">&#x27;K&#x27;</span>,<span class="hljs-string">&#x27;L&#x27;</span>,<span class="hljs-string">&#x27;N&#x27;</span>,<span class="hljs-string">&#x27;P&#x27;</span>,<span class="hljs-string">&#x27;Q&#x27;</span>,<span class="hljs-string">&#x27;R&#x27;</span>,<span class="hljs-string">&#x27;S&#x27;</span>,<span class="hljs-string">&#x27;T&#x27;</span>,<span class="hljs-string">&#x27;U&#x27;</span>,<span class="hljs-string">&#x27;V&#x27;</span>,<span class="hljs-string">&#x27;X&#x27;</span>,<span class="hljs-string">&#x27;Y&#x27;</span>,<span class="hljs-string">&#x27;Z&#x27;</span>]<br>label_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(keys, vals))<br><br>x_data = df[[<span class="hljs-string">&#x27;v&#x27;</span>+<span class="hljs-built_in">str</span>(i+<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">320</span>)]]<br>y_data = pd.DataFrame(&#123;<span class="hljs-string">&#x27;label&#x27;</span>:df[<span class="hljs-string">&#x27;label&#x27;</span>]&#125;)<br>y_data[<span class="hljs-string">&#x27;class&#x27;</span>] = y_data[<span class="hljs-string">&#x27;label&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: label_dict[x])<br><br><span class="hljs-comment"># 将数据分为训练集和测试集</span><br>X_train, X_test, Y_train, Y_test = train_test_split(x_data, y_data[<span class="hljs-string">&#x27;class&#x27;</span>], test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">42</span>)<br>x_train = np.array(X_train).reshape((<span class="hljs-number">1167</span>, <span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>))<br>x_test = np.array(X_test).reshape((<span class="hljs-number">501</span>, <span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>))<br><br><span class="hljs-comment"># 对标签值进行one-hot encoding</span><br>n_classes = <span class="hljs-number">31</span><br>y_train = np_utils.to_categorical(Y_train, n_classes)<br>y_val = np_utils.to_categorical(Y_test, n_classes)<br><br>input_shape = x_train[<span class="hljs-number">0</span>].shape<br><br><span class="hljs-comment"># CNN模型</span><br>model = Sequential()<br><br><span class="hljs-comment"># 卷积层和池化层</span><br>model.add(Conv2D(<span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), input_shape=input_shape, padding=<span class="hljs-string">&#x27;same&#x27;</span>))<br>model.add(Activation(<span class="hljs-string">&#x27;relu&#x27;</span>))<br>model.add(Conv2D(<span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>))<br>model.add(Activation(<span class="hljs-string">&#x27;relu&#x27;</span>))<br>model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>))<br><br><span class="hljs-comment"># Dropout层</span><br>model.add(Dropout(<span class="hljs-number">0.25</span>))<br><br>model.add(Conv2D(<span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>))<br>model.add(Activation(<span class="hljs-string">&#x27;relu&#x27;</span>))<br>model.add(Conv2D(<span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>))<br>model.add(Activation(<span class="hljs-string">&#x27;relu&#x27;</span>))<br>model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>))<br><br>model.add(Dropout(<span class="hljs-number">0.25</span>))<br><br>model.add(Conv2D(<span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>))<br>model.add(Activation(<span class="hljs-string">&#x27;relu&#x27;</span>))<br>model.add(Conv2D(<span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>))<br>model.add(Activation(<span class="hljs-string">&#x27;relu&#x27;</span>))<br>model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>))<br><br>model.add(Dropout(<span class="hljs-number">0.25</span>))<br><br>model.add(Flatten())<br><br><span class="hljs-comment"># 全连接层</span><br>model.add(Dense(<span class="hljs-number">256</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br>model.add(Dropout(<span class="hljs-number">0.5</span>))<br>model.add(Dense(<span class="hljs-number">128</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br>model.add(Dense(n_classes, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>))<br><br>model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br><span class="hljs-comment"># plot model</span><br>plot_model(model, to_file=<span class="hljs-string">r&#x27;./model.png&#x27;</span>, show_shapes=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 模型训练</span><br>callbacks = [EarlyStopping(monitor=<span class="hljs-string">&#x27;val_acc&#x27;</span>, patience=<span class="hljs-number">5</span>, verbose=<span class="hljs-number">1</span>)]<br>batch_size = <span class="hljs-number">64</span><br>n_epochs = <span class="hljs-number">100</span><br>history = model.fit(x_train, y_train, batch_size=batch_size, epochs=n_epochs, \<br>                    verbose=<span class="hljs-number">1</span>, validation_data=(x_test, y_val), callbacks=callbacks)<br><br>mp = <span class="hljs-string">&#x27;F://verifycode_data/verifycode_Keras.h5&#x27;</span><br>model.save(mp)<br><br><span class="hljs-comment"># 绘制验证集上的准确率曲线</span><br>val_acc = history.history[<span class="hljs-string">&#x27;val_acc&#x27;</span>]<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(val_acc)), val_acc, label=<span class="hljs-string">&#x27;CNN model&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Validation accuracy on verifycode dataset&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;epochs&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;accuracy&#x27;</span>)<br>plt.legend()<br>plt.show()<br></code></pre></td></tr></table></figure><p>在上述代码中，我们训练模型的时候采用了early stopping技巧。earlystopping是用于提前停止训练的callbacks。具体地，可以达到当训练集上的loss不在减小（即减小的程度小于某个阈值）的时候停止继续训练。</p><h3 id="模型训练">模型训练</h3><p>运行上述模型训练代码，输出的结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs bash">......(忽略之前的输出)<br>Epoch 22/100<br><br>  64/1167 [&gt;.............................] - ETA: 3s - loss: 0.0399 - acc: 1.0000<br> 128/1167 [==&gt;...........................] - ETA: 3s - loss: 0.1195 - acc: 0.9844<br> 192/1167 [===&gt;..........................] - ETA: 2s - loss: 0.1085 - acc: 0.9792<br> 256/1167 [=====&gt;........................] - ETA: 2s - loss: 0.1132 - acc: 0.9727<br> 320/1167 [=======&gt;......................] - ETA: 2s - loss: 0.1045 - acc: 0.9750<br> 384/1167 [========&gt;.....................] - ETA: 2s - loss: 0.1006 - acc: 0.9740<br> 448/1167 [==========&gt;...................] - ETA: 2s - loss: 0.1522 - acc: 0.9643<br> 512/1167 [============&gt;.................] - ETA: 1s - loss: 0.1450 - acc: 0.9648<br> 576/1167 [=============&gt;................] - ETA: 1s - loss: 0.1368 - acc: 0.9653<br> 640/1167 [===============&gt;..............] - ETA: 1s - loss: 0.1353 - acc: 0.9641<br> 704/1167 [=================&gt;............] - ETA: 1s - loss: 0.1280 - acc: 0.9659<br> 768/1167 [==================&gt;...........] - ETA: 1s - loss: 0.1243 - acc: 0.9674<br> 832/1167 [====================&gt;.........] - ETA: 0s - loss: 0.1577 - acc: 0.9639<br> 896/1167 [======================&gt;.......] - ETA: 0s - loss: 0.1488 - acc: 0.9665<br> 960/1167 [=======================&gt;......] - ETA: 0s - loss: 0.1488 - acc: 0.9656<br>1024/1167 [=========================&gt;....] - ETA: 0s - loss: 0.1427 - acc: 0.9668<br>1088/1167 [==========================&gt;...] - ETA: 0s - loss: 0.1435 - acc: 0.9669<br>1152/1167 [============================&gt;.] - ETA: 0s - loss: 0.1383 - acc: 0.9688<br>1167/1167 [==============================] - 4s 3ms/step - loss: 0.1380 - acc: 0.9683 - val_loss: 0.0835 - val_acc: 0.9760<br>Epoch 00022: early stopping<br></code></pre></td></tr></table></figure><p>可以看到，一共训练了21次，最近一次的训练后，在测试集上的准确率为96.83%。在测试集的准确率曲线如下图：</p><p><img src="/img/keras3_4.png" /></p><h3 id="模型预测">模型预测</h3><p>模型训练完后，我们对新的验证码进行预测。新的100张验证码如下图：</p><p><img src="/img/keras3_5.png" /></p><p>使用训练好的CNN模型，对这些新的验证码进行预测，预测的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">split_picture</span>(<span class="hljs-params">imagepath</span>):<br><br>    <span class="hljs-comment"># 以灰度模式读取图片</span><br>    gray = cv2.imread(imagepath, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># 将图片的边缘变为白色</span><br>    height, width = gray.shape<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(width):<br>        gray[<span class="hljs-number">0</span>, i] = <span class="hljs-number">255</span><br>        gray[height-<span class="hljs-number">1</span>, i] = <span class="hljs-number">255</span><br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(height):<br>        gray[j, <span class="hljs-number">0</span>] = <span class="hljs-number">255</span><br>        gray[j, width-<span class="hljs-number">1</span>] = <span class="hljs-number">255</span><br><br>    <span class="hljs-comment"># 中值滤波</span><br>    blur = cv2.medianBlur(gray, <span class="hljs-number">3</span>) <span class="hljs-comment">#模板大小3*3</span><br><br>    <span class="hljs-comment"># 二值化</span><br>    ret,thresh1 = cv2.threshold(blur, <span class="hljs-number">200</span>, <span class="hljs-number">255</span>, cv2.THRESH_BINARY)<br><br>    <span class="hljs-comment"># 提取单个字符</span><br>    chars_list = []<br>    image, contours, hierarchy = cv2.findContours(thresh1, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">for</span> cnt <span class="hljs-keyword">in</span> contours:<br>        <span class="hljs-comment"># 最小的外接矩形</span><br>        x, y, w, h = cv2.boundingRect(cnt)<br>        <span class="hljs-keyword">if</span> x != <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> y != <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> w*h &gt;= <span class="hljs-number">100</span>:<br>            chars_list.append((x,y,w,h))<br><br>    sorted_chars_list = <span class="hljs-built_in">sorted</span>(chars_list, key=<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">for</span> i,item <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sorted_chars_list):<br>        x, y, w, h = item<br>        cv2.imwrite(<span class="hljs-string">&#x27;F://test_verifycode/chars/%d.jpg&#x27;</span>%(i+<span class="hljs-number">1</span>), thresh1[y:y+h, x:x+w])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">remove_edge_picture</span>(<span class="hljs-params">imagepath</span>):<br><br>    image = cv2.imread(imagepath, <span class="hljs-number">0</span>)<br>    height, width = image.shape<br>    corner_list = [image[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>] &lt; <span class="hljs-number">127</span>,<br>                   image[height-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>] &lt; <span class="hljs-number">127</span>,<br>                   image[<span class="hljs-number">0</span>, width-<span class="hljs-number">1</span>]&lt;<span class="hljs-number">127</span>,<br>                   image[ height-<span class="hljs-number">1</span>, width-<span class="hljs-number">1</span>] &lt; <span class="hljs-number">127</span><br>                   ]<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">sum</span>(corner_list) &gt;= <span class="hljs-number">3</span>:<br>        os.remove(imagepath)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resplit_with_parts</span>(<span class="hljs-params">imagepath, parts</span>):<br>    image = cv2.imread(imagepath, <span class="hljs-number">0</span>)<br>    os.remove(imagepath)<br>    height, width = image.shape<br><br>    file_name = imagepath.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>].split(<span class="hljs-string">r&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]<br>    <span class="hljs-comment"># 将图片重新分裂成parts部分</span><br>    step = width//parts     <span class="hljs-comment"># 步长</span><br>    start = <span class="hljs-number">0</span>             <span class="hljs-comment"># 起始位置</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(parts):<br>        cv2.imwrite(<span class="hljs-string">&#x27;F://test_verifycode/chars/%s.jpg&#x27;</span>%(file_name+<span class="hljs-string">&#x27;-&#x27;</span>+<span class="hljs-built_in">str</span>(i)), \<br>                    image[:, start:start+step])<br>        start += step<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resplit</span>(<span class="hljs-params">imagepath</span>):<br><br>    image = cv2.imread(imagepath, <span class="hljs-number">0</span>)<br>    height, width = image.shape<br><br>    <span class="hljs-keyword">if</span> width &gt;= <span class="hljs-number">64</span>:<br>        resplit_with_parts(imagepath, <span class="hljs-number">4</span>)<br>    <span class="hljs-keyword">elif</span> width &gt;= <span class="hljs-number">48</span>:<br>        resplit_with_parts(imagepath, <span class="hljs-number">3</span>)<br>    <span class="hljs-keyword">elif</span> width &gt;= <span class="hljs-number">26</span>:<br>        resplit_with_parts(imagepath, <span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># rename and convert to 16*20 size</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert</span>(<span class="hljs-params"><span class="hljs-built_in">dir</span>, file</span>):<br><br>    imagepath = <span class="hljs-built_in">dir</span>+<span class="hljs-string">&#x27;/&#x27;</span>+file<br>    <span class="hljs-comment"># 读取图片</span><br>    image = cv2.imread(imagepath, <span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># 二值化</span><br>    ret, thresh = cv2.threshold(image, <span class="hljs-number">127</span>, <span class="hljs-number">255</span>, cv2.THRESH_BINARY)<br>    img = cv2.resize(thresh, (<span class="hljs-number">16</span>, <span class="hljs-number">20</span>), interpolation=cv2.INTER_AREA)<br>    <span class="hljs-comment"># 保存图片</span><br>    cv2.imwrite(<span class="hljs-string">&#x27;%s/%s&#x27;</span> % (<span class="hljs-built_in">dir</span>, file), img)<br><br><span class="hljs-comment"># 读取图片的数据，并转化为0-1值</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">Read_Data</span>(<span class="hljs-params"><span class="hljs-built_in">dir</span>, file</span>):<br><br>    imagepath = <span class="hljs-built_in">dir</span>+<span class="hljs-string">&#x27;/&#x27;</span>+file<br>    <span class="hljs-comment"># 读取图片</span><br>    image = cv2.imread(imagepath, <span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># 二值化</span><br>    ret, thresh = cv2.threshold(image, <span class="hljs-number">127</span>, <span class="hljs-number">255</span>, cv2.THRESH_BINARY)<br>    <span class="hljs-comment"># 显示图片</span><br>    bin_values = [<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> pixel==<span class="hljs-number">255</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> pixel <span class="hljs-keyword">in</span> thresh.ravel()]<br><br>    <span class="hljs-keyword">return</span> bin_values<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">VerifyCodePath</span>):<br><br>    <span class="hljs-built_in">dir</span> = <span class="hljs-string">&#x27;F://test_verifycode/chars&#x27;</span><br>    files = os.listdir(<span class="hljs-built_in">dir</span>)<br><br>    <span class="hljs-comment"># 清空原有的文件</span><br>    <span class="hljs-keyword">if</span> files:<br>        <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> files:<br>            os.remove(<span class="hljs-built_in">dir</span> + <span class="hljs-string">&#x27;/&#x27;</span> + file)<br><br>    split_picture(VerifyCodePath)<br><br>    files = os.listdir(<span class="hljs-built_in">dir</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> files:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;查看的文件夹为空！&#x27;</span>)<br>    <span class="hljs-keyword">else</span>:<br><br>        <span class="hljs-comment"># 去除噪声图片</span><br>        <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> files:<br>            remove_edge_picture(<span class="hljs-built_in">dir</span> + <span class="hljs-string">&#x27;/&#x27;</span> + file)<br><br>        <span class="hljs-comment"># 对黏连图片进行重分割</span><br>        <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> os.listdir(<span class="hljs-built_in">dir</span>):<br>            resplit(<span class="hljs-built_in">dir</span> + <span class="hljs-string">&#x27;/&#x27;</span> + file)<br><br>        <span class="hljs-comment"># 将图片统一调整至16*20大小</span><br>        <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> os.listdir(<span class="hljs-built_in">dir</span>):<br>            convert(<span class="hljs-built_in">dir</span>, file)<br><br>        <span class="hljs-comment"># 图片中的字符代表的向量</span><br>        files = <span class="hljs-built_in">sorted</span>(os.listdir(<span class="hljs-built_in">dir</span>), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">0</span>])<br>        table = np.array([Read_Data(<span class="hljs-built_in">dir</span>, file) <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> files]).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">20</span>,<span class="hljs-number">16</span>,<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 模型保存地址</span><br>        mp = <span class="hljs-string">&#x27;F://verifycode_data/verifycode_Keras.h5&#x27;</span><br>        <span class="hljs-comment"># 载入模型</span><br>        <span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br>        cnn = load_model(mp)<br>        <span class="hljs-comment"># 模型预测</span><br>        y_pred = cnn.predict(table)<br>        predictions = np.argmax(y_pred, axis=<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 标签字典</span><br>        keys = <span class="hljs-built_in">range</span>(<span class="hljs-number">31</span>)<br>        vals = [<span class="hljs-string">&#x27;1&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;3&#x27;</span>, <span class="hljs-string">&#x27;4&#x27;</span>, <span class="hljs-string">&#x27;5&#x27;</span>, <span class="hljs-string">&#x27;6&#x27;</span>, <span class="hljs-string">&#x27;7&#x27;</span>, <span class="hljs-string">&#x27;8&#x27;</span>, <span class="hljs-string">&#x27;9&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>, <span class="hljs-string">&#x27;F&#x27;</span>, <span class="hljs-string">&#x27;G&#x27;</span>, <span class="hljs-string">&#x27;H&#x27;</span>, <span class="hljs-string">&#x27;J&#x27;</span>, <span class="hljs-string">&#x27;K&#x27;</span>, <span class="hljs-string">&#x27;L&#x27;</span>, <span class="hljs-string">&#x27;N&#x27;</span>,<br>                <span class="hljs-string">&#x27;P&#x27;</span>, <span class="hljs-string">&#x27;Q&#x27;</span>, <span class="hljs-string">&#x27;R&#x27;</span>, <span class="hljs-string">&#x27;S&#x27;</span>, <span class="hljs-string">&#x27;T&#x27;</span>, <span class="hljs-string">&#x27;U&#x27;</span>, <span class="hljs-string">&#x27;V&#x27;</span>, <span class="hljs-string">&#x27;X&#x27;</span>, <span class="hljs-string">&#x27;Y&#x27;</span>, <span class="hljs-string">&#x27;Z&#x27;</span>]<br>        label_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(keys, vals))<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.join([label_dict[pred] <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> predictions])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br><br>    <span class="hljs-built_in">dir</span> = <span class="hljs-string">&#x27;F://VerifyCode/&#x27;</span><br>    correct = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i, file <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(os.listdir(<span class="hljs-built_in">dir</span>)):<br>        true_label = file.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]<br>        VerifyCodePath = <span class="hljs-built_in">dir</span>+file<br>        pred = predict(VerifyCodePath)<br><br>        <span class="hljs-keyword">if</span> true_label == pred:<br>            correct += <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span>(i+<span class="hljs-number">1</span>, (true_label, pred), true_label == pred, correct)<br><br>    total = <span class="hljs-built_in">len</span>(os.listdir(<span class="hljs-built_in">dir</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\n总共图片：%d张\n识别正确：%d张\n识别准确率:%.2f%%.&#x27;</span>\<br>          %(total, correct, correct*<span class="hljs-number">100</span>/total))<br><br>main()<br></code></pre></td></tr></table></figure><p>以下是该CNN模型的预测结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><code class="hljs bash">Using TensorFlow backend.<br>2018-10-25 15:13:50.390130: I C:\tf_jenkins\workspace\rel-win\M\windows\PY\35\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2<br>1 (<span class="hljs-string">&#x27;ZK6N&#x27;</span>, <span class="hljs-string">&#x27;ZK6N&#x27;</span>) True 1<br>2 (<span class="hljs-string">&#x27;4JPX&#x27;</span>, <span class="hljs-string">&#x27;4JPX&#x27;</span>) True 2<br>3 (<span class="hljs-string">&#x27;5GP5&#x27;</span>, <span class="hljs-string">&#x27;5GP5&#x27;</span>) True 3<br>4 (<span class="hljs-string">&#x27;5RQ8&#x27;</span>, <span class="hljs-string">&#x27;5RQ8&#x27;</span>) True 4<br>5 (<span class="hljs-string">&#x27;5TQP&#x27;</span>, <span class="hljs-string">&#x27;5TQP&#x27;</span>) True 5<br>6 (<span class="hljs-string">&#x27;7S62&#x27;</span>, <span class="hljs-string">&#x27;7S62&#x27;</span>) True 6<br>7 (<span class="hljs-string">&#x27;8R2Z&#x27;</span>, <span class="hljs-string">&#x27;8R2Z&#x27;</span>) True 7<br>8 (<span class="hljs-string">&#x27;8RFV&#x27;</span>, <span class="hljs-string">&#x27;8RFV&#x27;</span>) True 8<br>9 (<span class="hljs-string">&#x27;9BBT&#x27;</span>, <span class="hljs-string">&#x27;9BBT&#x27;</span>) True 9<br>10 (<span class="hljs-string">&#x27;9LNE&#x27;</span>, <span class="hljs-string">&#x27;9LNE&#x27;</span>) True 10<br>11 (<span class="hljs-string">&#x27;67UH&#x27;</span>, <span class="hljs-string">&#x27;67UH&#x27;</span>) True 11<br>12 (<span class="hljs-string">&#x27;74UK&#x27;</span>, <span class="hljs-string">&#x27;74UK&#x27;</span>) True 12<br>13 (<span class="hljs-string">&#x27;A5T2&#x27;</span>, <span class="hljs-string">&#x27;A5T2&#x27;</span>) True 13<br>14 (<span class="hljs-string">&#x27;AHYV&#x27;</span>, <span class="hljs-string">&#x27;AHYV&#x27;</span>) True 14<br>15 (<span class="hljs-string">&#x27;ASEY&#x27;</span>, <span class="hljs-string">&#x27;ASEY&#x27;</span>) True 15<br>16 (<span class="hljs-string">&#x27;B371&#x27;</span>, <span class="hljs-string">&#x27;B371&#x27;</span>) True 16<br>17 (<span class="hljs-string">&#x27;CCQL&#x27;</span>, <span class="hljs-string">&#x27;CCQL&#x27;</span>) True 17<br>18 (<span class="hljs-string">&#x27;CFD5&#x27;</span>, <span class="hljs-string">&#x27;GFD5&#x27;</span>) False 17<br>19 (<span class="hljs-string">&#x27;CJLJ&#x27;</span>, <span class="hljs-string">&#x27;CJLJ&#x27;</span>) True 18<br>20 (<span class="hljs-string">&#x27;D4QV&#x27;</span>, <span class="hljs-string">&#x27;D4QV&#x27;</span>) True 19<br>21 (<span class="hljs-string">&#x27;DFQ8&#x27;</span>, <span class="hljs-string">&#x27;DFQ8&#x27;</span>) True 20<br>22 (<span class="hljs-string">&#x27;DP18&#x27;</span>, <span class="hljs-string">&#x27;DP18&#x27;</span>) True 21<br>23 (<span class="hljs-string">&#x27;E3HC&#x27;</span>, <span class="hljs-string">&#x27;E3HC&#x27;</span>) True 22<br>24 (<span class="hljs-string">&#x27;E8VB&#x27;</span>, <span class="hljs-string">&#x27;E8VB&#x27;</span>) True 23<br>25 (<span class="hljs-string">&#x27;DE1U&#x27;</span>, <span class="hljs-string">&#x27;DE1U&#x27;</span>) True 24<br>26 (<span class="hljs-string">&#x27;FK1R&#x27;</span>, <span class="hljs-string">&#x27;FK1R&#x27;</span>) True 25<br>27 (<span class="hljs-string">&#x27;FK91&#x27;</span>, <span class="hljs-string">&#x27;FK91&#x27;</span>) True 26<br>28 (<span class="hljs-string">&#x27;FSKP&#x27;</span>, <span class="hljs-string">&#x27;FSKP&#x27;</span>) True 27<br>29 (<span class="hljs-string">&#x27;FVZP&#x27;</span>, <span class="hljs-string">&#x27;FVZP&#x27;</span>) True 28<br>30 (<span class="hljs-string">&#x27;GC6H&#x27;</span>, <span class="hljs-string">&#x27;GC6H&#x27;</span>) True 29<br>31 (<span class="hljs-string">&#x27;GH62&#x27;</span>, <span class="hljs-string">&#x27;GH62&#x27;</span>) True 30<br>32 (<span class="hljs-string">&#x27;H9FQ&#x27;</span>, <span class="hljs-string">&#x27;H9FQ&#x27;</span>) True 31<br>33 (<span class="hljs-string">&#x27;H67Q&#x27;</span>, <span class="hljs-string">&#x27;H67Q&#x27;</span>) True 32<br>34 (<span class="hljs-string">&#x27;HEKC&#x27;</span>, <span class="hljs-string">&#x27;HEKC&#x27;</span>) True 33<br>35 (<span class="hljs-string">&#x27;HV2B&#x27;</span>, <span class="hljs-string">&#x27;HV2B&#x27;</span>) True 34<br>36 (<span class="hljs-string">&#x27;J65Z&#x27;</span>, <span class="hljs-string">&#x27;J65Z&#x27;</span>) True 35<br>37 (<span class="hljs-string">&#x27;JZCX&#x27;</span>, <span class="hljs-string">&#x27;JZCX&#x27;</span>) True 36<br>38 (<span class="hljs-string">&#x27;KH5D&#x27;</span>, <span class="hljs-string">&#x27;KH5D&#x27;</span>) True 37<br>39 (<span class="hljs-string">&#x27;KXD2&#x27;</span>, <span class="hljs-string">&#x27;KXD2&#x27;</span>) True 38<br>40 (<span class="hljs-string">&#x27;1GDH&#x27;</span>, <span class="hljs-string">&#x27;1GDH&#x27;</span>) True 39<br>41 (<span class="hljs-string">&#x27;LCL3&#x27;</span>, <span class="hljs-string">&#x27;LCL3&#x27;</span>) True 40<br>42 (<span class="hljs-string">&#x27;LNZR&#x27;</span>, <span class="hljs-string">&#x27;LNZR&#x27;</span>) True 41<br>43 (<span class="hljs-string">&#x27;LZU5&#x27;</span>, <span class="hljs-string">&#x27;LZU5&#x27;</span>) True 42<br>44 (<span class="hljs-string">&#x27;N5AK&#x27;</span>, <span class="hljs-string">&#x27;N5AK&#x27;</span>) True 43<br>45 (<span class="hljs-string">&#x27;N5Q3&#x27;</span>, <span class="hljs-string">&#x27;N5Q3&#x27;</span>) True 44<br>46 (<span class="hljs-string">&#x27;N96Z&#x27;</span>, <span class="hljs-string">&#x27;N96Z&#x27;</span>) True 45<br>47 (<span class="hljs-string">&#x27;NCDG&#x27;</span>, <span class="hljs-string">&#x27;NCDG&#x27;</span>) True 46<br>48 (<span class="hljs-string">&#x27;NELS&#x27;</span>, <span class="hljs-string">&#x27;NELS&#x27;</span>) True 47<br>49 (<span class="hljs-string">&#x27;P96U&#x27;</span>, <span class="hljs-string">&#x27;P96U&#x27;</span>) True 48<br>50 (<span class="hljs-string">&#x27;PD42&#x27;</span>, <span class="hljs-string">&#x27;PD42&#x27;</span>) True 49<br>51 (<span class="hljs-string">&#x27;PECG&#x27;</span>, <span class="hljs-string">&#x27;PEQG&#x27;</span>) False 49<br>52 (<span class="hljs-string">&#x27;PPZF&#x27;</span>, <span class="hljs-string">&#x27;PPZF&#x27;</span>) True 50<br>53 (<span class="hljs-string">&#x27;PUUL&#x27;</span>, <span class="hljs-string">&#x27;PUUL&#x27;</span>) True 51<br>54 (<span class="hljs-string">&#x27;Q2DN&#x27;</span>, <span class="hljs-string">&#x27;D2DN&#x27;</span>) False 51<br>55 (<span class="hljs-string">&#x27;QCQ9&#x27;</span>, <span class="hljs-string">&#x27;QCQ9&#x27;</span>) True 52<br>56 (<span class="hljs-string">&#x27;QDB1&#x27;</span>, <span class="hljs-string">&#x27;QDBJ&#x27;</span>) False 52<br>57 (<span class="hljs-string">&#x27;QZUD&#x27;</span>, <span class="hljs-string">&#x27;QZUD&#x27;</span>) True 53<br>58 (<span class="hljs-string">&#x27;R3T5&#x27;</span>, <span class="hljs-string">&#x27;R3T5&#x27;</span>) True 54<br>59 (<span class="hljs-string">&#x27;S1YT&#x27;</span>, <span class="hljs-string">&#x27;S1YT&#x27;</span>) True 55<br>60 (<span class="hljs-string">&#x27;SP7L&#x27;</span>, <span class="hljs-string">&#x27;SP7L&#x27;</span>) True 56<br>61 (<span class="hljs-string">&#x27;SR2K&#x27;</span>, <span class="hljs-string">&#x27;SR2K&#x27;</span>) True 57<br>62 (<span class="hljs-string">&#x27;SUP5&#x27;</span>, <span class="hljs-string">&#x27;SVP5&#x27;</span>) False 57<br>63 (<span class="hljs-string">&#x27;T2SP&#x27;</span>, <span class="hljs-string">&#x27;T2SP&#x27;</span>) True 58<br>64 (<span class="hljs-string">&#x27;U6V9&#x27;</span>, <span class="hljs-string">&#x27;U6V9&#x27;</span>) True 59<br>65 (<span class="hljs-string">&#x27;UC9P&#x27;</span>, <span class="hljs-string">&#x27;UC9P&#x27;</span>) True 60<br>66 (<span class="hljs-string">&#x27;UFYD&#x27;</span>, <span class="hljs-string">&#x27;UFYD&#x27;</span>) True 61<br>67 (<span class="hljs-string">&#x27;V9NJ&#x27;</span>, <span class="hljs-string">&#x27;V9NH&#x27;</span>) False 61<br>68 (<span class="hljs-string">&#x27;V35X&#x27;</span>, <span class="hljs-string">&#x27;V35X&#x27;</span>) True 62<br>69 (<span class="hljs-string">&#x27;V98F&#x27;</span>, <span class="hljs-string">&#x27;V98F&#x27;</span>) True 63<br>70 (<span class="hljs-string">&#x27;VD28&#x27;</span>, <span class="hljs-string">&#x27;VD28&#x27;</span>) True 64<br>71 (<span class="hljs-string">&#x27;YGHE&#x27;</span>, <span class="hljs-string">&#x27;YGHE&#x27;</span>) True 65<br>72 (<span class="hljs-string">&#x27;YNKD&#x27;</span>, <span class="hljs-string">&#x27;YNKD&#x27;</span>) True 66<br>73 (<span class="hljs-string">&#x27;YVXV&#x27;</span>, <span class="hljs-string">&#x27;YVXV&#x27;</span>) True 67<br>74 (<span class="hljs-string">&#x27;ZFBS&#x27;</span>, <span class="hljs-string">&#x27;ZFBS&#x27;</span>) True 68<br>75 (<span class="hljs-string">&#x27;ET6X&#x27;</span>, <span class="hljs-string">&#x27;ET6X&#x27;</span>) True 69<br>76 (<span class="hljs-string">&#x27;TKVC&#x27;</span>, <span class="hljs-string">&#x27;TKVC&#x27;</span>) True 70<br>77 (<span class="hljs-string">&#x27;2UCU&#x27;</span>, <span class="hljs-string">&#x27;2UCU&#x27;</span>) True 71<br>78 (<span class="hljs-string">&#x27;HNBK&#x27;</span>, <span class="hljs-string">&#x27;HNBK&#x27;</span>) True 72<br>79 (<span class="hljs-string">&#x27;X8FD&#x27;</span>, <span class="hljs-string">&#x27;X8FD&#x27;</span>) True 73<br>80 (<span class="hljs-string">&#x27;ZGNX&#x27;</span>, <span class="hljs-string">&#x27;ZGNX&#x27;</span>) True 74<br>81 (<span class="hljs-string">&#x27;LQCU&#x27;</span>, <span class="hljs-string">&#x27;LQCU&#x27;</span>) True 75<br>82 (<span class="hljs-string">&#x27;JNZY&#x27;</span>, <span class="hljs-string">&#x27;JNZVY&#x27;</span>) False 75<br>83 (<span class="hljs-string">&#x27;RX34&#x27;</span>, <span class="hljs-string">&#x27;RX34&#x27;</span>) True 76<br>84 (<span class="hljs-string">&#x27;811E&#x27;</span>, <span class="hljs-string">&#x27;811E&#x27;</span>) True 77<br>85 (<span class="hljs-string">&#x27;ETDX&#x27;</span>, <span class="hljs-string">&#x27;ETDX&#x27;</span>) True 78<br>86 (<span class="hljs-string">&#x27;4CPR&#x27;</span>, <span class="hljs-string">&#x27;4CPR&#x27;</span>) True 79<br>87 (<span class="hljs-string">&#x27;FE91&#x27;</span>, <span class="hljs-string">&#x27;FE91&#x27;</span>) True 80<br>88 (<span class="hljs-string">&#x27;B7XH&#x27;</span>, <span class="hljs-string">&#x27;B7XH&#x27;</span>) True 81<br>89 (<span class="hljs-string">&#x27;1RUA&#x27;</span>, <span class="hljs-string">&#x27;1RUA&#x27;</span>) True 82<br>90 (<span class="hljs-string">&#x27;UBCX&#x27;</span>, <span class="hljs-string">&#x27;UBCX&#x27;</span>) True 83<br>91 (<span class="hljs-string">&#x27;KVT5&#x27;</span>, <span class="hljs-string">&#x27;KVT5&#x27;</span>) True 84<br>92 (<span class="hljs-string">&#x27;HZ3A&#x27;</span>, <span class="hljs-string">&#x27;HZ3A&#x27;</span>) True 85<br>93 (<span class="hljs-string">&#x27;3XLR&#x27;</span>, <span class="hljs-string">&#x27;3XLR&#x27;</span>) True 86<br>94 (<span class="hljs-string">&#x27;VC7T&#x27;</span>, <span class="hljs-string">&#x27;VC7T&#x27;</span>) True 87<br>95 (<span class="hljs-string">&#x27;7PG1&#x27;</span>, <span class="hljs-string">&#x27;7PQ1&#x27;</span>) False 87<br>96 (<span class="hljs-string">&#x27;4F21&#x27;</span>, <span class="hljs-string">&#x27;4F21&#x27;</span>) True 88<br>97 (<span class="hljs-string">&#x27;3HLJ&#x27;</span>, <span class="hljs-string">&#x27;3HLJ&#x27;</span>) True 89<br>98 (<span class="hljs-string">&#x27;1KT7&#x27;</span>, <span class="hljs-string">&#x27;1KT7&#x27;</span>) True 90<br>99 (<span class="hljs-string">&#x27;1RHE&#x27;</span>, <span class="hljs-string">&#x27;1RHE&#x27;</span>) True 91<br>100 (<span class="hljs-string">&#x27;1TTA&#x27;</span>, <span class="hljs-string">&#x27;1TTA&#x27;</span>) True 92<br><br>总共图片：100张<br>识别正确：92张<br>识别准确率:92.00%.<br></code></pre></td></tr></table></figure><p>可以看到，该训练后的CNN模型，其预测新验证的准确率在90%以上。</p><h3 id="总结">总结</h3><p>在文章<ahref="https://www.jianshu.com/p/0287bcd24f78">CNN大战验证码</a>中，笔者使用TensorFlow搭建了CNN模型，代码较长，训练时间在两个小时以上，而使用Keras搭建该模型，代码简洁，且使用earlystopping技巧后能缩短训练时间，同时保证模型的准确率，由此可见Keras的优势所在。</p><p>该项目已开源，Github地址为：https://github.com/percent4/CNN_4_Verifycode。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Keras</tag>
      
      <tag>CNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Keras入门（二）模型的保存、读取及加载</title>
    <link href="/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%8C%EF%BC%89%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E3%80%81%E8%AF%BB%E5%8F%96%E5%8F%8A%E5%8A%A0%E8%BD%BD/"/>
    <url>/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%8C%EF%BC%89%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E3%80%81%E8%AF%BB%E5%8F%96%E5%8F%8A%E5%8A%A0%E8%BD%BD/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文将会介绍如何利用Keras来实现模型的保存、读取以及加载。</p></blockquote><p>本文使用的模型为解决IRIS数据集的多分类问题而设计的深度神经网络（DNN）模型，模型的结构示意图如下：</p><p><img src="/img/keras2_1.png" /></p><p>具体的模型参数可以参考文章：<ahref="https://percent4.github.io/2023/08/06/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E6%90%AD%E5%BB%BA%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88DNN%EF%BC%89%E8%A7%A3%E5%86%B3%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/">Keras入门（一）搭建DNN解决多分类问题</a>。</p><h3 id="模型保存">模型保存</h3><p>Keras使用HDF5文件系统来保存模型。模型保存的方法很容易，只需要使用save()方法即可。</p><p>以<ahref="https://percent4.github.io/2023/08/06/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E6%90%AD%E5%BB%BA%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88DNN%EF%BC%89%E8%A7%A3%E5%86%B3%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/">Keras入门（一）搭建深度神经网络（DNN）解决多分类问题</a>中的DNN模型为例，整个模型的变量为model，我们设置模型共训练10次，在原先的代码中加入Python代码即可保存模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># save model</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Saving model to disk \n&quot;</span>)<br>mp = <span class="hljs-string">&quot;E://logs/iris_model.h5&quot;</span><br>model.save(mp)<br></code></pre></td></tr></table></figure><p>保存的模型文件（iris_model.h5）如下：</p><p><img src="/img/keras2_2.png" /></p><h3 id="模型读取">模型读取</h3><p>保存后的iris_model.h5以HDF5文件系统的形式储存，在我们使用Python读取h5文件里面的数据之前，我们先用HDF5的可视化工具HDFView来查看里面的数据：</p><p><img src="/img/keras2_3.png" /></p><p>我们感兴趣的是这个模型中的各个神经层之间的连接权重及偏重，也就是上图中的红色部分，model_weights里面包含了各个神经层之间的连接权重及偏重，分别位于dense_1,dense_2,dense_3中。蓝色部分为dense_3/dense_3/kernel:0的数据，即最后输出层的连接权重矩阵。</p><p>有了对模型参数的直观认识，我们要做的下一步工作就是读取各个神经层之间的连接权重及偏重。我们使用Python的h5py这个模块来这个iris_model.h5这个文件。关于h5py的快速入门指南，可以参考文章：<ahref="https://www.jianshu.com/p/a6328c4f4986">h5py快速入门指南</a>。</p><p>使用以下Python代码可以读取各个神经层之间的连接权重及偏重数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> h5py<br><br><span class="hljs-comment"># 模型地址</span><br>MODEL_PATH = <span class="hljs-string">&#x27;E://logs/iris_model.h5&#x27;</span><br><br><span class="hljs-comment"># 获取每一层的连接权重及偏重</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;读取模型中...&quot;</span>)<br><span class="hljs-keyword">with</span> h5py.File(MODEL_PATH, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    dense_1 = f[<span class="hljs-string">&#x27;/model_weights/dense_1/dense_1&#x27;</span>]<br>    dense_1_bias =  dense_1[<span class="hljs-string">&#x27;bias:0&#x27;</span>][:]<br>    dense_1_kernel = dense_1[<span class="hljs-string">&#x27;kernel:0&#x27;</span>][:]<br><br>    dense_2 = f[<span class="hljs-string">&#x27;/model_weights/dense_2/dense_2&#x27;</span>]<br>    dense_2_bias = dense_2[<span class="hljs-string">&#x27;bias:0&#x27;</span>][:]<br>    dense_2_kernel = dense_2[<span class="hljs-string">&#x27;kernel:0&#x27;</span>][:]<br><br>    dense_3 = f[<span class="hljs-string">&#x27;/model_weights/dense_3/dense_3&#x27;</span>]<br>    dense_3_bias = dense_3[<span class="hljs-string">&#x27;bias:0&#x27;</span>][:]<br>    dense_3_kernel = dense_3[<span class="hljs-string">&#x27;kernel:0&#x27;</span>][:]<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;第一层的连接权重矩阵：\n%s\n&quot;</span>%dense_1_kernel)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;第一层的连接偏重矩阵：\n%s\n&quot;</span>%dense_1_bias)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;第二层的连接权重矩阵：\n%s\n&quot;</span>%dense_2_kernel)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;第二层的连接偏重矩阵：\n%s\n&quot;</span>%dense_2_bias)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;第三层的连接权重矩阵：\n%s\n&quot;</span>%dense_3_kernel)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;第三层的连接偏重矩阵：\n%s\n&quot;</span>%dense_3_bias)<br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs dns">读取模型中...<br>第一层的连接权重矩阵：<br>[[ <span class="hljs-number">0.04141677</span>  <span class="hljs-number">0.03080632</span> -<span class="hljs-number">0.02768146</span>  <span class="hljs-number">0.14334357</span>  <span class="hljs-number">0.06242227</span>]<br> [-<span class="hljs-number">0.41209617</span> -<span class="hljs-number">0.77948487</span>  <span class="hljs-number">0.5648218</span>  -<span class="hljs-number">0.699587</span>   -<span class="hljs-number">0.19246106</span>]<br> [ <span class="hljs-number">0.6856315</span>   <span class="hljs-number">0.28241938</span> -<span class="hljs-number">0.91930366</span> -<span class="hljs-number">0.07989818</span>  <span class="hljs-number">0.47165248</span>]<br> [ <span class="hljs-number">0.8655262</span>   <span class="hljs-number">0.72175753</span>  <span class="hljs-number">0.36529952</span> -<span class="hljs-number">0.53172135</span>  <span class="hljs-number">0.26573092</span>]]<br><br>第一层的连接偏重矩阵：<br>[-<span class="hljs-number">0.16441862</span> -<span class="hljs-number">0.02462054</span> -<span class="hljs-number">0.14060321</span>  <span class="hljs-number">0</span>.         -<span class="hljs-number">0.14293939</span>]<br><br>第二层的连接权重矩阵：<br>[[ <span class="hljs-number">0.39296603</span>  <span class="hljs-number">0.01864707</span>  <span class="hljs-number">0.12538083</span>  <span class="hljs-number">0.07935872</span>  <span class="hljs-number">0.27940807</span> -<span class="hljs-number">0.4565802</span> ]<br> [-<span class="hljs-number">0.34312084</span>  <span class="hljs-number">0.6446907</span>  -<span class="hljs-number">0.92546445</span> -<span class="hljs-number">0.00538039</span>  <span class="hljs-number">0.95466876</span> -<span class="hljs-number">0.32819661</span>]<br> [-<span class="hljs-number">0.7593299</span>  -<span class="hljs-number">0.07227057</span>  <span class="hljs-number">0.20751365</span>  <span class="hljs-number">0.40547106</span>  <span class="hljs-number">0.35726753</span>  <span class="hljs-number">0.8884158</span> ]<br> [-<span class="hljs-number">0.48096</span>     <span class="hljs-number">0.11294878</span> -<span class="hljs-number">0.29462305</span> -<span class="hljs-number">0.410536</span>   -<span class="hljs-number">0.23620337</span> -<span class="hljs-number">0.72703975</span>]<br> [ <span class="hljs-number">0.7666149</span>  -<span class="hljs-number">0.41720924</span>  <span class="hljs-number">0.29576775</span> -<span class="hljs-number">0.6328017</span>   <span class="hljs-number">0.43118536</span>  <span class="hljs-number">0.6589351</span> ]]<br><br>第二层的连接偏重矩阵：<br>[-<span class="hljs-number">0.1899569</span>   <span class="hljs-number">0</span>.         -<span class="hljs-number">0.09710662</span> -<span class="hljs-number">0.12964155</span> -<span class="hljs-number">0.26443157</span>  <span class="hljs-number">0.6050924</span> ]<br><br>第三层的连接权重矩阵：<br>[[-<span class="hljs-number">0.44450542</span>  <span class="hljs-number">0.09977101</span>  <span class="hljs-number">0.12196152</span>]<br> [ <span class="hljs-number">0.14334357</span>  <span class="hljs-number">0.18546402</span> -<span class="hljs-number">0.23861367</span>]<br> [-<span class="hljs-number">0.7284191</span>   <span class="hljs-number">0.7859063</span>  -<span class="hljs-number">0.878823</span>  ]<br> [ <span class="hljs-number">0.0876545</span>   <span class="hljs-number">0.51531947</span>  <span class="hljs-number">0.09671918</span>]<br> [-<span class="hljs-number">0.7964963</span>  -<span class="hljs-number">0.16435687</span>  <span class="hljs-number">0.49531657</span>]<br> [ <span class="hljs-number">0.8645698</span>   <span class="hljs-number">0.4439873</span>   <span class="hljs-number">0.24599855</span>]]<br><br>第三层的连接偏重矩阵：<br>[ <span class="hljs-number">0.39192322</span> -<span class="hljs-number">0.1266532</span>  -<span class="hljs-number">0.29631865</span>]<br></code></pre></td></tr></table></figure><p>值得注意的是，我们得到的这些矩阵的数据类型都是numpy.ndarray。</p><p>OK，既然我们已经得到了各个神经层之间的连接权重及偏重的数据，那我们能做什么呢？当然是去做一些有趣的事啦，那就是用我们自己的方法来实现新数据的预测向量(softmax函数作用后的向量)。so,really?</p><p>新的输入向量为[6.1, 3.1, 5.1,1.1]，使用以下Python代码即可输出新数据的预测向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> h5py<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 模型地址</span><br>MODEL_PATH = <span class="hljs-string">&#x27;E://logs/iris_model.h5&#x27;</span><br><br><span class="hljs-comment"># 获取每一层的连接权重及偏重</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;读取模型中...&quot;</span>)<br><span class="hljs-keyword">with</span> h5py.File(MODEL_PATH, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    dense_1 = f[<span class="hljs-string">&#x27;/model_weights/dense_1/dense_1&#x27;</span>]<br>    dense_1_bias =  dense_1[<span class="hljs-string">&#x27;bias:0&#x27;</span>][:]<br>    dense_1_kernel = dense_1[<span class="hljs-string">&#x27;kernel:0&#x27;</span>][:]<br><br>    dense_2 = f[<span class="hljs-string">&#x27;/model_weights/dense_2/dense_2&#x27;</span>]<br>    dense_2_bias = dense_2[<span class="hljs-string">&#x27;bias:0&#x27;</span>][:]<br>    dense_2_kernel = dense_2[<span class="hljs-string">&#x27;kernel:0&#x27;</span>][:]<br><br>    dense_3 = f[<span class="hljs-string">&#x27;/model_weights/dense_3/dense_3&#x27;</span>]<br>    dense_3_bias = dense_3[<span class="hljs-string">&#x27;bias:0&#x27;</span>][:]<br>    dense_3_kernel = dense_3[<span class="hljs-string">&#x27;kernel:0&#x27;</span>][:]<br><br><span class="hljs-comment"># 模拟每个神经层的计算，得到该层的输出</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">layer_output</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, kernel, bias</span>):<br>    <span class="hljs-keyword">return</span> np.dot(<span class="hljs-built_in">input</span>, kernel) + bias<br><br><span class="hljs-comment"># 实现ReLU函数</span><br>relu = np.vectorize(<span class="hljs-keyword">lambda</span> x: x <span class="hljs-keyword">if</span> x &gt;=<span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># 实现softmax函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax_func</span>(<span class="hljs-params">arr</span>):<br>    exp_arr = np.exp(arr)<br>    arr_sum = np.<span class="hljs-built_in">sum</span>(exp_arr)<br>    softmax_arr = exp_arr/arr_sum<br>    <span class="hljs-keyword">return</span> softmax_arr<br><br><span class="hljs-comment"># 输入向量</span><br>unkown = np.array([[<span class="hljs-number">6.1</span>, <span class="hljs-number">3.1</span>, <span class="hljs-number">5.1</span>, <span class="hljs-number">1.1</span>]], dtype=np.float32)<br><br><span class="hljs-comment"># 第一层的输出</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;模型计算中...&quot;</span>)<br>output_1 = layer_output(unkown, dense_1_kernel, dense_1_bias)<br>output_1 = relu(output_1)<br><br><span class="hljs-comment"># 第二层的输出</span><br>output_2 = layer_output(output_1, dense_2_kernel, dense_2_bias)<br>output_2 = relu(output_2)<br><br><span class="hljs-comment"># 第三层的输出</span><br>output_3 = layer_output(output_2, dense_3_kernel, dense_3_bias)<br>output_3 = softmax_func(output_3)<br><br><span class="hljs-comment"># 最终的输出的softmax值</span><br>np.set_printoptions(precision=<span class="hljs-number">4</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;最终的预测值向量为: %s&quot;</span>%output_3)<br></code></pre></td></tr></table></figure><p>其输出的结果如下：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lua">读取模型中...<br>模型计算中...<br>最终的预测值向量为: <span class="hljs-string">[[0.0242 0.6763 0.2995]]</span><br></code></pre></td></tr></table></figure><p>额，这个输出的预测值向量会是我们的DNN模型的预测值向量吗？这时候，我们就需要回过头来看看<ahref="https://www.jianshu.com/p/1d88a6ed707e">Keras入门（一）搭建深度神经网络（DNN）解决多分类问题</a>中的代码了，注意，为了保证数值的可比较性，笔者已经将DNN模型的训练次数改为10次了。让我们来看看原来代码的输出结果吧：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs lua">Using model to predict species <span class="hljs-keyword">for</span> features: <br><span class="hljs-string">[[6.1 3.1 5.1 1.1]]</span><br><br>Predicted softmax vector is: <br><span class="hljs-string">[[0.0242 0.6763 0.2995]]</span><br><br>Predicted species is: <br>Iris-versicolor<br></code></pre></td></tr></table></figure><p>Yes,两者的预测值向量完全一致！因此，我们用自己的方法也实现了这个DNN模型的预测功能，棒！</p><h3 id="模型加载">模型加载</h3><p>当然，在实际的使用中，我们不需要再用自己的方法来实现模型的预测功能，只需使用Keras给我们提供好的模型导入功能（keras.models.load_model()）即可。使用以下Python代码即可加载模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型的加载及使用</span><br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Using loaded model to predict...&quot;</span>)<br>load_model = load_model(<span class="hljs-string">&quot;E://logs/iris_model.h5&quot;</span>)<br>np.set_printoptions(precision=<span class="hljs-number">4</span>)<br>unknown = np.array([[<span class="hljs-number">6.1</span>, <span class="hljs-number">3.1</span>, <span class="hljs-number">5.1</span>, <span class="hljs-number">1.1</span>]], dtype=np.float32)<br>predicted = load_model.predict(unknown)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Using model to predict species for features: &quot;</span>)<br><span class="hljs-built_in">print</span>(unknown)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nPredicted softmax vector is: &quot;</span>)<br><span class="hljs-built_in">print</span>(predicted)<br>species_dict = &#123;v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> Class_dict.items()&#125;<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nPredicted species is: &quot;</span>)<br><span class="hljs-built_in">print</span>(species_dict[np.argmax(predicted)])<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">Using loaded model to predict...<br>Using model to predict species <span class="hljs-keyword">for</span> features: <br>[[<span class="hljs-number">6.1</span> <span class="hljs-number">3.1</span> <span class="hljs-number">5.1</span> <span class="hljs-number">1.1</span>]]<br><br>Predicted softmax vector <span class="hljs-keyword">is</span>: <br>[[<span class="hljs-number">0.0242</span> <span class="hljs-number">0.6763</span> <span class="hljs-number">0.2995</span>]]<br><br>Predicted species <span class="hljs-keyword">is</span>: <br>Iris-versicolor<br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本文主要介绍如何利用Keras来实现模型的保存、读取以及加载。</p><p>本文将不再给出完整的Python代码，如需完整的代码，请参考Github地址：https://github.com/percent4/Keras_4_multiclass.</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Keras</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Keras入门（一）搭建DNN解决多分类问题</title>
    <link href="/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E6%90%AD%E5%BB%BA%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88DNN%EF%BC%89%E8%A7%A3%E5%86%B3%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"/>
    <url>/Keras%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E6%90%AD%E5%BB%BA%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88DNN%EF%BC%89%E8%A7%A3%E5%86%B3%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="keras介绍">Keras介绍</h3><p>Keras是一个开源的高层神经网络API，由纯Python编写而成，其后端可以基于Tensorflow、Theano、MXNet以及CNTK。Keras为支持快速实验而生，能够把你的idea迅速转换为结果。Keras适用的Python版本是：Python2.7-3.6。</p><p>Keras，在希腊语中意为“角”（horn），于2015年3月份第一次发行，它可以在Windows,Linux,Mac等系统中运行。那么，既然有了TensorFlow（或Theano、MXNet、CNTK），为什么还需要Keras呢？这是因为，尽管我们可以用TensorFlow等来创建深度神经网络系统，但Tensorflow等使用相对低级的抽象，直接编写TensorFlow代码具有一定的挑战性，而Keras在TensorFlow的基础上，增加了较易使用的抽象层，使用起来更加简单、高效。</p><p>什么样的场合适合用Keras呢？如果你有如下需求，请选择Keras：</p><ul><li><p>简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性）</p></li><li><p>支持CNN和RNN，或二者的结合</p></li><li><p>无缝CPU和GPU切换</p><p>如果想用在你的电脑上使用Keras，需要以下工具：</p></li><li><p>Python</p></li><li><p>TensorFlow</p></li><li><p>Keras</p></li></ul><p>在这里，我们选择TensorFlow作为Keras的后端工具。使用以下Python代码，可以输出Python、TensorFlow以及Keras的版本号：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> keras <span class="hljs-keyword">as</span> K<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>py_ver = sys.version<br>k_ver = K.__version__<br>tf_ver = tf.__version__<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Using Python version &quot;</span> + <span class="hljs-built_in">str</span>(py_ver))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Using Keras version &quot;</span> + <span class="hljs-built_in">str</span>(k_ver))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Using TensorFlow version &quot;</span> + <span class="hljs-built_in">str</span>(tf_ver))<br></code></pre></td></tr></table></figure><p>在笔者的电脑上，输出的结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Using</span> TensorFlow backend.<br><span class="hljs-attribute">Using</span> Python version <span class="hljs-number">3</span>.<span class="hljs-number">5</span>.<span class="hljs-number">1</span> (v3.<span class="hljs-number">5</span>.<span class="hljs-number">1</span>:<span class="hljs-number">37</span>a07cee5969, Dec  <span class="hljs-number">6</span> <span class="hljs-number">2015</span>, <span class="hljs-number">01</span>:<span class="hljs-number">54</span>:<span class="hljs-number">25</span>)<span class="hljs-meta"> [MSC v.1900 64 bit (AMD64)]</span><br><span class="hljs-attribute">Using</span> Keras version <span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">5</span><br><span class="hljs-attribute">Using</span> TensorFlow version <span class="hljs-number">1</span>.<span class="hljs-number">6</span>.<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>下面，笔者将使用IRIS数据集（鸢尾花数据集，一个经典的机器学习数据集，适合作为多分类问题的测试数据），使用Keras搭建一个深度神经网络（DNN），来解决IRIS数据集的多分类问题，作为Keras入门的第一个例子。</p><h3 id="iris数据集介绍">IRIS数据集介绍</h3><p>IRIS数据集（鸢尾花数据集），是一个经典的机器学习数据集，适合作为多分类问题的测试数据，它的下载地址为：http://archive.ics.uci.edu/ml/machine-learning-databases/iris/。</p><p>IRIS数据集是用来给鸢尾花做分类的数据集，一共150个样本，每个样本包含了花萼长度（sepallength in cm）、花萼宽度（sepal width in cm）、花瓣长度（petal length incm）、花瓣宽度（petal width incm）四个特征，将鸢尾花分为三类，分别为Iris Setosa，IrisVersicolour，Iris Virginica，每一类都有50个样本。</p><p>IRIS数据集具体如下（只展示部分数据，顺序已打乱）：</p><figure><img src="/img/keras1_1.png" alt="iris数据集预览" /><figcaption aria-hidden="true">iris数据集预览</figcaption></figure><h3 id="读取数据集">读取数据集</h3><p>笔者的IRIS数据集以csv格式储存，笔者将使用Pandas来读取IRIS数据集，并对目标变量进行0-1编码（One-hotEncoding），最后将该数据集分为训练集和测试集，比例为7:3。完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelBinarizer<br><br><span class="hljs-comment"># 读取CSV数据集，并拆分为训练集和测试集</span><br><span class="hljs-comment"># 该函数的传入参数为CSV_FILE_PATH: csv文件路径</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">CSV_FILE_PATH</span>):<br>    IRIS = pd.read_csv(CSV_FILE_PATH)<br>    target_var = <span class="hljs-string">&#x27;class&#x27;</span>  <span class="hljs-comment"># 目标变量</span><br>    <span class="hljs-comment"># 数据集的特征</span><br>    features = <span class="hljs-built_in">list</span>(IRIS.columns)<br>    features.remove(target_var)<br>    <span class="hljs-comment"># 目标变量的类别</span><br>    Class = IRIS[target_var].unique()<br>    <span class="hljs-comment"># 目标变量的类别字典</span><br>    Class_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(Class, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(Class))))<br>    <span class="hljs-comment"># 增加一列target, 将目标变量进行编码</span><br>    IRIS[<span class="hljs-string">&#x27;target&#x27;</span>] = IRIS[target_var].apply(<span class="hljs-keyword">lambda</span> x: Class_dict[x])<br>    <span class="hljs-comment"># 对目标变量进行0-1编码(One-hot Encoding)</span><br>    lb = LabelBinarizer()<br>    lb.fit(<span class="hljs-built_in">list</span>(Class_dict.values()))<br>    transformed_labels = lb.transform(IRIS[<span class="hljs-string">&#x27;target&#x27;</span>])<br>    y_bin_labels = []  <span class="hljs-comment"># 对多分类进行0-1编码的变量</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(transformed_labels.shape[<span class="hljs-number">1</span>]):<br>        y_bin_labels.append(<span class="hljs-string">&#x27;y&#x27;</span> + <span class="hljs-built_in">str</span>(i))<br>        IRIS[<span class="hljs-string">&#x27;y&#x27;</span> + <span class="hljs-built_in">str</span>(i)] = transformed_labels[:, i]<br>    <span class="hljs-comment"># 将数据集分为训练集和测试集</span><br>    train_x, test_x, train_y, test_y = train_test_split(IRIS[features], IRIS[y_bin_labels], \<br>                                                        train_size=<span class="hljs-number">0.7</span>, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span> train_x, test_x, train_y, test_y, Class_dict<br></code></pre></td></tr></table></figure><h3 id="搭建dnn">搭建DNN</h3><p>接下来，笔者将展示如何利用Keras来搭建一个简单的深度神经网络（DNN）来解决这个多分类问题。我们要搭建的DNN的结构如下图所示：</p><figure><img src="/img/keras1_2.png" alt="DNN结构示意图" /><figcaption aria-hidden="true">DNN结构示意图</figcaption></figure><p>我们搭建的DNN由输入层、隐藏层、输出层和softmax函数组成，其中输入层由4个神经元组成，对应IRIS数据集中的4个特征，作为输入向量，隐藏层有两层，每层分别有5和6个神经元，之后就是输出层，由3个神经元组成，对应IRIS数据集的目标变量的类别个数，最后，就是一个softmax函数，用于解决多分类问题而创建。</p><p>对应以上的DNN结构，用Keras来搭建的话，其Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> keras <span class="hljs-keyword">as</span> K<br> <span class="hljs-comment"># 2. 定义模型</span><br> init = K.initializers.glorot_uniform(seed=<span class="hljs-number">1</span>)<br> simple_adam = K.optimizers.Adam()<br> model = K.models.Sequential()<br> model.add(K.layers.Dense(units=<span class="hljs-number">5</span>, input_dim=<span class="hljs-number">4</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br> model.add(K.layers.Dense(units=<span class="hljs-number">6</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br> model.add(K.layers.Dense(units=<span class="hljs-number">3</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>))<br> model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=simple_adam, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br></code></pre></td></tr></table></figure><p>在这个模型中，我们选择的神经元激活函数为ReLU函数，损失函数为交叉熵（crossentropy），迭代的优化器（optimizer）选择Adam，最初各个层的连接权重（weights）和偏重（biases）是随机生成的。这样我们就讲这个DNN的模型定义完毕了。这么简单？Yes,that's it!</p><h3 id="训练及预测">训练及预测</h3><p>OK，定义完模型后，我们需要对模型进行训练、评估及预测。对于模型训练，我们每次训练的批数为1，共迭代100次，代码如下（接以上代码）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 3. 训练模型</span><br>b_size = <span class="hljs-number">1</span><br>max_epochs = <span class="hljs-number">100</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Starting training &quot;</span>)<br>h = model.fit(train_x, train_y, batch_size=b_size, epochs=max_epochs, shuffle=<span class="hljs-literal">True</span>, verbose=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Training finished \n&quot;</span>)<br></code></pre></td></tr></table></figure><p>为了对模型有个评估，感知模型的表现，需要输出该DNN模型的损失函数的值以及在测试集上的准确率，其Python代码如下（接以上代码）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 4. 评估模型</span><br><span class="hljs-built_in">eval</span> = model.evaluate(test_x, test_y, verbose=<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Evaluation on test data: loss = %0.6f accuracy = %0.2f%% \n&quot;</span> \<br>      % (<span class="hljs-built_in">eval</span>[<span class="hljs-number">0</span>], <span class="hljs-built_in">eval</span>[<span class="hljs-number">1</span>] * <span class="hljs-number">100</span>) )<br></code></pre></td></tr></table></figure><p>训练100次，输出的结果如下（中间部分的训练展示已忽略）：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs lasso">Starting training <br>Epoch <span class="hljs-number">1</span>/<span class="hljs-number">100</span><br><br>  <span class="hljs-number">1</span>/<span class="hljs-number">105</span> <span class="hljs-meta">[</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-meta">]</span> - ETA: 17s - loss: 0.3679 - acc: 1.0000<br> 42/105 <span class="hljs-meta">[</span>===========&gt;<span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-meta">]</span> - ETA: 0s - loss: 1.8081 - acc: 0.3095 <br> 89/105 <span class="hljs-meta">[</span>========================&gt;<span class="hljs-params">...</span>..<span class="hljs-meta">]</span> - ETA: 0s - loss: 1.5068 - acc: 0.4270<br>105/105 <span class="hljs-meta">[</span>==============================<span class="hljs-meta">]</span> - 0s 3ms/step - loss: 1.4164 - acc: 0.4667<br>Epoch 2/100<br><br>  1/105 <span class="hljs-meta">[</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-meta">]</span> - ETA: 0s - loss: 0.4766 - acc: 1.0000<br> 45/105 <span class="hljs-meta">[</span>===========&gt;<span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-meta">]</span> - ETA: 0s - loss: 1.0813 - acc: 0.4889<br> 93/105 <span class="hljs-meta">[</span>=========================&gt;<span class="hljs-params">...</span>.<span class="hljs-meta">]</span> - ETA: 0s - loss: 1.0335 - acc: 0.4839<br>105/105 <span class="hljs-meta">[</span>==============================<span class="hljs-meta">]</span> - 0s 1ms/step - loss: 1.0144 - acc: 0.4857<br><br>......<br><br>Epoch 99/100<br><br>  1/105 <span class="hljs-meta">[</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-meta">]</span> - ETA: 0s - loss: 0.0013 - acc: 1.0000<br> 43/105 <span class="hljs-meta">[</span>===========&gt;<span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-meta">]</span> - ETA: 0s - loss: 0.0447 - acc: 0.9767<br> 84/105 <span class="hljs-meta">[</span>=======================&gt;<span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-meta">]</span> - ETA: 0s - loss: 0.0824 - acc: 0.9524<br>105/105 <span class="hljs-meta">[</span>==============================<span class="hljs-meta">]</span> - 0s 1ms/step - loss: 0.0711 - acc: 0.9619<br>Epoch 100/100<br><br>  1/105 <span class="hljs-meta">[</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-meta">]</span> - ETA: 0s - loss: 2.3032 - acc: 0.0000e+00<br> 51/105 <span class="hljs-meta">[</span>=============&gt;<span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span>.<span class="hljs-meta">]</span> - ETA: 0s - loss: 0.1122 - acc: 0.9608    <br> 99/105 <span class="hljs-meta">[</span>===========================&gt;..<span class="hljs-meta">]</span> - ETA: 0s - loss: 0.0755 - acc: 0.9798<br>105/105 <span class="hljs-meta">[</span>==============================<span class="hljs-meta">]</span> - 0s 1ms/step - loss: 0.0756 - acc: 0.9810<br>Training finished <br><br>Evaluation on test data: loss = 0.094882 accuracy = 97.78% <br></code></pre></td></tr></table></figure><p>可以看到，训练完100次后，在测试集上的准确率已达到97.78%，效果相当好。</p><p>最后是对新数据集进行预测，我们假设一朵鸢尾花的4个特征为6.1,3.1,5.1,1.1，我们想知道这个DNN模型会把它预测到哪一类，其Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br> <span class="hljs-comment"># 5. 使用模型进行预测</span><br> np.set_printoptions(precision=<span class="hljs-number">4</span>)<br> unknown = np.array([[<span class="hljs-number">6.1</span>, <span class="hljs-number">3.1</span>, <span class="hljs-number">5.1</span>, <span class="hljs-number">1.1</span>]], dtype=np.float32)<br> predicted = model.predict(unknown)<br> <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Using model to predict species for features: &quot;</span>)<br> <span class="hljs-built_in">print</span>(unknown)<br> <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nPredicted softmax vector is: &quot;</span>)<br> <span class="hljs-built_in">print</span>(predicted)<br> species_dict = &#123;v:k <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> Class_dict.items()&#125;<br> <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nPredicted species is: &quot;</span>)<br> <span class="hljs-built_in">print</span>(species_dict[np.argmax(predicted)])<br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs lua">Using model to predict species <span class="hljs-keyword">for</span> features: <br><span class="hljs-string">[[ 6.1  3.1  5.1  1.1]]</span><br><br>Predicted softmax vector is: <br><span class="hljs-string">[[  2.0687e-07   9.7901e-01   2.0993e-02]]</span><br><br>Predicted species is: <br>versicolor<br></code></pre></td></tr></table></figure><p>如果我们仔细地比对IRIS数据集，就会发现，这个预测结果令人相当满意，这个鸢尾花样本的预测结果，以人类的眼光来看，也应当是versicolor。</p><h3 id="总结">总结</h3><p>到此为止，笔者就把这个演示例子给讲完了，作为入门Keras的第一步，这个例子还是可以的。回顾该模型，首先我们利用Pandas读取IRIS数据集，并分为训练集和测试集，然后用Keras搭建了一个简单的DNN模型，并对该模型进行训练及评估，最后看一下该模型在新数据集上的预测能力。从中，读者不难体会到Keras的优越性，因为，相比TensorFlow,搭建同样的DNN模型及模型训练、评估、预测，其Python代码无疑会比Keras来得长。</p><p>最后，附上该DNN模型的完整Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># iris_keras_dnn.py</span><br><span class="hljs-comment"># Python 3.5.1, TensorFlow 1.6.0, Keras 2.1.5</span><br><span class="hljs-comment"># ========================================================</span><br><span class="hljs-comment"># 导入模块</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> keras <span class="hljs-keyword">as</span> K<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelBinarizer<br>os.environ[<span class="hljs-string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>]=<span class="hljs-string">&#x27;2&#x27;</span><br><br><span class="hljs-comment"># 读取CSV数据集，并拆分为训练集和测试集</span><br><span class="hljs-comment"># 该函数的传入参数为CSV_FILE_PATH: csv文件路径</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">CSV_FILE_PATH</span>):<br>    IRIS = pd.read_csv(CSV_FILE_PATH)<br>    target_var = <span class="hljs-string">&#x27;class&#x27;</span>  <span class="hljs-comment"># 目标变量</span><br>    <span class="hljs-comment"># 数据集的特征</span><br>    features = <span class="hljs-built_in">list</span>(IRIS.columns)<br>    features.remove(target_var)<br>    <span class="hljs-comment"># 目标变量的类别</span><br>    Class = IRIS[target_var].unique()<br>    <span class="hljs-comment"># 目标变量的类别字典</span><br>    Class_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(Class, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(Class))))<br>    <span class="hljs-comment"># 增加一列target, 将目标变量进行编码</span><br>    IRIS[<span class="hljs-string">&#x27;target&#x27;</span>] = IRIS[target_var].apply(<span class="hljs-keyword">lambda</span> x: Class_dict[x])<br>    <span class="hljs-comment"># 对目标变量进行0-1编码(One-hot Encoding)</span><br>    lb = LabelBinarizer()<br>    lb.fit(<span class="hljs-built_in">list</span>(Class_dict.values()))<br>    transformed_labels = lb.transform(IRIS[<span class="hljs-string">&#x27;target&#x27;</span>])<br>    y_bin_labels = []  <span class="hljs-comment"># 对多分类进行0-1编码的变量</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(transformed_labels.shape[<span class="hljs-number">1</span>]):<br>        y_bin_labels.append(<span class="hljs-string">&#x27;y&#x27;</span> + <span class="hljs-built_in">str</span>(i))<br>        IRIS[<span class="hljs-string">&#x27;y&#x27;</span> + <span class="hljs-built_in">str</span>(i)] = transformed_labels[:, i]<br>    <span class="hljs-comment"># 将数据集分为训练集和测试集</span><br>    train_x, test_x, train_y, test_y = train_test_split(IRIS[features], IRIS[y_bin_labels], \<br>                                                        train_size=<span class="hljs-number">0.7</span>, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span> train_x, test_x, train_y, test_y, Class_dict<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br><br>    <span class="hljs-comment"># 0. 开始</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nIris dataset using Keras/TensorFlow &quot;</span>)<br>    np.random.seed(<span class="hljs-number">4</span>)<br>    tf.set_random_seed(<span class="hljs-number">13</span>)<br><br>    <span class="hljs-comment"># 1. 读取CSV数据集</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Loading Iris data into memory&quot;</span>)<br>    CSV_FILE_PATH = <span class="hljs-string">&#x27;E://iris.csv&#x27;</span><br>    train_x, test_x, train_y, test_y, Class_dict = load_data(CSV_FILE_PATH)<br><br>    <span class="hljs-comment"># 2. 定义模型</span><br>    init = K.initializers.glorot_uniform(seed=<span class="hljs-number">1</span>)<br>    simple_adam = K.optimizers.Adam()<br>    model = K.models.Sequential()<br>    model.add(K.layers.Dense(units=<span class="hljs-number">5</span>, input_dim=<span class="hljs-number">4</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br>    model.add(K.layers.Dense(units=<span class="hljs-number">6</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br>    model.add(K.layers.Dense(units=<span class="hljs-number">3</span>, kernel_initializer=init, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>))<br>    model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=simple_adam, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br>    <span class="hljs-comment"># 3. 训练模型</span><br>    b_size = <span class="hljs-number">1</span><br>    max_epochs = <span class="hljs-number">100</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Starting training &quot;</span>)<br>    h = model.fit(train_x, train_y, batch_size=b_size, epochs=max_epochs, shuffle=<span class="hljs-literal">True</span>, verbose=<span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Training finished \n&quot;</span>)<br><br>    <span class="hljs-comment"># 4. 评估模型</span><br>    <span class="hljs-built_in">eval</span> = model.evaluate(test_x, test_y, verbose=<span class="hljs-number">0</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Evaluation on test data: loss = %0.6f accuracy = %0.2f%% \n&quot;</span> \<br>          % (<span class="hljs-built_in">eval</span>[<span class="hljs-number">0</span>], <span class="hljs-built_in">eval</span>[<span class="hljs-number">1</span>] * <span class="hljs-number">100</span>) )<br><br>    <span class="hljs-comment"># 5. 使用模型进行预测</span><br>    np.set_printoptions(precision=<span class="hljs-number">4</span>)<br>    unknown = np.array([[<span class="hljs-number">6.1</span>, <span class="hljs-number">3.1</span>, <span class="hljs-number">5.1</span>, <span class="hljs-number">1.1</span>]], dtype=np.float32)<br>    predicted = model.predict(unknown)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Using model to predict species for features: &quot;</span>)<br>    <span class="hljs-built_in">print</span>(unknown)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nPredicted softmax vector is: &quot;</span>)<br>    <span class="hljs-built_in">print</span>(predicted)<br>    species_dict = &#123;v:k <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> Class_dict.items()&#125;<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nPredicted species is: &quot;</span>)<br>    <span class="hljs-built_in">print</span>(species_dict[np.argmax(predicted)])<br><br>main()<br></code></pre></td></tr></table></figure><h3 id="参考文献">参考文献</h3><ol type="1"><li>Keras中文文档： https://keras-cn.readthedocs.io/en/latest/</li><li>Keras Succinctly:http://ebooks.syncfusion.com/downloads/keras-succinctly/keras-succinctly.pdf?AWSAccessKeyId=AKIAJ5W3G2Z6F2ZHAREQ&amp;Expires=1539315050&amp;Signature=r6qJ%2BP7KUEU442WMObSLd2%2Flkqw%3D</li><li>IRIS数据集：http://archive.ics.uci.edu/ml/machine-learning-databases/iris/</li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Keras</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>书籍摘抄Latex代码</title>
    <link href="/%E4%B9%A6%E7%B1%8D%E6%91%98%E6%8A%84Latex%E4%BB%A3%E7%A0%81/"/>
    <url>/%E4%B9%A6%E7%B1%8D%E6%91%98%E6%8A%84Latex%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>使用工具: TeX Live + TeXstudio + Latex<br>Latex源代码：</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\documentclass</span>&#123;article&#125;<br><span class="hljs-keyword">\usepackage</span>[utf8]&#123;inputenc&#125;<br><span class="hljs-keyword">\usepackage</span>&#123;graphicx&#125; <span class="hljs-comment">% Required for inserting images</span><br><span class="hljs-keyword">\usepackage</span>&#123;wrapfig&#125;  <span class="hljs-comment">% 图文混排支持</span><br><span class="hljs-keyword">\usepackage</span>&#123;caption&#125;<br><span class="hljs-keyword">\usepackage</span>&#123;ctex&#125;<br><span class="hljs-keyword">\usepackage</span>&#123;color&#125;<br><span class="hljs-keyword">\usepackage</span>&#123;amssymb&#125;<br><span class="hljs-keyword">\usepackage</span>&#123;amsmath&#125;<br><span class="hljs-keyword">\usepackage</span>&#123;amsthm&#125;<br><span class="hljs-keyword">\usepackage</span>[a4paper,margin=1in]&#123;geometry&#125; <span class="hljs-comment">% 页面设置</span><br><span class="hljs-keyword">\usepackage</span>&#123;wallpaper&#125;<br><span class="hljs-comment">%\TileWallPaper&#123;\paperwidth&#125;&#123;\paperheight&#125;&#123;pictures/test.jpg&#125;</span><br><br><span class="hljs-keyword">\linespread</span>&#123;2&#125; <span class="hljs-comment">% 设置行距</span><br><br><span class="hljs-keyword">\title</span>&#123;《》摘抄&#125;<br><span class="hljs-keyword">\author</span>&#123;<span class="hljs-keyword">\quad</span> 著&#125;<br><span class="hljs-keyword">\date</span>&#123;<span class="hljs-keyword">\today</span>&#125;<br><br><span class="hljs-keyword">\begin</span>&#123;document&#125;<br><br><span class="hljs-keyword">\maketitle</span><br><br><span class="hljs-keyword">\begin</span>&#123;figure&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[width=16cm]&#123;pictures//test.jpg&#125;<br><span class="hljs-keyword">\caption</span>*&#123;书本封面&#125;<br><span class="hljs-keyword">\end</span>&#123;figure&#125;<br><br><span class="hljs-keyword">\newpage</span><br><span class="hljs-keyword">\songti</span><span class="hljs-keyword">\zihao</span>&#123;-4&#125;<br><br><span class="hljs-keyword">\begin</span>&#123;enumerate&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\item</span> <span class="hljs-keyword">\setlength</span>&#123;<span class="hljs-keyword">\parindent</span>&#125;&#123;2em&#125;<br><span class="hljs-keyword">\end</span>&#123;enumerate&#125;<br><br><br><span class="hljs-keyword">\end</span>&#123;document&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>书籍摘抄</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍摘抄</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《寻路中国》摘抄</title>
    <link href="/%E3%80%8A%E5%AF%BB%E8%B7%AF%E4%B8%AD%E5%9B%BD%E3%80%8B%E6%91%98%E6%8A%84/"/>
    <url>/%E3%80%8A%E5%AF%BB%E8%B7%AF%E4%B8%AD%E5%9B%BD%E3%80%8B%E6%91%98%E6%8A%84/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="/pdfjs/web/viewer.html?file=/pdf/《寻路中国》摘抄.pdf">PDF全屏浏览（PDF View in FullScreen）</a></p><iframe src='/pdfjs/web/viewer.html?file=/pdf/《寻路中国》摘抄.pdf' width="100%" height="800px"></iframe>]]></content>
    
    
    <categories>
      
      <category>书籍摘抄</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍摘抄</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《万里走单骑-老单日记》摘抄</title>
    <link href="/%E3%80%8A%E4%B8%87%E9%87%8C%E8%B5%B0%E5%8D%95%E9%AA%91-%E8%80%81%E5%8D%95%E6%97%A5%E8%AE%B0%E3%80%8B%E6%91%98%E6%8A%84/"/>
    <url>/%E3%80%8A%E4%B8%87%E9%87%8C%E8%B5%B0%E5%8D%95%E9%AA%91-%E8%80%81%E5%8D%95%E6%97%A5%E8%AE%B0%E3%80%8B%E6%91%98%E6%8A%84/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="/pdfjs/web/viewer.html?file=/pdf/《万里走单骑-老单日记》摘抄.pdf">PDF全屏浏览（PDF View in FullScreen）</a></p><iframe src='/pdfjs/web/viewer.html?file=/pdf/《万里走单骑-老单日记》摘抄.pdf' width="100%" height="800px"></iframe>]]></content>
    
    
    <categories>
      
      <category>书籍摘抄</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍摘抄</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch入门及其在深度学习中的应用介绍</title>
    <link href="/PyTorch%E5%85%A5%E9%97%A8%E5%8F%8A%E5%85%B6%E5%9C%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%BB%8B%E7%BB%8D/"/>
    <url>/PyTorch%E5%85%A5%E9%97%A8%E5%8F%8A%E5%85%B6%E5%9C%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="/pdfjs/web/viewer.html?file=/pdf/PyTorch入门及其在深度学习中的应用介绍.pdf">PDF全屏浏览（PDF View in FullScreen）</a></p><iframe src='/pdfjs/web/viewer.html?file=/pdf/PyTorch入门及其在深度学习中的应用介绍.pdf' width="100%" height="800px"></iframe>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch入门（八）Embedding层</title>
    <link href="/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AB%EF%BC%89Embedding%E5%B1%82/"/>
    <url>/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AB%EF%BC%89Embedding%E5%B1%82/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>词向量实现在PyTorch中对应于Embedding层，其实现代码的源码函数（PyTorch的版本为2.0）如下：</p><blockquote><p>torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None,max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False,_weight=None)</p></blockquote><p>该函数随机会生成了一个向量，可以把它看作一个词向量查询表，其size为[num_embeddings，embedding_dim]。其中num_embeddings是查询表的大小，embedding_dim是每个查询向量的维度。</p><p>函数参数解释：</p><ul><li>num_embeddings: int, 查询表的大小</li><li>embedding_dim: int, 每个查询向量的维度</li><li>padding_idx: int, 填充id</li><li>max_norm: float,最大范数，每个范数超过max_norm的embedding向量会重新规范化至其范数为max_norm</li><li>norm_type: float, p范数（p=norm_type），默认值为2</li></ul><p>需要注意的是，查询的下标向量的数据类型必须使Long，即Int64.</p><p>让我们来看几个Embedding层的使用例子。</p><ol type="1"><li>例子1：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># an Embedding module containing 10 tensors of size 3</span><br>embedding = nn.Embedding(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(embedding.weight)<br><span class="hljs-comment"># a batch of 2 samples of 4 indices each</span><br><span class="hljs-built_in">input</span> = torch.LongTensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">9</span>]])<br><span class="hljs-built_in">print</span>(embedding(<span class="hljs-built_in">input</span>))<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs bash">Parameter containing:<br>tensor([[ 1.9260, -1.3492,  0.3753],<br>        [ 1.2182,  1.8350,  0.7975],<br>        [ 0.1568,  0.9562,  1.1164],<br>        [ 1.4660,  0.8763,  0.1681],<br>        [ 0.4175,  0.4029, -1.3495],<br>        [-0.5182,  0.1465,  0.0280],<br>        [ 0.7748,  0.1848, -0.4229],<br>        [ 0.3740, -0.2761,  1.5017],<br>        [-0.4583,  0.2934,  0.2217],<br>        [-0.1402, -0.5671, -1.7069]], requires_grad=True)<br>tensor([[[ 1.2182,  1.8350,  0.7975],<br>         [ 0.1568,  0.9562,  1.1164],<br>         [ 0.4175,  0.4029, -1.3495],<br>         [-0.5182,  0.1465,  0.0280]],<br><br>        [[ 0.4175,  0.4029, -1.3495],<br>         [ 1.4660,  0.8763,  0.1681],<br>         [ 0.1568,  0.9562,  1.1164],<br>         [-0.1402, -0.5671, -1.7069]]], grad_fn=&lt;EmbeddingBackward&gt;)<br><br>Process finished with <span class="hljs-built_in">exit</span> code 0<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>例子2：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># Embedding with padding_idx</span><br>embedding = nn.Embedding(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>, padding_idx=<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(embedding.weight)<br><span class="hljs-built_in">input</span> = torch.LongTensor([[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">4</span>]])<br><span class="hljs-built_in">print</span>(embedding(<span class="hljs-built_in">input</span>))<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs inform7">Parameter containing:<br>tensor(<span class="hljs-comment">[<span class="hljs-comment">[ 0.0000,  0.0000,  0.0000]</span>,</span><br><span class="hljs-comment">        <span class="hljs-comment">[-1.4159, -1.2288,  0.2698]</span>,</span><br><span class="hljs-comment">        <span class="hljs-comment">[-2.2287, -1.5313,  0.3296]</span>,</span><br><span class="hljs-comment">        <span class="hljs-comment">[-1.0393, -0.3102,  0.2819]</span>,</span><br><span class="hljs-comment">        <span class="hljs-comment">[-0.2162, -0.2060,  0.3289]</span>]</span>, requires_grad=True)<br>tensor(<span class="hljs-comment">[<span class="hljs-comment">[<span class="hljs-comment">[ 0.0000,  0.0000,  0.0000]</span>,</span></span><br><span class="hljs-comment"><span class="hljs-comment">         <span class="hljs-comment">[-2.2287, -1.5313,  0.3296]</span>,</span></span><br><span class="hljs-comment"><span class="hljs-comment">         <span class="hljs-comment">[ 0.0000,  0.0000,  0.0000]</span>,</span></span><br><span class="hljs-comment"><span class="hljs-comment">         <span class="hljs-comment">[-0.2162, -0.2060,  0.3289]</span>]</span>]</span>, grad_fn=&lt;EmbeddingBackward&gt;)<br></code></pre></td></tr></table></figure><p>从中我们可以发现，Embedding层中padding_idx对应的向量为零向量。</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>Embedding source code: <ahref="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html">https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch入门（七）TensorBoard入门</title>
    <link href="/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%83%EF%BC%89TensorBoard%E5%85%A5%E9%97%A8/"/>
    <url>/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%83%EF%BC%89TensorBoard%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>PyTorch模型的可视化工具：</p><ul><li>Visdom</li><li>TensorBoard</li><li>Pytorchviz</li><li>Netron</li></ul><h3 id="tensorboard简介">TensorBoard简介</h3><p>TensorBoard是TensorFlow自带的一个强大的可视化工具，也是一个Web应用程序套件，可以记录训练过程的数字、图像等内容，以方便研究人员观察神经网络训练过程。</p><p>对于PyTorch等其它深度学习框架来说，目前还没有功能像TensorBoard一样全面的类似工具，一些已有的工具功能也有限，或使用起来比较困难。</p><p>TensorBoard提供的机器学习实验所需的可视化功能和工具如下：</p><ul><li><p>跟踪和可视化损失及准确率等指标</p></li><li><p>可视化模型图</p></li><li><p>查看权重、偏差或其它张量随时间变化的直方图</p></li><li><p>将嵌入向量投影到较低维度空间</p></li><li><p>显示图片、文字和音频数据</p></li><li><p>剖析TensorFlow程序</p><p>如果要使用TensorBoard，首先需要安装tensorflow, tensorboard,tensorboardX, 代码如下：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install tensorflow<br>pip3 install tensorboard<br>pip3 install tensorboardX<br></code></pre></td></tr></table></figure><p>其中，tensorboardX这个工具可使得TensorFlow外的其它深度学习框架也可以使用TensorBoard的便捷功能。</p><p>TensorBoard目前支持7种可视化，包括Scalars, Images, Audio, Graphs,Distributions, Histograms, Embeddings, 主要功能如下：</p><ul><li><p>Scalars:展示训练过程中的准确率、损失值、权重/偏差的变化情况</p></li><li><p>Images: 展示训练过程中记录的图像</p></li><li><p>Audio: 展示训练过程中记录的音频</p></li><li><p>Graphs:展示模型的数据流图，以及训练在各个设备上消耗的内存和时间</p></li><li><p>Distributions: 展示训练过程中记录的数据的分布图</p></li><li><p>Histograms: 展示训练过程中记录的数据的柱状图</p></li><li><p>Embeddings: 展示词向量的投影分布</p><p>启动TensorBoard:</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tonsorboard --logdir=./run/<br></code></pre></td></tr></table></figure><h3 id="tensorboard基础操作">TensorBoard基础操作</h3><ol type="1"><li>可视化数值</li></ol><p>使用add_scalar方法来记录数字常量，一般使用add_scalar方法来记录训练过程中的loss,arrcuracy, learning rate等数值的变化，直观地监控训练过程。</p><p>示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># import modules</span><br><span class="hljs-keyword">from</span> tensorboardX <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-comment"># add_scalar</span><br>writer = SummaryWriter(<span class="hljs-string">&#x27;run/scalar&#x27;</span>)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    writer.add_scalar(<span class="hljs-string">&#x27;指数&#x27;</span>, <span class="hljs-number">3</span>**i, global_step=i)<br></code></pre></td></tr></table></figure><figure><img src="/img/pytorch7_1.png" alt="在tensorboard中查看scalar" /><figcaption aria-hidden="true">在tensorboard中查看scalar</figcaption></figure><ol start="2" type="1"><li>可视化图片</li></ol><p>使用add_images方法来记录图像数据，一般会使用add_images来实时观察模型的生成效果，或者可视化分割、目标检测的结果，帮助调试模型。</p><p>示例代码： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># add_images</span><br><span class="hljs-keyword">import</span> cv2<br><br>writer = SummaryWriter(<span class="hljs-string">&#x27;run/image&#x27;</span>)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>):<br>    writer.add_images(<span class="hljs-string">&#x27;&#x27;</span>, <br>                      cv2.cvtColor(cv2.imread(<span class="hljs-string">&#x27;./image/image&#123;&#125;.png&#x27;</span>.<span class="hljs-built_in">format</span>(i)), cv2.COLOR_BGR2RGB), <br>                      global_step=i, <br>                      dataformats=<span class="hljs-string">&#x27;HWC&#x27;</span>)<br></code></pre></td></tr></table></figure></p><figure><img src="/img/pytorch7_2.png" alt="在tensorboard中查看图片" /><figcaption aria-hidden="true">在tensorboard中查看图片</figcaption></figure><ol start="3" type="1"><li>可视化统计图</li></ol><p>使用add_histogram方法来记录一组数据的直方图。可以通过观察数据、训练参数、特征的直方图了解到它们大致的分布情况，辅助神经网络的训练过程。</p><p>示例代码： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># add_histogram</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>writer = SummaryWriter(<span class="hljs-string">&#x27;run/histogram&#x27;</span>)<br>writer.add_histogram(<span class="hljs-string">&#x27;正态分布中心化&#x27;</span>, np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1000</span>), global_step=<span class="hljs-number">1</span>)<br>writer.add_histogram(<span class="hljs-string">&#x27;正态分布中心化&#x27;</span>, np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1000</span>), global_step=<span class="hljs-number">50</span>)<br>writer.add_histogram(<span class="hljs-string">&#x27;正态分布中心化&#x27;</span>, np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1000</span>), global_step=<span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure></p><p>在TensorBoard可视化界面中，我们会发现DISTRIBUTIONS和HISTOGRAMS两栏，它们都是用来观察数据分布的。在HISTOGRAMS中，同一数据不同步数的直方图可以上下错位排布（OFFSET）也可以重叠排布（OVERLAY）。</p><figure><img src="/img/pytorch7_3.png" alt="在tensorboard中查看柱状图" /><figcaption aria-hidden="true">在tensorboard中查看柱状图</figcaption></figure><ol start="4" type="1"><li>可视化模型图</li></ol><p>使用add_graph方法来可视化一个神经网络。该方法可以将神经网络模型可视化，显示模型中的操作和网络层。</p><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br>dummy_input = (torch.zeros(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>),)<br>writer = SummaryWriter(<span class="hljs-string">&#x27;run/graph&#x27;</span>)<br><br><span class="hljs-comment"># simple MLP model</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LinearInLinear</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(LinearInLinear, self).__init__()<br>        self.l = nn.Linear(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.l(x)<br><br>writer.add_graph(LinearInLinear(), dummy_input)<br></code></pre></td></tr></table></figure><figure><img src="/img/pytorch7_4.png" alt="在tensorboard中查看模型图" /><figcaption aria-hidden="true">在tensorboard中查看模型图</figcaption></figure><ol start="5" type="1"><li>可视化向量</li></ol><p>使用add_embedding方法可以在二维或三维空间可视化Embedding向量。add_embedding方法是一个很实用的方法，不仅可以将高维特征使用PCA,T-SNE等方法降维至二维平面或三维空间，还可以观察每一个数据点在降维前的特征空间的K近邻情况。</p><p>下面的例子中我们取MNIST训练集中的前30个数据，将图像展开成一维向量作为Embedding，使用TensorBoardX进行可视化。</p><p>示例代码如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># add_embedding</span><br><span class="hljs-keyword">import</span> torchvision<br><br>writer = SummaryWriter(<span class="hljs-string">&#x27;run/vector&#x27;</span>)<br>mnist = torchvision.datasets.MNIST(<span class="hljs-string">&#x27;./&#x27;</span>, download=<span class="hljs-literal">False</span>)<br>writer.add_embedding(mnist.data.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">28</span>*<span class="hljs-number">28</span>))[:<span class="hljs-number">30</span>, :],<br>                     metadata=mnist.targets[:<span class="hljs-number">30</span>],<br>                     label_img = mnist.data[:<span class="hljs-number">30</span>, :, :].reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)).<span class="hljs-built_in">float</span>()/<span class="hljs-number">255</span>,<br>                     global_step=<span class="hljs-number">0</span><br>                    )<br></code></pre></td></tr></table></figure></p><p>可以发现，虽然还没有做任何特征提取工作，但MNIST数据已经呈现出聚类的效果，相同数字之间距离更近一些。</p><figure><img src="/img/pytorch7_5.png" alt="在tensorboard中查看向量嵌入" /><figcaption aria-hidden="true">在tensorboard中查看向量嵌入</figcaption></figure><h3 id="tensorboard实战">TensorBoard实战</h3><ol type="1"><li>例子1：在模型训练过程中记录loss和accuracy. Python示例代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> vstack<br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> argmax<br><span class="hljs-keyword">from</span> pandas <span class="hljs-keyword">import</span> read_csv<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelEncoder, LabelBinarizer<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> SGD, Adam<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader, random_split<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Linear, ReLU, Softmax, Module, CrossEntropyLoss<br><span class="hljs-keyword">from</span> torch.nn.init <span class="hljs-keyword">import</span> kaiming_uniform_, xavier_uniform_<br><br><span class="hljs-keyword">from</span> tensorboardX <span class="hljs-keyword">import</span> SummaryWriter<br><br><br><span class="hljs-comment"># dataset definition</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CSVDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-comment"># load the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, path</span>):<br>        <span class="hljs-comment"># load the csv file as a dataframe</span><br>        df = read_csv(path, header=<span class="hljs-literal">None</span>)<br>        <span class="hljs-comment"># store the inputs and outputs</span><br>        self.X = df.values[:, :-<span class="hljs-number">1</span>]<br>        self.y = df.values[:, -<span class="hljs-number">1</span>]<br>        <span class="hljs-comment"># ensure input data is floats</span><br>        self.X = self.X.astype(<span class="hljs-string">&#x27;float32&#x27;</span>)<br>        <span class="hljs-comment"># label encode target and ensure the values are floats</span><br>        self.y = LabelEncoder().fit_transform(self.y)<br><br>    <span class="hljs-comment"># number of rows in the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.X)<br><br>    <span class="hljs-comment"># get a row at an index</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> [self.X[idx], self.y[idx]]<br><br>    <span class="hljs-comment"># get indexes for train and test rows</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_splits</span>(<span class="hljs-params">self, n_test=<span class="hljs-number">0.3</span></span>):<br>        <span class="hljs-comment"># determine sizes</span><br>        test_size = <span class="hljs-built_in">round</span>(n_test * <span class="hljs-built_in">len</span>(self.X))<br>        train_size = <span class="hljs-built_in">len</span>(self.X) - test_size<br>        <span class="hljs-comment"># calculate the split</span><br>        <span class="hljs-keyword">return</span> random_split(self, [train_size, test_size])<br><br><br><span class="hljs-comment"># model definition</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>(<span class="hljs-title class_ inherited__">Module</span>):<br>    <span class="hljs-comment"># define model elements</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_inputs</span>):<br>        <span class="hljs-built_in">super</span>(MLP, self).__init__()<br>        <span class="hljs-comment"># input to first hidden layer</span><br>        self.hidden1 = Linear(n_inputs, <span class="hljs-number">5</span>)<br>        kaiming_uniform_(self.hidden1.weight, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>        self.act1 = ReLU()<br>        <span class="hljs-comment"># second hidden layer</span><br>        self.hidden2 = Linear(<span class="hljs-number">5</span>, <span class="hljs-number">6</span>)<br>        kaiming_uniform_(self.hidden2.weight, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>        self.act2 = ReLU()<br>        <span class="hljs-comment"># third hidden layer and output</span><br>        self.hidden3 = Linear(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>)<br>        xavier_uniform_(self.hidden3.weight)<br><br>    <span class="hljs-comment"># forward propagate input</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-comment"># input to first hidden layer</span><br>        X = self.hidden1(X)<br>        X = self.act1(X)<br>        <span class="hljs-comment"># second hidden layer</span><br>        X = self.hidden2(X)<br>        X = self.act2(X)<br>        <span class="hljs-comment"># output layer</span><br>        X = self.hidden3(X)<br>        <span class="hljs-keyword">return</span> X<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, file_path, model</span>):<br>        self.writer = SummaryWriter(<span class="hljs-string">&#x27;./run/mlp_demo&#x27;</span>)<br>        <span class="hljs-comment"># load the dataset</span><br>        dataset = CSVDataset(file_path)<br>        <span class="hljs-comment"># calculate split</span><br>        train, test = dataset.get_splits()<br>        <span class="hljs-comment"># prepare data loaders</span><br>        self.train_dl = DataLoader(train, batch_size=<span class="hljs-number">4</span>, shuffle=<span class="hljs-literal">True</span>)<br>        self.test_dl = DataLoader(test, batch_size=<span class="hljs-number">1024</span>, shuffle=<span class="hljs-literal">False</span>)<br>        <span class="hljs-comment"># model</span><br>        self.model = model<br><br>    <span class="hljs-comment"># train the model</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self</span>):<br>        criterion = CrossEntropyLoss()<br>        optimizer = Adam(self.model.parameters())<br>        <span class="hljs-comment"># enumerate epochs</span><br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>            init_loss = torch.Tensor([<span class="hljs-number">0.0</span>])<br>            <span class="hljs-comment"># enumerate mini batches</span><br>            <span class="hljs-keyword">for</span> i, (inputs, targets) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.train_dl):<br>                targets = targets.long()<br>                <span class="hljs-comment"># clear the gradients</span><br>                optimizer.zero_grad()<br>                <span class="hljs-comment"># compute the model output</span><br>                yhat = self.model(inputs)<br>                <span class="hljs-comment"># calculate loss</span><br>                loss = criterion(yhat, targets)<br>                <span class="hljs-comment"># credit assignment</span><br>                loss.backward()<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch: &#123;&#125;, batch: &#123;&#125;, loss: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, i, loss.data))<br>                init_loss += loss.data<br>                <span class="hljs-comment"># update model weights</span><br>                optimizer.step()<br><br>            self.writer.add_scalar(<span class="hljs-string">&#x27;Loss/Train&#x27;</span>, init_loss/(i+<span class="hljs-number">1</span>), epoch)<br>            test_accuracy = self.evaluate_model()<br>            self.writer.add_scalar(<span class="hljs-string">&#x27;Accuracy/Test&#x27;</span>, test_accuracy, epoch)<br><br>    <span class="hljs-comment"># evaluate the model</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_model</span>(<span class="hljs-params">self</span>):<br>        predictions, actuals = [], []<br>        <span class="hljs-keyword">for</span> i, (inputs, targets) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.test_dl):<br>            <span class="hljs-comment"># evaluate the model on the test set</span><br>            yhat = self.model(inputs)<br>            <span class="hljs-comment"># retrieve numpy array</span><br>            yhat = yhat.detach().numpy()<br>            actual = targets.numpy()<br>            <span class="hljs-comment"># convert to class labels</span><br>            yhat = argmax(yhat, axis=<span class="hljs-number">1</span>)<br>            <span class="hljs-comment"># reshape for stacking</span><br>            actual = actual.reshape((<span class="hljs-built_in">len</span>(actual), <span class="hljs-number">1</span>))<br>            yhat = yhat.reshape((<span class="hljs-built_in">len</span>(yhat), <span class="hljs-number">1</span>))<br>            <span class="hljs-comment"># store</span><br>            predictions.append(yhat)<br>            actuals.append(actual)<br>        predictions, actuals = vstack(predictions), vstack(actuals)<br>        <span class="hljs-comment"># calculate accuracy</span><br>        acc = accuracy_score(actuals, predictions)<br>        <span class="hljs-keyword">return</span> acc<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># train the model</span><br>    Model(<span class="hljs-string">&#x27;iris.csv&#x27;</span>, MLP(<span class="hljs-number">4</span>)).train()<br></code></pre></td></tr></table></figure></li></ol><p>在训练过程中的训练集的损失值以及验证集的准确率如下：</p><figure><img src="/img/pytorch7_6.png"alt="在tensorboard中查看loss和accuracy" /><figcaptionaria-hidden="true">在tensorboard中查看loss和accuracy</figcaption></figure><ol start="2" type="1"><li>例子2： 利用TensorBoard查看ONNX文件</li></ol><p>需安装Python第三方模块onnx, Python代码如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> tensorboardX <span class="hljs-keyword">import</span> SummaryWriter<br><br><span class="hljs-keyword">with</span> SummaryWriter(<span class="hljs-string">&#x27;./run/onnx&#x27;</span>) <span class="hljs-keyword">as</span> w:<br>    w.add_onnx_graph(<span class="hljs-string">&#x27;iris.onnx&#x27;</span>)<br></code></pre></td></tr></table></figure></p><p>在TensorBoard中选择Graphs, Run选项选择onnx，模型图如下：</p><figure><img src="/img/pytorch7_7.png" alt="在tensorboard中查看onnx模型图" /><figcaptionaria-hidden="true">在tensorboard中查看onnx模型图</figcaption></figure><p>从中可以看出，TensorBoard对于ONNX模型文件支持不是太好，可以尝试使用Netron.</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>tensorboardX Tutorials: <ahref="https://tensorboardx.readthedocs.io/en/latest/tutorial.html#tutorials">https://tensorboardx.readthedocs.io/en/latest/tutorial.html#tutorials</a></li><li>动手学PyTorch深度学习建模与应用，王国平著</li><li>PyTorch 使用 TensorboardX 进行网络可视化：<ahref="https://www.pytorchtutorial.com/pytorch-tensorboardx/">https://www.pytorchtutorial.com/pytorch-tensorboardx/</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
      <tag>TensorBoard</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch入门（六）使用Transformer模型进行中文文本分类</title>
    <link href="/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8Transformer%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    <url>/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8Transformer%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在文章<ahref="https://percent4.github.io/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%94%EF%BC%89%E4%BD%BF%E7%94%A8CNN%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">PyTorch入门（五）使用CNN模型进行中文文本分类</a>中，笔者介绍了如何在PyTorch中使用CNN模型进行中文文本分类。本文将会使用Transformer模型实现中文文本分类。</p><p>本文将会使用相同的数据集。文本预处理已经在文章<ahref="https://blog.csdn.net/jclian91/article/details/129657824">PyTorch入门（五）使用CNN模型进行中文文本分类</a>中介绍，本文使用Transformer模型的Encoder部分，Transformer模型如图：</p><figure><img src="/img/pytorch6_1.png" alt="Transformer模型图" /><figcaption aria-hidden="true">Transformer模型图</figcaption></figure><p>使用Transformer的Encoder部分建立文本分类模型，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @Time : 2023/3/16 14:28</span><br><span class="hljs-comment"># @Author : Jclian91</span><br><span class="hljs-comment"># @File : model.py</span><br><span class="hljs-comment"># @Place : Minghang, Shanghai</span><br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">from</span> params <span class="hljs-keyword">import</span> NUM_WORDS, EMBEDDING_SIZE<br><br><br><span class="hljs-comment"># https://pytorch.org/tutorials/beginner/transformer_tutorial.html</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PositionalEncoding</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, vocab_size=<span class="hljs-number">5000</span>, dropout=<span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.dropout = nn.Dropout(p=dropout)<br><br>        pe = torch.zeros(vocab_size, d_model)<br>        position = torch.arange(<span class="hljs-number">0</span>, vocab_size, dtype=torch.<span class="hljs-built_in">float</span>).unsqueeze(<span class="hljs-number">1</span>)<br>        div_term = torch.exp(<br>            torch.arange(<span class="hljs-number">0</span>, d_model, <span class="hljs-number">2</span>).<span class="hljs-built_in">float</span>()<br>            * (-math.log(<span class="hljs-number">10000.0</span>) / d_model)<br>        )<br>        pe[:, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>] = torch.sin(position * div_term)<br>        pe[:, <span class="hljs-number">1</span>::<span class="hljs-number">2</span>] = torch.cos(position * div_term)<br>        pe = pe.unsqueeze(<span class="hljs-number">0</span>)<br>        self.register_buffer(<span class="hljs-string">&quot;pe&quot;</span>, pe)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = x + self.pe[:, : x.size(<span class="hljs-number">1</span>), :]<br>        <span class="hljs-keyword">return</span> self.dropout(x)<br><br><br><span class="hljs-comment"># Text classifier based on a pytorch TransformerEncoder.</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TextClassifier</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">            self,</span><br><span class="hljs-params">            nhead=<span class="hljs-number">8</span>,</span><br><span class="hljs-params">            dim_feedforward=<span class="hljs-number">2048</span>,</span><br><span class="hljs-params">            num_layers=<span class="hljs-number">6</span>,</span><br><span class="hljs-params">            dropout=<span class="hljs-number">0.1</span>,</span><br><span class="hljs-params">            activation=<span class="hljs-string">&quot;relu&quot;</span>,</span><br><span class="hljs-params">            classifier_dropout=<span class="hljs-number">0.1</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        vocab_size = NUM_WORDS + <span class="hljs-number">2</span><br>        d_model = EMBEDDING_SIZE<br>        <span class="hljs-comment"># vocab_size, d_model = embeddings.size()</span><br>        <span class="hljs-keyword">assert</span> d_model % nhead == <span class="hljs-number">0</span>, <span class="hljs-string">&quot;nheads must divide evenly into d_model&quot;</span><br><br>        <span class="hljs-comment"># Embedding layer definition</span><br>        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=<span class="hljs-number">0</span>)<br><br>        self.pos_encoder = PositionalEncoding(<br>            d_model=d_model,<br>            dropout=dropout,<br>            vocab_size=vocab_size<br>        )<br><br>        encoder_layer = nn.TransformerEncoderLayer(<br>            d_model=d_model,<br>            nhead=nhead,<br>            dim_feedforward=dim_feedforward,<br>            dropout=dropout<br>        )<br>        self.transformer_encoder = nn.TransformerEncoder(<br>            encoder_layer,<br>            num_layers=num_layers<br>        )<br>        self.classifier = nn.Linear(d_model, <span class="hljs-number">5</span>)<br>        self.d_model = d_model<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.emb(x) * math.sqrt(self.d_model)<br>        x = self.pos_encoder(x)<br>        x = self.transformer_encoder(x)<br>        x = x.mean(dim=<span class="hljs-number">1</span>)<br>        x = self.classifier(x)<br><br>        <span class="hljs-keyword">return</span> x<br><br></code></pre></td></tr></table></figure><p>需要注意的是，Encoder部分的位置编码（PositionalEncoding类）需要自己实现，因为PyTorch中没有实现。</p><p>设置模型参数如下：</p><ul><li>文字总数为5500</li><li>文本长度（SENT_LENGTH）为200</li><li>词向量维度（EMBEDDING_SIZE）为128</li><li>Transformer的Encoder层数（num_layers）为1</li><li>学习率（learning rate）为0.01</li><li>训练轮数（epoch）为10</li><li>批量大小（batch size）为32</li></ul><p>进行模型训练，得到在验证集上的结果为：accuracy=0.9010,precision=0.9051, recall=0.9010, f1-score=0.9018, 混淆矩阵为：</p><figure><img src="/img/pytorch6_2.png" alt="在验证集上的混淆矩阵" /><figcaption aria-hidden="true">在验证集上的混淆矩阵</figcaption></figure><h3 id="参数影响">参数影响</h3><p>我们考察模型参数对模型在验证集上的表现的影响。</p><ul><li>考察句子长度对模型表现的影响</li></ul><p>保持其它参数不变，设置文本长度（SENT_LENGTH）分别为200，256，300，结果如下：</p><table><thead><tr class="header"><th>文本长度</th><th>accuracy</th><th>precision</th><th>recall</th><th>f1-score</th></tr></thead><tbody><tr class="odd"><td>200</td><td>0.9010</td><td>0.9051</td><td>0.9010</td><td>0.9018</td></tr><tr class="even"><td>256</td><td>0.8990</td><td>0.9019</td><td>0.8990</td><td>0.8977</td></tr><tr class="odd"><td>300</td><td>0.8788</td><td>0.8824</td><td>0.8788</td><td>0.8774</td></tr></tbody></table><ul><li>考察词向量维度对模型表现的影响</li></ul><p>设置文本长度（SENT_LENGTH）为200，保持其它参数不变，设置词向量维度为32,64， 128，结果如下：</p><table><thead><tr class="header"><th>词向量维度</th><th>accuracy</th><th>precision</th><th>recall</th><th>f1-score</th></tr></thead><tbody><tr class="odd"><td>32</td><td>0.6869</td><td>0.7402</td><td>0.6869</td><td>0.6738</td></tr><tr class="even"><td>64</td><td>0.7576</td><td>0.7629</td><td>0.7576</td><td>0.7518</td></tr><tr class="odd"><td>128</td><td>0.9010</td><td>0.9051</td><td>0.9010</td><td>0.9018</td></tr><tr class="even"><td>256</td><td>0.9212</td><td>0.9238</td><td>0.9212</td><td>0.9213</td></tr></tbody></table><p>从中，我们可以发现，文本长度对模型表现的影响不如词向量维度对模型表现的影响大，当然，这是相对而言，因为文本长度一直保持在200以上，如果文本长度下降很多的话，模型表现会迅速下降。</p><h3 id="总结">总结</h3><p>本文介绍了如何使用Transformer模型进行中文文本分类，并考察了各重要参数对模型表现的影响。</p><p>本项目已上传至Github，访问网址为：<ahref="https://github.com/percent4/pytorch_transformer_chinese_text_classification">https://github.com/percent4/pytorch_transformer_chinese_text_classification</a></p><h3 id="参考文献">参考文献</h3><ol type="1"><li>Language Modeling with nn.Transformer and TorchText: <ahref="https://pytorch.org/tutorials/beginner/transformer_tutorial.html">https://pytorch.org/tutorials/beginner/transformer_tutorial.html</a></li><li>The Annotated Transformer: <ahref="http://nlp.seas.harvard.edu/annotated-transformer/">http://nlp.seas.harvard.edu/annotated-transformer/</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch入门（五）使用CNN模型进行中文文本分类</title>
    <link href="/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%94%EF%BC%89%E4%BD%BF%E7%94%A8CNN%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    <url>/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%94%EF%BC%89%E4%BD%BF%E7%94%A8CNN%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会介绍如何在PyTorch中使用CNN模型进行中文文本分类。</p><p>使用CNN实现中文文本分类的基本思路：</p><ul><li><p>文本预处理</p></li><li><p>将字（或token）进行汇总，形成字典文件，可保留前n个字</p></li><li><p>文字转数字，不在字典文件中用<UNK>表示</p></li><li><p>对文本进行阶段与填充，填充用<PAD>，将文本向量长度统一</p></li><li><p>建立Embedding层</p></li><li><p>建立CNN模型</p></li><li><p>训练模型，调整参数得到最优表现的模型，获取模型评估指标</p></li><li><p>保存模型，并在新样本上进行预测</p><p>我们以搜狗小分类数据集为例，使用CNN模型对其进行文本分类。</p></li></ul><h3 id="数据集介绍">数据集介绍</h3><p>搜狗小分类数据集，共有5个类别，分别为体育、健康、军事、教育、汽车。划分为训练集和测试集，其中训练集每个类别800条样本，测试集每个类别100条样本。</p><h3 id="文本预处理">文本预处理</h3><p>读取训练集中的文本数据，形成文字列表，打乱顺序，保留前N个文字，形成Pickle文件，并保存类别列表至Pickle文件，便于后续处理，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @Time : 2023/3/16 10:32</span><br><span class="hljs-comment"># @Author : Jclian91</span><br><span class="hljs-comment"># @File : preprocessing.py</span><br><span class="hljs-comment"># @Place : Minghang, Shanghai</span><br><span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> shuffle<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter, defaultdict<br><br><span class="hljs-keyword">from</span> params <span class="hljs-keyword">import</span> TRAIN_FILE_PATH, NUM_WORDS<br><span class="hljs-keyword">from</span> pickle_file_operaor <span class="hljs-keyword">import</span> PickleFileOperator<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FilePreprossing</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n</span>):<br>        <span class="hljs-comment"># 保留前n个字</span><br>        self.__n = n<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_read_train_file</span>(<span class="hljs-params">self</span>):<br>        train_pd = pd.read_csv(TRAIN_FILE_PATH)<br>        label_list = train_pd[<span class="hljs-string">&#x27;label&#x27;</span>].unique().tolist()<br>        <span class="hljs-comment"># 统计文字频数</span><br>        character_dict = defaultdict(<span class="hljs-built_in">int</span>)<br>        <span class="hljs-keyword">for</span> content <span class="hljs-keyword">in</span> train_pd[<span class="hljs-string">&#x27;content&#x27;</span>]:<br>            <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> Counter(content).items():<br>                character_dict[key] += value<br>        <span class="hljs-comment"># 不排序</span><br>        sort_char_list = [(k, v) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> character_dict.items()]<br>        shuffle(sort_char_list)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;total <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(character_dict)&#125;</span> characters.&#x27;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;top 10 chars: &#x27;</span>, sort_char_list[:<span class="hljs-number">10</span>])<br>        <span class="hljs-comment"># 保留前n个文字</span><br>        top_n_chars = [_[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> sort_char_list[:self.__n]]<br><br>        <span class="hljs-keyword">return</span> label_list, top_n_chars<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">self</span>):<br>        label_list, top_n_chars = self._read_train_file()<br>        PickleFileOperator(data=label_list, file_path=<span class="hljs-string">&#x27;labels.pk&#x27;</span>).save()<br>        PickleFileOperator(data=top_n_chars, file_path=<span class="hljs-string">&#x27;chars.pk&#x27;</span>).save()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    processor = FilePreprossing(NUM_WORDS)<br>    processor.run()<br>    <span class="hljs-comment"># 读取pickle文件</span><br>    labels = PickleFileOperator(file_path=<span class="hljs-string">&#x27;labels.pk&#x27;</span>).read()<br>    <span class="hljs-built_in">print</span>(labels)<br>    content = PickleFileOperator(file_path=<span class="hljs-string">&#x27;chars.pk&#x27;</span>).read()<br>    <span class="hljs-built_in">print</span>(content)<br><br></code></pre></td></tr></table></figure><p>文字转数字，不在字典文件中用UNK表示。对文本进行阶段与填充，填充用PAD，将文本向量长度统一。Python实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @Time : 2023/3/16 11:15</span><br><span class="hljs-comment"># @Author : Jclian91</span><br><span class="hljs-comment"># @File : text_featuring.py</span><br><span class="hljs-comment"># @Place : Minghang, Shanghai</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> T<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader, random_split<br><br><span class="hljs-keyword">from</span> params <span class="hljs-keyword">import</span> (PAD_NO,<br>                    UNK_NO,<br>                    START_NO,<br>                    SENT_LENGTH,<br>                    TEST_FILE_PATH,<br>                    TRAIN_FILE_PATH)<br><span class="hljs-keyword">from</span> pickle_file_operaor <span class="hljs-keyword">import</span> PickleFileOperator<br><br><br><span class="hljs-comment"># load csv file</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_csv_file</span>(<span class="hljs-params">file_path</span>):<br>    df = pd.read_csv(file_path)<br>    samples, y_true = [], []<br>    <span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> df.iterrows():<br>        y_true.append(row[<span class="hljs-string">&#x27;label&#x27;</span>])<br>        samples.append(row[<span class="hljs-string">&#x27;content&#x27;</span>])<br>    <span class="hljs-keyword">return</span> samples, y_true<br><br><br><span class="hljs-comment"># 读取pickle文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_file_file</span>():<br>    labels = PickleFileOperator(file_path=<span class="hljs-string">&#x27;labels.pk&#x27;</span>).read()<br>    chars = PickleFileOperator(file_path=<span class="hljs-string">&#x27;chars.pk&#x27;</span>).read()<br>    label_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(labels, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels))))<br>    char_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(chars, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(chars))))<br>    <span class="hljs-keyword">return</span> label_dict, char_dict<br><br><br><span class="hljs-comment"># 文本预处理</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">text_feature</span>(<span class="hljs-params">labels, contents, label_dict, char_dict</span>):<br>    samples, y_true = [], []<br>    <span class="hljs-keyword">for</span> s_label, s_content <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(labels, contents):<br>        <span class="hljs-comment"># one_hot_vector = [0] * len(label_dict)</span><br>        <span class="hljs-comment"># one_hot_vector[label_dict[s_label]] = 1</span><br>        <span class="hljs-comment"># y_true.append([one_hot_vector])</span><br>        y_true.append(label_dict[s_label])<br>        train_sample = []<br>        <span class="hljs-keyword">for</span> char <span class="hljs-keyword">in</span> s_content:<br>            <span class="hljs-keyword">if</span> char <span class="hljs-keyword">in</span> char_dict:<br>                train_sample.append(START_NO + char_dict[char])<br>            <span class="hljs-keyword">else</span>:<br>                train_sample.append(UNK_NO)<br>        <span class="hljs-comment"># 补充或截断</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(train_sample) &lt; SENT_LENGTH:<br>            samples.append(train_sample + [PAD_NO] * (SENT_LENGTH - <span class="hljs-built_in">len</span>(train_sample)))<br>        <span class="hljs-keyword">else</span>:<br>            samples.append(train_sample[:SENT_LENGTH])<br><br>    <span class="hljs-keyword">return</span> samples, y_true<br><br><br><span class="hljs-comment"># dataset</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CSVDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-comment"># load the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, file_path</span>):<br>        label_dict, char_dict = load_file_file()<br>        samples, y_true = load_csv_file(file_path)<br>        x, y = text_feature(y_true, samples, label_dict, char_dict)<br>        self.X = T.from_numpy(np.array(x)).long()<br>        self.y = T.from_numpy(np.array(y))<br><br>    <span class="hljs-comment"># number of rows in the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.X)<br><br>    <span class="hljs-comment"># get a row at an index</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> [self.X[idx], self.y[idx]]<br><br>    <span class="hljs-comment"># get indexes for train and test rows</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_splits</span>(<span class="hljs-params">self, n_test=<span class="hljs-number">0.3</span></span>):<br>        <span class="hljs-comment"># determine sizes</span><br>        test_size = <span class="hljs-built_in">round</span>(n_test * <span class="hljs-built_in">len</span>(self.X))<br>        train_size = <span class="hljs-built_in">len</span>(self.X) - test_size<br>        <span class="hljs-comment"># calculate the split</span><br>        <span class="hljs-keyword">return</span> random_split(self, [train_size, test_size])<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    p = CSVDataset().__getitem__(<span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(p)<br><br></code></pre></td></tr></table></figure><p>以下面的文本为例，将其转化为向量（假设最大长度为40）后的结果为：</p><blockquote><p>盖世汽车讯，特斯拉去年击败了宝马，夺得了美国豪华汽车市场的桂</p></blockquote><blockquote><p>[3899, 4131, 2497, 496, 3746, 221, 3273, 1986, 4002, 4882, 3238,5114, 1516, 353, 4767, 2357, 221, 2920, 387, 353, 4434, 4930, 4079,4187, 2497, 496, 883, 1325, 1061, 3901, 0, 0, 0, 0, 0, 0, 0, 0, 0,0]</p></blockquote><h3 id="创建模型">创建模型</h3><p>创建模型：建立Embedding层，建立CNN模型，模型图如下：</p><p><img src="/img/pytorch5_1.png" /></p><p>Python实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">from</span> params <span class="hljs-keyword">import</span> NUM_WORDS, SENT_LENGTH, EMBEDDING_SIZE<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TextClassifier</span>(nn.ModuleList):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(TextClassifier, self).__init__()<br>        <span class="hljs-comment"># Parameters regarding text preprocessing</span><br>        self.seq_len = SENT_LENGTH<br>        self.num_words = NUM_WORDS<br>        self.embedding_size = EMBEDDING_SIZE<br><br>        <span class="hljs-comment"># Dropout definition</span><br>        self.dropout = nn.Dropout(<span class="hljs-number">0.25</span>)<br><br>        <span class="hljs-comment"># CNN parameters definition</span><br>        <span class="hljs-comment"># Kernel sizes</span><br>        self.kernel_1 = <span class="hljs-number">2</span><br>        self.kernel_2 = <span class="hljs-number">3</span><br>        self.kernel_3 = <span class="hljs-number">4</span><br>        self.kernel_4 = <span class="hljs-number">5</span><br><br>        <span class="hljs-comment"># Output size for each convolution</span><br>        self.out_size = <span class="hljs-number">32</span><br>        <span class="hljs-comment"># Number of strides for each convolution</span><br>        self.stride = <span class="hljs-number">2</span><br><br>        <span class="hljs-comment"># Embedding layer definition</span><br>        self.embedding = nn.Embedding(self.num_words + <span class="hljs-number">2</span>, self.embedding_size)<br><br>        <span class="hljs-comment"># Convolution layers definition</span><br>        self.conv_1 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_1, self.stride)<br>        self.conv_2 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_2, self.stride)<br>        self.conv_3 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_3, self.stride)<br>        self.conv_4 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_4, self.stride)<br><br>        <span class="hljs-comment"># Max pooling layers definition</span><br>        self.pool_1 = nn.MaxPool1d(self.kernel_1, self.stride)<br>        self.pool_2 = nn.MaxPool1d(self.kernel_2, self.stride)<br>        self.pool_3 = nn.MaxPool1d(self.kernel_3, self.stride)<br>        self.pool_4 = nn.MaxPool1d(self.kernel_4, self.stride)<br><br>        <span class="hljs-comment"># Fully connected layer definition</span><br>        self.fc = nn.Linear(self.in_features_fc(), <span class="hljs-number">5</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">in_features_fc</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Calculates the number of output features after Convolution + Max pooling</span><br><span class="hljs-string">        Convolved_Features = ((embedding_size + (2 * padding) - dilation * (kernel - 1) - 1) / stride) + 1</span><br><span class="hljs-string">        Pooled_Features = ((embedding_size + (2 * padding) - dilation * (kernel - 1) - 1) / stride) + 1</span><br><span class="hljs-string">        source: https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br><br>        <span class="hljs-comment"># Calcualte size of convolved/pooled features for convolution_1/max_pooling_1 features</span><br>        out_conv_1 = ((self.embedding_size - <span class="hljs-number">1</span> * (self.kernel_1 - <span class="hljs-number">1</span>) - <span class="hljs-number">1</span>) / self.stride) + <span class="hljs-number">1</span><br>        out_conv_1 = math.floor(out_conv_1)<br>        out_pool_1 = ((out_conv_1 - <span class="hljs-number">1</span> * (self.kernel_1 - <span class="hljs-number">1</span>) - <span class="hljs-number">1</span>) / self.stride) + <span class="hljs-number">1</span><br>        out_pool_1 = math.floor(out_pool_1)<br><br>        <span class="hljs-comment"># Calcualte size of convolved/pooled features for convolution_2/max_pooling_2 features</span><br>        out_conv_2 = ((self.embedding_size - <span class="hljs-number">1</span> * (self.kernel_2 - <span class="hljs-number">1</span>) - <span class="hljs-number">1</span>) / self.stride) + <span class="hljs-number">1</span><br>        out_conv_2 = math.floor(out_conv_2)<br>        out_pool_2 = ((out_conv_2 - <span class="hljs-number">1</span> * (self.kernel_2 - <span class="hljs-number">1</span>) - <span class="hljs-number">1</span>) / self.stride) + <span class="hljs-number">1</span><br>        out_pool_2 = math.floor(out_pool_2)<br><br>        <span class="hljs-comment"># Calcualte size of convolved/pooled features for convolution_3/max_pooling_3 features</span><br>        out_conv_3 = ((self.embedding_size - <span class="hljs-number">1</span> * (self.kernel_3 - <span class="hljs-number">1</span>) - <span class="hljs-number">1</span>) / self.stride) + <span class="hljs-number">1</span><br>        out_conv_3 = math.floor(out_conv_3)<br>        out_pool_3 = ((out_conv_3 - <span class="hljs-number">1</span> * (self.kernel_3 - <span class="hljs-number">1</span>) - <span class="hljs-number">1</span>) / self.stride) + <span class="hljs-number">1</span><br>        out_pool_3 = math.floor(out_pool_3)<br><br>        <span class="hljs-comment"># Calculate size of convolved/pooled features for convolution_4/max_pooling_4 features</span><br>        out_conv_4 = ((self.embedding_size - <span class="hljs-number">1</span> * (self.kernel_4 - <span class="hljs-number">1</span>) - <span class="hljs-number">1</span>) / self.stride) + <span class="hljs-number">1</span><br>        out_conv_4 = math.floor(out_conv_4)<br>        out_pool_4 = ((out_conv_4 - <span class="hljs-number">1</span> * (self.kernel_4 - <span class="hljs-number">1</span>) - <span class="hljs-number">1</span>) / self.stride) + <span class="hljs-number">1</span><br>        out_pool_4 = math.floor(out_pool_4)<br><br>        <span class="hljs-comment"># Returns &quot;flattened&quot; vector (input for fully connected layer)</span><br>        <span class="hljs-keyword">return</span> (out_pool_1 + out_pool_2 + out_pool_3 + out_pool_4) * self.out_size<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># Sequence of tokes is filterd through an embedding layer</span><br>        x = self.embedding(x)<br><br>        <span class="hljs-comment"># Convolution layer 1 is applied</span><br>        x1 = self.conv_1(x)<br>        x1 = torch.relu(x1)<br>        x1 = self.pool_1(x1)<br><br>        <span class="hljs-comment"># Convolution layer 2 is applied</span><br>        x2 = self.conv_2(x)<br>        x2 = torch.relu((x2))<br>        x2 = self.pool_2(x2)<br><br>        <span class="hljs-comment"># Convolution layer 3 is applied</span><br>        x3 = self.conv_3(x)<br>        x3 = torch.relu(x3)<br>        x3 = self.pool_3(x3)<br><br>        <span class="hljs-comment"># Convolution layer 4 is applied</span><br>        x4 = self.conv_4(x)<br>        x4 = torch.relu(x4)<br>        x4 = self.pool_4(x4)<br><br>        <span class="hljs-comment"># The output of each convolutional layer is concatenated into a unique vector</span><br>        union = torch.cat((x1, x2, x3, x4), <span class="hljs-number">2</span>)<br>        union = union.reshape(union.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># The &quot;flattened&quot; vector is passed through a fully connected layer</span><br>        out = self.fc(union)<br>        <span class="hljs-comment"># Dropout is applied</span><br>        out = self.dropout(out)<br>        <span class="hljs-comment"># Activation function is applied</span><br>        <span class="hljs-comment"># out = nn.Softmax(dim=1)(out)</span><br><br>        <span class="hljs-keyword">return</span> out<br><br></code></pre></td></tr></table></figure><p>训练模型，调整参数得到最优表现的模型，获取模型评估指标，Python实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> RMSprop, Adam<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> CrossEntropyLoss, Softmax<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> vstack, argmax<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> TextClassifier<br><span class="hljs-keyword">from</span> text_featuring <span class="hljs-keyword">import</span> CSVDataset<br><span class="hljs-keyword">from</span> params <span class="hljs-keyword">import</span> TRAIN_BATCH_SIZE, TEST_BATCH_SIZE, LEARNING_RATE, EPOCHS, TRAIN_FILE_PATH, TEST_FILE_PATH<br><br><br><span class="hljs-comment"># model train</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ModelTrainer</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-comment"># evaluate the model</span><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_model</span>(<span class="hljs-params">test_dl, model</span>):<br>        predictions, actuals = [], []<br>        <span class="hljs-keyword">for</span> i, (inputs, targets) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(test_dl):<br>            <span class="hljs-comment"># evaluate the model on the test set</span><br>            yhat = model(inputs)<br>            <span class="hljs-comment"># retrieve numpy array</span><br>            yhat = yhat.detach().numpy()<br>            actual = targets.numpy()<br>            <span class="hljs-comment"># convert to class labels</span><br>            yhat = argmax(yhat, axis=<span class="hljs-number">1</span>)<br>            <span class="hljs-comment"># reshape for stacking</span><br>            actual = actual.reshape((<span class="hljs-built_in">len</span>(actual), <span class="hljs-number">1</span>))<br>            yhat = yhat.reshape((<span class="hljs-built_in">len</span>(yhat), <span class="hljs-number">1</span>))<br>            <span class="hljs-comment"># store</span><br>            predictions.append(yhat)<br>            actuals.append(actual)<br>        predictions, actuals = vstack(predictions), vstack(actuals)<br>        <span class="hljs-comment"># calculate accuracy</span><br>        acc = accuracy_score(actuals, predictions)<br>        <span class="hljs-keyword">return</span> acc<br><br>    <span class="hljs-comment"># Model Training, evaluation and metrics calculation</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self, model</span>):<br>        <span class="hljs-comment"># calculate split</span><br>        train = CSVDataset(TRAIN_FILE_PATH)<br>        test = CSVDataset(TEST_FILE_PATH)<br>        <span class="hljs-comment"># prepare data loaders</span><br>        train_dl = DataLoader(train, batch_size=TRAIN_BATCH_SIZE, shuffle=<span class="hljs-literal">True</span>)<br>        test_dl = DataLoader(test, batch_size=TEST_BATCH_SIZE)<br><br>        <span class="hljs-comment"># Define optimizer</span><br>        optimizer = Adam(model.parameters(), lr=LEARNING_RATE)<br>        <span class="hljs-comment"># Starts training phase</span><br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(EPOCHS):<br>            <span class="hljs-comment"># Starts batch training</span><br>            <span class="hljs-keyword">for</span> x_batch, y_batch <span class="hljs-keyword">in</span> train_dl:<br>                y_batch = y_batch.long()<br>                <span class="hljs-comment"># Clean gradients</span><br>                optimizer.zero_grad()<br>                <span class="hljs-comment"># Feed the model</span><br>                y_pred = model(x_batch)<br>                <span class="hljs-comment"># Loss calculation</span><br>                loss = CrossEntropyLoss()(y_pred, y_batch)<br>                <span class="hljs-comment"># Gradients calculation</span><br>                loss.backward()<br>                <span class="hljs-comment"># Gradients update</span><br>                optimizer.step()<br><br>            <span class="hljs-comment"># Evaluation</span><br>            test_accuracy = self.evaluate_model(test_dl, model)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Epoch: %d, loss: %.5f, Test accuracy: %.5f&quot;</span> % (epoch+<span class="hljs-number">1</span>, loss.item(), test_accuracy))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = TextClassifier()<br>    <span class="hljs-comment"># 统计参数量</span><br>    num_params = <span class="hljs-built_in">sum</span>(param.numel() <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> model.parameters())<br>    <span class="hljs-built_in">print</span>(num_params)<br>    ModelTrainer().train(model)<br>    torch.save(model, <span class="hljs-string">&#x27;sougou_mini_cls.pth&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="模型预测">模型预测</h3><p>对保存好的模型，在验证集上进行指标评估，得到的结果：accuracy为0.7960，precision，recall为0.7960，F1-score为0.7953，混淆矩阵如下：</p><figure><img src="/img/pytorch5_2.png" alt="在验证集上的混淆矩阵" /><figcaption aria-hidden="true">在验证集上的混淆矩阵</figcaption></figure><p>对新样本进行预测，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @Time : 2023/3/16 16:42</span><br><span class="hljs-comment"># @Author : Jclian91</span><br><span class="hljs-comment"># @File : model_predict.py</span><br><span class="hljs-comment"># @Place : Minghang, Shanghai</span><br><span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> T<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">from</span> text_featuring <span class="hljs-keyword">import</span> load_file_file, text_feature<br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> TextClassifier<br><br>model = T.load(<span class="hljs-string">&#x27;sougou_mini_cls.pth&#x27;</span>)<br><br>label_dict, char_dict = load_file_file()<br><span class="hljs-built_in">print</span>(label_dict)<br><br>text = <span class="hljs-string">&#x27;盖世汽车讯，特斯拉去年击败了宝马，夺得了美国豪华汽车市场的桂冠，并在今年实现了开门红。1月份，得益于大幅降价和7500美元美国电动汽车税收抵免，特斯拉再度击败宝马，蝉联了美国豪华车销冠，并且注册量超过了排名第三的梅赛德斯-奔驰和排名第四的雷克萨斯的总和。根据Experian的数据，在所有豪华品牌中，1月份，特斯拉在美国的豪华车注册量为49，917辆，同比增长34%；宝马的注册量为31，070辆，同比增长2.5%；奔驰的注册量为23，345辆，同比增长7.3%；雷克萨斯的注册量为23，082辆，同比下降6.6%。奥迪以19，113辆的注册量排名第五，同比增长38%。凯迪拉克注册量为13，220辆，较去年同期增长36%，排名第六。排名第七的讴歌的注册量为10，833辆，同比增长32%。沃尔沃汽车排名第八，注册量为8，864辆，同比增长1.8%。路虎以7，003辆的注册量排名第九，林肯以6，964辆的注册量排名第十。&#x27;</span><br><br>label, sample = [<span class="hljs-string">&#x27;汽车&#x27;</span>], [text]<br>samples, y_true = text_feature(label, sample, label_dict, char_dict)<br><span class="hljs-built_in">print</span>(text)<br><span class="hljs-built_in">print</span>(samples, y_true)<br>x = T.from_numpy(np.array(samples)).long()<br>y_pred = model(x)<br><span class="hljs-built_in">print</span>(y_pred)<br><br></code></pre></td></tr></table></figure><p>预测结果如下：</p><table><thead><tr class="header"><th>新文本</th><th>预测类别</th></tr></thead><tbody><tr class="odd"><td>盖世汽车讯，特斯拉去年击败了宝马，夺得了美国豪华汽车市场的桂冠，并在今年实现了开门红。1月份，得益于大幅降价和7500美元美国电动汽车税收抵免，特斯拉再度击败宝马，蝉联了美国豪华车销冠，并且注册量超过了排名第三的梅赛德斯-奔驰和排名第四的雷克萨斯的总和。根据Experian的数据，在所有豪华品牌中，1月份，特斯拉在美国的豪华车注册量为49，917辆，同比增长34%；宝马的注册量为31，070辆，同比增长2.5%；奔驰的注册量为23，345辆，同比增长7.3%；雷克萨斯的注册量为23，082辆，同比下降6.6%。奥迪以19，113辆的注册量排名第五，同比增长38%。凯迪拉克注册量为13，220辆，较去年同期增长36%，排名第六。排名第七的讴歌的注册量为10，833辆，同比增长32%。沃尔沃汽车排名第八，注册量为8，864辆，同比增长1.8%。路虎以7，003辆的注册量排名第九，林肯以6，964辆的注册量排名第十。</td><td>汽车</td></tr><tr class="even"><td>北京时间3月16日，NBA官方公布了对于灰熊球星贾-莫兰特直播中持枪事件的调查结果灰熊，由于无法确定枪支是否为莫兰特所有，也无法证明他曾持枪到过NBA场馆，因为对他处以禁赛八场的处罚，且此前已禁赛场次将算在禁赛八场的场次内，他最早将在下周复出。</td><td>体育</td></tr><tr class="odd"><td>3月11日，由新浪教育、微博教育、择校行联合主办的“新浪&amp;微博2023国际教育春季巡展•深圳站”于深圳凯宾斯基酒店成功举办。深圳优质学校亮相展会，上千组家庭前来逛展。近30所全国及深圳民办国际化学校、外籍人员子女学校、公办学校国际部等多元化、多类型优质学校参与了本次活动。此外，近10位国际化学校校长分享了学校的办学特色、教育理念及学生的成长案例，参展家庭纷纷表示受益匪浅。展会搭建家校沟通桥梁，帮助家长们合理规划孩子的国际教育之路。深圳国际预科书院/招生办主任沈兰NancyShen参加了本次活动并带来了精彩的演讲，以下为演讲实录："</td><td>教育</td></tr><tr class="even"><td>指导专家：皮肤科教研室副主任、武汉协和医院皮肤性病科主任医师冯爱平教授在临床上，经常能看到有些人出现反复发作的口腔溃疡，四季不断，深受其扰。其实这已不单单是口腔问题，而是全身疾病的体现，特别是一些免疫系统疾病，不仅表现在皮肤还会损害黏膜，下列几种情况是造成“复发性口腔溃疡”的原因。缺乏维生素及微量元素。缺乏微量元素锌、铁、叶酸、维生素B12等时，会引发口角炎。很多日常生活行为可能造成维生素的缺乏，如过分淘洗米、长期进食精米面、吃素食等，很容易造成B族维生素的缺失。</td><td>健康</td></tr></tbody></table><h3 id="总结">总结</h3><p>本项目已上传至Github，访问网址为：<ahref="https://github.com/percent4/PyTorch_Learning/tree/master/cnn_text_classification">https://github.com/percent4/PyTorch_Learning/tree/master/cnn_text_classification</a></p><h3 id="参考文献">参考文献</h3><ol type="1"><li>Text-Classification-CNN-PyTorch: <ahref="https://github.com/FernandoLpz/Text-Classification-CNN-PyTorch">https://github.com/FernandoLpz/Text-Classification-CNN-PyTorch</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CNN</tag>
      
      <tag>文本分类</tag>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch入门（四）优化器比较</title>
    <link href="/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E5%9B%9B%EF%BC%89%E4%BC%98%E5%8C%96%E5%99%A8%E6%AF%94%E8%BE%83/"/>
    <url>/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E5%9B%9B%EF%BC%89%E4%BC%98%E5%8C%96%E5%99%A8%E6%AF%94%E8%BE%83/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>优化器就是在深度学习反向传播过程中，指引损失函数的各个参数往正确的方向更新合适的大小，使得更新后的各个参数让损失函数（目标函数）值不断逼近全局最小。</p><p>常见的优化器有：</p><ul><li><p>梯度及梯度下降算法</p></li><li><p>随机梯度下降算法</p></li><li><p>标准动量优化算法</p></li><li><p>AdaGrad算法</p></li><li><p>RMSProp算法</p></li><li><p>Adam算法</p><p>本文将不会介绍这些算法的细节，我们通过一个例子来比较各优化器的表现。</p><p>在PyTorch，实现的优化算法有SGD（随机梯度下降算法）、Adagrad（AdaGrad算法）、RMSprop（RMSprop算法）、Adam（Adam算法），我们将会通过各优化器在优化样例目标函数的最小值来观察它们的表现。以下是Python实现代码：</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @Time : 2023/3/18 11:01</span><br><span class="hljs-comment"># @Author : Jclian91</span><br><span class="hljs-comment"># @File : optimizer_comparsion.py</span><br><span class="hljs-comment"># @Place : Minghang, Shanghai</span><br><span class="hljs-comment"># comparison in Five optimizers in PyTorch: SGD, AdaGrad, RMSProp, Adam</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn<br><span class="hljs-keyword">import</span> torch.utils.data <span class="hljs-keyword">as</span> Data<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> rcParams<br>rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = <span class="hljs-string">&#x27;SimHei&#x27;</span><br><br><span class="hljs-comment"># prepare data</span><br>x = torch.unsqueeze(torch.linspace(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">500</span>), dim=<span class="hljs-number">1</span>)<br>y = x.<span class="hljs-built_in">pow</span>(<span class="hljs-number">3</span>)<br><br><span class="hljs-comment"># set parameters</span><br>lr = <span class="hljs-number">0.01</span><br>batch_size = <span class="hljs-number">15</span><br>epoch = <span class="hljs-number">5</span><br>torch.manual_seed(<span class="hljs-number">1234</span>)<br><br><br><span class="hljs-comment"># Dataloader</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-comment"># load the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x, y</span>):<br>        self.X = x<br>        self.y = y<br><br>    <span class="hljs-comment"># number of rows in the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.X)<br><br>    <span class="hljs-comment"># get a row at an index</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> [self.X[idx], self.y[idx]]<br><br><br>loader = Data.DataLoader(dataset=MyDataset(x, y),<br>                         batch_size=batch_size,<br>                         shuffle=<span class="hljs-literal">True</span>,<br>                         num_workers=<span class="hljs-number">2</span>)<br><br><br><span class="hljs-comment"># create model</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_input, n_hidden, n_output</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.hidden_layer = torch.nn.Linear(n_input, n_hidden)<br>        self.output_layer = torch.nn.Linear(n_hidden, n_output)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        x = torch.relu(self.hidden_layer(<span class="hljs-built_in">input</span>))<br>        output = self.output_layer(x)<br>        <span class="hljs-keyword">return</span> output<br><br><br><span class="hljs-comment"># train model and plot</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>():<br>    net_sgd = Net(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1</span>)<br>    net_adagrad = Net(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1</span>)<br>    net_rmsprop = Net(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1</span>)<br>    net_adam = Net(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1</span>)<br>    nets = [net_sgd, net_adagrad, net_rmsprop, net_adam]<br><br>    <span class="hljs-comment"># optimizer</span><br>    opt_sgd = torch.optim.SGD(net_sgd.parameters(), lr=lr)<br>    opt_momentum = torch.optim.Adagrad(net_adagrad.parameters(), lr=lr, lr_decay=<span class="hljs-number">0</span>)<br>    opt_rmsprop = torch.optim.RMSprop(net_rmsprop.parameters(), lr=lr, alpha=<span class="hljs-number">0.9</span>)<br>    opt_adam = torch.optim.Adam(net_adam.parameters(), lr=lr, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.99</span>))<br>    optimizers = [opt_sgd, opt_momentum, opt_rmsprop, opt_adam]<br><br>    <span class="hljs-comment"># loss function</span><br>    loss_func = torch.nn.MSELoss()<br>    losses = [[], [], [], []]<br>    <span class="hljs-keyword">for</span> i_epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>        <span class="hljs-keyword">for</span> step, (batch_x, batch_y) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>            <span class="hljs-keyword">for</span> net, optimizer, loss_list <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(nets, optimizers, losses):<br>                pred_y = net(batch_x)<br>                loss = loss_func(pred_y, batch_y)<br>                optimizer.zero_grad()<br>                loss.backward()<br>                optimizer.step()<br>                loss_list.append(loss.data.numpy())<br><br>    plt.figure()<br>    labels = [<span class="hljs-string">&#x27;SGD&#x27;</span>, <span class="hljs-string">&#x27;AdaGrad&#x27;</span>, <span class="hljs-string">&#x27;RMSProp&#x27;</span>, <span class="hljs-string">&#x27;Adam&#x27;</span>]<br>    <span class="hljs-keyword">for</span> i, loss <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(losses):<br>        plt.plot(loss, label=labels[i])<br><br>    plt.legend(loc=<span class="hljs-string">&#x27;upper right&#x27;</span>, fontsize=<span class="hljs-number">15</span>)<br>    plt.tick_params(labelsize=<span class="hljs-number">13</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;训练步骤&#x27;</span>, size=<span class="hljs-number">15</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;模型损失&#x27;</span>, size=<span class="hljs-number">15</span>)<br>    plt.ylim((<span class="hljs-number">0</span>, <span class="hljs-number">0.3</span>))<br>    <span class="hljs-comment"># plt.show()</span><br>    plt.savefig(<span class="hljs-string">&#x27;optimizer_comparison.png&#x27;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    train()<br><br></code></pre></td></tr></table></figure><p>各优化器在优化目标函数的损失值的图像如下：</p><p><img src="/img/pytorch4_1.png" /></p><p>从中我们可以看到，在上述四个优化器中，Adam和RMSProp优化器表现较好，其中Adam优化器收敛最快，表现最稳定。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
      <tag>优化器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch入门（三）模块的保存与加载</title>
    <link href="/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD/"/>
    <url>/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将介绍如何使用PyTorch保存模块和加载模型。</p><h3 id="pytorch模型保存与加载">PyTorch模型保存与加载</h3><p>在PyTorch中，一个<code>torch.nn.Module</code>模型的可训练参数（即权重与偏移项）保存在模型的<em>参数</em>（<em>parameters</em>)，使用<code>model.parameters()</code>获得)中。一个<code>state_dict</code>就是一个简单的Python字典，将每层映射到其参数张量。PyTorch的模型文件以<code>.pt</code>或<code>.pth</code>为后缀。使用函数<code>torch.save</code>保存模型，使用函数<code>torch.load</code>加载模型。</p><p>PyTorch有两种保存与加载模型的方式，一种是保存整个模型（包括模型结构及参数值），另一种是只保存模型的参数值（即<code>state_dict</code>）。</p><ol type="1"><li>保存整个网络结构信息和模型参数信息:</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.save(model_object, <span class="hljs-string">&#x27;./model.pth&#x27;</span>)<br></code></pre></td></tr></table></figure><p>直接加载即可使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model = torch.load(<span class="hljs-string">&#x27;./model.pth&#x27;</span>)<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>只保存网络的模型参数</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.save(model_object.state_dict(), <span class="hljs-string">&#x27;./params.pth&#x27;</span>)<br></code></pre></td></tr></table></figure><p>加载则要先从本地网络模块导入网络，然后再加载参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> models <span class="hljs-keyword">import</span> Model<br>model = Model()<br>model.load_state_dict(torch.load(<span class="hljs-string">&#x27;./params.pth&#x27;</span>))<br></code></pre></td></tr></table></figure><h3 id="示例代码">示例代码</h3><p>我们以文章<ahref="https://percent4.github.io/2023/07/30/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%8C%EF%BC%89%E6%90%AD%E5%BB%BAMLP%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">PyTorch入门（二）搭建MLP模型实现分类任务</a>中的二分类MLP模型为例，来演示如何在PyTorch中保存模型和加载代码。</p><p>只保存模型参数值的示例Python代码（<code>save_model.py</code>）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> vstack<br><span class="hljs-keyword">from</span> pandas <span class="hljs-keyword">import</span> read_csv<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelEncoder<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> Tensor<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> SGD<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader, random_split<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Linear, ReLU, Sigmoid, Module, BCELoss<br><span class="hljs-keyword">from</span> torch.nn.init <span class="hljs-keyword">import</span> kaiming_uniform_, xavier_uniform_<br><br><br><span class="hljs-comment"># dataset definition</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CSVDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-comment"># load the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, path</span>):<br>        <span class="hljs-comment"># load the csv file as a dataframe</span><br>        df = read_csv(path, header=<span class="hljs-literal">None</span>)<br>        <span class="hljs-comment"># store the inputs and outputs</span><br>        self.X = df.values[:, :-<span class="hljs-number">1</span>]<br>        self.y = df.values[:, -<span class="hljs-number">1</span>]<br>        <span class="hljs-comment"># ensure input data is floats</span><br>        self.X = self.X.astype(<span class="hljs-string">&#x27;float32&#x27;</span>)<br>        <span class="hljs-comment"># label encode target and ensure the values are floats</span><br>        self.y = LabelEncoder().fit_transform(self.y)<br>        self.y = self.y.astype(<span class="hljs-string">&#x27;float32&#x27;</span>)<br>        self.y = self.y.reshape((<span class="hljs-built_in">len</span>(self.y), <span class="hljs-number">1</span>))<br><br>    <span class="hljs-comment"># number of rows in the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.X)<br><br>    <span class="hljs-comment"># get a row at an index</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> [self.X[idx], self.y[idx]]<br><br>    <span class="hljs-comment"># get indexes for train and test rows</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_splits</span>(<span class="hljs-params">self, n_test=<span class="hljs-number">0.3</span></span>):<br>        <span class="hljs-comment"># determine sizes</span><br>        test_size = <span class="hljs-built_in">round</span>(n_test * <span class="hljs-built_in">len</span>(self.X))<br>        train_size = <span class="hljs-built_in">len</span>(self.X) - test_size<br>        <span class="hljs-comment"># calculate the split</span><br>        <span class="hljs-keyword">return</span> random_split(self, [train_size, test_size])<br><br><br><span class="hljs-comment"># model definition</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>(<span class="hljs-title class_ inherited__">Module</span>):<br>    <span class="hljs-comment"># define model elements</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_inputs</span>):<br>        <span class="hljs-built_in">super</span>(MLP, self).__init__()<br>        <span class="hljs-comment"># input to first hidden layer</span><br>        self.hidden1 = Linear(n_inputs, <span class="hljs-number">10</span>)<br>        kaiming_uniform_(self.hidden1.weight, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>        self.act1 = ReLU()<br>        <span class="hljs-comment"># second hidden layer</span><br>        self.hidden2 = Linear(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>)<br>        kaiming_uniform_(self.hidden2.weight, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>        self.act2 = ReLU()<br>        <span class="hljs-comment"># third hidden layer and output</span><br>        self.hidden3 = Linear(<span class="hljs-number">8</span>, <span class="hljs-number">1</span>)<br>        xavier_uniform_(self.hidden3.weight)<br>        self.act3 = Sigmoid()<br><br>    <span class="hljs-comment"># forward propagate input</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-comment"># input to first hidden layer</span><br>        X = self.hidden1(X)<br>        X = self.act1(X)<br>        <span class="hljs-comment"># second hidden layer</span><br>        X = self.hidden2(X)<br>        X = self.act2(X)<br>        <span class="hljs-comment"># third hidden layer and output</span><br>        X = self.hidden3(X)<br>        X = self.act3(X)<br>        <span class="hljs-keyword">return</span> X<br><br><br><span class="hljs-comment"># prepare the dataset</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_data</span>(<span class="hljs-params">path</span>):<br>    <span class="hljs-comment"># load the dataset</span><br>    dataset = CSVDataset(path)<br>    <span class="hljs-comment"># calculate split</span><br>    train, test = dataset.get_splits()<br>    <span class="hljs-comment"># prepare data loaders</span><br>    train_dl = DataLoader(train, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">True</span>)<br>    test_dl = DataLoader(test, batch_size=<span class="hljs-number">1024</span>, shuffle=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">return</span> train_dl, test_dl<br><br><br><span class="hljs-comment"># train the model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_model</span>(<span class="hljs-params">train_dl, model</span>):<br>    <span class="hljs-comment"># define the optimization</span><br>    criterion = BCELoss()<br>    optimizer = SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0.9</span>)<br>    <span class="hljs-comment"># enumerate epochs</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>        <span class="hljs-comment"># enumerate mini batches</span><br>        <span class="hljs-keyword">for</span> i, (inputs, targets) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dl):<br>            <span class="hljs-comment"># clear the gradients</span><br>            optimizer.zero_grad()<br>            <span class="hljs-comment"># compute the model output</span><br>            yhat = model(inputs)<br>            <span class="hljs-comment"># calculate loss</span><br>            loss = criterion(yhat, targets)<br>            <span class="hljs-comment"># credit assignment</span><br>            loss.backward()<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch: &#123;&#125;, batch: &#123;&#125;, loss: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, i, loss.data))<br>            <span class="hljs-comment"># update model weights</span><br>            optimizer.step()<br><br><br><span class="hljs-comment"># evaluate the model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_model</span>(<span class="hljs-params">test_dl, model</span>):<br>    predictions, actuals = [], []<br>    <span class="hljs-keyword">for</span> i, (inputs, targets) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(test_dl):<br>        <span class="hljs-comment"># evaluate the model on the test set</span><br>        yhat = model(inputs)<br>        <span class="hljs-comment"># retrieve numpy array</span><br>        yhat = yhat.detach().numpy()<br>        actual = targets.numpy()<br>        actual = actual.reshape((<span class="hljs-built_in">len</span>(actual), <span class="hljs-number">1</span>))<br>        <span class="hljs-comment"># round to class values</span><br>        yhat = yhat.<span class="hljs-built_in">round</span>()<br>        <span class="hljs-comment"># store</span><br>        predictions.append(yhat)<br>        actuals.append(actual)<br>    predictions, actuals = vstack(predictions), vstack(actuals)<br>    <span class="hljs-comment"># calculate accuracy</span><br>    acc = accuracy_score(actuals, predictions)<br>    <span class="hljs-keyword">return</span> acc<br><br><br><span class="hljs-comment"># make a class prediction for one row of data</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">row, model</span>):<br>    <span class="hljs-comment"># convert row to data</span><br>    row = Tensor([row])<br>    <span class="hljs-comment"># make prediction</span><br>    yhat = model(row)<br>    <span class="hljs-comment"># retrieve numpy array</span><br>    yhat = yhat.detach().numpy()<br>    <span class="hljs-keyword">return</span> yhat<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># prepare the data</span><br>    path = <span class="hljs-string">&#x27;./data/ionosphere.csv&#x27;</span><br>    train_dl, test_dl = prepare_data(path)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(train_dl.dataset), <span class="hljs-built_in">len</span>(test_dl.dataset))<br>    <span class="hljs-comment"># define the network</span><br>    model = MLP(<span class="hljs-number">34</span>)<br>    <span class="hljs-built_in">print</span>(model)<br>    <span class="hljs-comment"># train the model</span><br>    train_model(train_dl, model)<br>    torch.save(model.state_dict(), <span class="hljs-string">&#x27;binary_classification.pth&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(model.state_dict())<br>    <span class="hljs-comment"># evaluate the model</span><br>    acc = evaluate_model(test_dl, model)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accuracy: %.3f&#x27;</span> % acc)<br></code></pre></td></tr></table></figure><p>运行代码，会输出该MLP模型的参数值（<code>state_dict</code>）如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">OrderedDict([(<span class="hljs-string">&#x27;hidden1.weight&#x27;</span>, tensor([[-4.3042e-02, -1.3315e-01, -3.5050e-01, -1.4949e-01, -1.6642e-01,<br>         ......), (<span class="hljs-string">&#x27;hidden1.bias&#x27;</span>, tensor([ 0.2563, -0.0024, -0.1276,  0.1943, -0.2728, -0.2992,  0.3130,  0.0245,<br>        -0.0381,  0.4498])), (<span class="hljs-string">&#x27;hidden2.weight&#x27;</span>, tensor([[-0.5759, -0.9750,  1.0027,  0.5148,  0.6903,  0.3534, -1.0665,  0.1220,<br>         -0.0757,  0.4448], ......), (<span class="hljs-string">&#x27;hidden2.bias&#x27;</span>, tensor([ 1.7468e-01,  5.9972e-02, -4.2997e-02, -2.2675e-01,  8.3250e-01,<br>        -3.2392e-04,  3.9665e-01, -2.5674e-01])), (<span class="hljs-string">&#x27;hidden3.weight&#x27;</span>, tensor([[ 1.3292, -0.6698, -0.2412,  1.0923, -2.5248,  0.3479, -1.1331, -0.0240]])), (<span class="hljs-string">&#x27;hidden3.bias&#x27;</span>, tensor([-0.8218]))])<br></code></pre></td></tr></table></figure><p>值得注意的是，<code>state_dict</code>输出的格式为Python字典结构。保存为文件名称为binary_classification.pth。</p><p>接着我们加载该模型文件，并对新数据进行预测，示例代码（<code>load_model.py</code>）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> Tensor<br><br><span class="hljs-keyword">from</span> save_model <span class="hljs-keyword">import</span> MLP<br><br>model = MLP(<span class="hljs-number">34</span>)<br>state_dict = torch.load(<span class="hljs-string">&#x27;./binary_classification.pth&#x27;</span>)<br>model.load_state_dict(state_dict)<br><span class="hljs-built_in">print</span>(model)<br><span class="hljs-comment"># make a single prediction (expect class=1)</span><br>row = [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0.99539</span>, -<span class="hljs-number">0.05889</span>, <span class="hljs-number">0.85243</span>, <span class="hljs-number">0.02306</span>, <span class="hljs-number">0.83398</span>, -<span class="hljs-number">0.37708</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.03760</span>, <span class="hljs-number">0.85243</span>, -<span class="hljs-number">0.17755</span>, <span class="hljs-number">0.59755</span>, -<span class="hljs-number">0.44945</span>,<br>       <span class="hljs-number">0.60536</span>, -<span class="hljs-number">0.38223</span>, <span class="hljs-number">0.84356</span>, -<span class="hljs-number">0.38542</span>, <span class="hljs-number">0.58212</span>, -<span class="hljs-number">0.32192</span>, <span class="hljs-number">0.56971</span>, -<span class="hljs-number">0.29674</span>, <span class="hljs-number">0.36946</span>, -<span class="hljs-number">0.47357</span>, <span class="hljs-number">0.56811</span>, -<span class="hljs-number">0.51171</span>,<br>       <span class="hljs-number">0.41078</span>, -<span class="hljs-number">0.46168</span>, <span class="hljs-number">0.21266</span>, -<span class="hljs-number">0.34090</span>, <span class="hljs-number">0.42267</span>, -<span class="hljs-number">0.54487</span>, <span class="hljs-number">0.18641</span>, -<span class="hljs-number">0.45300</span>]<br>row = Tensor([row])<br><span class="hljs-comment"># make prediction</span><br>yhat = model(row)<br><span class="hljs-comment"># retrieve numpy array</span><br>yhat = yhat.detach().numpy()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Predicted: %.3f (class=%d)&#x27;</span> % (yhat, yhat.<span class="hljs-built_in">round</span>()))<br></code></pre></td></tr></table></figure><p>如果我们想保存、加载整个模型及模型参数，则在模型保存代码（<code>save_model.py</code>）中使用代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.save(model, <span class="hljs-string">&#x27;binary_classification.pth&#x27;</span>)<br></code></pre></td></tr></table></figure><p>加载模型部分代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> Tensor<br><br><span class="hljs-keyword">from</span> save_model <span class="hljs-keyword">import</span> MLP<br><br>model = torch.load(<span class="hljs-string">&#x27;./binary_classification.pth&#x27;</span>)<br><br><span class="hljs-comment"># make a single prediction (expect class=1)</span><br>row = [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0.99539</span>, -<span class="hljs-number">0.05889</span>, <span class="hljs-number">0.85243</span>, <span class="hljs-number">0.02306</span>, <span class="hljs-number">0.83398</span>, -<span class="hljs-number">0.37708</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.03760</span>, <span class="hljs-number">0.85243</span>, -<span class="hljs-number">0.17755</span>, <span class="hljs-number">0.59755</span>, -<span class="hljs-number">0.44945</span>,<br>       <span class="hljs-number">0.60536</span>, -<span class="hljs-number">0.38223</span>, <span class="hljs-number">0.84356</span>, -<span class="hljs-number">0.38542</span>, <span class="hljs-number">0.58212</span>, -<span class="hljs-number">0.32192</span>, <span class="hljs-number">0.56971</span>, -<span class="hljs-number">0.29674</span>, <span class="hljs-number">0.36946</span>, -<span class="hljs-number">0.47357</span>, <span class="hljs-number">0.56811</span>, -<span class="hljs-number">0.51171</span>,<br>       <span class="hljs-number">0.41078</span>, -<span class="hljs-number">0.46168</span>, <span class="hljs-number">0.21266</span>, -<span class="hljs-number">0.34090</span>, <span class="hljs-number">0.42267</span>, -<span class="hljs-number">0.54487</span>, <span class="hljs-number">0.18641</span>, -<span class="hljs-number">0.45300</span>]<br>row = Tensor([row])<br><span class="hljs-comment"># make prediction</span><br>yhat = model(row)<br><span class="hljs-comment"># retrieve numpy array</span><br>yhat = yhat.detach().numpy()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Predicted: %.3f (class=%d)&#x27;</span> % (yhat, yhat.<span class="hljs-built_in">round</span>()))<br></code></pre></td></tr></table></figure><p>需要注意的是，模型结构MLP类仍需在代码中（虽然后面代码中并没有用到MLP类），这样模型才能加载成功，否则会报模型加载失败。</p><h3 id="总结">总结</h3><p>本文简单介绍了如何在PyTorch中保存和加载模型。本文介绍的模型代码已开源，Github地址为：<ahref="https://github.com/percent4/PyTorch_Learning">https://github.com/percent4/PyTorch_Learning</a>。后续将持续介绍PyTorch内容，欢迎大家关注~</p>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch入门（二）搭建MLP模型实现分类任务</title>
    <link href="/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%8C%EF%BC%89%E6%90%AD%E5%BB%BAMLP%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/"/>
    <url>/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%8C%EF%BC%89%E6%90%AD%E5%BB%BAMLP%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文是PyTorch入门的第二篇文章，后续将会持续更新，作为PyTorch系列文章。</p><p>本文将会介绍如何使用PyTorch来搭建简单的MLP（Multi-layer Perceptron，多层感知机）模型，来实现二分类及多分类任务。</p><h3 id="数据集介绍">数据集介绍</h3><p>二分类数据集为<code>ionosphere.csv</code>(电离层数据集)，是<a href="http://archive.ics.uci.edu/ml/index.php">UCI机器学习数据集</a>中的经典二分类数据集。它一共有351个观测值，34个自变量，1个因变量（类别），类别取值为<code>g</code>(good)和<code>b</code>(bad)。在<code>ionosphere.csv</code>文件中，共351行，前34列作为自变量（输入的X），最后一列作为类别值（输出的y）。</p><p><img src="/img/pytorch2_1.png" alt="电离层数据"></p><p>多分类数据集为<code>iris.csv</code>（鸢尾花数据集），是<a href="http://archive.ics.uci.edu/ml/index.php">UCI机器学习数据集</a>中的经典多分类数据集。它一共有150个观测值，4个自变量（萼片长度，萼片宽度，花瓣长度，花瓣宽度），1个因变量（类别），类别取值为<code>Iris-setosa</code>,<code>Iris-versicolour</code>,<code>Iris-virginica</code>。在<code>iris.csv</code>文件中，共150行，前4列作为自变量（输入的X），最后一列作为类别值（输出的y）。前几行数据如下图：</p><p><img src="/img/pytorch2_2.png" alt="鸢尾花数据集"></p><h3 id="分类模型流程">分类模型流程</h3><p>使用PyTorch构建神经网络模型来解决分类问题的基本流程如下：</p><p><img src="/img/pytorch2_4.png" alt=""></p><p>其中<code>加载数据集</code>和<code>划分数据集</code>为数据处理部分，<code>构建模型</code>和<code>选择损失函数及优化器</code>为创建模型部分，<code>模型训练</code>的目标是选择合适的优化器及训练步长使得损失函数的值很小，<code>模型预测</code>是在模型测试集或新数据上的预测。</p><h3 id="二分类模型">二分类模型</h3><p>使用PyTorch构建MLP模型来实现二分类任务，模型结果图如下：</p><p><img src="/img/pytorch2_3.png" alt="MLP模型示意图"></p><p>实现MLP模型的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># pytorch mlp for binary classification</span><br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> vstack<br><span class="hljs-keyword">from</span> pandas <span class="hljs-keyword">import</span> read_csv<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelEncoder<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> Tensor<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> SGD<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader, random_split<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Linear, ReLU, Sigmoid, Module, BCELoss<br><span class="hljs-keyword">from</span> torch.nn.init <span class="hljs-keyword">import</span> kaiming_uniform_, xavier_uniform_<br><br><br><span class="hljs-comment"># dataset definition</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CSVDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-comment"># load the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, path</span>):<br>        <span class="hljs-comment"># load the csv file as a dataframe</span><br>        df = read_csv(path, header=<span class="hljs-literal">None</span>)<br>        <span class="hljs-comment"># store the inputs and outputs</span><br>        self.X = df.values[:, :-<span class="hljs-number">1</span>]<br>        self.y = df.values[:, -<span class="hljs-number">1</span>]<br>        <span class="hljs-comment"># ensure input data is floats</span><br>        self.X = self.X.astype(<span class="hljs-string">&#x27;float32&#x27;</span>)<br>        <span class="hljs-comment"># label encode target and ensure the values are floats</span><br>        self.y = LabelEncoder().fit_transform(self.y)<br>        self.y = self.y.astype(<span class="hljs-string">&#x27;float32&#x27;</span>)<br>        self.y = self.y.reshape((<span class="hljs-built_in">len</span>(self.y), <span class="hljs-number">1</span>))<br><br>    <span class="hljs-comment"># number of rows in the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.X)<br><br>    <span class="hljs-comment"># get a row at an index</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> [self.X[idx], self.y[idx]]<br><br>    <span class="hljs-comment"># get indexes for train and test rows</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_splits</span>(<span class="hljs-params">self, n_test=<span class="hljs-number">0.3</span></span>):<br>        <span class="hljs-comment"># determine sizes</span><br>        test_size = <span class="hljs-built_in">round</span>(n_test * <span class="hljs-built_in">len</span>(self.X))<br>        train_size = <span class="hljs-built_in">len</span>(self.X) - test_size<br>        <span class="hljs-comment"># calculate the split</span><br>        <span class="hljs-keyword">return</span> random_split(self, [train_size, test_size])<br><br><br><span class="hljs-comment"># model definition</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>(<span class="hljs-title class_ inherited__">Module</span>):<br>    <span class="hljs-comment"># define model elements</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_inputs</span>):<br>        <span class="hljs-built_in">super</span>(MLP, self).__init__()<br>        <span class="hljs-comment"># input to first hidden layer</span><br>        self.hidden1 = Linear(n_inputs, <span class="hljs-number">10</span>)<br>        kaiming_uniform_(self.hidden1.weight, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>        self.act1 = ReLU()<br>        <span class="hljs-comment"># second hidden layer</span><br>        self.hidden2 = Linear(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>)<br>        kaiming_uniform_(self.hidden2.weight, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>        self.act2 = ReLU()<br>        <span class="hljs-comment"># third hidden layer and output</span><br>        self.hidden3 = Linear(<span class="hljs-number">8</span>, <span class="hljs-number">1</span>)<br>        xavier_uniform_(self.hidden3.weight)<br>        self.act3 = Sigmoid()<br><br>    <span class="hljs-comment"># forward propagate input</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-comment"># input to first hidden layer</span><br>        X = self.hidden1(X)<br>        X = self.act1(X)<br>        <span class="hljs-comment"># second hidden layer</span><br>        X = self.hidden2(X)<br>        X = self.act2(X)<br>        <span class="hljs-comment"># third hidden layer and output</span><br>        X = self.hidden3(X)<br>        X = self.act3(X)<br>        <span class="hljs-keyword">return</span> X<br><br><br><span class="hljs-comment"># prepare the dataset</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_data</span>(<span class="hljs-params">path</span>):<br>    <span class="hljs-comment"># load the dataset</span><br>    dataset = CSVDataset(path)<br>    <span class="hljs-comment"># calculate split</span><br>    train, test = dataset.get_splits()<br>    <span class="hljs-comment"># prepare data loaders</span><br>    train_dl = DataLoader(train, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">True</span>)<br>    test_dl = DataLoader(test, batch_size=<span class="hljs-number">1024</span>, shuffle=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">return</span> train_dl, test_dl<br><br><br><span class="hljs-comment"># train the model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_model</span>(<span class="hljs-params">train_dl, model</span>):<br>    <span class="hljs-comment"># define the optimization</span><br>    criterion = BCELoss()<br>    optimizer = SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0.9</span>)<br>    <span class="hljs-comment"># enumerate epochs</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>        <span class="hljs-comment"># enumerate mini batches</span><br>        <span class="hljs-keyword">for</span> i, (inputs, targets) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dl):<br>            <span class="hljs-comment"># clear the gradients</span><br>            optimizer.zero_grad()<br>            <span class="hljs-comment"># compute the model output</span><br>            yhat = model(inputs)<br>            <span class="hljs-comment"># calculate loss</span><br>            loss = criterion(yhat, targets)<br>            <span class="hljs-comment"># credit assignment</span><br>            loss.backward()<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch: &#123;&#125;, batch: &#123;&#125;, loss: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, i, loss.data))<br>            <span class="hljs-comment"># update model weights</span><br>            optimizer.step()<br><br><br><span class="hljs-comment"># evaluate the model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_model</span>(<span class="hljs-params">test_dl, model</span>):<br>    predictions, actuals = [], []<br>    <span class="hljs-keyword">for</span> i, (inputs, targets) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(test_dl):<br>        <span class="hljs-comment"># evaluate the model on the test set</span><br>        yhat = model(inputs)<br>        <span class="hljs-comment"># retrieve numpy array</span><br>        yhat = yhat.detach().numpy()<br>        actual = targets.numpy()<br>        actual = actual.reshape((<span class="hljs-built_in">len</span>(actual), <span class="hljs-number">1</span>))<br>        <span class="hljs-comment"># round to class values</span><br>        yhat = yhat.<span class="hljs-built_in">round</span>()<br>        <span class="hljs-comment"># store</span><br>        predictions.append(yhat)<br>        actuals.append(actual)<br>    predictions, actuals = vstack(predictions), vstack(actuals)<br>    <span class="hljs-comment"># calculate accuracy</span><br>    acc = accuracy_score(actuals, predictions)<br>    <span class="hljs-keyword">return</span> acc<br><br><br><span class="hljs-comment"># make a class prediction for one row of data</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">row, model</span>):<br>    <span class="hljs-comment"># convert row to data</span><br>    row = Tensor([row])<br>    <span class="hljs-comment"># make prediction</span><br>    yhat = model(row)<br>    <span class="hljs-comment"># retrieve numpy array</span><br>    yhat = yhat.detach().numpy()<br>    <span class="hljs-keyword">return</span> yhat<br><br><br><span class="hljs-comment"># prepare the data</span><br>path = <span class="hljs-string">&#x27;./data/ionosphere.csv&#x27;</span><br>train_dl, test_dl = prepare_data(path)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(train_dl.dataset), <span class="hljs-built_in">len</span>(test_dl.dataset))<br><span class="hljs-comment"># define the network</span><br>model = MLP(<span class="hljs-number">34</span>)<br><span class="hljs-built_in">print</span>(model)<br><span class="hljs-comment"># train the model</span><br>train_model(train_dl, model)<br><span class="hljs-comment"># evaluate the model</span><br>acc = evaluate_model(test_dl, model)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accuracy: %.3f&#x27;</span> % acc)<br><span class="hljs-comment"># make a single prediction (expect class=1)</span><br>row = [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0.99539</span>, -<span class="hljs-number">0.05889</span>, <span class="hljs-number">0.85243</span>, <span class="hljs-number">0.02306</span>, <span class="hljs-number">0.83398</span>, -<span class="hljs-number">0.37708</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.03760</span>, <span class="hljs-number">0.85243</span>, -<span class="hljs-number">0.17755</span>, <span class="hljs-number">0.59755</span>, -<span class="hljs-number">0.44945</span>,<br>       <span class="hljs-number">0.60536</span>, -<span class="hljs-number">0.38223</span>, <span class="hljs-number">0.84356</span>, -<span class="hljs-number">0.38542</span>, <span class="hljs-number">0.58212</span>, -<span class="hljs-number">0.32192</span>, <span class="hljs-number">0.56971</span>, -<span class="hljs-number">0.29674</span>, <span class="hljs-number">0.36946</span>, -<span class="hljs-number">0.47357</span>, <span class="hljs-number">0.56811</span>, -<span class="hljs-number">0.51171</span>,<br>       <span class="hljs-number">0.41078</span>, -<span class="hljs-number">0.46168</span>, <span class="hljs-number">0.21266</span>, -<span class="hljs-number">0.34090</span>, <span class="hljs-number">0.42267</span>, -<span class="hljs-number">0.54487</span>, <span class="hljs-number">0.18641</span>, -<span class="hljs-number">0.45300</span>]<br>yhat = predict(row, model)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Predicted: %.3f (class=%d)&#x27;</span> % (yhat, yhat.<span class="hljs-built_in">round</span>()))<br></code></pre></td></tr></table></figure><p>在上面代码中，CSVDataset类为csv数据集加载类，处理成模型适合的数据格式，并划分训练集和测试集比例为7:3。MLP类为MLP模型，模型输出层采用Sigmoid函数，损失函数采用BCELoss，优化器采用SGD，共训练100次。evaluate_model函数是模型在测试集上的表现，predict函数为在新数据上的预测结果。MLP模型的PyTorch输出如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">MLP(<br>  (hidden1): Linear(in_features=34, out_features=10, bias=True)<br>  (act1): ReLU()<br>  (hidden2): Linear(in_features=10, out_features=8, bias=True)<br>  (act2): ReLU()<br>  (hidden3): Linear(in_features=8, out_features=1, bias=True)<br>  (act3): Sigmoid()<br>)<br></code></pre></td></tr></table></figure><p>运行上述代码，输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">epoch: 0, batch: 0, loss: 0.7491992712020874<br>epoch: 0, batch: 1, loss: 0.750106692314148<br>epoch: 0, batch: 2, loss: 0.7033759355545044<br>......<br>epoch: 99, batch: 5, loss: 0.020291464403271675<br>epoch: 99, batch: 6, loss: 0.02309396117925644<br>epoch: 99, batch: 7, loss: 0.0278386902064085<br>Accuracy: 0.924<br>Predicted: 0.989 (class=1)<br></code></pre></td></tr></table></figure><p>可以看到，该MLP模型的最终训练loss值为0.02784，在测试集上的Accuracy为0.924，在新数据上预测完全正确。</p><h3 id="多分类模型">多分类模型</h3><p>接着我们来创建MLP模型实现iris数据集的三分类任务，Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># pytorch mlp for multiclass classification</span><br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> vstack<br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> argmax<br><span class="hljs-keyword">from</span> pandas <span class="hljs-keyword">import</span> read_csv<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelEncoder, LabelBinarizer<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> Tensor<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> SGD, Adam<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader, random_split<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Linear, ReLU, Softmax, Module, CrossEntropyLoss<br><span class="hljs-keyword">from</span> torch.nn.init <span class="hljs-keyword">import</span> kaiming_uniform_, xavier_uniform_<br><br><br><span class="hljs-comment"># dataset definition</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CSVDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-comment"># load the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, path</span>):<br>        <span class="hljs-comment"># load the csv file as a dataframe</span><br>        df = read_csv(path, header=<span class="hljs-literal">None</span>)<br>        <span class="hljs-comment"># store the inputs and outputs</span><br>        self.X = df.values[:, :-<span class="hljs-number">1</span>]<br>        self.y = df.values[:, -<span class="hljs-number">1</span>]<br>        <span class="hljs-comment"># ensure input data is floats</span><br>        self.X = self.X.astype(<span class="hljs-string">&#x27;float32&#x27;</span>)<br>        <span class="hljs-comment"># label encode target and ensure the values are floats</span><br>        self.y = LabelEncoder().fit_transform(self.y)<br>        <span class="hljs-comment"># self.y = LabelBinarizer().fit_transform(self.y)</span><br><br>    <span class="hljs-comment"># number of rows in the dataset</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.X)<br><br>    <span class="hljs-comment"># get a row at an index</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> [self.X[idx], self.y[idx]]<br><br>    <span class="hljs-comment"># get indexes for train and test rows</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_splits</span>(<span class="hljs-params">self, n_test=<span class="hljs-number">0.3</span></span>):<br>        <span class="hljs-comment"># determine sizes</span><br>        test_size = <span class="hljs-built_in">round</span>(n_test * <span class="hljs-built_in">len</span>(self.X))<br>        train_size = <span class="hljs-built_in">len</span>(self.X) - test_size<br>        <span class="hljs-comment"># calculate the split</span><br>        <span class="hljs-keyword">return</span> random_split(self, [train_size, test_size])<br><br><br><span class="hljs-comment"># model definition</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>(<span class="hljs-title class_ inherited__">Module</span>):<br>    <span class="hljs-comment"># define model elements</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_inputs</span>):<br>        <span class="hljs-built_in">super</span>(MLP, self).__init__()<br>        <span class="hljs-comment"># input to first hidden layer</span><br>        self.hidden1 = Linear(n_inputs, <span class="hljs-number">5</span>)<br>        kaiming_uniform_(self.hidden1.weight, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>        self.act1 = ReLU()<br>        <span class="hljs-comment"># second hidden layer</span><br>        self.hidden2 = Linear(<span class="hljs-number">5</span>, <span class="hljs-number">6</span>)<br>        kaiming_uniform_(self.hidden2.weight, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>        self.act2 = ReLU()<br>        <span class="hljs-comment"># third hidden layer and output</span><br>        self.hidden3 = Linear(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>)<br>        xavier_uniform_(self.hidden3.weight)<br>        self.act3 = Softmax(dim=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># forward propagate input</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-comment"># input to first hidden layer</span><br>        X = self.hidden1(X)<br>        X = self.act1(X)<br>        <span class="hljs-comment"># second hidden layer</span><br>        X = self.hidden2(X)<br>        X = self.act2(X)<br>        <span class="hljs-comment"># output layer</span><br>        X = self.hidden3(X)<br>        X = self.act3(X)<br>        <span class="hljs-keyword">return</span> X<br><br><br><span class="hljs-comment"># prepare the dataset</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_data</span>(<span class="hljs-params">path</span>):<br>    <span class="hljs-comment"># load the dataset</span><br>    dataset = CSVDataset(path)<br>    <span class="hljs-comment"># calculate split</span><br>    train, test = dataset.get_splits()<br>    <span class="hljs-comment"># prepare data loaders</span><br>    train_dl = DataLoader(train, batch_size=<span class="hljs-number">1</span>, shuffle=<span class="hljs-literal">True</span>)<br>    test_dl = DataLoader(test, batch_size=<span class="hljs-number">1024</span>, shuffle=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">return</span> train_dl, test_dl<br><br><br><span class="hljs-comment"># train the model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_model</span>(<span class="hljs-params">train_dl, model</span>):<br>    <span class="hljs-comment"># define the optimization</span><br>    criterion = CrossEntropyLoss()<br>    <span class="hljs-comment"># optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)</span><br>    optimizer = Adam(model.parameters())<br>    <span class="hljs-comment"># enumerate epochs</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>        <span class="hljs-comment"># enumerate mini batches</span><br>        <span class="hljs-keyword">for</span> i, (inputs, targets) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dl):<br>            targets = targets.long()<br>            <span class="hljs-comment"># clear the gradients</span><br>            optimizer.zero_grad()<br>            <span class="hljs-comment"># compute the model output</span><br>            yhat = model(inputs)<br>            <span class="hljs-comment"># calculate loss</span><br>            loss = criterion(yhat, targets)<br>            <span class="hljs-comment"># credit assignment</span><br>            loss.backward()<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch: &#123;&#125;, batch: &#123;&#125;, loss: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, i, loss.data))<br>            <span class="hljs-comment"># update model weights</span><br>            optimizer.step()<br><br><br><span class="hljs-comment"># evaluate the model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_model</span>(<span class="hljs-params">test_dl, model</span>):<br>    predictions, actuals = [], []<br>    <span class="hljs-keyword">for</span> i, (inputs, targets) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(test_dl):<br>        <span class="hljs-comment"># evaluate the model on the test set</span><br>        yhat = model(inputs)<br>        <span class="hljs-comment"># retrieve numpy array</span><br>        yhat = yhat.detach().numpy()<br>        actual = targets.numpy()<br>        <span class="hljs-comment"># convert to class labels</span><br>        yhat = argmax(yhat, axis=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># reshape for stacking</span><br>        actual = actual.reshape((<span class="hljs-built_in">len</span>(actual), <span class="hljs-number">1</span>))<br>        yhat = yhat.reshape((<span class="hljs-built_in">len</span>(yhat), <span class="hljs-number">1</span>))<br>        <span class="hljs-comment"># store</span><br>        predictions.append(yhat)<br>        actuals.append(actual)<br>    predictions, actuals = vstack(predictions), vstack(actuals)<br>    <span class="hljs-comment"># calculate accuracy</span><br>    acc = accuracy_score(actuals, predictions)<br>    <span class="hljs-keyword">return</span> acc<br><br><br><span class="hljs-comment"># make a class prediction for one row of data</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">row, model</span>):<br>    <span class="hljs-comment"># convert row to data</span><br>    row = Tensor([row])<br>    <span class="hljs-comment"># make prediction</span><br>    yhat = model(row)<br>    <span class="hljs-comment"># retrieve numpy array</span><br>    yhat = yhat.detach().numpy()<br>    <span class="hljs-keyword">return</span> yhat<br><br><br><span class="hljs-comment"># prepare the data</span><br>path = <span class="hljs-string">&#x27;./data/iris.csv&#x27;</span><br>train_dl, test_dl = prepare_data(path)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(train_dl.dataset), <span class="hljs-built_in">len</span>(test_dl.dataset))<br><span class="hljs-comment"># define the network</span><br>model = MLP(<span class="hljs-number">4</span>)<br><span class="hljs-built_in">print</span>(model)<br><span class="hljs-comment"># train the model</span><br>train_model(train_dl, model)<br><span class="hljs-comment"># evaluate the model</span><br>acc = evaluate_model(test_dl, model)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accuracy: %.3f&#x27;</span> % acc)<br><span class="hljs-comment"># make a single prediction</span><br>row = [<span class="hljs-number">5.1</span>, <span class="hljs-number">3.5</span>, <span class="hljs-number">1.4</span>, <span class="hljs-number">0.2</span>]<br>yhat = predict(row, model)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Predicted: %s (class=%d)&#x27;</span> % (yhat, argmax(yhat)))<br></code></pre></td></tr></table></figure><p>可以看到，多分类代码与二分类代码大同小异，在加载数据集、模型结构、模型训练（训练batch值取1）代码上略有不同。运行上述代码，输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">105 45<br>MLP(<br>  (hidden1): Linear(in_features=4, out_features=5, bias=True)<br>  (act1): ReLU()<br>  (hidden2): Linear(in_features=5, out_features=6, bias=True)<br>  (act2): ReLU()<br>  (hidden3): Linear(in_features=6, out_features=3, bias=True)<br>  (act3): Softmax(dim=1)<br>)<br>epoch: 0, batch: 0, loss: 1.4808106422424316<br>epoch: 0, batch: 1, loss: 1.4769641160964966<br>epoch: 0, batch: 2, loss: 0.654313325881958<br>......<br>epoch: 99, batch: 102, loss: 0.5514447093009949<br>epoch: 99, batch: 103, loss: 0.620153546333313<br>epoch: 99, batch: 104, loss: 0.5514482855796814<br>Accuracy: 0.933<br>Predicted: [[9.9999809e-01 1.8837408e-06 2.4509615e-19]] (class=0)<br></code></pre></td></tr></table></figure><p>可以看到，该MLP模型的最终训练loss值为0.5514，在测试集上的Accuracy为0.933，在新数据上预测完全正确。</p><h3 id="总结">总结</h3><p>本文介绍的模型代码已开源，Github地址为：<a href="https://github.com/percent4/PyTorch_Learning">https://github.com/percent4/PyTorch_Learning</a>。后续将持续介绍PyTorch内容，欢迎大家关注~</p>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch入门（一）向量</title>
    <link href="/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E5%90%91%E9%87%8F/"/>
    <url>/PyTorch%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E5%90%91%E9%87%8F/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="什么是pytorch">什么是PyTorch？</h3><p><img src="/img/pytorch1_1.png" /></p><p>PyTorch是Facebook人工智能团队开发的一个机器学习和深度学习工具，用于处理大规模图像分析，包括物体检测，分割与分类。但是它的功能不仅限于此。它与其它深度学习框架结合，能够完成复杂的算法。PyTorch用Python和C++编写。</p><p>PyTorch属于深度学习框架中的重要一员，与TensorFlow, Keras,Theano等其它深度学习框架不同，它是动态计算图模式，其应用模型支持在运行过程中根据运行参数动态改变，而其它框架都是静态计算图模式，其模型在运行之前就已经确定。以下是各个深度学习框架的热度对比:</p><p><img src="/img/pytorch1_2.png" /></p><p>关于各个深度学习框架的对比，可以参考网址：<ahref="https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software">Comparisonof deep learning software</a> 。</p><p>PyTorch是使用GPU和CPU优化的深度学习张量库。</p><p>下面，我们将一起来学习PyTorch中向量（Tensor）的相关操作。</p><h3 id="安装与运行">安装与运行</h3><p>PyTorch的安装十分简单，需要用pip安装即可：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip3 <span class="hljs-keyword">install</span> torch<br>pip3 <span class="hljs-keyword">install</span> torchvision<br></code></pre></td></tr></table></figure><p>其中torchvision包含了一些torch内置的图片与视频数据集。</p><p>用以下的Python代码可以输出安装的PyTorch版本信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-built_in">print</span>(torch.version.__version__)<br></code></pre></td></tr></table></figure><p>在笔者的电脑上，输出的结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">1</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.post2<br></code></pre></td></tr></table></figure><h3 id="向量的基本操作">向量的基本操作</h3><h5 id="导入模块">导入模块</h5><figure><img src="/img/pytorch1_3.png" alt="导入模块" /><figcaption aria-hidden="true">导入模块</figcaption></figure><h5 id="检测是否为pytorch中的向量">检测是否为PyTorch中的向量</h5><p>is_tensor()函数可以检测某个序列是否为PyTorch中的向量，is_storage()可以检测某个序列是否被存储为PyTorch中的向量。</p><figure><img src="/img/pytorch1_4.png" alt="向量检测" /><figcaption aria-hidden="true">向量检测</figcaption></figure><p>可以看到，Python中的列表并不是PyTorch中的向量，也不会被存储为PyTorch中的向量。那么，如何创建PyTorch中的向量呢？</p><h5 id="创建随机向量">创建随机向量</h5><p>利用randn()函数可以创建随机向量，随机数为0~1的随机浮点数，可以指定创建的向量的维数。</p><figure><img src="/img/pytorch1_5.png" alt="创建随机向量" /><figcaption aria-hidden="true">创建随机向量</figcaption></figure><p>可以看到，我们创建了1*2*3维的向量，用size()函数可以查看向量的维数情况，用numel()函数可以查看向量中的所有元素个数。</p><h5 id="创建零向量">创建零向量</h5><p>利用zeros()函数可以创建零向量，即所有元素均为零的向量，只需指定向量的维数即可。</p><figure><img src="/img/pytorch1_6.png" alt="创建零向量" /><figcaption aria-hidden="true">创建零向量</figcaption></figure><p>在上面，我们创建了4*4的零向量。</p><h5 id="创建单位向量">创建单位向量</h5><p>利用eye()函数可以创建单位向量，即主对角元素为1，其余元素均为零的向量，只需指定向量的维数即可。当二维向量的行数与列数不一样时，主对角元素为1，其余为0。</p><figure><img src="/img/pytorch1_7.png" alt="创建单位向量" /><figcaption aria-hidden="true">创建单位向量</figcaption></figure><h5 id="从numpy中创建向量">从numpy中创建向量</h5><p>PyTorch支持直接从numpy中创建向量，这为PyTorch和numpy提供了无缝对接，这也是PyTorch的一个优势。</p><figure><img src="/img/pytorch1_8.png" alt="从numpy直接创建向量" /><figcaption aria-hidden="true">从numpy直接创建向量</figcaption></figure><p>当然，PyTorch也可以将向量转化为numpy中的ndarrays.</p><figure><img src="/img/pytorch1_9.png" alt="向量转化为numpy.ndarrays" /><figcaption aria-hidden="true">向量转化为numpy.ndarrays</figcaption></figure><h5 id="tensor函数创建向量">Tensor函数创建向量</h5><p>可以利用Tensor()直接创建向量。</p><figure><img src="/img/pytorch1_10.png" alt="Tensor函数" /><figcaption aria-hidden="true">Tensor函数</figcaption></figure><h5 id="linspace与logspace创建向量">linspace与logspace创建向量</h5><p>linspace(tart, end, steps=100,out=None)通过指定开始值、终值和元素个数创建表示等差数列的一维数组，可以通过endpoint参数指定是否包含终值，默认值为True，即包含终值。</p><p>logspace(tart, end, steps=100,out=None)返回一个1维张量，包含在区间10exp(start)和10exp(end)上以对数刻度均匀间隔的steps个点。</p><figure><img src="/img/pytorch1_11.png" alt="linspace() &amp; logspace()" /><figcaption aria-hidden="true">linspace() &amp; logspace()</figcaption></figure><h5 id="创建均匀分布向量">创建均匀分布向量</h5><p>rand()函数可以创建指定维数的满足均匀分布的向量。</p><figure><img src="/img/pytorch1_12.png" alt="rand()" /><figcaption aria-hidden="true">rand()</figcaption></figure><h5 id="随机整数排列向量">随机整数排列向量</h5><p>randperm(n, out=None) ,给定参数n，返回一个从0 到n -1的随机整数排列。</p><figure><img src="/img/pytorch1_13.png" alt="randperm()" /><figcaption aria-hidden="true">randperm()</figcaption></figure><h5 id="等差数列向量">等差数列向量</h5><p>arange(start, end, step=1, out=None) ,返回一个1维张量，包含从start到end，以step为步长的一组序列值(默认步长为1)。</p><figure><img src="/img/pytorch1_14.png" alt="arange()" /><figcaption aria-hidden="true">arange()</figcaption></figure><h5 id="寻找最大值最小组">寻找最大值、最小组</h5><p>argmin()和argmax()函数可以寻找向量所在的最小值和最大值的下标，0表示沿着行查找，1表示沿着列查找。</p><figure><img src="/img/pytorch1_15.png" alt="argmin(), argmax()" /><figcaption aria-hidden="true">argmin(), argmax()</figcaption></figure><h5 id="向量拼接">向量拼接</h5><p>cat()函数在给定维度上对输入的张量序列seq进行连接操作，默认的维度为0，即按行拼接。</p><figure><img src="/img/pytorch1_16.png" alt="cat()" /><figcaption aria-hidden="true">cat()</figcaption></figure><h6 id="向量分块">向量分块</h6><p>chunk(tensor, chunks,dim=0)函数在给定维度(轴)上将输入张量进行分块，默认为0，即按行进行分块。</p><figure><img src="/img/pytorch1_25.png" alt="chunk()" /><figcaption aria-hidden="true">chunk()</figcaption></figure><h5 id="gather函数">gather()函数</h5><p>gather(input, dim, index, out=None),沿给定轴dim，将输入索引张量index指定位置的值进行聚合。gather()函数理解起来比较困难，先看例子，再解释：</p><figure><img src="/img/pytorch1_17.png" alt="gather()" /><figcaption aria-hidden="true">gather()</figcaption></figure><p>gather的作用是这样的，index是索引，具体是行还是列的索引要看前面dim，比如对于我们的例子, [[11, 12], [23, 24]],指定dim=1，也就是横向，那么索引就是列号。index的大小就是输出的大小，所以比如index是[[0,0],[1,0]]，那么看index第一行，0列指的是11，同理，第二行为1, 0 ,这样就是[24,23]，参考这样的解释看上面的输出结果，即可理解gather的含义。</p><h5 id="索引">索引</h5><p>index_select(input, dim, index, out=None)，沿着指定维度对输入进行切片，取index中指定的相应项(index为一个LongTensor)，然后返回到一个新的张量，返回的张量与原始张量_Tensor_有相同的维度(在指定轴上)。</p><figure><img src="/img/pytorch1_18.png" alt="index_select()" /><figcaption aria-hidden="true">index_select()</figcaption></figure><h5 id="split函数">split()函数</h5><p>split(tensor, split_size, dim=0),将输入张量分割成相等形状的chunks（如果可分）。如果沿指定维的张量形状大小不能被split_size整分，则最后一个分块会小于其它分块。</p><figure><img src="/img/pytorch1_19.png" alt="split()" /><figcaption aria-hidden="true">split()</figcaption></figure><h6 id="向量转置">向量转置</h6><p>二维向量的转置可以用t()或transpos(1, 0)实现。</p><figure><img src="/img/pytorch1_20.png" alt="向量转置" /><figcaption aria-hidden="true">向量转置</figcaption></figure><h5 id="unbind">unbind()</h5><p>unbind(tensor, dim=0),移除指定维后，返回一个元组，包含了沿着指定维切片后的各个切片，默认维度为1，表示行，1表示列。</p><figure><img src="/img/pytorch1_21.png" alt="unbind()" /><figcaption aria-hidden="true">unbind()</figcaption></figure><h5 id="判断是否为零元素">判断是否为零元素</h5><p>nonzero()函数可以判断向量中的元素是否为0.</p><figure><img src="/img/pytorch1_22.png" alt="nonzero()" /><figcaption aria-hidden="true">nonzero()</figcaption></figure><h5 id="向量运算">向量运算</h5><p>以下将演示几种常见的矩阵运算。</p><figure><img src="/img/pytorch1_23.png" alt="矩阵运算" /><figcaption aria-hidden="true">矩阵运算</figcaption></figure><p>矩阵的点乘与矩阵乘法</p><figure><img src="/img/pytorch1_24.png" alt="矩阵点乘与矩阵乘法" /><figcaption aria-hidden="true">矩阵点乘与矩阵乘法</figcaption></figure><h3 id="总结">总结</h3><p>本文的github地址为：https://github.com/percent4/PyTorch_Learning/blob/master/pytorch_tensor_demo.ipynb。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>深度学习框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
      <tag>向量</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（六十三）使用Baichuan-7b模型微调人物关系分类任务</title>
    <link href="/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%89%EF%BC%89%E4%BD%BF%E7%94%A8Baichuan-7b%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/"/>
    <url>/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%89%EF%BC%89%E4%BD%BF%E7%94%A8Baichuan-7b%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="任务介绍">任务介绍</h3><p>人物关系分类指的是对文本中的两个人物，在特定的关系列表中，判断他们之间的人物关系。以样本<code>亲戚 1837年6月20日，威廉四世辞世，他的侄女维多利亚即位。</code>为例，其中<code>亲戚</code>为人物关系，<code>威廉四世</code>为实体1，<code>维多利亚</code>为实体2。</p><p>笔者自己利用业余时间标注的样本数据有3881条，分布如下图：</p><figure><img src="/img/nlp42_1.png" alt="人物关系分布图" /><figcaption aria-hidden="true">人物关系分布图</figcaption></figure><p>对上述数据集进行划分，训练集与测试集的比例为8:2，其中训练集3105条，测试集776条。</p><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%80%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%AE%9E%E6%88%98/">NLP（二十一）人物关系抽取的一次实战</a>中，当时的标注数据为2900多条，使用BERT向量提取+BiGRU+Attention模型，取得的平均F1值为78.97%.</p><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%8C%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E7%9A%84%E5%86%8D%E6%AC%A1%E5%B0%9D%E8%AF%95/">NLP（四十二）人物关系分类的再次尝试</a>中，借助BERT微调（当作分类任务），取得的平均F1值为82.69%.</p><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%94%EF%BC%89R-BERT%E5%9C%A8%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%B0%9D%E8%AF%95%E5%8F%8AKeras%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/">NLP（四十五）R-BERT在人物关系分类上的尝试及Keras代码复现</a>中，借助专用于关系分类任务的R-BERT模型，在ChineseRoberta模型上取得的F1值为85.35%.</p><p>在本文中，将尝试使用大模型（Large Language Model,LLM）中的中文模型代表Baichuan-7b,对人物关系分类任务进行微调，看看它的表现。</p><h3 id="好的提示">好的提示</h3><p>在开始模型微调之前，我们需要一个好的提示（Prompt），我们借助GPT-4：</p><figure><img src="/img/nlp63_1.png" alt="GPT-4给出的关于关系分类的Prompt" /><figcaptionaria-hidden="true">GPT-4给出的关于关系分类的Prompt</figcaption></figure><p>别小看了Prompt的威力，笔者在使用微调模型过程中，发现自己写的Prompt与GPT-4给出的Prompt，在训练结果F1值上可能相差3-4%。可见Prompt工程的重要性！</p><h3 id="模型微调">模型微调</h3><p>我们使用上述Prompt，加工数据集（当作多轮对话任务），格式如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;conversation_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;category&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;relation classification&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;conversation&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;human&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;给定以下标签：[&#x27;不确定&#x27;, &#x27;夫妻&#x27;, &#x27;父母&#x27;, &#x27;兄弟姐妹&#x27;, &#x27;上下级&#x27;, &#x27;师生&#x27;, &#x27;好友&#x27;, &#x27;同学&#x27;, &#x27;合作&#x27;, &#x27;同一个人&#x27;, &#x27;情侣&#x27;, &#x27;祖孙&#x27;, &#x27;同门&#x27;, &#x27;亲戚&#x27;]，请在以下句子中分析并分类实体之间的关系：&#x27;与李源澄论戴东原书&#x27;在这个句子中，戴东原和李源澄之间的关系应该属于哪个标签？&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;assistant&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;不知道&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>使用Firefly框架进行模型微调，访问网址为：<ahref="https://github.com/yangjianxin1/Firefly">https://github.com/yangjianxin1/Firefly</a>.本文基于Baichuan-7b为基座模型，采用QLora方式训练，训练参数如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;output_dir&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;output/firefly-baichuan-7b-people&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;model_name_or_path&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/home/test/baichun_7b&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;train_file&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;./data/train.jsonl&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;num_train_epochs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">5</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;per_device_train_batch_size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">8</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;gradient_accumulation_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;learning_rate&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2e-4</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;max_seq_length&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">256</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;logging_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">100</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;save_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">100</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;save_total_limit&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lr_scheduler_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;constant_with_warmup&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;warmup_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">100</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lora_rank&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">64</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lora_alpha&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">16</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lora_dropout&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.05</span><span class="hljs-punctuation">,</span><br><br>    <span class="hljs-attr">&quot;gradient_checkpointing&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;disable_tqdm&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;optim&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;paged_adamw_32bit&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;seed&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">42</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;fp16&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;report_to&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;tensorboard&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;dataloader_num_workers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;save_strategy&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;steps&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;weight_decay&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;max_grad_norm&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.3</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;remove_unused_columns&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>使用命令行<code>torchrun --nproc_per_node=2 train_qlora.py --train_args_file train_args/qlora/baichuan-7b-sft-qlora.json</code>进行训练，训练时间大约20分钟，最终的trainloss为0.0273。</p><p>在Firefly框架中设置好merge_lora.py中的模型文件路径，将adapter的权重与Baichuan-7b模型合并，合并得到新文件<code>firefly-baichuan-7b-people-merge</code>。</p><p>在Firefly框架，仿造script/chat/single_chat.py文件，将其改写成API调用方式的文件single_chat_server.py，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai</span><br><span class="hljs-comment"># @file: single_chat_server.py</span><br><span class="hljs-comment"># @time: 2023/7/25 22:27</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-comment"># 单轮对话web服务</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request, jsonify<br><br>app = Flask(<span class="hljs-string">&quot;single_chat_server&quot;</span>)<br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/people_rel_cls&#x27;</span>, methods=[<span class="hljs-string">&#x27;POST&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>():<br>    req_dict = request.json<br>    text, people1, people2 = req_dict[<span class="hljs-string">&quot;text&quot;</span>], req_dict[<span class="hljs-string">&quot;people1&quot;</span>], req_dict[<span class="hljs-string">&quot;people2&quot;</span>]<br>    text = text.strip()<br>    content = <span class="hljs-string">f&quot;给定以下标签：[&#x27;不确定&#x27;, &#x27;夫妻&#x27;, &#x27;父母&#x27;, &#x27;兄弟姐妹&#x27;, &#x27;上下级&#x27;, &#x27;师生&#x27;, &#x27;好友&#x27;, &#x27;同学&#x27;, &quot;</span> \<br>              <span class="hljs-string">f&quot;&#x27;合作&#x27;, &#x27;同一个人&#x27;, &#x27;情侣&#x27;, &#x27;祖孙&#x27;, &#x27;同门&#x27;, &#x27;亲戚&#x27;]，&quot;</span> \<br>              <span class="hljs-string">f&quot;请在以下句子中分析并分类实体之间的关系：&#x27;<span class="hljs-subst">&#123;text&#125;</span>&#x27;&quot;</span> \<br>              <span class="hljs-string">f&quot;在这个句子中，<span class="hljs-subst">&#123;people1&#125;</span>和<span class="hljs-subst">&#123;people2&#125;</span>之间的关系应该属于哪个标签？&quot;</span><br>    <span class="hljs-built_in">print</span>(content)<br>    input_ids = tokenizer(content, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, add_special_tokens=<span class="hljs-literal">False</span>).input_ids.to(device)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        outputs = model.generate(<br>            input_ids=input_ids, max_new_tokens=max_new_tokens, do_sample=<span class="hljs-literal">True</span>,<br>            top_p=top_p, temperature=temperature, repetition_penalty=repetition_penalty,<br>            eos_token_id=tokenizer.eos_token_id<br>        )<br>    outputs = outputs.tolist()[<span class="hljs-number">0</span>][<span class="hljs-built_in">len</span>(input_ids[<span class="hljs-number">0</span>]):]<br>    response = tokenizer.decode(outputs)<br>    <span class="hljs-built_in">print</span>(outputs, response)<br>    response = response.strip().replace(text, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&#x27;&lt;s&gt;&#x27;</span>, <span class="hljs-string">&quot;&quot;</span>).strip()<br>    <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&quot;result&quot;</span>: response&#125;)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model_name = <span class="hljs-string">&quot;/home/test/Firefly/script/checkpoint/firefly-baichuan-7b-people-merge&quot;</span><br>    max_new_tokens = <span class="hljs-number">5</span><br>    top_p = <span class="hljs-number">0.9</span><br>    temperature = <span class="hljs-number">0.01</span><br>    repetition_penalty = <span class="hljs-number">1.0</span><br>    device = <span class="hljs-string">&#x27;cuda:0&#x27;</span><br>    input_pattern = <span class="hljs-string">&#x27;&lt;s&gt;&#123;&#125;&lt;/s&gt;&#x27;</span><br>    model = AutoModelForCausalLM.from_pretrained(<br>        model_name,<br>        trust_remote_code=<span class="hljs-literal">True</span>,<br>        low_cpu_mem_usage=<span class="hljs-literal">True</span>,<br>        torch_dtype=torch.float16,<br>    ).to(device).<span class="hljs-built_in">eval</span>()<br>    tokenizer = AutoTokenizer.from_pretrained(<br>        model_name,<br>        trust_remote_code=<span class="hljs-literal">True</span>,<br>        <span class="hljs-comment"># llama不支持fast</span><br>        use_fast=<span class="hljs-literal">False</span> <span class="hljs-keyword">if</span> model.config.model_type == <span class="hljs-string">&#x27;llama&#x27;</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">True</span><br>    )<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;model loaded!&quot;</span>)<br>    app.run(host=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, port=<span class="hljs-number">5000</span>, threaded=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>使用API调用方式可以对测试集进行模型评估。</p><h3 id="结果比对">结果比对</h3><p>不同模型（包括BERT时代前后的模型方法）的评估结果（均为当时模型的SOTA结果或接近SOTA结果）如下：</p><table><thead><tr class="header"><th>模型方法</th><th>基座模型</th><th>F1值</th><th>说明</th></tr></thead><tbody><tr class="odd"><td>BERT向量提取+BiGRU+Attention</td><td>BiGRU+Attention</td><td>78.97%</td><td>BERT模型作为特征提取处理</td></tr><tr class="even"><td>BERT cls finetuning</td><td>BERT</td><td>82.69%</td><td>当作文本分类任务处理</td></tr><tr class="odd"><td>R-BERT</td><td>chinese-roberta-wwm-ext</td><td>85.35%</td><td>BERT时代的关系分类模型代表</td></tr><tr class="even"><td>R-BERT</td><td>chinese-roberta-wwm-ext-large</td><td>87.22%</td><td>BERT时代的关系分类模型代表</td></tr><tr class="odd"><td>QLora</td><td>Baichuan-7b</td><td>88.25%</td><td>其它参数上文给出，epoch=5</td></tr><tr class="even"><td>QLora</td><td>Baichuan-7b</td><td>89.15%</td><td>其它参数上文给出，epoch=10</td></tr></tbody></table><h3 id="存在问题">存在问题</h3><p>在大模型时代中，大模型突破了以前NLP任务的范畴，走向了更加通用化，从上述结果中，我们也不难发现，大模型（Baichuan-7b）在传统的NLP任务（如笔者自己的人物关系数据集）上取得了更好的结果，达到了新的SOTA，这是符合我们的认知的。</p><p>但在笔者模型微调过程中，也发现了不少的问题或有待于进一步验证的地方，记录如下：</p><ul><li><p>Baichuan-7b模型取得了SOTA结果，但同样的训练框架和训练参数，Baichuan-13B-Base模型却表现惨淡，甚至很差</p></li><li><p>不同的Prompt对于训练结果的影响，比如笔者自己写的Prompt和GPT-4写的Prompt对于最终结果差距较大，相差3-4%</p></li><li><p>相同的模型，采用full, lora,qlora三种形式进行SFT，训练结果会有何不同</p><p>后续笔者将尝试使用不同的训练框架进行Baichuan-13B-Base的微调。</p></li></ul><h3 id="总结分享">总结分享</h3><p>本文主要介绍如何使用Baichuan-7b模型微调人物关系分类任务，并比BERT时代的模型取得了进步，达到了新的SOTA.</p><p>本文的想法很朴素，主要是想测试下LLM在传统NLP人物上的表现，也是对于笔者自己的人物关系数据集的一次效果提升，这也是笔者一直在关注和构建的数据集。这一次，大模型再一次让我震惊！</p><p>本文使用的人物关系数据集已开源至HuggingFace Datasets, 网址为: <ahref="https://huggingface.co/datasets/jclian91/people_relation_classification">https://huggingface.co/datasets/jclian91/people_relation_classification</a>.</p><p>本人的个人博客网址为：<ahref="https://percent4.github.io/">https://percent4.github.io/</a>,欢迎大家关注~</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>NLP（二十一）人物关系抽取的一次实战: <ahref="https://percent4.github.io/2023/07/08/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%80%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%AE%9E%E6%88%98/">https://percent4.github.io/2023/07/08/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%80%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%AE%9E%E6%88%98/</a></li><li>NLP（四十二）人物关系分类的再次尝试: <ahref="https://percent4.github.io/2023/07/10/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%8C%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E7%9A%84%E5%86%8D%E6%AC%A1%E5%B0%9D%E8%AF%95/">https://percent4.github.io/2023/07/10/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%8C%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E7%9A%84%E5%86%8D%E6%AC%A1%E5%B0%9D%E8%AF%95/</a></li><li>NLP（四十五）R-BERT在人物关系分类上的尝试及Keras代码复现: <ahref="https://percent4.github.io/2023/07/10/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%94%EF%BC%89R-BERT%E5%9C%A8%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%B0%9D%E8%AF%95%E5%8F%8AKeras%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/">https://percent4.github.io/2023/07/10/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%94%EF%BC%89R-BERT%E5%9C%A8%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%B0%9D%E8%AF%95%E5%8F%8AKeras%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/</a></li><li>微调百川Baichuan-13B保姆式教程，手把手教你训练百亿大模型: <ahref="https://mp.weixin.qq.com/s/ZBY6kbogHjbCQvZBzNEqag">https://mp.weixin.qq.com/s/ZBY6kbogHjbCQvZBzNEqag</a></li><li>HuggingFace Dataset people_relation_classification: <ahref="https://huggingface.co/datasets/jclian91/people_relation_classification">https://huggingface.co/datasets/jclian91/people_relation_classification</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>Baichuan-7b</tag>
      
      <tag>人物关系</tag>
      
      <tag>关系分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo的Fluid主题中自定义iconfont图标</title>
    <link href="/Hexo%E7%9A%84Fluid%E4%B8%BB%E9%A2%98%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89iconfont%E5%9B%BE%E6%A0%87/"/>
    <url>/Hexo%E7%9A%84Fluid%E4%B8%BB%E9%A2%98%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89iconfont%E5%9B%BE%E6%A0%87/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="hexo的fluid主题介绍">Hexo的Fluid主题介绍</h3><p>Hexo是一个快速、简洁且高效的博客框架。Hexo使用Markdown（或其他标记语言）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p><p>Fluid是Hexo中一个优雅的主题，这是一款MaterialDesign风格的Hexo主题，以简约的设计帮助你专注于写作，其配置页面可参考<ahref="https://hexo.fluid-dev.com/docs/guide/">https://hexo.fluid-dev.com/docs/guide/</a>.</p><p>Fluid主题中的主页（about）中可使用社交图标，使用可参考<ahref="https://fluid-dev.github.io/hexo-fluid-docs/icon/">https://fluid-dev.github.io/hexo-fluid-docs/icon/</a>. 但主页内置的社交图标太少，有时候我们需要自定义图标。</p><p>本文将介绍在Hexo的Fluid主题中自定义iconfont图标，并纠正现有公开博客文章的错误。</p><h3 id="如何自定义iconfont图标">如何自定义iconfont图标</h3><p>iconfont是国内功能很强大且图标内容很丰富的矢量图标库，提供矢量图标下载、在线存储、格式转换等功能，由阿里巴巴体验团队倾力打造，是一款有助于设计和前端开发的便捷工具，网址为：<ahref="https://www.iconfont.cn/">https://www.iconfont.cn/</a> .</p><p>在Hexo的Fluid主题中自定义iconfont图标的步骤（以今日头条图标为例）如下：</p><ol type="1"><li>在iconfont网站中搜索今日头条图标，添加至购物车，并下载代码至本地；</li></ol><figure><img src="/img/hexo_fluid_1.png" alt="下载今日头条图标的代码" /><figcaption aria-hidden="true">下载今日头条图标的代码</figcaption></figure><ol start="2" type="1"><li><p>将下载代码压缩文件解压，并重命名为toutiao；</p></li><li><p>将toutiao文件夹放至Hexo项目中的source/css文件夹下；</p></li><li><p>在_config.fluid.yml文件中配置如下：</p></li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">skip_render:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">&#x27;css/**/*&#x27;</span><br>  <br><span class="hljs-attr">custom_css:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">/css/toutiao/iconfont.css</span><br><br><span class="hljs-attr">about:</span><br>  <span class="hljs-attr">avatar:</span> <span class="hljs-string">/img/avatar.png</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;Fluid&quot;</span><br>  <span class="hljs-attr">intro:</span> <span class="hljs-string">&quot;个人博客&quot;</span><br>  <span class="hljs-attr">icons:</span><br>    <span class="hljs-bullet">-</span> &#123; <span class="hljs-attr">class:</span> <span class="hljs-string">&#x27;icon iconfont icon-jinritoutiao&#x27;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&#x27;you own toutiao website&#x27;</span>, <span class="hljs-attr">tip:</span> <span class="hljs-string">&#x27;今日头条&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><ol start="5" type="1"><li>部署Hexo，结果如下：</li></ol><figure><img src="/img/hexo_fluid_2.png" alt="主页页面自定义图标成功" /><figcaption aria-hidden="true">主页页面自定义图标成功</figcaption></figure><h3 id="纠错之处">纠错之处</h3><p>在上述配置中的第4步，现在很少有参考文章，而仅有的中文参考文章中的配置icons中的class方法是不正确的。</p><p>正确的方法是打开toutiao文件夹中的示例页面（demo_index.html），右击FontClass中的图标，选择查看：</p><figure><img src="/img/hexo_fluid_5.png" alt="demo_index.html文件" /><figcaption aria-hidden="true">demo_index.html文件</figcaption></figure><figure><img src="/img/hexo_fluid_3.png" alt="查看Font Class图标" /><figcaption aria-hidden="true">查看Font Class图标</figcaption></figure><p>class应该选择如下：</p><figure><img src="/img/hexo_fluid_4.png" alt="如何查看class" /><figcaption aria-hidden="true">如何查看class</figcaption></figure><p>以上是本文对现有的公开博客文章关于如何在Hexo的Fluid主题中配置icons的class的纠正之处。</p><p>欢迎访问本人的个人博客：<ahref="https://percent4.github.io/">https://percent4.github.io/</a> .</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Elasticsearch入门笔记（一）</title>
    <link href="/Elasticsearch%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <url>/Elasticsearch%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="环境搭建">环境搭建</h3><p>Elasticsearch是搜索引擎，是常见的搜索工具之一。</p><p>Kibana 是一个开源的分析和可视化平台，旨在与 Elasticsearch合作。Kibana 提供搜索、查看和与存储在 Elasticsearch索引中的数据进行交互的功能。开发者或运维人员可以轻松地执行高级数据分析，并在各种图表、表格和地图中可视化数据。</p><p>其它可视化还有elasticsearch-head(轻量级，有对应的Chrome插件)，本文不会详细介绍。</p><p>Elasticsearch和Kibana的版本采用7.17.0，环境搭建采用Docker，<code>docker-compose.yml</code>文件如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.1&quot;</span><br><span class="hljs-comment"># 服务配置</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">elasticsearch:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">elasticsearch-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">elasticsearch:7.17.0</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;ES_JAVA_OPTS=-Xms1024m -Xmx1024m&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;http.host=0.0.0.0&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;node.name=elastic01&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;cluster.name=cluster_elasticsearch&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;discovery.type=single-node&quot;</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9200:9200&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9300:9300&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./es/plugins:/usr/share/elasticsearch/plugins</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./es/data:/usr/share/elasticsearch/data</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elastic_net</span><br><br>  <span class="hljs-attr">kibana:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">kibana-7.17.0</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">kibana:7.17.0</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;5601:5601&quot;</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">elastic_net</span><br><br><span class="hljs-comment"># 网络配置</span><br><span class="hljs-attr">networks:</span><br>  <span class="hljs-attr">elastic_net:</span><br>    <span class="hljs-attr">driver:</span> <span class="hljs-string">bridge</span><br></code></pre></td></tr></table></figure><h3 id="基础命令">基础命令</h3><ul><li>查看ElasticSearch是否启动成功：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://IP:9200<br></code></pre></td></tr></table></figure><ul><li>查看集群是否健康</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://IP:9200/_cat/health?v<br></code></pre></td></tr></table></figure><ul><li>查看ElasticSearch所有的index</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://IP:9200/_cat/indices<br></code></pre></td></tr></table></figure><ul><li>查看ElasticSearch所有indices或者某个index的文档数量</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://IP:9200/_cat/count?v<br>curl http://IP:9200/_cat/count/some_index_name?v<br></code></pre></td></tr></table></figure><ul><li>查看每个节点正在运行的插件信息</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://IP:9200/_cat/plugins?v&amp;s=component&amp;h=name,component,version,description<br></code></pre></td></tr></table></figure><ul><li>查看ik插件的分词结果</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -H <span class="hljs-string">&#x27;Content-Type: application/json&#x27;</span>  -XGET <span class="hljs-string">&#x27;http://IP:9200/_analyze?pretty&#x27;</span> -d <span class="hljs-string">&#x27;&#123;&quot;analyzer&quot;:&quot;ik_max_word&quot;,&quot;text&quot;:&quot;美国留给伊拉克的是个烂摊子吗&quot;&#125;&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="index操作">index操作</h3><ul><li>查看某个index的mapping</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://IP:9200/some_index_name/_mapping<br></code></pre></td></tr></table></figure><ul><li>查看某个index的所有数据</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://IP:9200/some_index_name/_search<br></code></pre></td></tr></table></figure><ul><li>按ID进行查询</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -X GET http://IP:9200/索引名称/文档类型/ID<br></code></pre></td></tr></table></figure><ul><li>检索某个index的全部数据</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://IP:9200/索引名称/_search?pretty<br>curl -X POST http://IP:9200/索引名称/_search?pretty -d <span class="hljs-string">&quot;&#123;\&quot;query\&quot;: &#123;\&quot;match_all\&quot;: &#123;&#125; &#125;&#125;&quot;</span><br></code></pre></td></tr></table></figure><ul><li>检索某个index的前几条数据(如果不指定size,则默认为10条)</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -XPOST IP:9200/索引名称/_search?pretty -d <span class="hljs-string">&quot;&#123;\&quot;query\&quot;: &#123;\&quot;match_all\&quot;: &#123;&#125; &#125;, \&quot;size\&quot; : 2&#125;&quot;</span><br></code></pre></td></tr></table></figure><ul><li>检索某个index的中间几条数据(比如第11-20条数据)</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -XPOST IP:9200/索引名称/_search?pretty -d <span class="hljs-string">&quot;&#123;\&quot;query\&quot;: &#123;\&quot;match_all\&quot;: &#123;&#125; &#125;, \&quot;from\&quot; : 10, \&quot;size\&quot; : 10&#125;&#125;&quot;</span><br></code></pre></td></tr></table></figure><ul><li>检索某个index, 只返回context字段</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -XPOST IP:9200/索引名称/_search?pretty -d <span class="hljs-string">&quot;&#123;\&quot;query\&quot;: &#123;\&quot;match_all\&quot;: &#123;&#125; &#125;, \&quot;_source\&quot;: [\&quot;context\&quot;]&#125;&quot;</span><br></code></pre></td></tr></table></figure><ul><li>删除某个index</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -XDELETE <span class="hljs-string">&#x27;IP:9200/index_name&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="es搜索">ES搜索</h3><ol type="1"><li>如果有多个搜索关键字， Elastic 认为它们是or关系。</li><li>如果要执行多个关键词的and搜索，必须使用布尔查询。</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl <span class="hljs-string">&#x27;localhost:9200/索引名称/文档类型/_search&#x27;</span>  -d <span class="hljs-string">&#x27;</span><br><span class="hljs-string">&#123;</span><br><span class="hljs-string">  &quot;query&quot;: &#123;</span><br><span class="hljs-string">    &quot;bool&quot;: &#123;</span><br><span class="hljs-string">      &quot;must&quot;: [</span><br><span class="hljs-string">        &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;软件&quot; &#125; &#125;,</span><br><span class="hljs-string">        &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;系统&quot; &#125; &#125;</span><br><span class="hljs-string">      ]</span><br><span class="hljs-string">    &#125;</span><br><span class="hljs-string">  &#125;</span><br><span class="hljs-string">&#125;&#x27;</span><br></code></pre></td></tr></table></figure><ol start="3" type="1"><li>复杂搜索：</li></ol><p>SQL语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> test_index <span class="hljs-keyword">where</span> name<span class="hljs-operator">=</span><span class="hljs-string">&#x27;tom&#x27;</span> <span class="hljs-keyword">or</span> (hired <span class="hljs-operator">=</span><span class="hljs-literal">true</span> <span class="hljs-keyword">and</span> (personality <span class="hljs-operator">=</span><span class="hljs-string">&#x27;good&#x27;</span> <span class="hljs-keyword">and</span> rude <span class="hljs-operator">!=</span> <span class="hljs-literal">true</span> ))<br></code></pre></td></tr></table></figure><p>DSL语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">GET</span> <span class="hljs-operator">/</span>test_index<span class="hljs-operator">/</span>_search<br>&#123;<br>    &quot;query&quot;: &#123;<br>            &quot;bool&quot;: &#123;<br>                &quot;must&quot;: &#123; &quot;match&quot;:&#123; &quot;name&quot;: &quot;tom&quot; &#125;&#125;,<br>                &quot;should&quot;: [<br>                    &#123; &quot;match&quot;:&#123; &quot;hired&quot;: <span class="hljs-literal">true</span> &#125;&#125;,<br>                    &#123; &quot;bool&quot;: &#123;<br>                        &quot;must&quot;:&#123; &quot;match&quot;: &#123; &quot;personality&quot;: &quot;good&quot; &#125;&#125;,<br>                        &quot;must_not&quot;: &#123; &quot;match&quot;: &#123; &quot;rude&quot;: <span class="hljs-literal">true</span> &#125;&#125;<br>                    &#125;&#125;<br>                ],<br>                &quot;minimum_should_match&quot;: <span class="hljs-number">1</span><br>            &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="ik分词器">ik分词器</h3><p>ik分词器是Elasticsearch的中文分词器插件，对中文分词支持较好。ik版本要与Elasticsearch保持一致。</p><p>ik 7.17.0下载地址为：<ahref="https://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v7.17.0">https://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v7.17.0</a>，下载后将其重名为ik，将其放至Elasticsearch的plugins文件夹下。</p><p>ik分词器的使用命令（Kibana环境）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">POST _analyze<br>&#123;<br>  <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;戚发轫是哪里人&quot;</span>,<br>  <span class="hljs-string">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;ik_smart&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;tokens&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;token&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;戚&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;start_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;end_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CN_CHAR&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;position&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;token&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;发轫&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;start_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;end_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CN_WORD&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;position&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;token&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;是&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;start_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;end_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CN_CHAR&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;position&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;token&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;哪里人&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;start_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;end_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">7</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CN_WORD&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;position&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>ik支持加载用户词典和停用词。ik 提供了配置文件IKAnalyzer.cfg.xml（将其放在ik/config路径下），可以用来配置自己的扩展用户词典、停用词词典和远程扩展用户词典，都可以配置多个。</p><p>配置完扩展用户词典和远程扩展用户词典都需要重启ES，后续对用户词典进行更新的话，需要重启ES，远程扩展用户词典配置完后支持热更新，每60秒检查更新。两个扩展词典都是添加到ik的主词典中，对所有索引生效。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span> encoding=<span class="hljs-string">&quot;UTF-8&quot;</span>?&gt;</span><br><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-keyword">properties</span> <span class="hljs-keyword">SYSTEM</span> <span class="hljs-string">&quot;http://java.sun.com/dtd/properties.dtd&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">properties</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">comment</span>&gt;</span>IK Analyzer 扩展配置<span class="hljs-tag">&lt;/<span class="hljs-name">comment</span>&gt;</span><br><span class="hljs-comment">&lt;!--用户可以在这里配置自己的扩展字典 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">entry</span> <span class="hljs-attr">key</span>=<span class="hljs-string">&quot;ext_dict&quot;</span>&gt;</span>custom/mydict.dic<span class="hljs-tag">&lt;/<span class="hljs-name">entry</span>&gt;</span><br> <span class="hljs-comment">&lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">entry</span> <span class="hljs-attr">key</span>=<span class="hljs-string">&quot;ext_stopwords&quot;</span>&gt;</span>custom/ext_stopword.dic<span class="hljs-tag">&lt;/<span class="hljs-name">entry</span>&gt;</span><br><span class="hljs-comment">&lt;!--用户可以在这里配置远程扩展字典 --&gt;</span><br><span class="hljs-comment">&lt;!-- &lt;entry key=&quot;remote_ext_dict&quot;&gt;words_location&lt;/entry&gt; --&gt;</span><br><span class="hljs-comment">&lt;!--用户可以在这里配置远程扩展停止词字典--&gt;</span><br><span class="hljs-comment">&lt;!-- &lt;entry key=&quot;remote_ext_stopwords&quot;&gt;words_location&lt;/entry&gt; --&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">properties</span>&gt;</span><br></code></pre></td></tr></table></figure><p>用户词典文件路径为：custom/mydict.dic，停用词词典路径为：custom/ext_stopword.dic，将它们放在ik/config/custom路径下。</p><p>用户词典文件中加入'戚发轫'，停用词词典加入'是'，对原来文本进行分词：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">POST _analyze<br>&#123;<br>  <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;戚发轫是哪里人&quot;</span>,<br>  <span class="hljs-string">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;ik_smart&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;tokens&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;token&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;戚发轫&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;start_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;end_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CN_WORD&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;position&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;token&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;哪里人&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;start_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;end_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">7</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CN_WORD&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;position&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>如果'analyzer'选择ik_smart，则会将文本做最粗粒度的拆分；选择ik_max_word，则会将文本做最细粒度的拆分。测试如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">POST _analyze<br>&#123;<br>  <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;戚发轫是哪里人&quot;</span>,<br>  <span class="hljs-string">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;ik_max_word&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;tokens&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;token&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;戚发轫&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;start_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;end_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CN_WORD&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;position&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;token&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;发轫&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;start_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;end_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CN_WORD&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;position&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;token&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;哪里人&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;start_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;end_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">7</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CN_WORD&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;position&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;token&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;哪里&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;start_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;end_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">6</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CN_WORD&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;position&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;token&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;里人&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;start_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">5</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;end_offset&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">7</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CN_WORD&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;position&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本文主要介绍了Elasticsearch一些基础命令和用法，是笔者的Elasticsearch学习笔记第一篇，后续将持续更新。</p><p>本文代码已放至Github，网址为：<ahref="https://github.com/percent4/ES_Learning">https://github.com/percent4/ES_Learning</a>.</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Elasticsearch</tag>
      
      <tag>Kibana</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Elasticsearch简介与实战</title>
    <link href="/Elasticsearch%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    <url>/Elasticsearch%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%9E%E6%88%98/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="什么是elasticsearch">什么是Elasticsearch?</h3><p><img src="/img/es1_1.png" /></p><p>Elasticsearch是一个开源的分布式、RESTful风格的搜索和数据分析引擎，它的底层是开源库Apache Lucene。</p><p>Lucene可以说是当下最先进、高性能、全功能的搜索引擎库——无论是开源还是私有，但它也仅仅只是一个库。为了充分发挥其功能，你需要使用Java 并将 Lucene 直接集成到应用程序中。更糟糕的是，您可能需要获得信息检索学位才能了解其工作原理，因为Lucene非常复杂。</p><p>为了解决Lucene使用时的繁复性，于是Elasticsearch便应运而生。它使用Java 编写，内部采用 Lucene做索引与搜索，但是它的目标是使全文检索变得更简单，简单来说，就是对Lucene做了一层封装，它提供了一套简单一致的 RESTful API来帮助我们实现存储和检索。</p><p>当然，Elasticsearch 不仅仅是Lucene，并且也不仅仅只是一个全文搜索引擎。它可以被下面这样准确地形容：</p><ul><li>一个分布式的实时文档存储，每个字段可以被索引与搜索；</li><li>一个分布式实时分析搜索引擎；</li><li>能胜任上百个服务节点的扩展，并支持 PB级别的结构化或者非结构化数据。</li></ul><p>由于Elasticsearch的功能强大和使用简单，维基百科、卫报、StackOverflow、GitHub等都纷纷采用它来做搜索。现在，Elasticsearch已成为全文搜索领域的主流软件之一。</p><p>下面将介绍Elasticsearch的安装与简单使用。</p><h3 id="安装并运行elasticsearch">安装并运行Elasticsearch</h3><p>安装 Elasticsearch 之前，你需要先安装一个较新版本的Java，最好的选择是，你可以从 <ahref="http://www.java.com/"><em>www.java.com</em></a>获得官方提供的最新版本的Java。</p><p>你可以从 elastic 的官网 <ahref="https://www.elastic.co/downloads/elasticsearch">elastic.co/downloads/elasticsearch</a>获取最新版本的Elasticsearch。解压文档后，按照下面的操作，即可在前台(foregroud)启动Elasticsearch：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> elasticsearch-&lt;version&gt;<br>./bin/elasticsearch<br></code></pre></td></tr></table></figure><p>此时，Elasticsearch运行在本地的9200端口，在浏览器中输入网址“http://localhost:9200/”，如果看到以下信息就说明你的电脑已成功安装Elasticsearch：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;name&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;YTK8L4q&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;cluster_name&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;elasticsearch&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;cluster_uuid&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;hB2CZPlvSJavhJxx85fUqQ&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;version&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;number&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;6.5.4&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;build_flavor&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;default&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;build_type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;tar&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;build_hash&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;d2ef93d&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;build_date&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2018-12-17T21:17:40.758843Z&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;build_snapshot&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lucene_version&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;7.5.0&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;minimum_wire_compatibility_version&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;5.6.0&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;minimum_index_compatibility_version&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;5.0.0&quot;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;tagline&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;You Know, for Search&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>在这里，我们安装的Elasticsearch版本号为6.5.4。</p><p>Kibana 是一个开源的分析和可视化平台，旨在与 Elasticsearch合作。Kibana 提供搜索、查看和与存储在 Elasticsearch索引中的数据进行交互的功能。开发者或运维人员可以轻松地执行高级数据分析，并在各种图表、表格和地图中可视化数据。</p><p>你可以从 elastic 的官网 <ahref="https://www.elastic.co/downloads/kibana">https://www.elastic.co/downloads/kibana</a>获取最新版本的Kibana。解压文档后，按照下面的操作，即可在前台(foregroud)启动Kibana：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> kibana-&lt;version&gt;<br>./bin/kabana<br></code></pre></td></tr></table></figure><p>此时，Kibana运行在本地的5601端口，在浏览器中输入网址“http://localhost:5601”，即可看到以下界面：</p><figure><img src="/img/es1_2.png" alt="Kibana启动界面" /><figcaption aria-hidden="true">Kibana启动界面</figcaption></figure><p>下面，让我们来了解Elasticsearch的一些基本概念，这有助于我们更好地理解和使用Elasticsearch。</p><h3 id="elasticsearch基本概念">Elasticsearch基本概念</h3><h4 id="全文搜索full-text-search">全文搜索(Full-text Search)</h4><p>全文检索是指计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。</p><p>在全文搜索的世界中，存在着几个庞大的帝国，也就是主流工具，主要有：</p><ul><li>Apache Lucene</li><li>Elasticsearch</li><li>Solr</li><li>Ferret</li></ul><h4 id="倒排索引inverted-index">倒排索引（Inverted Index）</h4><p>该索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(invertedindex)。Elasticsearch能够实现快速、高效的搜索功能，正是基于倒排索引原理。</p><h4 id="节点-集群node-cluster">节点 &amp; 集群（Node &amp;Cluster）</h4><p>Elasticsearch本质上是一个分布式数据库，允许多台服务器协同工作，每台服务器可以运行多个Elasticsearch实例。单个Elasticsearch实例称为一个节点（Node），一组节点构成一个集群（Cluster）。</p><h4 id="索引index">索引（Index）</h4><p>Elasticsearch 数据管理的顶层单位就叫做Index（索引），相当于关系型数据库里的数据库的概念。另外，每个Index的名字必须是小写。</p><h4 id="文档document">文档（Document）</h4><p>Index里面单条的记录称为 Document（文档）。许多条 Document 构成了一个Index。Document 使用 JSON 格式表示。同一个 Index 里面的Document，不要求有相同的结构（scheme），但是最好保持相同，这样有利于提高搜索效率。</p><h4 id="类型type">类型（Type）</h4><p>Document 可以分组，比如employee这个 Index里面，可以按部门分组，也可以按职级分组。这种分组就叫做Type，它是虚拟的逻辑分组，用来过滤Document，类似关系型数据库中的数据表。</p><p>不同的 Type 应该有相似的结构（Schema），性质完全不同的数据（比如products 和 logs）应该存成两个 Index，而不是一个 Index 里面的两个Type（虽然可以做到）。</p><h3 id="文档元数据document-metadata">文档元数据（Documentmetadata）</h3><p>文档元数据为_index, _type, _id,这三者可以唯一表示一个文档，_index表示文档在哪存放，_type表示文档的对象类别，_id为文档的唯一标识。</p><h4 id="字段fields">字段（Fields）</h4><p>每个Document都类似一个JSON结构，它包含了许多字段，每个字段都有其对应的值，多个字段组成了一个Document，可以类比关系型数据库数据表中的字段。</p><p>在 Elasticsearch中，文档（Document）归属于一种类型（Type），而这些类型存在于索引（Index）中，下图展示了Elasticsearch与传统关系型数据库的类比：</p><p><img src="/img/es1_3.png" /></p><h3 id="elasticsearch入门">Elasticsearch入门</h3><p>Elasticsearch提供了多种交互使用方式，包括Java API和RESTful API，本文主要介绍RESTful API 。所有其他语言可以使用RESTful API 通过端口<em>9200</em> 和 Elasticsearch 进行通信，你可以用你最喜爱的 web客户端访问 Elasticsearch 。甚至，你还可以使用 <code>curl</code> 命令来和Elasticsearch 交互。</p><p>一个Elasticsearch请求和任何 HTTP请求一样，都由若干相同的部件组成：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -X&lt;VERB&gt; <span class="hljs-string">&#x27;&lt;PROTOCOL&gt;://&lt;HOST&gt;:&lt;PORT&gt;/&lt;PATH&gt;?&lt;QUERY_STRING&gt;&#x27;</span> -d <span class="hljs-string">&#x27;&lt;BODY&gt;&#x27;</span><br></code></pre></td></tr></table></figure><p>返回的数据格式为JSON，因为Elasticsearch中的文档以JSON格式储存。其中，被<code>&lt; &gt;</code> 标记的部件：</p><table><thead><tr class="header"><th>部件</th><th>说明</th></tr></thead><tbody><tr class="odd"><td>VERB</td><td>适当的 HTTP <em>方法</em> 或 <em>谓词</em> : <code>GET</code>、<code>POST</code>、 <code>PUT</code>、 <code>HEAD</code> 或者<code>DELETE</code>。</td></tr><tr class="even"><td>PROTOCOL</td><td><code>http</code> 或者 <code>https</code>（如果你在 Elasticsearch前面有一个 <code>https</code> 代理）</td></tr><tr class="odd"><td>HOST</td><td>Elasticsearch 集群中任意节点的主机名，或者用 <code>localhost</code>代表本地机器上的节点。</td></tr><tr class="even"><td>PORT</td><td>运行 Elasticsearch HTTP 服务的端口号，默认是 <code>9200</code>。</td></tr><tr class="odd"><td>PATH</td><td>API 的终端路径（例如 <code>_count</code>将返回集群中文档数量）。Path可能包含多个组件，例如：<code>_cluster/stats</code> 和<code>_nodes/stats/jvm</code> 。</td></tr><tr class="even"><td>QUERY_STRING</td><td>任意可选的查询字符串参数 (例如 <code>?pretty</code> 将格式化地输出JSON 返回值，使其更容易阅读)</td></tr><tr class="odd"><td>BODY</td><td>一个 JSON 格式的请求体 (如果请求需要的话)</td></tr></tbody></table><p>对于HTTP方法，它们的具体作用为：</p><table><thead><tr class="header"><th>HTTP方法</th><th>说明</th></tr></thead><tbody><tr class="odd"><td>GET</td><td>获取请求对象的当前状态</td></tr><tr class="even"><td>POST</td><td>改变对象的当前状态</td></tr><tr class="odd"><td>PUT</td><td>创建一个对象</td></tr><tr class="even"><td>DELETE</td><td>销毁对象</td></tr><tr class="odd"><td>HEAD</td><td>请求获取对象的基础信息</td></tr></tbody></table><p>我们以下面的数据为例，来展示Elasticsearch的用法。</p><p><img src="/img/es1_4.png" /></p><p>以下全部的操作都在Kibana中完成，创建的index为conference, type为event.</p><h5 id="插入数据">插入数据</h5><p>首先创建index为conference, 创建type为event,插入id为1的第一条数据，只需运行下面命令就行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">PUT /conference/event/1<br>&#123;<br>  <span class="hljs-string">&quot;host&quot;</span>: <span class="hljs-string">&quot;Dave&quot;</span>,<br>  <span class="hljs-string">&quot;title&quot;</span>: <span class="hljs-string">&quot;Elasticsearch at Rangespan and Exonar&quot;</span>,<br>  <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;Representatives from Rangespan and Exonar will come and discuss how they use Elasticsearch&quot;</span>,<br>  <span class="hljs-string">&quot;attendees&quot;</span>: [<span class="hljs-string">&quot;Dave&quot;</span>, <span class="hljs-string">&quot;Andrew&quot;</span>, <span class="hljs-string">&quot;David&quot;</span>, <span class="hljs-string">&quot;Clint&quot;</span>],<br>  <span class="hljs-string">&quot;date&quot;</span>: <span class="hljs-string">&quot;2013-06-24T18:30&quot;</span>,<br>  <span class="hljs-string">&quot;reviews&quot;</span>: 3<br>&#125;<br></code></pre></td></tr></table></figure><p>在上面的命令中，路径/conference/event/1表示文档的index为conference,type为event, id为1.类似于上面的操作，依次插入剩余的4条数据，完成插入后，查看数据如下：</p><figure><img src="/img/es1_5.png" alt="插入数据" /><figcaption aria-hidden="true">插入数据</figcaption></figure><h5 id="删除数据">删除数据</h5><p>比如我们想要删除conference中event里面id为5的数据，只需运行下面命令即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">DELETE /conference/event/5<br></code></pre></td></tr></table></figure><p>返回结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;_index&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;conference&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;event&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_id&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;5&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_version&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;result&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;deleted&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_shards&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;total&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;successful&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;failed&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_seq_no&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_primary_term&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>表示该文档已成功删除。如果想删除整个event类型，可输入命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">DELETE /conference/event<br></code></pre></td></tr></table></figure><p>如果想删除整个conference索引，可输入命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">DELETE /conference<br></code></pre></td></tr></table></figure><h5 id="修改数据">修改数据</h5><p>修改数据的命令为POST,比如我们想要将conference中event里面id为4的文档的作者改为Bob，那么需要运行命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">POST /conference/event/4/_update<br>&#123;<br>  <span class="hljs-string">&quot;doc&quot;</span>: &#123;<span class="hljs-string">&quot;host&quot;</span>: <span class="hljs-string">&quot;Bob&quot;</span>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>返回的信息如下：（表示修改数据成功）</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;_index&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;conference&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;event&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_id&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;4&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_version&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">7</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;result&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;updated&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_shards&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;total&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;successful&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;failed&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_seq_no&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">7</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_primary_term&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>查看修改后的数据如下：</p><figure><img src="/img/es1_6.png" alt="修改数据" /><figcaption aria-hidden="true">修改数据</figcaption></figure><h5 id="查询数据">查询数据</h5><p>查询数据的命令为GET，查询命令也是Elasticsearch最为重要的功能之一。比如我们想查询conference中event里面id为1的数据，运行命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">GET /conference/event/1<br></code></pre></td></tr></table></figure><p>返回的结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;_index&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;conference&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;event&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_id&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;1&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_version&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;found&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_source&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;host&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Dave&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;title&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Elasticsearch at Rangespan and Exonar&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;description&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Representatives from Rangespan and Exonar will come and discuss how they use Elasticsearch&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;attendees&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-string">&quot;Dave&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;Andrew&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;David&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;Clint&quot;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;date&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2013-06-24T18:30&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;reviews&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>在_source 属性中，内容是原始的 JSON文档，还包含有其它属性，比如_index, _type, _id, _found等。</p><p>如果想要搜索conference中event里面所有的文档，运行命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">GET /conference/event/_search<br></code></pre></td></tr></table></figure><p>返回结果包括了所有四个文档，放在数组 hits 中。</p><p>当然，Elasticsearch 提供更加丰富灵活的查询语言叫做<em>查询表达式</em> ，它支持构建更加复杂和健壮的查询。利用<em>查询表达式</em>，我们可以检索出conference中event里面所有host为Bob的文档，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">GET /conference/event/_search<br>&#123;<br>    <span class="hljs-string">&quot;query&quot;</span> : &#123;<br>        <span class="hljs-string">&quot;match&quot;</span> : &#123;<br>            <span class="hljs-string">&quot;host&quot;</span> : <span class="hljs-string">&quot;Bob&quot;</span><br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>返回的结果只包括了一个文档，放在数组 hits 中。</p><p>接着，让我们尝试稍微高级点儿的全文搜索——一项传统数据库确实很难搞定的任务。搜索下所有description中含有"useElasticsearch"的event：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">GET /conference/event/_search<br>&#123;<br>    <span class="hljs-string">&quot;query&quot;</span> : &#123;<br>        <span class="hljs-string">&quot;match&quot;</span> : &#123;<br>            <span class="hljs-string">&quot;description&quot;</span> : <span class="hljs-string">&quot;use Elasticsearch&quot;</span><br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>返回的结果（部分）如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br> ...<br>  <span class="hljs-attr">&quot;hits&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;total&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;max_score&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">0.65109104</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;hits&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-punctuation">&#123;</span><br>        ...<br>        <span class="hljs-attr">&quot;_score&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">0.65109104</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_source&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;host&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Dave Nolan&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;title&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;real-time Elasticsearch&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;description&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;We will discuss using Elasticsearch to index data in real time&quot;</span><span class="hljs-punctuation">,</span><br>          ...<br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-punctuation">&#123;</span><br>        ...<br>        <span class="hljs-attr">&quot;_score&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">0.5753642</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;_source&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;host&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Dave&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;title&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Elasticsearch at Rangespan and Exonar&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;description&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Representatives from Rangespan and Exonar will come and discuss how they use Elasticsearch&quot;</span><span class="hljs-punctuation">,</span><br>          ...<br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br><br></code></pre></td></tr></table></figure><p>返回的结果包含了两个文档，放在数组 hits中。让我们对这个结果做一些分析，第一个文档的description里面含有“usingElasticsearch”，这个能匹配“useElasticsearch”是因为Elasticsearch含有内置的词干提取算法，之后两个文档按_score进行排序，_score字段表示文档的相似度（默认的相似度算法为BM25）。</p><p>如果想搜索下所有description中严格含有"useElasticsearch"这个短语的event，可以使用下面的命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">GET /conference/event/_search<br>&#123;<br>    <span class="hljs-string">&quot;query&quot;</span> : &#123;<br>        <span class="hljs-string">&quot;match_phrase&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;description&quot;</span> : <span class="hljs-string">&quot;use Elasticsearch&quot;</span><br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这时候返回的结果只有一个文档，就是上面输出的第二个文档。</p><p>当然，Elasticsearch还支持更多的搜索功能，比如过滤器，高亮搜索，结构化搜索等，希望接下来能有更多的时间和经历来介绍~</p><h3 id="总结">总结</h3><p>后续有机会再介绍如何利用Python来操作Elasticsearch~</p><p>本次分享到此结束，感谢大家阅读~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Elasticsearch</tag>
      
      <tag>Kibana</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（六十二）HuggingFace中的Datasets使用</title>
    <link href="/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%BA%8C%EF%BC%89HuggingFace%E4%B8%AD%E7%9A%84Datasets%E4%BD%BF%E7%94%A8/"/>
    <url>/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%BA%8C%EF%BC%89HuggingFace%E4%B8%AD%E7%9A%84Datasets%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><code>Datasets</code>库是<code>HuggingFace</code>生态系统中一个重要的数据集库，可用于轻松地访问和共享数据集，这些数据集是关于音频、计算机视觉、以及自然语言处理等领域。<code>Datasets</code>库可以通过一行来加载一个数据集，并且可以使用 <code>Hugging Face</code>强大的数据处理方法来快速准备好你的数据集。在 <code>Apache Arrow</code>格式的支持下，通过 <code>zero-copy read</code>来处理大型数据集，而没有任何内存限制，从而实现最佳速度和效率。</p><p>当需要微调模型的时候，需要对数据集进行以下操作：</p><ol type="1"><li>数据集加载：下载、加载数据集</li><li>数据集预处理：使用Dataset.map() 预处理数据</li><li>数据集评估指标：加载和计算指标</li></ol><p>可以在HuggingFace官网来搜共享索数据集：<ahref="https://huggingface.co/datasets"class="uri">https://huggingface.co/datasets</a>。本文中使用的主要数据集为<code>squad</code>数据集，其在HuggingFace网站上的数据前几行如下：</p><figure><img src="/img/nlp62_1.png" alt="squad数据集前几行" /><figcaption aria-hidden="true">squad数据集前几行</figcaption></figure><h3 id="加载数据">加载数据</h3><ul><li>加载Dataset数据集</li></ul><p>Dataset数据集可以是HuggingFaceDatasets网站上的数据集或者是本地路径对应的数据集，也可以同时加载多个数据集。</p><p>以下是加载英语阅读理解数据集<code>squad</code>， 该数据集的网址为：<ahref="https://huggingface.co/datasets/squad"class="uri">https://huggingface.co/datasets/squad</a>，也是本文中使用的主要数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> datasets<br><br><span class="hljs-comment"># 加载单个数据集</span><br>raw_datasets = datasets.load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br><span class="hljs-comment"># 加载多个数据集</span><br>raw_datasets = datasets.load_dataset(<span class="hljs-string">&#x27;glue&#x27;</span>, <span class="hljs-string">&#x27;mrpc&#x27;</span>)<br></code></pre></td></tr></table></figure><ul><li>从文件中加载数据</li></ul><p>支持csv, tsv, txt, json, jsonl等格式的文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>data_files = &#123;<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;./data/sougou_mini/train.csv&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;./data/sougou_mini/test.csv&quot;</span>&#125;<br>drug_dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="hljs-string">&quot;,&quot;</span>)<br></code></pre></td></tr></table></figure><ul><li>从Dataframe中加载数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset <br><br>my_dict = &#123;<span class="hljs-string">&quot;a&quot;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], <span class="hljs-string">&quot;b&quot;</span>: [<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>]&#125; <br>dataset1 = Dataset.from_dict(my_dict) <br> <br>df = pd.DataFrame(my_dict) <br>dataset2 = Dataset.from_pandas(df)<br></code></pre></td></tr></table></figure><h3 id="查看数据">查看数据</h3><ul><li>数据结构</li></ul><p>数据结构包括：</p><ol type="1"><li>数据集的划分：train，valid，test数据集</li><li>数据集的数量</li><li>数据集的feature</li></ol><p><code>squad</code>数据的数据结构如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs json">DatasetDict(<span class="hljs-punctuation">&#123;</span><br>    train<span class="hljs-punctuation">:</span> Dataset(<span class="hljs-punctuation">&#123;</span><br>        features<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>&#x27;id&#x27;<span class="hljs-punctuation">,</span> &#x27;title&#x27;<span class="hljs-punctuation">,</span> &#x27;context&#x27;<span class="hljs-punctuation">,</span> &#x27;question&#x27;<span class="hljs-punctuation">,</span> &#x27;answers&#x27;<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        num_rows<span class="hljs-punctuation">:</span> <span class="hljs-number">87599</span><br>    <span class="hljs-punctuation">&#125;</span>)<br>    validation<span class="hljs-punctuation">:</span> Dataset(<span class="hljs-punctuation">&#123;</span><br>        features<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>&#x27;id&#x27;<span class="hljs-punctuation">,</span> &#x27;title&#x27;<span class="hljs-punctuation">,</span> &#x27;context&#x27;<span class="hljs-punctuation">,</span> &#x27;question&#x27;<span class="hljs-punctuation">,</span> &#x27;answers&#x27;<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        num_rows<span class="hljs-punctuation">:</span> <span class="hljs-number">10570</span><br>    <span class="hljs-punctuation">&#125;</span>)<br><span class="hljs-punctuation">&#125;</span>)<br></code></pre></td></tr></table></figure><ul><li>数据切分</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> datasets<br><br>raw_dataset = datasets.load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br><br><span class="hljs-comment"># 获取某个划分数据集，比如train</span><br>train_dataset = raw_dataset[<span class="hljs-string">&#x27;train&#x27;</span>]<br><span class="hljs-comment"># 获取前10条数据</span><br>head_dataset = train_dataset.select(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))<br><span class="hljs-comment"># 获取随机10条数据</span><br>shuffle_dataset = train_dataset.shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))<br><span class="hljs-comment"># 数据切片</span><br>slice_dataset = train_dataset[<span class="hljs-number">10</span>:<span class="hljs-number">20</span>]<br></code></pre></td></tr></table></figure><h3 id="更多特性">更多特性</h3><ul><li>数据打乱（shuffle）</li></ul><p>shuffle的功能是打乱datasets中的数据，其中seed是设置打乱的参数，如果设置打乱的seed是相同的，那我们就可以得到一个完全相同的打乱结果，这样用相同的打乱结果才能重复的进行模型试验。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> datasets<br><br>raw_dataset = datasets.load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br><span class="hljs-comment"># 打乱数据集</span><br>shuffle_dataset = train_dataset.shuffle(seed=<span class="hljs-number">42</span>)<br></code></pre></td></tr></table></figure><ul><li>数据流（stream）</li></ul><p>stream的功能是将数据集进行流式化，可以不用在下载整个数据集的情况下使用该数据集。这在以下场景中特别有用：</p><ol type="1"><li>你不想等待整个庞大的数据集下载完毕</li><li>数据集大小超过了你计算机的可用硬盘空间</li><li>你想快速探索数据集的少数样本</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>dataset = load_dataset(<span class="hljs-string">&#x27;oscar-corpus/OSCAR-2201&#x27;</span>, <span class="hljs-string">&#x27;en&#x27;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(dataset)))<br></code></pre></td></tr></table></figure><ul><li>数据列重命名（rename columns）</li></ul><p>数据集支持对列重命名。下面的代码将<code>squad</code>数据集中的context列重命名为text：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br>squad = squad.rename_column(<span class="hljs-string">&#x27;context&#x27;</span>, <span class="hljs-string">&#x27;text&#x27;</span>)<br></code></pre></td></tr></table></figure><ul><li>数据丢弃列（drop columns）</li></ul><p>数据集支持对列进行丢弃，在删除一个或多个列时，向<code>remove_columns()</code>函数提供要删除的列名。单个列删除传入列名，多个列删除传入列名的列表。下面的代码将<code>squad</code>数据集中的id列丢弃：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br><span class="hljs-comment"># 删除一个列</span><br>squad = squad.remove_columns(<span class="hljs-string">&#x27;id&#x27;</span>)<br><span class="hljs-comment"># 删除多个列</span><br>squad = squad.remove_columns([<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;text&#x27;</span>])<br></code></pre></td></tr></table></figure><ul><li>数据新增列（add new columns）</li></ul><p>数据集支持新增列。下面的代码在<code>squad</code>数据集上新增一列test，内容全为字符串111：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br><span class="hljs-comment"># 新增列</span><br>new_train_squad = squad[<span class="hljs-string">&#x27;train&#x27;</span>].add_column(<span class="hljs-string">&quot;test&quot;</span>, [<span class="hljs-string">&#x27;111&#x27;</span>] * squad[<span class="hljs-string">&#x27;train&#x27;</span>].num_rows)<br></code></pre></td></tr></table></figure><ul><li>数据类型转换（cast）</li></ul><p><code>cast()</code>函数对一个或多个列的特征类型进行转换。这个函数接受你的新特征作为其参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br><span class="hljs-comment"># 新增列</span><br>new_train_squad = squad[<span class="hljs-string">&#x27;train&#x27;</span>].add_column(<span class="hljs-string">&quot;test&quot;</span>, [<span class="hljs-string">&#x27;111&#x27;</span>] * squad[<span class="hljs-string">&#x27;train&#x27;</span>].num_rows)<br><span class="hljs-built_in">print</span>(new_train_squad.features)<br><span class="hljs-comment"># 转换test列的数据类型</span><br>new_features = new_train_squad.features.copy()<br>new_features[<span class="hljs-string">&quot;test&quot;</span>] = Value(<span class="hljs-string">&quot;int64&quot;</span>)<br>new_train_squad = new_train_squad.cast(new_features)<br><span class="hljs-comment"># 输出转换后的数据类型</span><br><span class="hljs-built_in">print</span>(new_train_squad.features)<br></code></pre></td></tr></table></figure><ul><li>数据展平（flatten）</li></ul><p>针对嵌套结构的数据类型，可使用<code>flatten()</code>函数将子字段提取到它们自己的独立列中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br>flatten_dataset = squad[<span class="hljs-string">&#x27;train&#x27;</span>].flatten()<br><span class="hljs-built_in">print</span>(flatten_dataset)<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">Dataset(&#123;<br>    features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;context&#x27;</span>, <span class="hljs-string">&#x27;question&#x27;</span>, <span class="hljs-string">&#x27;answers.text&#x27;</span>, <span class="hljs-string">&#x27;answers.answer_start&#x27;</span>],<br>    num_rows: 87599<br>&#125;)<br></code></pre></td></tr></table></figure><ul><li>数据合并（Concatenate Multiple Datasets）</li></ul><p>如果独立的数据集有相同的列类型，那么它们可以被串联起来。用<code>concatenate_datasets()</code>来连接不同的数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> concatenate_datasets, load_dataset<br><br>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br>squad_v2 = load_dataset(<span class="hljs-string">&#x27;squad_v2&#x27;</span>)<br><span class="hljs-comment"># 合并数据集</span><br>squad_all = concatenate_datasets([squad[<span class="hljs-string">&#x27;train&#x27;</span>], squad_v2[<span class="hljs-string">&#x27;train&#x27;</span>]])<br></code></pre></td></tr></table></figure><ul><li>数据过滤（filter）</li></ul><p><code>filter()</code>函数支持对数据集进行过滤，一般采用lambda函数实现。下面的代码对<code>squad</code>数据集中的训练集的question字段，过滤掉split后长度小于等于10的数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br>filter_dataset = squad[<span class="hljs-string">&#x27;train&#x27;</span>].<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x[<span class="hljs-string">&quot;question&quot;</span>].split()) &gt; <span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">Dataset(&#123;<br>    features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;context&#x27;</span>, <span class="hljs-string">&#x27;question&#x27;</span>, <span class="hljs-string">&#x27;answers&#x27;</span>],<br>    num_rows: 34261<br>&#125;)<br></code></pre></td></tr></table></figure><ul><li>数据排序（sort）</li></ul><p>使用<code>sort()</code>对列值根据其数值进行排序。下面的代码是对<code>squad</code>数据集中的训练集按照标题长度进行排序：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br><span class="hljs-comment"># 新增列, title_length, 标题长度</span><br>new_train_squad = squad[<span class="hljs-string">&#x27;train&#x27;</span>].add_column(<span class="hljs-string">&quot;title_length&quot;</span>, [<span class="hljs-built_in">len</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> squad[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-string">&#x27;title&#x27;</span>]])<br><span class="hljs-comment"># 按照title_length排序</span><br>new_train_squad = new_train_squad.sort(<span class="hljs-string">&quot;title_length&quot;</span>)<br></code></pre></td></tr></table></figure><ul><li>数据格式（set_format）</li></ul><p><code>set_format()</code>函数改变了一个列的格式，使之与一些常见的数据格式兼容。在类型参数中指定你想要的输出和你想要格式化的列。格式化是即时应用的。支持的数据格式有：None,numpy, torch, tensorflow, pandas, arrow,如果选择None，就会返回python对象。</p><p>下面的代码将新增标题长度列，并将其转化为numpy格式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br><span class="hljs-comment"># 新增列, title_length, 标题长度</span><br>new_train_squad = squad[<span class="hljs-string">&#x27;train&#x27;</span>].add_column(<span class="hljs-string">&quot;title_length&quot;</span>, [<span class="hljs-built_in">len</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> squad[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-string">&#x27;title&#x27;</span>]])<br><span class="hljs-comment"># 转换为numpy支持的数据格式</span><br>new_train_squad.set_format(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;numpy&quot;</span>, columns=[<span class="hljs-string">&quot;title_length&quot;</span>])<br></code></pre></td></tr></table></figure><ul><li>数据指标（load metrics）</li></ul><p><a href="https://huggingface.co/metrics">HuggingFaceHub</a>上提供了一系列的评估指标（metrics），前20个指标如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> list_metrics<br>metrics_list = list_metrics()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;, &#x27;</span>.join(metric <span class="hljs-keyword">for</span> metric <span class="hljs-keyword">in</span> metrics_list[:<span class="hljs-number">20</span>]))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">accuracy, bertscore, bleu, bleurt, brier_score, cer, character, charcut_mt, chrf, code_eval, comet, competition_math, coval, cuad, exact_match, f1, frugalscore, glue, google_bleu, indic_glue<br></code></pre></td></tr></table></figure><p>从Hub中加载一个指标，使用 <ahref="https://huggingface.co/docs/datasets/v1.0.1/package_reference/loading_methods.html#datasets.load_metric"title="datasets.load_metric"><code>datasets.load_metric()</code></a>命令，比如加载<code>squad</code>数据集的指标：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric<br>metric = load_metric(<span class="hljs-string">&#x27;squad&#x27;</span>)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs bash">Metric(name: <span class="hljs-string">&quot;squad&quot;</span>, features: &#123;<span class="hljs-string">&#x27;predictions&#x27;</span>: &#123;<span class="hljs-string">&#x27;id&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=None), <span class="hljs-string">&#x27;prediction_text&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=None)&#125;, <span class="hljs-string">&#x27;references&#x27;</span>: &#123;<span class="hljs-string">&#x27;id&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=None), <span class="hljs-string">&#x27;answers&#x27;</span>: Sequence(feature=&#123;<span class="hljs-string">&#x27;text&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=None), <span class="hljs-string">&#x27;answer_start&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;int32&#x27;</span>, <span class="hljs-built_in">id</span>=None)&#125;, length=-1, <span class="hljs-built_in">id</span>=None)&#125;&#125;, usage: <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;</span><br><span class="hljs-string">Computes SQuAD scores (F1 and EM).</span><br><span class="hljs-string">Args:</span><br><span class="hljs-string">    predictions: List of question-answers dictionaries with the following key-values:</span><br><span class="hljs-string">        - &#x27;id&#x27;: id of the question-answer pair as given in the references (see below)</span><br><span class="hljs-string">        - &#x27;prediction_text&#x27;: the text of the answer</span><br><span class="hljs-string">    references: List of question-answers dictionaries with the following key-values:</span><br><span class="hljs-string">        - &#x27;id&#x27;: id of the question-answer pair (see above),</span><br><span class="hljs-string">        - &#x27;answers&#x27;: a Dict in the SQuAD dataset format</span><br><span class="hljs-string">            &#123;</span><br><span class="hljs-string">                &#x27;text&#x27;: list of possible texts for the answer, as a list of strings</span><br><span class="hljs-string">                &#x27;answer_start&#x27;: list of start positions for the answer, as a list of ints</span><br><span class="hljs-string">            &#125;</span><br><span class="hljs-string">            Note that answer_start values are not taken into account to compute the metric.</span><br><span class="hljs-string">Returns:</span><br><span class="hljs-string">    &#x27;exact_match&#x27;: Exact match (the normalized answer exactly match the gold answer)</span><br><span class="hljs-string">    &#x27;f1&#x27;: The F-score of predicted tokens versus the gold answer</span><br><span class="hljs-string">Examples:</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &gt;&gt;&gt; predictions = [&#123;&#x27;prediction_text&#x27;: &#x27;1976&#x27;, &#x27;id&#x27;: &#x27;56e10a3be3433e1400422b22&#x27;&#125;]</span><br><span class="hljs-string">    &gt;&gt;&gt; references = [&#123;&#x27;answers&#x27;: &#123;&#x27;answer_start&#x27;: [97], &#x27;text&#x27;: [&#x27;1976&#x27;]&#125;, &#x27;id&#x27;: &#x27;56e10a3be3433e1400422b22&#x27;&#125;]</span><br><span class="hljs-string">    &gt;&gt;&gt; squad_metric = datasets.load_metric(&quot;</span>squad<span class="hljs-string">&quot;)</span><br><span class="hljs-string">    &gt;&gt;&gt; results = squad_metric.compute(predictions=predictions, references=references)</span><br><span class="hljs-string">    &gt;&gt;&gt; print(results)</span><br><span class="hljs-string">    &#123;&#x27;exact_match&#x27;: 100.0, &#x27;f1&#x27;: 100.0&#125;</span><br><span class="hljs-string">&quot;</span><span class="hljs-string">&quot;&quot;</span>, stored examples: 0)<br></code></pre></td></tr></table></figure><p>load_metric还支持分布式计算，本文不再详细讲述。</p><p>load_metric现在已经是老版本了，新版本将用<code>evaluate</code>模块代替，访问网址为：<ahref="https://github.com/huggingface/evaluate"class="uri">https://github.com/huggingface/evaluate</a> 。</p><ul><li>数据映射（map）</li></ul><p>map就是映射，它接收一个函数，Dataset中的每个元素都会被当作这个函数的输入，并将函数返回值作为新的Dataset。常见的map函数的应用是对文本进行tokenize：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>squad_dataset = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br><br>checkpoint = <span class="hljs-string">&#x27;bert-base-cased&#x27;</span><br>tokenizer = AutoTokenizer.from_pretrained(checkpoint)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">sample</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(sample[<span class="hljs-string">&#x27;context&#x27;</span>], truncation=<span class="hljs-literal">True</span>, max_length=<span class="hljs-number">256</span>)<br><br>tokenized_dataset = squad_dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;context&#x27;</span>, <span class="hljs-string">&#x27;question&#x27;</span>, <span class="hljs-string">&#x27;answers&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;attention_mask&#x27;</span>],<br>        num_rows: 87599<br>    &#125;)<br>    validation: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;context&#x27;</span>, <span class="hljs-string">&#x27;question&#x27;</span>, <span class="hljs-string">&#x27;answers&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;attention_mask&#x27;</span>],<br>        num_rows: 10570<br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure><ul><li>数据保存/加载（save to disk/ load from disk）</li></ul><p>使用<code>save_to_disk()</code>来保存数据集，方便在以后重新使用它,使用<code>load_from_disk()</code>函数重新加载数据集。我们将上面map后的tokenized_dataset数据集进行保存：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenized_dataset.save_to_disk(<span class="hljs-string">&quot;squad_tokenized&quot;</span>)<br></code></pre></td></tr></table></figure><p>保存后的文件结构如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">squad_tokenized/<br>├── dataset_dict.json<br>├── train<br>│   ├── data-00000-of-00001.arrow<br>│   ├── dataset_info.json<br>│   └── state.json<br>└── validation<br>    ├── data-00000-of-00001.arrow<br>    ├── dataset_info.json<br>    └── state.json<br></code></pre></td></tr></table></figure><p>加载数据的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_from_disk<br>reloaded_dataset = load_from_disk(<span class="hljs-string">&quot;squad_tokenized&quot;</span>) <br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本文可作为dataset库的入门，详细介绍了数据集的各种操作，这样方便后续进行模型训练。</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>Datasets: <ahref="https://www.huaxiaozhuan.com/%E5%B7%A5%E5%85%B7/huggingface_transformer/chapters/2_datasets.html"class="uri">https://www.huaxiaozhuan.com/%E5%B7%A5%E5%85%B7/huggingface_transformer/chapters/2_datasets.html</a></li><li>Huggingface详细入门介绍之dataset库：<ahref="https://zhuanlan.zhihu.com/p/554678463"class="uri">https://zhuanlan.zhihu.com/p/554678463</a></li><li>Stream: <a href="https://huggingface.co/docs/datasets/stream"class="uri">https://huggingface.co/docs/datasets/stream</a></li><li>HuggingFace教程 Datasets基本操作: Process: <ahref="https://zhuanlan.zhihu.com/p/557032513"class="uri">https://zhuanlan.zhihu.com/p/557032513</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>HuggingFace</tag>
      
      <tag>Datasets</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《你一定想知道的日本文学简史》摘抄</title>
    <link href="/%E3%80%8A%E4%BD%A0%E4%B8%80%E5%AE%9A%E6%83%B3%E7%9F%A5%E9%81%93%E7%9A%84%E6%97%A5%E6%9C%AC%E6%96%87%E5%AD%A6%E7%AE%80%E5%8F%B2%E3%80%8B%E6%91%98%E6%8A%84/"/>
    <url>/%E3%80%8A%E4%BD%A0%E4%B8%80%E5%AE%9A%E6%83%B3%E7%9F%A5%E9%81%93%E7%9A%84%E6%97%A5%E6%9C%AC%E6%96%87%E5%AD%A6%E7%AE%80%E5%8F%B2%E3%80%8B%E6%91%98%E6%8A%84/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="/pdfjs/web/viewer.html?file=/pdf/《你一定想知道的日本文学简史》摘抄.pdf">PDF全屏浏览（PDF View in FullScreen）</a></p><iframe src='/pdfjs/web/viewer.html?file=/pdf/《你一定想知道的日本文学简史》摘抄.pdf' width="100%" height="800px"></iframe>]]></content>
    
    
    <categories>
      
      <category>书籍摘抄</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍摘抄</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《大英博物馆日记：外二种》摘抄</title>
    <link href="/%E3%80%8A%E5%A4%A7%E8%8B%B1%E5%8D%9A%E7%89%A9%E9%A6%86%E6%97%A5%E8%AE%B0%EF%BC%9A%E5%A4%96%E4%BA%8C%E7%A7%8D%E3%80%8B%E6%91%98%E8%A6%81/"/>
    <url>/%E3%80%8A%E5%A4%A7%E8%8B%B1%E5%8D%9A%E7%89%A9%E9%A6%86%E6%97%A5%E8%AE%B0%EF%BC%9A%E5%A4%96%E4%BA%8C%E7%A7%8D%E3%80%8B%E6%91%98%E8%A6%81/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="/pdfjs/web/viewer.html?file=/pdf/《大英博物馆日记：外二种》摘要.pdf">PDF全屏浏览（PDF View in FullScreen）</a></p><iframe src='/pdfjs/web/viewer.html?file=/pdf/《大英博物馆日记：外二种》摘要.pdf' width="100%" height="800px"></iframe>]]></content>
    
    
    <categories>
      
      <category>书籍摘抄</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍摘抄</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《台湾战后七十年》摘抄</title>
    <link href="/%E3%80%8A%E5%8F%B0%E6%B9%BE%E6%88%98%E5%90%8E%E4%B8%83%E5%8D%81%E5%B9%B4%E3%80%8B%E6%91%98%E6%8A%84/"/>
    <url>/%E3%80%8A%E5%8F%B0%E6%B9%BE%E6%88%98%E5%90%8E%E4%B8%83%E5%8D%81%E5%B9%B4%E3%80%8B%E6%91%98%E6%8A%84/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="/pdfjs/web/viewer.html?file=/pdf/《台湾战后七十年》摘抄.pdf">PDF全屏浏览（PDF View in FullScreen）</a></p><iframe src='/pdfjs/web/viewer.html?file=/pdf/《台湾战后七十年》摘抄.pdf' width="100%" height="800px"></iframe>]]></content>
    
    
    <categories>
      
      <category>书籍摘抄</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍摘抄</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《中共党史珍闻录》摘抄</title>
    <link href="/%E3%80%8A%E4%B8%AD%E5%85%B1%E5%85%9A%E5%8F%B2%E7%8F%8D%E9%97%BB%E5%BD%95%E3%80%8B%E6%91%98%E6%8A%84/"/>
    <url>/%E3%80%8A%E4%B8%AD%E5%85%B1%E5%85%9A%E5%8F%B2%E7%8F%8D%E9%97%BB%E5%BD%95%E3%80%8B%E6%91%98%E6%8A%84/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="/pdfjs/web/viewer.html?file=/pdf/《中共党史珍闻录》摘抄.pdf">PDF全屏浏览（PDF View in FullScreen）</a></p><iframe src='/pdfjs/web/viewer.html?file=/pdf/《中共党史珍闻录》摘抄.pdf' width="100%" height="800px"></iframe>]]></content>
    
    
    <categories>
      
      <category>书籍摘抄</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍摘抄</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《大学何为》摘抄</title>
    <link href="/%E5%A4%A7%E5%AD%A6%E4%BD%95%E4%B8%BA/"/>
    <url>/%E5%A4%A7%E5%AD%A6%E4%BD%95%E4%B8%BA/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="/pdfjs/web/viewer.html?file=/pdf/《大学何为》摘抄.pdf">PDF全屏浏览（PDF View in FullScreen）</a></p><iframe src='/pdfjs/web/viewer.html?file=/pdf/《大学何为》摘抄.pdf' width="100%" height="800px"></iframe>]]></content>
    
    
    <categories>
      
      <category>书籍摘抄</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍摘抄</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（六十一）使用Baichuan-13B-Chat模型构建智能文档问答助手</title>
    <link href="/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%80%EF%BC%89%E4%BD%BF%E7%94%A8Baichuan-13B-Chat%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E6%96%87%E6%A1%A3%E9%97%AE%E7%AD%94%E5%8A%A9%E6%89%8B/"/>
    <url>/NLP%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%80%EF%BC%89%E4%BD%BF%E7%94%A8Baichuan-13B-Chat%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E6%96%87%E6%A1%A3%E9%97%AE%E7%AD%94%E5%8A%A9%E6%89%8B/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E5%85%AD%E5%8D%81%EF%BC%89Baichuan-13B-Chat%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/">NLP（六十）Baichuan-13B-Chat模型使用体验</a>中，我们介绍了Baichuan-13B-Chat模型及其在向量嵌入和文档阅读上的初步尝试。</p><p>本文将详细介绍如何使用Baichuan-13B-Chat模型来构建智能文档问答助手。</p><h3 id="文档问答流程">文档问答流程</h3><p>智能文档问答助手的流程图如下：</p><figure><img src="/img/nlp60_5.jpeg" alt="文档问答流程图" /><figcaption aria-hidden="true">文档问答流程图</figcaption></figure><ul><li><p>文档加载（DocumentLoading）:加载文档，文档格式为URL，PDF，Database。本项目暂时先支持txt文件，后续将支持更多文件格式；</p></li><li><p>文档划分（Splitting）：将文档按照特定格式进行划分，形成文档片段。本项目采用的文档划分方式为LangChain中的RecursiveCharacterTextSplitter，参考网址为：<ahref="https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter">https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter</a>。</p></li><li><p>文档存储（Storage）:将划分后的文档进行向量嵌入，再插入至向量数据库。本项目采用的储存方式为ElasticSearch及向量数据库Milvus。</p></li><li><p>文档召回：对于输入query，从文档存储中召回相关文档片段。本项目采用的召回方式为ElasticSearch中的内置BM25相似度算法及Milvus中的向量距离。</p></li><li><p>问答输出：对于召回文档和输入query，构建合适的Prompt，利用大模型（LLM）输出最终答案。</p><p>下面讲介绍细节。本项目已在Github上开源，项目网址为：<ahref="https://github.com/percent4/document_qa_with_llm">https://github.com/percent4/document_qa_with_llm</a>。</p></li></ul><h3 id="环境搭建">环境搭建</h3><p>本项目开发的Web框架为Flask，API接口两个：文件上传接口和文档问答接口。文件上传接口如下：</p><figure><img src="/img/nlp61_1.png" alt="文件上传接口" /><figcaption aria-hidden="true">文件上传接口</figcaption></figure><p>文档召回采用ElasticSearch和Milvus相结合的方式，设置ElasticSearch和Milvus召回最相似文本数量为2。</p><p>ElasticSearch中创建的index为docs，mapping结构如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;docs&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;mappings&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;properties&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;cont_id&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;integer&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;content&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;analyzer&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ik_smart&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;source&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>其中source代表上传文档名称，cont_id为文本片段编号，content为文本片段。<code>content</code>字段采用的analyzer为<code>ik_smart</code>，该analyzer可较好地对中文进行分词。</p><p>Milvus创建的collection为docs_qa，schema如下：</p><figure><img src="/img/nlp61_2.png" alt="Milvus中docs_qa集合的schema" /><figcaption aria-hidden="true">Milvus中docs_qa集合的schema</figcaption></figure><p><code>embeddings</code>字段为Baichuan-13B-Chat模型的文本向量嵌入，向量维度为512，范数为1（即单位向量），搜索距离度量采用<code>IP</code>，即两个向量的内积。</p><p>大模型采用Baichuan-13B-Chat，主要用于文本片段的向量嵌入和文档问答。关于Baichuan-13B-Chat模型的部署和使用，可参考文章<ahref="https://percent4.github.io/2023/07/21/NLP%EF%BC%88%E5%85%AD%E5%8D%81%EF%BC%89Baichuan-13B-Chat%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/">NLP（六十）Baichuan-13B-Chat模型使用体验</a>。</p><h3 id="文档问答">文档问答</h3><p>本文使用的文档为<code>《封神》耗资30亿，第一部上映第次日，北京文化跌停</code>，访问网址为：<ahref="https://m.jrj.com.cn/madapter/stock/2023/07/22141537710254.shtml">https://m.jrj.com.cn/madapter/stock/2023/07/22141537710254.shtml</a>，将其文本内容保存为txt文件，并通过文件上传接口，将数据内容插入至ES和Milvus。</p><p>我们的问题（输入query）为：<code>封神第一部什么时候上映的？</code>，对其进行向量嵌入，在ES和Milvus中召回的相似文本为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">《封神》耗资30亿，第一部上映第次日，北京文化跌停热点快报 2023-07-22 14:15:04《封神第一部》刚刚上映，北京文化股价却出现下跌。7月21日，A股影视传媒板块震荡下挫，北京文化收于跌停，报7.56元，总市值54.12亿元，板块内个股慈文传媒、荣信文化、中国出版、上海电影等跟跌。值得关注的是，《封神第一部》7月20日才正式上映，北京文化为该影片的出品方。<br>落地误差只有1公里，3条飞船实现了第一阶段的全部任务。<br>北京文化曾成功投资《我不是药神》《战狼》《流浪地球》《你好，李焕英》等多部爆款影片。此前《封神第一部》宣布定档，北京文化曾迎来3连板。<br></code></pre></td></tr></table></figure><p>大模型文档问答的Prompt为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;system&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你是一个出色的文档问答助手，回答要合理、简洁，回复语言采用中文。若问题与文本片段相关，请根据给定的文本片段和问题，答案以\&quot;根据文档知识\&quot;开头若问题与文本片段相关性较小，则使用外部知识回答问题，答案以\&quot;根据外部知识\&quot;开头。&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;使用下面的文本片段列表，回答问题：封神第一部什么时候上映的？\n\n文本片段1: 《封神》耗资30亿，第一部上映第次日，北京文化跌停热点快报 2023-07-22 14:15:04《封神第一部》刚刚上映，北京文化股价却出现下跌。7月21日，A股影视传媒板块震荡下挫，北京文化收于跌停，报7.56元，总市值54.12亿元，板块内个股慈文传媒、荣信文化、中国出版、上海电影等跟跌。值得关注的是，《封神第一部》7月20日才正式上映，北京文化为该影片的出品方。\n文本片段2: 落地误差只有1公里，3条飞船实现了第一阶段的全部任务。\n文本片段3: 北京文化曾成功投资《我不是药神》《战狼》《流浪地球》《你好，李焕英》等多部爆款影片。此前《封神第一部》宣布定档，北京文化曾迎来3连板。\n&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">]</span><br></code></pre></td></tr></table></figure><p>输出答案为：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dns">根据文档知识，《封神第一部》于<span class="hljs-number">2023年7月20</span>日上映。<br></code></pre></td></tr></table></figure><p>更多测试内容可参考本项目的Github网址。</p><h3 id="总结">总结</h3><p>本项目的Github网址为：<ahref="https://github.com/percent4/document_qa_with_llm">https://github.com/percent4/document_qa_with_llm</a>，后续将持续优化这个项目，提升文档问答的方便性和智能性。</p><p>本文详细介绍了如何使用Baichuan-13B-Chat模型来构建智能文档问答助手，希望能给读者们一些启发。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>Baichuan-13B-Chat</tag>
      
      <tag>ElasticSearch</tag>
      
      <tag>Milvus</tag>
      
      <tag>文档问答</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（六十）Baichuan-13B-Chat模型使用体验</title>
    <link href="/NLP%EF%BC%88%E5%85%AD%E5%8D%81%EF%BC%89Baichuan-13B-Chat%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/"/>
    <url>/NLP%EF%BC%88%E5%85%AD%E5%8D%81%EF%BC%89Baichuan-13B-Chat%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>2023年7月11日，百川智能正式发布参数量130亿的通用大语言模型Baichuan-13B-Base、对话模型Baichuan-13B-Chat及其INT4/INT8两个量化版本。</p><p>本文将介绍大模型BaiChuan-13B-Chat的使用体验，其HuggingFace网址为：<ahref="https://huggingface.co/baichuan-inc/Baichuan-13B-Chat">https://huggingface.co/baichuan-inc/Baichuan-13B-Chat</a>。</p><p>BaiChuan-13B-Chat模型采用<code>FastChat</code>工具部署，部署方式与Baichuan-7B模型相同，关于部署的详细步骤，可参考文章：<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%B9%9D%EF%BC%89%E4%BD%BF%E7%94%A8FastChat%E9%83%A8%E7%BD%B2%E7%99%BE%E5%B7%9D%E5%A4%A7%E6%A8%A1%E5%9E%8B/">NLP（五十九）使用FastChat部署百川大模型</a>。</p><h3 id="使用初体验">使用初体验</h3><p>GPT3.5或者GPT4模型在中文问答上偶尔会出现“幻觉”问题，比如一些常识性的中文问题，在这方面，Baichuan-13B-Chat模型的表现较好。</p><p>我们考虑以下三个问题：</p><ul><li><p>鲁迅和周树人是同一个人吗，简要回答？</p></li><li><p>中国第三大岛是哪个？</p></li><li><p>拉普拉斯获得过诺贝尔奖吗？</p><p>这是GPT3.5的回答：</p></li></ul><figure><img src="/img/nlp60_1.png" alt="GPT3.5的回复" /><figcaption aria-hidden="true">GPT3.5的回复</figcaption></figure><p>这是GPT4的回复：</p><figure><img src="/img/nlp60_2.png" alt="GPT4的回复" /><figcaption aria-hidden="true">GPT4的回复</figcaption></figure><p>这是Baichuan-13B-Chat模型的回复：</p><figure><img src="/img/nlp60_3.png" alt="Baichuan-13B-Chat模型的回复" /><figcaption aria-hidden="true">Baichuan-13B-Chat模型的回复</figcaption></figure><h3 id="向量嵌入embedding">向量嵌入（Embedding）</h3><p>当我们完成Baichuan-13B-Chat模型的部署后，我们可以使用类似OpenAI的调用方式来调用该模型，以下是其在向量嵌入方面的表现。</p><p>我们选择五个初始文本：</p><ul><li>唯心主义的对立面是什么</li><li>你好</li><li>上海的人口是多少？</li><li>北京的旅游景点有哪些？</li><li>中国的第一高楼</li></ul><p>首先使用模型对以上文本进行向量嵌入（Embedding），向量维度为512维，范数为1（即已经进行规范化）。再使用新的文本进行向量嵌入，通过向量的余弦相似度获得五个文本中的最相似文本。实现Python如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_text_embedding</span>(<span class="hljs-params">text</span>):<br><span class="hljs-comment"># Baichuan-13B-Chat Embedding</span><br>    url = <span class="hljs-string">&quot;http://localhost:8000/v1/embeddings&quot;</span><br>    headers = &#123;<span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>&#125;<br>    payload = json.dumps(&#123;<br>        <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;Baichuan-13B-Chat&quot;</span>,<br>        <span class="hljs-string">&quot;input&quot;</span>: text<br>    &#125;)<br>    response = requests.request(<span class="hljs-string">&quot;POST&quot;</span>, url, headers=headers, data=payload)<br>    <span class="hljs-keyword">return</span> response.json()[<span class="hljs-string">&quot;data&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;embedding&#x27;</span>]<br><br><br>contents = [<span class="hljs-string">&quot;唯心主义的对立面是什么&quot;</span>,<br>            <span class="hljs-string">&quot;你好&quot;</span>,<br>            <span class="hljs-string">&quot;上海的人口是多少？&quot;</span>,<br>            <span class="hljs-string">&quot;北京的旅游景点有哪些？&quot;</span>,<br>            <span class="hljs-string">&quot;中国的第一高楼&quot;</span>]<br><br>embeddings = [get_text_embedding(content) <span class="hljs-keyword">for</span> content <span class="hljs-keyword">in</span> contents]<br><br>new_text = <span class="hljs-string">&#x27;苏州的旅游景点有哪些？&#x27;</span><br>new_embedding = get_text_embedding(new_text)<br><br>cosine_sim_list = []<br><span class="hljs-keyword">for</span> embedding <span class="hljs-keyword">in</span> embeddings:<br>    cosine_sim_list.append(np.dot(np.array(new_embedding), np.array(embedding)))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;输入：<span class="hljs-subst">&#123;new_text&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;最相似文本：<span class="hljs-subst">&#123;contents[cosine_sim_list.index(<span class="hljs-built_in">max</span>(cosine_sim_list))]&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure><p>测试结果如下：</p><blockquote><p>输入：苏州的旅游景点有哪些？ 最相似文本：北京的旅游景点有哪些？</p></blockquote><blockquote><p>输入：柏拉图的哲学思想是什么？ 最相似文本：唯心主义的对立面是什么</p></blockquote><blockquote><p>输入：北京的人口 最相似文本：上海的人口是多少？</p></blockquote><h3 id="文档阅读">文档阅读</h3><p>在向量嵌入的基础上，我们使用LangChain工具，将文档进行切分（split），之后转化为向量（Embedding），存入向量数据库（如Milvus），这样完成文档的储存。</p><p>对于用户的新问题，使用文本相似度进行向量数据库查询，找到最接近的K条文本，使用这K条文本和新问题，进行文档问答，类似于BERT时代的阅读理解（MRC）。</p><p>我们以<code>中国载人登月工程</code>百度百科中的文本为例，访问网址为：<ahref="https://baike.baidu.com/item/%E4%B8%AD%E5%9B%BD%E8%BD%BD%E4%BA%BA%E7%99%BB%E6%9C%88%E5%B7%A5%E7%A8%8B/7147309">https://baike.baidu.com/item/%E4%B8%AD%E5%9B%BD%E8%BD%BD%E4%BA%BA%E7%99%BB%E6%9C%88%E5%B7%A5%E7%A8%8B/7147309</a>，将其储存为txt文件。</p><figure><img src="/img/nlp60_4.png" alt="中国载人登月工程百度百科" /><figcaption aria-hidden="true">中国载人登月工程百度百科</figcaption></figure><p>以此为例进行文档问答，流程图参考如下：</p><figure><img src="/img/nlp60_5.jpeg" alt="LangChain中的文档问答流程" /><figcaption aria-hidden="true">LangChain中的文档问答流程</figcaption></figure><p>实现Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> TextLoader<br><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter<br><span class="hljs-keyword">from</span> pymilvus <span class="hljs-keyword">import</span> (<br>    connections,<br>    utility,<br>    FieldSchema,<br>    CollectionSchema,<br>    DataType,<br>    Collection,<br>)<br><br><span class="hljs-comment"># 指定要使用的文档加载器</span><br>documents = TextLoader(<span class="hljs-string">&#x27;dengyue.txt&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>).load()<br><span class="hljs-comment"># 接下来，我们将文档拆分成块。</span><br>text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="hljs-number">250</span>, chunk_overlap=<span class="hljs-number">0</span>)<br>texts = text_splitter.split_documents(documents)<br><br><br><span class="hljs-comment"># 获取文本的向量嵌入，使用Baichuan-13B-Chat模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_text_embedding</span>(<span class="hljs-params">req_text</span>):<br>    url = <span class="hljs-string">&quot;http://localhost:8000/v1/embeddings&quot;</span><br>    headers = &#123;<span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>&#125;<br>    payload = json.dumps(&#123;<span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;Baichuan-13B-Chat&quot;</span>, <span class="hljs-string">&quot;input&quot;</span>: req_text&#125;)<br>    new_req = requests.request(<span class="hljs-string">&quot;POST&quot;</span>, url, headers=headers, data=payload)<br>    <span class="hljs-keyword">return</span> new_req.json()[<span class="hljs-string">&#x27;data&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;embedding&#x27;</span>]<br><br><span class="hljs-comment"># 使用Baichuan-13B-Chat模型获取文档问答的答案</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_doc_qa</span>(<span class="hljs-params">qa_template</span>):<br>    url = <span class="hljs-string">&quot;http://localhost:8000/v1/chat/completions&quot;</span><br>    payload = json.dumps(&#123;<br>        <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;Baichuan-13B-Chat&quot;</span>,<br>        <span class="hljs-string">&quot;messages&quot;</span>: [<br>            &#123;<br>                <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>                <span class="hljs-string">&quot;content&quot;</span>: qa_chain_prompt<br>            &#125;<br>        ]<br>    &#125;)<br>    headers = &#123;<span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>&#125;<br>    response = requests.request(<span class="hljs-string">&quot;POST&quot;</span>, url, headers=headers, data=payload)<br>    <span class="hljs-keyword">return</span> response.json()[<span class="hljs-string">&#x27;choices&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;message&#x27;</span>][<span class="hljs-string">&#x27;content&#x27;</span>]<br><br><br><span class="hljs-comment"># 连接Milvus</span><br>connections.connect(<span class="hljs-string">&quot;default&quot;</span>, host=<span class="hljs-string">&quot;localhost&quot;</span>, port=<span class="hljs-string">&quot;19530&quot;</span>)<br><br><span class="hljs-comment"># 创建一个collection</span><br>fields = [<br>    FieldSchema(name=<span class="hljs-string">&quot;pk&quot;</span>, dtype=DataType.INT64, is_primary=<span class="hljs-literal">True</span>, auto_id=<span class="hljs-literal">False</span>),<br>    FieldSchema(name=<span class="hljs-string">&quot;source&quot;</span>, dtype=DataType.VARCHAR, max_length=<span class="hljs-number">100</span>),<br>    FieldSchema(name=<span class="hljs-string">&quot;text&quot;</span>, dtype=DataType.VARCHAR, max_length=<span class="hljs-number">1000</span>),<br>    FieldSchema(name=<span class="hljs-string">&quot;embeddings&quot;</span>, dtype=DataType.FLOAT_VECTOR, dim=<span class="hljs-number">5120</span>)<br>]<br>schema = CollectionSchema(fields, <span class="hljs-string">&quot;vector db for docs qa&quot;</span>)<br>hello_milvus = Collection(<span class="hljs-string">&quot;docs_qa&quot;</span>, schema)<br><br><span class="hljs-comment"># 数据插入</span><br>_ids = []<br>sources = []<br>contents = []<br>embeddings = []<br><span class="hljs-keyword">for</span> i, text <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(texts):<br>    source = text.metadata[<span class="hljs-string">&#x27;source&#x27;</span>]<br>    <span class="hljs-built_in">print</span>(i+<span class="hljs-number">1</span>, source)<br>    content = text.page_content<br>    embedding = get_text_embedding(content)<br>    _ids.append(i+<span class="hljs-number">1</span>)<br>    sources.append(source)<br>    contents.append(content)<br>    embeddings.append(embedding)<br><br>insert_result = hello_milvus.insert([_ids, sources, contents, embeddings])<br><span class="hljs-comment"># After final entity is inserted, it is best to call flush to have no growing segments left in memory</span><br>hello_milvus.flush()<br><br><span class="hljs-comment"># 在entities字段创建索引</span><br>index = &#123;<br>    <span class="hljs-string">&quot;index_type&quot;</span>: <span class="hljs-string">&quot;IVF_FLAT&quot;</span>,<br>    <span class="hljs-string">&quot;metric_type&quot;</span>: <span class="hljs-string">&quot;IP&quot;</span>,<br>    <span class="hljs-string">&quot;params&quot;</span>: &#123;<span class="hljs-string">&quot;nlist&quot;</span>: <span class="hljs-number">128</span>&#125;,<br>&#125;<br>hello_milvus.create_index(<span class="hljs-string">&quot;embeddings&quot;</span>, index)<br><br><span class="hljs-comment"># 将collection加载至内存</span><br>hello_milvus.load()<br><br><span class="hljs-comment"># 输入问题，进行文档问答</span><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    query = <span class="hljs-built_in">input</span>(<span class="hljs-string">&#x27;输入问题：&#x27;</span>)<br>    vectors_to_search = [get_text_embedding(query)]<br>    <span class="hljs-comment"># 通过嵌入向量相似度获取相似文本，数量为3个</span><br>    search_params = &#123;<br>        <span class="hljs-string">&quot;metric_type&quot;</span>: <span class="hljs-string">&quot;IP&quot;</span>,<br>        <span class="hljs-string">&quot;params&quot;</span>: &#123;<span class="hljs-string">&quot;nprobe&quot;</span>: <span class="hljs-number">10</span>&#125;,<br>    &#125;<br>    result = hello_milvus.search(vectors_to_search, <span class="hljs-string">&quot;embeddings&quot;</span>, search_params, limit=<span class="hljs-number">3</span>, output_fields=[<span class="hljs-string">&quot;text&quot;</span>])<br>    context = <span class="hljs-string">&#x27;&#x27;</span>.join([_.entity.get(<span class="hljs-string">&#x27;text&#x27;</span>) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> result[<span class="hljs-number">0</span>]])<br><br>    <span class="hljs-comment"># 建立prompt</span><br>    qa_chain_prompt = <span class="hljs-string">f&quot;&quot;&quot;使用以下文本来回答最后的问题。</span><br><span class="hljs-string">    如果你不知道答案，就说你不知道，不要试图编造答案，尽可能保持答案简洁。 </span><br><span class="hljs-string">    文本: <span class="hljs-subst">&#123;context&#125;</span></span><br><span class="hljs-string">    问题: <span class="hljs-subst">&#123;query&#125;</span></span><br><span class="hljs-string">    答案:&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># print(qa_chain_prompt)</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;问题：<span class="hljs-subst">&#123;query&#125;</span>&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;回答：<span class="hljs-subst">&#123;get_doc_qa(qa_chain_prompt)&#125;</span>&#x27;</span>)<br><br></code></pre></td></tr></table></figure><p>测试结果如下：</p><blockquote><p>问题：美国什么时候登上月球？回答：美国在20世纪60年代和70年代通过“阿波罗”计划成功登上月球。</p></blockquote><blockquote><p>问题：中国预计在什么登上月球？回答：中国预计在2025年实现航天员登月。目前，关于中国载人登月工程计划的时间，国内有三种说法：2020年、2025年和2030年。不过，这些时间表都是专家的观点和预测，国家尚未公布一个明确的时间表。</p></blockquote><blockquote><p>问题：嫦娥二号、嫦娥三号的总指挥是谁？回答：嫦娥二号、嫦娥三号的总指挥是叶培建。</p></blockquote><blockquote><p>问题：神舟十六号载人飞行任务新闻发布会在哪里举行？回答：神舟十六号载人飞行任务新闻发布会在酒泉卫星发射中心举行。</p></blockquote><p>当然，上述的文档问答方案并不是很完善，仅仅使用向量嵌入有时无法召回相似文本，这样就会造成回答错误。</p><p>后续笔者将考虑ES +向量加入的结合方式进行召回，同时支持更多类型的文本，不仅限于txt文件。</p><h3 id="总结">总结</h3><p>本文主要介绍了Baichuan-13B-Chat模型使用体验，包括其与GPT系列模型在中文常识性问题上的测试，以及向量嵌入、文档问答等。</p><p>笔者使用下来的初步感受是，Baichuan-13B-Chat模型的问答效果还是不错的！</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>Baichuan-13B-Chat</tag>
      
      <tag>Milvus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《一个中国记者看二战》摘抄</title>
    <link href="/%E3%80%8A%E4%B8%80%E4%B8%AA%E4%B8%AD%E5%9B%BD%E8%AE%B0%E8%80%85%E7%9C%8B%E4%BA%8C%E6%88%98%E3%80%8B%E6%91%98%E6%8A%84/"/>
    <url>/%E3%80%8A%E4%B8%80%E4%B8%AA%E4%B8%AD%E5%9B%BD%E8%AE%B0%E8%80%85%E7%9C%8B%E4%BA%8C%E6%88%98%E3%80%8B%E6%91%98%E6%8A%84/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="/pdfjs/web/viewer.html?file=/pdf/《一个中国记者看二战》摘抄.pdf">PDF全屏浏览（PDF View in FullScreen）</a></p><iframe src='/pdfjs/web/viewer.html?file=/pdf/《一个中国记者看二战》摘抄.pdf' width="100%" height="800px"></iframe>]]></content>
    
    
    <categories>
      
      <category>书籍摘抄</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍摘抄</tag>
      
      <tag>二战</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（五十九）使用FastChat部署百川大模型</title>
    <link href="/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%B9%9D%EF%BC%89%E4%BD%BF%E7%94%A8FastChat%E9%83%A8%E7%BD%B2%E7%99%BE%E5%B7%9D%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    <url>/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%B9%9D%EF%BC%89%E4%BD%BF%E7%94%A8FastChat%E9%83%A8%E7%BD%B2%E7%99%BE%E5%B7%9D%E5%A4%A7%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会介绍如何使用FastChat来部署国产大模型——百川模型。</p><p>在此之前，我们先来了解两个概念——<code>百川模型</code>和<code>FastChat</code>.</p><h3 id="百川模型">百川模型</h3><p>2023年6月15日，被称为「中国 ChatGPT 梦之队」的百川智能公司，推出了 70亿参数量的中英文预训练大模型——<code>baichuan-7B</code>。</p><p><code>baichuan-7B</code>是由百川智能开发的一个开源的大规模预训练模型。基于Transformer结构，在大约1.2万亿tokens上训练的70亿参数模型，支持中英双语，上下文窗口长度为4096。在标准的中文和英文权威benchmark（C-EVAL/MMLU）上均取得同尺寸最好的效果。</p><p>在构建预训练语料库方面，百川智能以高质量中文语料为基础，同时融合了优质的英文数据。相较于其他同参数规模的开源中文预训练模型，数据量提高了超过50%。</p><ul><li>在数据质量方面，通过质量模型对数据进行打分，对原始数据集进行篇章级和句子级的精确筛选</li><li>在内容多样性方面，利用自研超大规模局部敏感哈希聚类系统和语义聚类系统，对数据进行了多层次多粒度的聚类</li><li>最终构建了包含 1.2 万亿 token 的兼顾质量和多样性的预训练数据。</li></ul><p>不同于LLaMA完全禁止商业使用，<code>baichuan-7B</code>代码使用更宽松的开源协议——Apache-2.0协议，允许用于商业目的</p><h3 id="fastchat">FastChat</h3><p><code>FastChat</code>是用于对话机器人模型训练、部署、评估的开放平台，其核心特性包括：</p><ul><li>模型权重，训练代码，评估代码可用于SOTA模型（比如Vicuna，FastChat-T5）</li><li>分布式多模型部署系统，自带Web UI和OpenAI兼容的RESTful APIs</li></ul><p><code>FastChat</code>集成了Vicuna、Koala、alpaca、LLaMA等开源模型，其中Vicuna号称能够达到GPT-4的90%的质量，是开源的chatGPT模型中对答效果比较好的。</p><p><code>FastChat</code>的访问地址是：<ahref="https://link.zhihu.com/?target=https%3A//chat.lmsys.org/">https://chat.lmsys.org/</a>, <code>FastChat</code>的安装方式为：<code>pip3 install fschat</code>.</p><h3 id="cli部署">CLI部署</h3><p>在Huggingface Hub上下载<code>baichuan-7B</code>模型，访问网址为：<ahref="https://huggingface.co/baichuan-inc/Baichuan-7B"class="uri">https://huggingface.co/baichuan-inc/Baichuan-7B</a>,放在GPU机器上的本地路径。</p><p>笔者的GPU机器为4 * RTX6000，每张RTX6000的显存为80G。</p><p><code>FastChat</code>使用CLI部署百川大模型的命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 -m fastchat.serve.cli --model-path path_of_Baichuan-7B --num-gpus 2<br></code></pre></td></tr></table></figure><p>在CLI部署时，如遇到以下的报错：<code>trust_remote_code=True</code>,参考issue网址：<a href="https://github.com/lm-sys/FastChat/issues/1789"class="uri">https://github.com/lm-sys/FastChat/issues/1789</a>,则在对应的Python路径下，将FastChat的fastchat/model/model_adapter.py文件中的代码中的第57至61行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer = AutoTokenizer.from_pretrained(<br>             model_path,<br>             use_fast=self.use_fast_tokenizer,<br>             revision=revision,<br>         )<br></code></pre></td></tr></table></figure><p>和69至71行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">model = AutoModelForCausalLM.from_pretrained(<br>          model_path, low_cpu_mem_usage=<span class="hljs-literal">True</span>, **from_pretrained_kwargs<br>      )<br></code></pre></td></tr></table></figure><p>中添加代码：`<code>trust_remote_code=True</code>` ,则可顺利部署。</p><pre><code class="hljs">部署成功后的界面如下：</code></pre><figure><img src="/img/fastchat_cli.png" alt="CLI部署成功后的用户界面" /><figcaption aria-hidden="true">CLI部署成功后的用户界面</figcaption></figure><h3 id="web部署">WEB部署</h3><p><code>FastChat</code>还支持WEB部署，可Web UI和OpenAI兼容的RESTfulAPIs.</p><p>这里主要介绍如何实现与OpenAI兼容的具有RESTfulAPIs的部署方式，参考网址为：<ahref="https://github.com/lm-sys/FastChat/blob/main/docs/openai_api.md"class="uri">https://github.com/lm-sys/FastChat/blob/main/docs/openai_api.md</a>.</p><p>部署一共分为三步：</p><ol type="1"><li><code>python3 -m fastchat.serve.controller</code></li><li><code>python3 -m fastchat.serve.model</code><em><code>worker --model-path path_of_</code></em><code>Baichuan-7B</code></li><li><code>python3 -m fastchat.serve.openai_api_server --host localhost --port 8000</code></li></ol><p>在部署过程中，如果遇到<code>PydanticImportError</code>，原因为pydantic版本的问题，只需将pydantic版本降为<code>1.*</code>版本即可。</p><p>部署成功后，该服务可提供与OpenAI风格类似的RESTful APIs，如下：</p><ul><li>查看模型</li></ul><p>curl命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/models<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;list&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;data&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;baichun_7b&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;model&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1689004839</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;owned_by&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;fastchat&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;root&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;baichun_7b&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;parent&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;permission&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;modelperm-UERow2kYwq5B2M8aVQkwdk&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;model_permission&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1689004839</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_create_engine&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_sampling&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_logprobs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_search_indices&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_view&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;allow_fine_tuning&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;organization&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;*&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;group&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;is_blocking&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><ul><li>文本补充（Text Completions）</li></ul><p>curl命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/completions \<br>  -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \<br>  -d <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">    &quot;model&quot;: &quot;baichun_7b&quot;,</span><br><span class="hljs-string">    &quot;prompt&quot;: &quot;Once upon a time&quot;,</span><br><span class="hljs-string">    &quot;max_tokens&quot;: 40,</span><br><span class="hljs-string">    &quot;temperature&quot;: 0.5</span><br><span class="hljs-string">  &#125;&#x27;</span> | jq .<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cmpl-izbe3cRRiY4zAbJueBAyxZ&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text_completion&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1689004991</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;baichun_7b&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;choices&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;index&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;, you could find a variety of different types of chocolate in stores. But now, many chocolate companies are focusing on creating vegan chocolate that is not only delicious but also cruelty-free. Here are&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;logprobs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;finish_reason&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;length&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;usage&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;prompt_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;total_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">43</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;completion_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">39</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><ul><li>对话（Chat Completions）</li></ul><p>curl命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/chat/completions \<br>  -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \<br>  -d <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">    &quot;model&quot;: &quot;baichun_7b&quot;,</span><br><span class="hljs-string">    &quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请用中文简单介绍三国演义？&quot;&#125;]</span><br><span class="hljs-string">  &#125;&#x27;</span> | jq .<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;chatcmpl-3SiRqRgbZR8v6gLnQYo9eJ&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;chat.completion&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1689005219</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;baichun_7b&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;choices&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;index&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;message&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot; 三国演义是中国古代长篇小说，讲述了东汉末年至晋朝初年的历史故事。主要人物包括曹操、刘备、孙权和关羽等。故事情节曲折复杂，涉及政治、军事、文化等多个方面，被誉为中国古代小说的经典之作。《三国演义》不仅是一部文学作品，也是中国文化的重要组成部分，对中国历史和文化产生了深远的影响。&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;finish_reason&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;stop&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;usage&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;prompt_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">533</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;total_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">629</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;completion_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">96</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><ul><li>多轮对话</li></ul><p>curl命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/chat/completions \<br>  -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \<br>  -d <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">    &quot;model&quot;: &quot;baichun_7b&quot;,</span><br><span class="hljs-string">    &quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请用中文简单介绍西游记？&quot;&#125;, &#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;三国演义是中国古代长篇小说，讲述了东汉末年至晋朝初年的历史故事。主要人物包括曹操、刘备、孙权和关羽等。故事情节曲折复杂，涉及政治、军事、文化等多个方面，被誉为中国古代小说的经典之作。《三国演义》不仅是一部文学作品，也是中国文化的重要组成部分，对中国历史和文化产生了深远的影响。&quot;&#125;, &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;它的作者是谁？&quot;&#125;]</span><br><span class="hljs-string">  &#125;&#x27;</span> | jq .<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;chatcmpl-8oE57oXC862wKYyrPLnSGM&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;chat.completion&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1689005374</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;baichun_7b&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;choices&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;index&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;message&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot; 《三国演义》的作者是明代小说家罗贯中。罗贯中是明代文学家，他的代表作品还有《水浒传》和《西游记》等。他在创作《三国演义》时，参考了大量的历史资料和传说，将这些内容融合在一起，创造了一个虚构的世界，成为了中国文学史上的经典之作。&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;finish_reason&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;stop&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;usage&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;prompt_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">640</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;total_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">724</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;completion_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">84</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><ul><li>使用Python代码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> openai<br>openai.api_key = <span class="hljs-string">&quot;EMPTY&quot;</span> <span class="hljs-comment"># Not support yet</span><br>openai.api_base = <span class="hljs-string">&quot;http://localhost:8000/v1&quot;</span><br><br>model = <span class="hljs-string">&quot;baichun_7b&quot;</span><br>prompt = <span class="hljs-string">&quot;Once upon a time&quot;</span><br><br><span class="hljs-comment"># create a completion</span><br>completion = openai.Completion.create(model=model, prompt=prompt, max_tokens=<span class="hljs-number">64</span>)<br><span class="hljs-comment"># print the completion</span><br><span class="hljs-built_in">print</span>(prompt + completion.choices[<span class="hljs-number">0</span>].text)<br><br><span class="hljs-comment"># create a chat completion</span><br>completion = openai.ChatCompletion.create(<br>  model=model,<br>  messages=[&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Hello! What is your name?&quot;</span>&#125;]<br>)<br><span class="hljs-comment"># print the completion</span><br><span class="hljs-built_in">print</span>(completion.choices[<span class="hljs-number">0</span>].message.content)<br></code></pre></td></tr></table></figure><p><strong>以上两种部署方式，都支持流式输出，且模型推理速度较快，笔者在上述测试例子中的推理时间一般为5-7秒，且支持分布式部署，并发量高。</strong></p><h3 id="总结">总结</h3><p>本文主要介绍了如何使用FastChat来部署国产大模型——百川模型，并演示了两种部署方式——WEB部署和CLI部署，以及在部署过程中出现的问题和解决方案，希望能给读者带来启示。</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>百川智能发布 70 亿参数量开源中英文大模型: <ahref="https://www.geekpark.net/news/320721"class="uri">https://www.geekpark.net/news/320721</a></li><li>baichuan-inc/Baichuan-7B in Huggingface Hub: <ahref="https://huggingface.co/baichuan-inc/Baichuan-7B"class="uri">https://huggingface.co/baichuan-inc/Baichuan-7B</a></li><li>OpenAI-Compatible RESTful APIs &amp; SDK: <ahref="https://github.com/lm-sys/FastChat/blob/main/docs/openai_api.md"class="uri">https://github.com/lm-sys/FastChat/blob/main/docs/openai_api.md</a></li><li>report error while i execute<code>python -m fastchat.serve.openai_api_server --host localhost --port 8000</code>:<a href="https://github.com/lm-sys/FastChat/issues/1641"class="uri">https://github.com/lm-sys/FastChat/issues/1641</a></li><li>FastChat in Github: <a href="https://github.com/lm-sys/FastChat"class="uri">https://github.com/lm-sys/FastChat</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>AIGC</tag>
      
      <tag>大模型</tag>
      
      <tag>百川模型</tag>
      
      <tag>FastChat</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（五十八）LangChain使用Google Search Agent</title>
    <link href="/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E5%85%AB%EF%BC%89LangChain%E4%BD%BF%E7%94%A8Google-Search-Agent/"/>
    <url>/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E5%85%AB%EF%BC%89LangChain%E4%BD%BF%E7%94%A8Google-Search-Agent/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="大模型存在的问题">大模型存在的问题</h3><p>大模型在给人带来眼前一亮的表现，深深地震撼各行各业人们的同时，其本身也存在着不少问题。</p><p>以OpenAI的ChatGPT模型为例，其存在的问题有：</p><ol type="1"><li>事实错误，容易一本正经地胡说八道，造成幻觉问题。 <imgsrc="/img/nlp58_1.png"alt="个园、瘦西湖重复，平江路古街是苏州的景点，回答错误" /></li><li>逻辑推理能力弱，缺乏像人类一样的判断能力 <img src="/img/nlp58_2.png"alt="大模型不会坚持自己正确的答案，逻辑推理能力弱" /></li><li>世界知识的局限性与时限性，对专业领域知识、私人知识和实时信息，无法回答<img src="/img/nlp58_3.png"alt="OpenAI的ChatGPT模型的知识库截止至2021年9月，无法回答这之后的信息" /></li></ol><h3 id="langchain中的agent">LangChain中的Agent</h3><p>Agent（代理）是LangChain中的高级功能，可插件化地对模型回答进行修改或补充，弥补模型存在的不足，相当于模型的插件。其中，GoogleSearch代理允许我们使用谷歌搜索。</p><p>首先，我们需要在Google Cloud credential console (<ahref="https://console.cloud.google.com/apis/credentials">https://console.cloud.google.com/apis/credentials</a>)中获取GOOGLE_API_KEY，在ProgrammableSearch Enginge (<ahref="https://programmablesearchengine.google.com/controlpanel/create">https://programmablesearchengine.google.com/controlpanel/create</a>)中获取GOOGLE_CSE_ID，接着安装<code>pip install google-api-python-client</code>第三方模块。具体的设置过程不在此讲述，读者可自行设置。</p><p>下面将介绍如何在LangChain中使用Google SearchAgent，Python示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br>os.environ[<span class="hljs-string">&quot;GOOGLE_CSE_ID&quot;</span>] = <span class="hljs-string">&quot;xxx&quot;</span><br>os.environ[<span class="hljs-string">&quot;GOOGLE_API_KEY&quot;</span>] = <span class="hljs-string">&quot;xxx&quot;</span><br><br><span class="hljs-keyword">from</span> langchain.tools <span class="hljs-keyword">import</span> Tool<br><span class="hljs-keyword">from</span> langchain.utilities <span class="hljs-keyword">import</span> GoogleSearchAPIWrapper<br><br>search = GoogleSearchAPIWrapper()<br><br><br><span class="hljs-comment"># return first five search results</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">top3_results</span>(<span class="hljs-params">query</span>):<br>    <span class="hljs-keyword">return</span> search.results(query, <span class="hljs-number">3</span>)<br><br><br>tool = Tool(<br>    name=<span class="hljs-string">&quot;Google Search&quot;</span>,<br>    description=<span class="hljs-string">&quot;Search Google for recent results.&quot;</span>,<br>    func=top3_results,<br>)<br><br><span class="hljs-built_in">print</span>(tool.run(<span class="hljs-string">&quot;2022年诺贝尔物理学奖获得者?&quot;</span>))<br></code></pre></td></tr></table></figure><p>谷歌搜索结果如下：</p><blockquote><p>[{'title': '三名科学家分享2022年诺贝尔物理学奖-新华网', 'link':'http://www.news.cn/2022-10/04/c_1129050882.htm', 'snippet': 'Oct 4,2022 ...新华社斯德哥尔摩10月4日电（记者和苗付一鸣）瑞典皇家科学院4日宣布，将2022年诺贝尔物理学奖授予法国科学家阿兰·阿斯佩、美国科学家约翰·克劳泽和...'},{'title': '2022年诺贝尔物理学奖为何颁给了这三位？ -中新网', 'link':'https://www.chinanews.com.cn/cj/2022/10-05/9867029.shtml', 'snippet':'Oct 5, 2022 ...北京时间10月4日下午，瑞典皇家科学院宣布，将2022年诺贝尔物理学奖颁给法国科学家阿兰·阿斯佩(AlainAspect)、美国科学家约翰·克劳泽(John F.'}, {'title':'解读2022年诺贝尔物理学奖：为第二次量子革命奠定基础--经济·科技 ...','link': 'http://finance.people.com.cn/n1/2022/1010/c1004-32542107.html','snippet': 'Oct 10, 2022 ...瑞典皇家科学院4日宣布，将2022年诺贝尔物理学奖授予法国科学家阿兰·阿斯佩、美国科学家约翰·克劳泽和奥地利科学家安东·蔡林格，以表彰他们在“纠缠光子...'}]</p></blockquote><h3 id="使用google-search-agent改善大模型">使用Google SearchAgent改善大模型</h3><p>借助Google SearchAgent，针对大模型回答不了实时信息或超过训练预料库知识的问题，我们能很好地改善这一问题。这也是如何使用外部知识来改善大模型表现的一种办法。</p><p>以下是示例Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> ZeroShotAgent, Tool, AgentExecutor<br><span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ConversationBufferMemory<br><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> OpenAI, LLMChain<br><span class="hljs-keyword">from</span> langchain.utilities <span class="hljs-keyword">import</span> GoogleSearchAPIWrapper<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> initialize_agent<br><span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> AgentType<br><span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> load_tools<br><br>os.environ[<span class="hljs-string">&quot;GOOGLE_CSE_ID&quot;</span>] = <span class="hljs-string">&quot;xxx&quot;</span><br>os.environ[<span class="hljs-string">&quot;GOOGLE_API_KEY&quot;</span>] = <span class="hljs-string">&quot;xxx&quot;</span><br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&#x27;sk-xxx&#x27;</span><br><br>llm = OpenAI(model_name=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>, temperature=<span class="hljs-number">0</span>)<br>tools = load_tools([<span class="hljs-string">&quot;google-search&quot;</span>], llm=llm)<br><br>agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=<span class="hljs-literal">True</span>)<br><br><span class="hljs-built_in">print</span>(agent.run(<span class="hljs-string">&quot;现在上海的地铁里程有多少？&quot;</span>))<br></code></pre></td></tr></table></figure><p>对于“现在上海的地铁里程有多少？”这个问题，LangChain的回复链及最终答案如下：</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs vbnet">&gt; Entering <span class="hljs-built_in">new</span>  chain...<br>I<span class="hljs-comment">&#x27;m not sure about the current length of the Shanghai subway system.</span><br><span class="hljs-symbol">Action:</span> google_search<br>Action Input: <span class="hljs-string">&quot;current length of Shanghai subway system&quot;</span><br><span class="hljs-symbol">Observation:</span> <span class="hljs-keyword">With</span> a total length <span class="hljs-keyword">of</span> <span class="hljs-number">169</span> km it <span class="hljs-built_in">is</span> the world<span class="hljs-comment">&#x27;s 2nd largest fully automated metro system, after the Singapore MRT. Most lines currently use 6 car sets, with the ... Dec 29, 2021 ... Beijing&#x27;s epic subway system added 53 kilometers of new track in 2021, ... addition of Line 14, the total length of the Shanghai Metro now ... This article lists the openings of lines, line segments, stations and fare schemes of the ... The first section opened in 1993, and the system currently has 802 ... Apr 15, 2010</span><br><span class="hljs-symbol">Thought:</span>Based <span class="hljs-keyword">on</span> the search results, the current length <span class="hljs-keyword">of</span> the Shanghai subway system <span class="hljs-built_in">is</span> <span class="hljs-number">831</span> kilometers (<span class="hljs-number">516.4</span> miles).<br>Final Answer: The current length <span class="hljs-keyword">of</span> the Shanghai subway system <span class="hljs-built_in">is</span> <span class="hljs-number">831</span> kilometers.<br><br>&gt; Finished chain.<br>The current length <span class="hljs-keyword">of</span> the Shanghai subway system <span class="hljs-built_in">is</span> <span class="hljs-number">831</span> kilometers.<br></code></pre></td></tr></table></figure><p>我们再来看几个例子：</p><blockquote><p>问题：2022年的诺贝尔物理学家获得者是谁？ 回答：The 2022 Nobel Prizein Physics was awarded to Alain Aspect, John F. Clauser, and AntonZeilinger.</p></blockquote><blockquote><p>问题：2022年的上海市市长是谁？ 回答：2022年的上海市市长是龚正。</p></blockquote><blockquote><p>问题：2023年苏迪曼杯在哪里举行，获胜者是谁？ 回答：The 2023 SudirmanCup was held in Suzhou, China, and the winner was China.</p></blockquote><blockquote><p>问题：今年的端午节是哪几天？ 回答：This year's Dragon Boat Festivalwill be on June 22nd, 2023.</p></blockquote><p>有了Google SearchAgent，ChatGPT能很好地回复上述问题，解决了实时信息无法回答的问题，避免了世界知识的局限性和时效性。而没有GoogleSearchAgent，对于上述问题，基本无法回答，就算能回答，也是2021年9月之前的文本信息了。</p><p>美中不足的是，LangChain使用Google SearchAgent，给出的问题答复，往往都是英语。而我们想得到中文答案的话，还需要再想一点办法，但回复的内容是令人满意的。</p><h3 id="总结">总结</h3><p>本文主要介绍了如何在LangChain中使用Google SearchAgent，来改善大模型存在的不足之处。</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>Google Search：<ahref="https://python.langchain.com/docs/modules/agents/tools/integrations/google_search">https://python.langchain.com/docs/modules/agents/tools/integrations/google_search</a></li><li>Google搜索包装器：<ahref="https://www.langchain.asia/ecosystem/google_search">https://www.langchain.asia/ecosystem/google_search</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>LangChain</tag>
      
      <tag>AIGC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（五十七）LangChain的结构化输出</title>
    <link href="/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%B8%83%EF%BC%89LangChain%E7%9A%84%E7%BB%93%E6%9E%84%E5%8C%96%E8%BE%93%E5%87%BA/"/>
    <url>/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%B8%83%EF%BC%89LangChain%E7%9A%84%E7%BB%93%E6%9E%84%E5%8C%96%E8%BE%93%E5%87%BA/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在使用大模型的时候，尽管我们的prompt已经要求大模型给出固定的输出格式，比如JSON，但很多时候，大模型还是会输出额外的信息，使得我们在对输出信息进行结构化的时候产生困难。LangChain工具可以很好地将输出信息进行结构化。</p><p>关于LangChain的结构化输出，可参考网址：<ahref="https://python.langchain.com/docs/modules/model_io/output_parsers/">https://python.langchain.com/docs/modules/model_io/output_parsers/</a>，这其中，我们较为关注的是<code>Structured output parser</code>，通过定义<code>StructuredOutputParser</code>来使用，使用方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">response_schemas = [<br>    ResponseSchema(name=<span class="hljs-string">&quot;answer&quot;</span>, description=<span class="hljs-string">&quot;answer to the user&#x27;s question&quot;</span>),<br>    ResponseSchema(name=<span class="hljs-string">&quot;source&quot;</span>, description=<span class="hljs-string">&quot;source used to answer the user&#x27;s question, should be a website.&quot;</span>)<br>]<br>output_parser = StructuredOutputParser.from_response_schemas(response_schemas)<br></code></pre></td></tr></table></figure><h3 id="一个例子">一个例子</h3><p>首先，我们先来看一个简单的结构化输出的prompt的写法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> langchain.output_parsers <span class="hljs-keyword">import</span> StructuredOutputParser, ResponseSchema<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><br><span class="hljs-comment"># 告诉他我们生成的内容需要哪些字段，每个字段类型式啥</span><br>response_schemas = [<br>    ResponseSchema(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;string&quot;</span>, name=<span class="hljs-string">&quot;bad_string&quot;</span>, description=<span class="hljs-string">&quot;This a poorly formatted user input string&quot;</span>),<br>    ResponseSchema(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;string&quot;</span>, name=<span class="hljs-string">&quot;good_string&quot;</span>, description=<span class="hljs-string">&quot;This is your response, a reformatted response&quot;</span>)<br>]<br><br><span class="hljs-comment"># 初始化解析器</span><br>output_parser = StructuredOutputParser.from_response_schemas(response_schemas)<br><br><span class="hljs-comment"># 生成的格式提示符</span><br>format_instructions = output_parser.get_format_instructions()<br><span class="hljs-built_in">print</span>(format_instructions)<br><br><span class="hljs-comment"># 加入至template中</span><br>template = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">You will be given a poorly formatted string from a user.</span><br><span class="hljs-string">Reformat it and make sure all the words are spelled correctly</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;format_instructions&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">% USER INPUT:</span><br><span class="hljs-string">&#123;user_input&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">YOUR RESPONSE:</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># 将我们的格式描述嵌入到prompt中去，告诉llm我们需要他输出什么样格式的内容</span><br>prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;user_input&quot;</span>],<br>    partial_variables=&#123;<span class="hljs-string">&quot;format_instructions&quot;</span>: format_instructions&#125;,<br>    template=template<br>)<br><br>promptValue = prompt.<span class="hljs-built_in">format</span>(user_input=<span class="hljs-string">&quot;welcom to califonya!&quot;</span>)<br><span class="hljs-built_in">print</span>(promptValue)<br></code></pre></td></tr></table></figure><p>此时，结构化输出的内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">The output should be a markdown code snippet formatted <span class="hljs-keyword">in</span> the following schema, including the leading and trailing <span class="hljs-string">&quot;```json&quot;</span> and <span class="hljs-string">&quot;```&quot;</span>:<br><br>\```json<br>&#123;<br><span class="hljs-string">&quot;bad_string&quot;</span>: string  // This a poorly formatted user input string<br><span class="hljs-string">&quot;good_string&quot;</span>: string  // This is your response, a reformatted response<br>&#125;<br>\```<br></code></pre></td></tr></table></figure><p>prompt的内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">You will be given a poorly formatted string from a user.<br>Reformat it and make sure all the words are spelled correctly<br><br>The output should be a markdown code snippet formatted <span class="hljs-keyword">in</span> the following schema, including the leading and trailing <span class="hljs-string">&quot;```json&quot;</span> and <span class="hljs-string">&quot;```&quot;</span>:<br><br>\```json<br>&#123;<br><span class="hljs-string">&quot;bad_string&quot;</span>: string  // This a poorly formatted user input string<br><span class="hljs-string">&quot;good_string&quot;</span>: string  // This is your response, a reformatted response<br>&#125;<br>\```<br><br>% USER INPUT:<br>welcom to califonya!<br><br>YOUR RESPONSE:<br></code></pre></td></tr></table></figure><p>将上述内容使用LLM进行回复，示例Pyhon代码如下（接上述代码）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><br><span class="hljs-comment"># set api key</span><br><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&#x27;sk-xxx&#x27;</span><br><br>llm = OpenAI(model_name=<span class="hljs-string">&quot;text-davinci-003&quot;</span>)<br><br>llm_output = llm(promptValue)<br><span class="hljs-built_in">print</span>(llm_output)<br><br><span class="hljs-comment"># 使用解析器进行解析生成的内容</span><br><span class="hljs-built_in">print</span>(output_parser.parse(llm_output))<br></code></pre></td></tr></table></figure><p>输出结果如下： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">```json<br>&#123;<br><span class="hljs-string">&quot;bad_string&quot;</span>: <span class="hljs-string">&quot;welcom to califonya!&quot;</span>,<br><span class="hljs-string">&quot;good_string&quot;</span>: <span class="hljs-string">&quot;Welcome to California!&quot;</span><br>&#125;<br>\```<br>&#123;<span class="hljs-string">&#x27;bad_string&#x27;</span>: <span class="hljs-string">&#x27;welcom to califonya!&#x27;</span>, <span class="hljs-string">&#x27;good_string&#x27;</span>: <span class="hljs-string">&#x27;Welcome to California!&#x27;</span>&#125;<br></code></pre></td></tr></table></figure></p><p>可以看到，大模型的输出结果正是我们所要求的JSON格式，且字段和数据类型、输出结果付出预期。</p><h3 id="结构化抽取">结构化抽取</h3><p>有了上述的结构化输出，我们尝试对文本进行结构化抽取，并使得抽取结果按JSON格式输出。示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> langchain.output_parsers <span class="hljs-keyword">import</span> StructuredOutputParser, ResponseSchema<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><br><span class="hljs-comment"># set api key</span><br><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&#x27;sk-xxx&#x27;</span><br><br>llm = OpenAI(model_name=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br><br><span class="hljs-comment"># 告诉他我们生成的内容需要哪些字段，每个字段类型式啥</span><br>response_schemas = [<br>    ResponseSchema(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;number&quot;</span>, name=<span class="hljs-string">&quot;number&quot;</span>, description=<span class="hljs-string">&quot;文本中的数字&quot;</span>),<br>    ResponseSchema(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;string&quot;</span>, name=<span class="hljs-string">&quot;people&quot;</span>, description=<span class="hljs-string">&quot;文本中的人物&quot;</span>),<br>    ResponseSchema(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;string&quot;</span>, name=<span class="hljs-string">&quot;place&quot;</span>, description=<span class="hljs-string">&quot;文本中的地点&quot;</span>),<br>]<br><br><span class="hljs-comment"># 初始化解析器</span><br>output_parser = StructuredOutputParser.from_response_schemas(response_schemas)<br><br><span class="hljs-comment"># 生成的格式提示符</span><br>format_instructions = output_parser.get_format_instructions()<br><span class="hljs-built_in">print</span>(format_instructions)<br><br>template = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">给定下面的文本，找出特定的结构化信息。</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;format_instructions&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">% USER INPUT:</span><br><span class="hljs-string">&#123;user_input&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">YOUR RESPONSE:</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># prompt</span><br>prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;user_input&quot;</span>],<br>    partial_variables=&#123;<span class="hljs-string">&quot;format_instructions&quot;</span>: format_instructions&#125;,<br>    template=template<br>)<br><br>promptValue = prompt.<span class="hljs-built_in">format</span>(user_input=<span class="hljs-string">&quot;张晓明今天在香港坐了2趟地铁。&quot;</span>)<br><span class="hljs-built_in">print</span>(promptValue)<br>llm_output = llm(promptValue)<br><span class="hljs-built_in">print</span>(llm_output)<br><br><span class="hljs-comment"># 使用解析器进行解析生成的内容</span><br><span class="hljs-built_in">print</span>(output_parser.parse(llm_output))<br></code></pre></td></tr></table></figure><p>在这个例子中，我们要求从输入文本中抽取出number、people、place字段，数据类型分别为number、string、string，抽取要求为文本中的数字、人物、地点。注意，ResponseSchema中的数据类型（type）与JSON数据类型一致。</p><p>对两个样例文本进行抽取，抽取结果如下：</p><blockquote><p>输入：张晓明今天在香港坐了2趟地铁。 抽取结果：{'number': 2, 'people':'张晓明', 'place': '香港'}</p></blockquote><blockquote><p>输入：昨天B站14周年的分享会上，B站CEO陈睿对这个指标做了官方的定义，用户观看视频所花费的时间，也就是播放分钟数。抽取结果：{'number': 14, 'people': '陈睿', 'place': 'B站'}</p></blockquote><p>抽取的结果大多符合预期，除了第二句中将B站识别为地点，不太合理。当然，我们写的prompt过于简单，读者可以尝试更多更好的prompt的描述方式，这样也许能提升抽取的效果。</p><h3 id="结构化抽取进阶">结构化抽取进阶</h3><p>在这个例子中，我们使用结构化输出，来实现NLP中的常见任务：<code>命名实体识别（NER）</code>，我们需要从文本中抽取出其中的时间、人物、地点、组织机构等，并以JSON格式输出，每个字段都以列表形式呈现。</p><p>实现的Python代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> langchain.output_parsers <span class="hljs-keyword">import</span> StructuredOutputParser, ResponseSchema<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><br><span class="hljs-comment"># set api key</span><br><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&#x27;sk-xxx&#x27;</span><br><br>llm = OpenAI(model_name=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br><br><span class="hljs-comment"># 告诉他我们生成的内容需要哪些字段，每个字段类型式啥</span><br>response_schemas = [<br>    ResponseSchema(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;array&quot;</span>, name=<span class="hljs-string">&quot;time&quot;</span>, description=<span class="hljs-string">&quot;文本中的日期时间列表&quot;</span>),<br>    ResponseSchema(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;array&quot;</span>, name=<span class="hljs-string">&quot;people&quot;</span>, description=<span class="hljs-string">&quot;文本中的人物列表&quot;</span>),<br>    ResponseSchema(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;array&quot;</span>, name=<span class="hljs-string">&quot;place&quot;</span>, description=<span class="hljs-string">&quot;文本中的地点列表&quot;</span>),<br>    ResponseSchema(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;array&quot;</span>, name=<span class="hljs-string">&quot;org&quot;</span>, description=<span class="hljs-string">&quot;文本中的组织机构列表&quot;</span>),<br>]<br><br><span class="hljs-comment"># 初始化解析器</span><br>output_parser = StructuredOutputParser.from_response_schemas(response_schemas)<br><br><span class="hljs-comment"># 生成的格式提示符</span><br>format_instructions = output_parser.get_format_instructions()<br><span class="hljs-built_in">print</span>(format_instructions)<br><br>template = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">给定下面的文本，找出特定的实体信息，并以结构化数据格式返回。</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;format_instructions&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">% USER INPUT:</span><br><span class="hljs-string">&#123;user_input&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">YOUR RESPONSE:</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># prompt</span><br>prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;user_input&quot;</span>],<br>    partial_variables=&#123;<span class="hljs-string">&quot;format_instructions&quot;</span>: format_instructions&#125;,<br>    template=template<br>)<br><br>promptValue = prompt.<span class="hljs-built_in">format</span>(user_input=<span class="hljs-string">&quot;6月26日，广汽集团在科技日上首次公开展示飞行汽车项目，飞行汽车GOVE完成全球首飞。广汽研究院院长吴坚表示，GOVE可以垂直起降，并搭载双备份多旋翼飞行系统，保障飞行安全。&quot;</span>)<br><span class="hljs-built_in">print</span>(promptValue)<br>llm_output = llm(promptValue)<br><span class="hljs-built_in">print</span>(llm_output)<br><br><span class="hljs-comment"># 使用解析器进行解析生成的内容</span><br><span class="hljs-built_in">print</span>(output_parser.parse(llm_output))<br></code></pre></td></tr></table></figure><p>我们在三个示例文本中进行实验，看看大模型在NER方面的表现：</p><blockquote><p>输入：6月26日周一，乌克兰总统泽连斯基视察了乌克兰军队东线司令部总部，而就在几小时前，俄罗斯宣布控制该国东部顿涅茨克以南的利夫诺波尔。抽取结果：{'time': ['6月26日周一'], 'people': ['泽连斯基'], 'place':['乌克兰军队东线司令部总部', '顿涅茨克', '利夫诺波尔'], 'org':['乌克兰总统', '俄罗斯']}</p></blockquote><blockquote><p>输入：日前，马自达找来梁家辉代言汽车，引发了业内的热议。相信很多人对于马自达的品牌认知来自梁家辉的那部电影。抽取结果：{'time': [], 'people': ['梁家辉'], 'place': [], 'org':['马自达']}</p></blockquote><blockquote><p>输入：6月26日，广汽集团在科技日上首次公开展示飞行汽车项目，飞行汽车GOVE完成全球首飞。广汽研究院院长吴坚表示，GOVE可以垂直起降，并搭载双备份多旋翼飞行系统，保障飞行安全。抽取结果：{'time': ['6月26日'], 'people': ['吴坚'], 'place': [], 'org':['广汽集团', '广汽研究院']}</p></blockquote><p>可以看到，在经过简单的prompt和结构化输出后，大模型的抽取结果大致上令人满意。</p><h3 id="总结">总结</h3><p>本文主要介绍了LangChain的结构化输出，这在我们需要对模型输出结果进行结构化解析时较为有用，同时，我们也能接住结构化输出完成一些常见的NLP的任务，如NER等。</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>LangChain 中文入门教程: <ahref="https://liaokong.gitbook.io/llm-kai-fa-jiao-cheng/">https://liaokong.gitbook.io/llm-kai-fa-jiao-cheng/</a></li><li>Structured output parser: <ahref="https://python.langchain.com/docs/modules/model_io/output_parsers/structured">https://python.langchain.com/docs/modules/model_io/output_parsers/structured</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>LangChain</tag>
      
      <tag>AIGC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（五十六）LangChain入门</title>
    <link href="/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E5%85%AD%EF%BC%89LangChain%E5%85%A5%E9%97%A8/"/>
    <url>/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E5%85%AD%EF%BC%89LangChain%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="langchain简介">LangChain简介</h3><h4 id="背景">背景</h4><p>由于ChatGPT的发行，大模型（Large Language Model,LLM）已经变得非常流行了。也许你可能没有足够的资金和计算资源从头开始训练大模型，但你仍然可以使用大模型来做一些比较酷的事情，比如：</p><ul><li>个人助理：能基于你的数据与外部世界进行互动交流</li><li>对话机器人：适合你个人使用偏好的对话机器人</li><li>分析总结：对文档或代码进行分析和总结</li></ul><p>通过各式各样的API和提示工程（PromptEngineering），大模型正在改变我们创建基于AI开发的产品的方式。这正是为什么在LLM背景下，现在到处都在出现新的开发者工具，这就有了一个新的专业术语：LLMOps（类似的专业术语为DevOps）。</p><p>其中的一个新工具就是LangChain。</p><h4 id="langchain介绍">LangChain介绍</h4><p>LangChain是一个基于语言模型的应用开发框架。它在提升应用方面的作用为：</p><ul><li>数据感知：可以使用其它数据资源来连接一个语言模型</li><li>代理式的：允许一个语言模型与它的环境进行互动</li></ul><p>LangChain的主要道具为：</p><ol type="1"><li>分支（Components）：对如何使用语言模型来进行工作的摘要，每个摘要都有一个执行操作的集合。分支是模块化的，容易使用的，不管你是否在使用LangChain框架的剩余部分。</li><li>现成的链（Chains）：用于完成特定更高阶任务的分支的结构化组装</li></ol><p>现成的链使得它容易上手。对于更复杂的应用和细致的使用案例，分支使得它容易去适应现有的链或创建新的链。</p><h4 id="langchain能做什么">LangChain能做什么</h4><p>LangChain提供了六个主要模块的支持，这些模块按照逐渐增加的复杂性排列如下：</p><ul><li><ahref="https://www.langchain.asia/modules/models">模型（models）</a> :LangChain 支持的各种模型类型和模型集成。</li><li><ahref="https://www.langchain.asia/modules/prompts">提示（prompts）</a> :包括提示管理、提示优化和提示序列化。</li><li><ahref="https://www.langchain.asia/modules/memory">内存（memory）</a> :内存是在链/代理调用之间保持状态的概念。LangChain提供了一个标准的内存接口、一组内存实现及使用内存的链/代理示例。</li><li><ahref="https://www.langchain.asia/modules/indexes">索引（indexes）</a> :与您自己的文本数据结合使用时，语言模型往往更加强大——此模块涵盖了执行此操作的最佳实践。</li><li><a href="https://www.langchain.asia/modules/chains">链（chains）</a>: 链不仅仅是单个 LLM 调用，还包括一系列调用（无论是调用 LLM还是不同的使用工具）。LangChain提供了一种标准的链接口、许多与其它工具的集成。LangChain提供了用于常见应用程序的端到端的链调用。</li><li><ahref="https://www.langchain.asia/modules/agents">代理（agents）</a> :代理涉及 LLM做出行动决策、执行该行动、查看一个观察结果，并重复该过程直到完成。LangChain提供了一个标准的代理接口，一系列可供选择的代理，以及端到端代理的示例。</li></ul><h3 id="langchain快速入门">LangChain快速入门</h3><p>LangChain是一个由<a href="https://twitter.com/hwchase17">HarrisonChase</a>开源的项目，Github访问网址为：<ahref="https://github.com/hwchase17/langchain">https://github.com/hwchase17/langchain</a>.</p><p>LangChain提供了对应的Python第三方模块，在安装前，需确保你的Python版本大于等于3.8.1，小于4.0，安装方式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install langchain<br></code></pre></td></tr></table></figure><p>本文使用的langchain的版本为0.0.201。在开始介绍LangChain的使用前，你还需要有相关大模型的APIkey，比如OpenAI key等。</p><h4 id="模型支持">模型支持</h4><p>LangChain提供了一系列大模型的支持，但首先你需要这些大模型的APIkey。LangChain支持的大模型如下图：</p><p><img src="/img/nlp56_1.png" /></p><ul><li>Proprietarymodels（私有模型）：由拥有大型专业团队和大额AI预算的公司研发的闭源模型，它们通常会比开源模型更大，且表现更好，但API调用较为昂贵。私有模型的提供商有OpenAI,co:here, AI21 Labs, Anthropic等。</li><li>Open-sourceLLMS（开源模型）：比私有模型尺寸更小，能力较差，但它们比私有模型更节省花费。开源模型的代表有BLOOM,LLaMA, Flan-T5, GPT-J等。许多开源模型已由HuggingFace提供了良好的支持。</li><li>Model Hub（模型仓库）：模型储存的仓库，比如Hugging Face等。</li></ul><p>下面为langchain加载不同模型的示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Proprietary LLM from e.g. OpenAI</span><br><span class="hljs-comment"># pip install openai</span><br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br>llm = OpenAI(model_name=<span class="hljs-string">&quot;text-davinci-003&quot;</span>)<br><br><span class="hljs-comment"># Alternatively, open-source LLM hosted on Hugging Face</span><br><span class="hljs-comment"># pip install huggingface_hub</span><br><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> HuggingFaceHub<br>llm = HuggingFaceHub(repo_id=<span class="hljs-string">&quot;google/flan-t5-xl&quot;</span>)<br></code></pre></td></tr></table></figure><p>本文主要基于OpenAI进行演示，因此，如果你有OpenAIkey，你将会有更好的使用langchain的体验。</p><h4 id="prompt管理">Prompt管理</h4><p>大模型的表现取决于Prompt（提示），一个好的Prompt可以使大模型的表现良好，反之，大模型的表现可能会不如人意。</p><p>langchain提供了<code>PromptTemplates</code>,帮助你更好地为不同的分支创建合理的Prompt。比如创建一个普通的Prompt（零样本问题Prompt模板），Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> PromptTemplate<br><br>template = <span class="hljs-string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span><br><br>prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;product&quot;</span>],<br>    template=template,<br>)<br><br><span class="hljs-built_in">print</span>(prompt.<span class="hljs-built_in">format</span>(product=<span class="hljs-string">&quot;colorful socks&quot;</span>))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">What is a good name <span class="hljs-keyword">for</span> a company that makes colorful socks?<br></code></pre></td></tr></table></figure><p>同样地，langchain还提供了few-shot（少样本）文本的Prompt模板，Python示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> PromptTemplate, FewShotPromptTemplate<br><br>examples = [<br>    &#123;<span class="hljs-string">&quot;word&quot;</span>: <span class="hljs-string">&quot;happy&quot;</span>, <span class="hljs-string">&quot;antonym&quot;</span>: <span class="hljs-string">&quot;sad&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;word&quot;</span>: <span class="hljs-string">&quot;tall&quot;</span>, <span class="hljs-string">&quot;antonym&quot;</span>: <span class="hljs-string">&quot;short&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;word&quot;</span>: <span class="hljs-string">&quot;fat&quot;</span>, <span class="hljs-string">&quot;antonym&quot;</span>: <span class="hljs-string">&quot;thin&quot;</span>&#125;,<br>]<br><br>example_template = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">-&gt; Word: &#123;word&#125;</span><br><span class="hljs-string">-&gt; Antonym: &#123;antonym&#125;</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>example_prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;word&quot;</span>, <span class="hljs-string">&quot;antonym&quot;</span>],<br>    template=example_template,<br>)<br><br>few_shot_prompt = FewShotPromptTemplate(<br>    examples=examples,<br>    example_prompt=example_prompt,<br>    prefix=<span class="hljs-string">&quot;Give the antonym of every input&quot;</span>,<br>    suffix=<span class="hljs-string">&quot;\n-&gt;Word: &#123;input&#125;\n-&gt;Antonym:&quot;</span>,<br>    input_variables=[<span class="hljs-string">&quot;input&quot;</span>],<br>    example_separator=<span class="hljs-string">&quot;\n&quot;</span>,<br>)<br><br><span class="hljs-built_in">print</span>(few_shot_prompt.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;big&quot;</span>))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">Give the antonym of every input<br><br>-&gt; Word: happy<br>-&gt; Antonym: sad<br><br><br>-&gt; Word: tall<br>-&gt; Antonym: short<br><br><br>-&gt; Word: fat<br>-&gt; Antonym: thin<br><br><br>-&gt;Word: big<br>-&gt;Antonym:<br></code></pre></td></tr></table></figure><h4 id="链chains">链（Chains）</h4><p>langchain中的链描述了将大模型与其它分支组合起来创建一个应用的过程。比如，LLMChain允许我们对创建的Prompt使用大模型，Python示例代码（需安装openai模块，使用<code>pip install openai</code>）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> LLMChain<br><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> PromptTemplate<br><br><span class="hljs-comment"># set api key</span><br><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&#x27;sk-xxx&#x27;</span><br><br><span class="hljs-comment"># install openai and choose model</span><br>llm = OpenAI(model_name=<span class="hljs-string">&#x27;gpt-3.5-turbo&#x27;</span>)<br><br><span class="hljs-comment"># make prompt</span><br>template = <span class="hljs-string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span><br><br>prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;product&quot;</span>],<br>    template=template,<br>)<br><br><span class="hljs-comment"># chain</span><br>chain = LLMChain(llm=llm, prompt=prompt)<br><br><span class="hljs-comment"># Run the chain only specifying the input variable.</span><br><span class="hljs-built_in">print</span>(chain.run(<span class="hljs-string">&quot;colorful socks&quot;</span>))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">Rainbow Socks Co.<br></code></pre></td></tr></table></figure><p>对少样本提示，Python示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> LLMChain<br><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> PromptTemplate, FewShotPromptTemplate<br><br><span class="hljs-comment"># set api key</span><br><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&#x27;sk-xxx&#x27;</span><br><br><span class="hljs-comment"># install openai and choose model</span><br>llm = OpenAI(model_name=<span class="hljs-string">&#x27;gpt-3.5-turbo&#x27;</span>)<br><br><span class="hljs-comment"># make few-shot prompt</span><br>examples = [<br>    &#123;<span class="hljs-string">&quot;word&quot;</span>: <span class="hljs-string">&quot;happy&quot;</span>, <span class="hljs-string">&quot;antonym&quot;</span>: <span class="hljs-string">&quot;sad&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;word&quot;</span>: <span class="hljs-string">&quot;tall&quot;</span>, <span class="hljs-string">&quot;antonym&quot;</span>: <span class="hljs-string">&quot;short&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;word&quot;</span>: <span class="hljs-string">&quot;fat&quot;</span>, <span class="hljs-string">&quot;antonym&quot;</span>: <span class="hljs-string">&quot;thin&quot;</span>&#125;,<br>]<br><br>example_template = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">-&gt; Word: &#123;word&#125;</span><br><span class="hljs-string">-&gt; Antonym: &#123;antonym&#125;</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>example_prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;word&quot;</span>, <span class="hljs-string">&quot;antonym&quot;</span>],<br>    template=example_template,<br>)<br><br>few_shot_prompt = FewShotPromptTemplate(<br>    examples=examples,<br>    example_prompt=example_prompt,<br>    prefix=<span class="hljs-string">&quot;Give the antonym of every input&quot;</span>,<br>    suffix=<span class="hljs-string">&quot;\n-&gt;Word: &#123;input&#125;\n-&gt;Antonym:&quot;</span>,<br>    input_variables=[<span class="hljs-string">&quot;input&quot;</span>],<br>    example_separator=<span class="hljs-string">&quot;\n&quot;</span>,<br>)<br><br><span class="hljs-comment"># chain</span><br>chain = LLMChain(llm=llm, prompt=few_shot_prompt)<br><br><span class="hljs-comment"># Run the chain only specifying the input variable.</span><br><span class="hljs-built_in">print</span>(chain.run(<span class="hljs-string">&quot;big&quot;</span>))<br><br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">small<br></code></pre></td></tr></table></figure><p>如果我们想要使用之前的LLM的输出作为当前LLM的输入，我们可以使用<code>SimpleSequentialChain</code>，示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> LLMChain, SimpleSequentialChain<br><br><span class="hljs-comment"># set api key</span><br><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&#x27;sk-xxx&#x27;</span><br><br><span class="hljs-comment"># install openai and choose model</span><br>llm = OpenAI(model_name=<span class="hljs-string">&#x27;gpt-3.5-turbo&#x27;</span>)<br><br><span class="hljs-comment"># Define the first chain as in the previous code example</span><br>template = <span class="hljs-string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span><br><br>prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;product&quot;</span>],<br>    template=template,<br>)<br><br>chain = LLMChain(llm=llm, prompt=prompt)<br><br><span class="hljs-comment"># Create a second chain with a prompt template and an LLM</span><br>second_prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;company_name&quot;</span>],<br>    template=<span class="hljs-string">&quot;Write a catchphrase for the following company: &#123;company_name&#125;&quot;</span>,<br>)<br><br>chain_two = LLMChain(llm=llm, prompt=second_prompt)<br><br><span class="hljs-comment"># Combine the first and the second chain</span><br>overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># Run the chain specifying only the input variable for the first chain.</span><br>catchphrase = overall_chain.run(<span class="hljs-string">&quot;colorful socks&quot;</span>)<br><span class="hljs-built_in">print</span>(catchphrase)<br><br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; Entering new  chain...<br>Rainbow Sox Co.<br><span class="hljs-string">&quot;Step up your sock game with Rainbow Sox Co.&quot;</span><br><br>&gt; Finished chain.<br><span class="hljs-string">&quot;Step up your sock game with Rainbow Sox Co.&quot;</span><br></code></pre></td></tr></table></figure><h3 id="langchain高阶使用">LangChain高阶使用</h3><p>langchain还支持更多有趣的高阶使用（通过插件实现），比如文档问答，天气查询，数学计算，基于WikaPedia的问答等等，详细的应用介绍的访问网址为：<ahref="https://python.langchain.com/docs/modules/agents/tools">https://python.langchain.com/docs/modules/agents/tools</a>。本文将介绍文档问答，天气查询，数学计算这三个插件应用。</p><h4 id="文档问答">文档问答</h4><p>众所周知，ChatGPT的知识库截至2021年9月，因此，ChatGPT无法回答这以后的问题，比如我们询问ChatGPT“2022年的诺贝尔文学奖获得者是谁？”，结果如下图：</p><p><img src="/img/nlp56_2.png" /></p><p>langchain的文档阅读允许我们将大模型与外部文档结合起来，对文档内容进行回答。我们在网上寻找有关于2022年的诺贝尔文学奖获得者的信息，比如网址：<ahref="https://www.theguardian.com/books/2022/oct/06/annie-ernaux-wins-the-2022-nobel-prize-in-literature">https://www.theguardian.com/books/2022/oct/06/annie-ernaux-wins-the-2022-nobel-prize-in-literature</a>, 保存为Annie Ernaux.txt，作为ChatGPT的外部输入文档。</p><p>langchain使用文档加载器将数据加载为Document.一个Document是一系列文本片段和相关的元数据。加载文件后有三个主要步骤:</p><ol type="1"><li>将文档分割成块</li><li>为每个文档创建嵌入向量</li><li>在向量库中存储文档和嵌入向量</li></ol><p>默认情况下，LangChain 使用 Chroma作为向量存储来索引和搜索嵌入。因此我们需要先安装chromadb，命令为：`pipinstall chromadb`. </p><p>基于此，我们可以对外部文档进行问答，Python示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> TextLoader<br><span class="hljs-keyword">from</span> langchain.indexes <span class="hljs-keyword">import</span> VectorstoreIndexCreator<br><br><span class="hljs-comment"># set api key</span><br><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&#x27;sk-xxx&#x27;</span><br><br><span class="hljs-comment"># install openai and choose model</span><br>llm = OpenAI(model_name=<span class="hljs-string">&#x27;gpt-3.5-turbo&#x27;</span>)<br><br><span class="hljs-comment"># prompt with no answer</span><br>prompt = <span class="hljs-string">&quot;Who is the winner of 2022 Noble Prize in literature?&quot;</span><br>completion = llm(prompt)<br><span class="hljs-built_in">print</span>(completion)<br><br><span class="hljs-comment"># load other source data</span><br>loader = TextLoader(<span class="hljs-string">&#x27;Annie Ernaux.txt&#x27;</span>)<br>index = VectorstoreIndexCreator().from_loaders([loader])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;index the document.&#x27;</span>)<br><br><span class="hljs-comment"># prompt with answer</span><br>query = <span class="hljs-string">&quot;Who is the winner of 2022 Noble Prize in literature?&quot;</span><br><span class="hljs-built_in">print</span>(index.query_with_sources(query))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">As an AI language model, I <span class="hljs-keyword">do</span> not have the ability to predict future events or outcomes such as the winner of the 2022 Nobel Prize <span class="hljs-keyword">in</span> Literature. Only the Nobel Committee can make such announcements.<br>index the document.<br>&#123;<span class="hljs-string">&#x27;question&#x27;</span>: <span class="hljs-string">&#x27;Who is the winner of 2022 Noble Prize in literature?&#x27;</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27; Annie Ernaux is the winner of the 2022 Nobel Prize in Literature.\n&#x27;</span>, <span class="hljs-string">&#x27;sources&#x27;</span>: <span class="hljs-string">&#x27;Annie Ernaux.txt&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><p>可以看到，原始的ChatGPT对于问题“Who is the winner of 2022 Noble Prizeinliterature?”无法给出准确答案，而加入了外部数据后，再使用文档问答，可以准确地回答出该问题。</p><h4 id="天气查询">天气查询</h4><p>ChatGPT无法查询实时信息，比如天气、股票信息等，以下为ChatGPT回答“上海今天天气如何？”的示例，如下图：</p><p><img src="/img/nlp56_3.png" /></p><p>因此，我们需要用到代理（Agents）工具<code>OpenWeatherMap API</code>来获取天气信息。OpenWeatherMap可以获取全世界各地的天气信息，但首先你需要在它的官网上注册并获取<code>OPENWEATHERMAP_API_KEY</code>。以下为使用代理工具<code>OpenWeatherMap API</code>来回答天气的Python示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> load_tools, initialize_agent, AgentType<br><span class="hljs-keyword">from</span> langchain.utilities <span class="hljs-keyword">import</span> OpenWeatherMapAPIWrapper<br><span class="hljs-keyword">import</span> os<br><br>os.environ[<span class="hljs-string">&quot;OPENWEATHERMAP_API_KEY&quot;</span>] = <span class="hljs-string">&quot;xxx&quot;</span><br>os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&quot;sk-xxx&quot;</span><br><br><span class="hljs-comment"># direct get weather info</span><br>weather = OpenWeatherMapAPIWrapper()<br>weather_data = weather.run(<span class="hljs-string">&quot;shanghai&quot;</span>)<br><span class="hljs-built_in">print</span>(weather_data)<br><br><span class="hljs-comment"># use LLM to do NLU</span><br>llm = OpenAI(temperature=<span class="hljs-number">0</span>)<br>tools = load_tools([<span class="hljs-string">&quot;openweathermap-api&quot;</span>], llm)<br><br>agent_chain = initialize_agent(<br>    tools=tools,<br>    llm=llm,<br>    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,<br>    verbose=<span class="hljs-literal">True</span><br>)<br><br><span class="hljs-comment"># get weather info by natural language</span><br><span class="hljs-built_in">print</span>(agent_chain.run(<span class="hljs-string">&quot;今天上海天气如何？&quot;</span>))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs bash">In shanghai, the current weather is as follows:<br>Detailed status: light rain<br>Wind speed: 5 m/s, direction: 300°<br>Humidity: 77%<br>Temperature: <br>  - Current: 28.6°C<br>  - High: 29.92°C<br>  - Low: 27.71°C<br>  - Feels like: 33.09°C<br>Rain: &#123;<span class="hljs-string">&#x27;1h&#x27;</span>: 0.69&#125;<br>Heat index: None<br>Cloud cover: 75%<br><br><br>&gt; Entering new  chain...<br> 我需要查询上海的天气信息。<br>Action: OpenWeatherMap<br>Action Input: Shanghai,CN<br>Observation: In Shanghai,CN, the current weather is as follows:<br>Detailed status: light rain<br>Wind speed: 5 m/s, direction: 300°<br>Humidity: 77%<br>Temperature: <br>  - Current: 28.6°C<br>  - High: 29.92°C<br>  - Low: 27.71°C<br>  - Feels like: 33.09°C<br>Rain: &#123;<span class="hljs-string">&#x27;1h&#x27;</span>: 0.65&#125;<br>Heat index: None<br>Cloud cover: 75%<br>Thought: 根据上海的天气信息，我可以得出结论。<br>Final Answer: 今天上海有轻度降雨，风速为5米/秒，湿度为77％，温度为28.6°C，最高温度为29.92°C，最低温度为27.71°C，体感温度为33.09°C，降雨量为0.65毫米，云量为75％。<br><br>&gt; Finished chain.<br>今天上海有轻度降雨，风速为5米/秒，湿度为77％，温度为28.6°C，最高温度为29.92°C，最低温度为27.71°C，体感温度为33.09°C，降雨量为0.65毫米，云量为75％。<br></code></pre></td></tr></table></figure><h4 id="数学计算">数学计算</h4><p>langchain提供了代理工具<code>Wolfram Alpha</code>来更好地进行数学计算，首先你需要在WolframAlpha官网上注册并获取WOLFRAM_ALPHA_APPID，然后安装wolframalpha模块，命令为：<code>pip install wolframalpha</code>.示例Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> ssl<br>ssl._create_default_https_context = ssl._create_unverified_context<br><br>os.environ[<span class="hljs-string">&quot;WOLFRAM_ALPHA_APPID&quot;</span>] = <span class="hljs-string">&quot;xxx&quot;</span><br><br><span class="hljs-keyword">from</span> langchain.utilities.wolfram_alpha <span class="hljs-keyword">import</span> WolframAlphaAPIWrapper<br><br>wolfram = WolframAlphaAPIWrapper()<br><br><span class="hljs-comment"># 一元一次方程</span><br><span class="hljs-built_in">print</span>(wolfram.run(<span class="hljs-string">&quot;What is 2x+5 = -3x+7?&quot;</span>))<br><br><span class="hljs-comment"># 一元二次方程</span><br><span class="hljs-built_in">print</span>(wolfram.run(<span class="hljs-string">&quot;What is x^2-5x+4=0?&quot;</span>))<br><br><span class="hljs-comment"># 多项式展开</span><br><span class="hljs-built_in">print</span>(wolfram.run(<span class="hljs-string">&quot;Expand (x+y)^3?&quot;</span>))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">Assumption: 2 x + 5 = -3 x + 7 <br>Answer: x = 2/5<br>Assumption: x^2 - 5 x + 4 = 0 <br>Answer: x = 1<br>Assumption: <span class="hljs-built_in">expand</span> | (x + y)^3 <br>Answer: x^3 + 3 x^2 y + 3 x y^2 + y^3<br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本文主要介绍了LangChain，以及LangChain的模型支持、Prompt管理、链，并在此基础上介绍了三个有趣的工具使用。</p><p>后续笔者将会进一步介绍LangChain的使用，欢迎大家的关注~</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>Getting Started with LangChain: A Beginner’s Guide to BuildingLLM-Powered Applications: <ahref="https://towardsdatascience.com/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c">https://towardsdatascience.com/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c</a></li><li>LangChain Document in Python: <ahref="https://python.langchain.com/docs/get_started/introduction.html">https://python.langchain.com/docs/get_started/introduction.html</a></li><li>LangChain Agents: <ahref="https://python.langchain.com/docs/modules/agents/">https://python.langchain.com/docs/modules/agents/</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>LangChain</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（五十五）tiktoken的使用</title>
    <link href="/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%BA%94%EF%BC%89tiktoken%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%BA%94%EF%BC%89tiktoken%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><code>tiktoken</code>是OpenAI于近期开源的Python第三方模块，该模块主要实现了tokenizer的BPE（Bytepairencoding）算法，并对运行性能做了极大的优化。本文将介绍tiktoken模块的使用。</p><h3 id="tiktoken简介">tiktoken简介</h3><p><code>BPE(Byte pair encoding)</code>算法是NLP中常见的tokenizer方式，关于其介绍和实现原理，读者可参考<ahref="https://zhuanlan.zhihu.com/p/86965595">深入理解NLPSubword算法：BPE、WordPiece、ULM</a>。</p><p><code>tiktoken</code>已开源至Github，访问网址为：<ahref="https://github.com/openai/tiktoken">https://github.com/openai/tiktoken</a>，tiktoken会比其它开源的tokenizer库运行快3-6倍，以下是它与huggingface的tokenizer库的性能比较：</p><figure><img src="/img/nlp55_1.png"alt="不同线程数下tiktoken与hugging face的性能比较" /><figcaption aria-hidden="true">不同线程数下tiktoken与huggingface的性能比较</figcaption></figure><p>以上结果是使用GPT-2tokenizer在1G文本上进行的性能测试，使用的<code>GPT2TokenizerFast</code>来源于<code>tokenizers==0.13.2</code>,<code>transformers==4.24.0</code> , <code>tiktoken==0.2.0</code>。</p><h3 id="简单使用">简单使用</h3><p><code>tiktoken</code>的Encodings（编码方式）用于展示文本是如何被转化为token的。不同的模型使用不同类型的编码方式。<code>tiktoken</code>支持如下三种OpenAI模型的编码方式：</p><table><thead><tr class="header"><th>编码方式</th><th>OpenAI模型</th></tr></thead><tbody><tr class="odd"><td>cl100k_base</td><td>gpt-4, gpt-3.5-turbo, text-embedding-ada-002</td></tr><tr class="even"><td>p50k_base</td><td>Codex模型，如 text-davinci-002, text-davinci-003</td></tr><tr class="odd"><td>r50k_base (或gpt2)</td><td>GPT-3模型，如davinci</td></tr></tbody></table><p>可以通过如下代码来获取模型的编码方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> tiktoken<br><br><span class="hljs-comment"># get encoding name</span><br><span class="hljs-built_in">print</span>(tiktoken.encoding_for_model(<span class="hljs-string">&#x27;gpt-3.5-turbo&#x27;</span>))<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lisp">&lt;Encoding &#x27;cl100k_base&#x27;&gt;<br></code></pre></td></tr></table></figure><p>注意，<code>p50k_base</code>与<code>r50k_base</code>基本类似，在非代码应用中，它们通常会给出相同的token。</p><p><code>cl100k_base</code>中的100k代码该编码方式中的词汇表数量大约为100k，词汇表文件为cl100k_base_vocab.json，下载网址为：<ahref="https://raw.githubusercontent.com/weikang-wang/ChatGPT-Vocabulary/main/cl100k_base_vocab.json">https://raw.githubusercontent.com/weikang-wang/ChatGPT-Vocabulary/main/cl100k_base_vocab.json</a>，词汇数量为100256，如此庞大的词汇数量使得OpenAI模型在多种语言上都有不俗的表现。</p><h3 id="编码与解码">编码与解码</h3><p>编码（encode）是指将文本映射为token的数字列表，解码（decode）是指将token的数字列表转化为文本。参看以下的Python代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> tiktoken<br><br><span class="hljs-comment"># simple test</span><br>enc = tiktoken.get_encoding(<span class="hljs-string">&quot;cl100k_base&quot;</span>)<br><span class="hljs-built_in">print</span>(enc.encode(<span class="hljs-string">&quot;hello world&quot;</span>) == [<span class="hljs-number">15339</span>, <span class="hljs-number">1917</span>])<br><span class="hljs-built_in">print</span>(enc.decode([<span class="hljs-number">15339</span>, <span class="hljs-number">1917</span>]) == <span class="hljs-string">&quot;hello world&quot;</span>)<br><span class="hljs-built_in">print</span>(enc.encode(<span class="hljs-string">&quot;hello &lt;|endoftext|&gt;&quot;</span>, allowed_special=<span class="hljs-string">&quot;all&quot;</span>) == [<span class="hljs-number">15339</span>, <span class="hljs-number">220</span>, <span class="hljs-number">100257</span>])<br><br><span class="hljs-comment"># encode</span><br>tokens = enc.encode(<span class="hljs-string">&quot;tiktoken is great!&quot;</span>)<br><span class="hljs-built_in">print</span>(tokens)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(tokens))<br><br><span class="hljs-comment"># decode</span><br><span class="hljs-built_in">print</span>(enc.decode([<span class="hljs-number">83</span>, <span class="hljs-number">1609</span>, <span class="hljs-number">5963</span>, <span class="hljs-number">374</span>, <span class="hljs-number">2294</span>, <span class="hljs-number">0</span>]))<br><br><span class="hljs-comment"># chinese encode</span><br>tokens = enc.encode(<span class="hljs-string">&quot;大模型是什么？&quot;</span>)<br><span class="hljs-built_in">print</span>(tokens)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(tokens))<br><br><span class="hljs-comment"># chinese decode</span><br><span class="hljs-built_in">print</span>(enc.decode([<span class="hljs-number">27384</span>, <span class="hljs-number">54872</span>, <span class="hljs-number">25287</span>, <span class="hljs-number">21043</span>, <span class="hljs-number">6271</span>, <span class="hljs-number">222</span>, <span class="hljs-number">82696</span>, <span class="hljs-number">11571</span>]))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-literal">True</span><br><span class="hljs-literal">True</span><br><span class="hljs-literal">True</span><br>[<span class="hljs-number">83</span>, <span class="hljs-number">1609</span>, <span class="hljs-number">5963</span>, <span class="hljs-number">374</span>, <span class="hljs-number">2294</span>, <span class="hljs-number">0</span>]<br><span class="hljs-number">6</span><br><span class="hljs-string">tiktoken</span> <span class="hljs-string">is</span> <span class="hljs-string">great!</span><br>[<span class="hljs-number">27384</span>, <span class="hljs-number">54872</span>, <span class="hljs-number">25287</span>, <span class="hljs-number">21043</span>, <span class="hljs-number">6271</span>, <span class="hljs-number">222</span>, <span class="hljs-number">82696</span>, <span class="hljs-number">11571</span>]<br><span class="hljs-number">8</span><br><span class="hljs-string">大模型是什么？</span><br></code></pre></td></tr></table></figure><h3 id="计算token数量">计算token数量</h3><p>OpenAI模型中token数量较为关键，毕竟，OpenAI接口调用的收费方式是按照token数量来的。关于OpenAI接口调用的收费方式，可以参考网站：<ahref="https://openai.com/pricing">https://openai.com/pricing</a>。</p><p>下面是用<code>tiktoken</code>来计算token数量的Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> tiktoken<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">num_tokens_from_string</span>(<span class="hljs-params">string: <span class="hljs-built_in">str</span>, encoding_name: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>    <span class="hljs-comment"># Returns the number of tokens in a text string.</span><br>    encoding = tiktoken.get_encoding(encoding_name)<br>    num_tokens = <span class="hljs-built_in">len</span>(encoding.encode(string))<br>    <span class="hljs-keyword">return</span> num_tokens<br><br><br><span class="hljs-built_in">print</span>(num_tokens_from_string(<span class="hljs-string">&#x27;tiktoken is great!&#x27;</span>, <span class="hljs-string">&#x27;cl100k_base&#x27;</span>))<br><span class="hljs-built_in">print</span>(num_tokens_from_string(<span class="hljs-string">&#x27;大模型是什么？&#x27;</span>, <span class="hljs-string">&#x27;cl100k_base&#x27;</span>))<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs">6<br>8<br></code></pre></td></tr></table></figure><p>在huggingface网站上，已经有人实现了tiktoken的token数量计算，访问网站为：<ahref="https://huggingface.co/spaces/JacobLinCool/tiktoken-calculator">https://huggingface.co/spaces/JacobLinCool/tiktoken-calculator</a>，页面如下：</p><figure><img src="/img/nlp55_2.png" alt="tiktoken的token数量计算" /><figcaption aria-hidden="true">tiktoken的token数量计算</figcaption></figure><p>在对话补全（chatcompletion）场景中计算token数量，以模型<code>gpt-3.5-turbo</code>为例，实现Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> tiktoken<br><span class="hljs-keyword">import</span> openai<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">num_tokens_from_messages</span>(<span class="hljs-params">messages</span>):<br>    <span class="hljs-comment"># Returns the number of tokens used by a list of messages.</span><br>    encoding = tiktoken.encoding_for_model(<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br>    tokens_per_message = <span class="hljs-number">4</span>  <span class="hljs-comment"># every message follows &lt;|start|&gt;&#123;role/name&#125;\n&#123;content&#125;&lt;|end|&gt;\n</span><br>    tokens_per_name = -<span class="hljs-number">1</span>  <span class="hljs-comment"># if there&#x27;s a name, the role is omitted</span><br>    num_tokens = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> message <span class="hljs-keyword">in</span> messages:<br>        num_tokens += tokens_per_message<br>        <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> message.items():<br>            num_tokens += <span class="hljs-built_in">len</span>(encoding.encode(value))<br>            <span class="hljs-keyword">if</span> key == <span class="hljs-string">&quot;name&quot;</span>:<br>                num_tokens += tokens_per_name<br>    num_tokens += <span class="hljs-number">3</span>  <span class="hljs-comment"># every reply is primed with &lt;|start|&gt;assistant&lt;|message|&gt;</span><br>    <span class="hljs-keyword">return</span> num_tokens<br><br>example_messages = [<br>    &#123;<br>        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,<br>        <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful, pattern-following assistant that translates corporate jargon into plain English.&quot;</span>,<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;example_user&quot;</span>,<br>        <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;New synergies will help drive top-line growth.&quot;</span>,<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;example_assistant&quot;</span>,<br>        <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Things working well together will increase revenue.&quot;</span>,<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;example_user&quot;</span>,<br>        <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Let&#x27;s circle back when we have more bandwidth to touch base on opportunities for increased leverage.&quot;</span>,<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;example_assistant&quot;</span>,<br>        <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Let&#x27;s talk later when we&#x27;re less busy about how to do better.&quot;</span>,<br>    &#125;,<br>    &#123;<br>        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>        <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;This late pivot means we don&#x27;t have time to boil the ocean for the client deliverable.&quot;</span>,<br>    &#125;,<br>]<br><br><br><span class="hljs-comment"># example token count from the function defined above</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;num_tokens_from_messages(example_messages)&#125;</span> prompt tokens counted by num_tokens_from_messages().&quot;</span>)<br><span class="hljs-comment"># example token count from the OpenAI API</span><br>openai.api_key = <span class="hljs-string">&quot;&quot;</span><br>response = openai.ChatCompletion.create(<br>    model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>    messages=example_messages,<br>    temperature=<span class="hljs-number">0</span>,<br>    max_tokens=<span class="hljs-number">1</span><br>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;response[<span class="hljs-string">&quot;usage&quot;</span>][<span class="hljs-string">&quot;prompt_tokens&quot;</span>]&#125;</span> prompt tokens counted by the OpenAI API.&#x27;</span>)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">127 </span>prompt tokens counted by num_tokens_from_messages().<br><span class="hljs-symbol">127 </span>prompt tokens counted by the OpenAI API.<br></code></pre></td></tr></table></figure><p>可见，在<code>num_tokens_from_messages</code>中，对于输入messages中的每条message，token数量先加上4，然后对字典中的value值进行token数量统计，如果此时对应的key为name，则token数量减1，因为要忽略role字段的token数量。在模型<code>gpt-3.5-turbo</code>中，<code>num_tokens_from_messages</code>函数与OpenAI对话补全中的token数量计算方式是一致的。</p><h3 id="总结">总结</h3><p>本文介绍了<code>tiktoken</code>模型和它的简单使用，以及token数量计算方式。</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>深入理解NLP Subword算法：BPE、WordPiece、ULM: <ahref="https://zhuanlan.zhihu.com/p/86965595">https://zhuanlan.zhihu.com/p/86965595</a></li><li>tiktoken的Github网址：<ahref="https://github.com/openai/tiktoken">https://github.com/openai/tiktoken</a></li><li>tiktoken-calculator: <ahref="https://huggingface.co/spaces/JacobLinCool/tiktoken-calculator">https://huggingface.co/spaces/JacobLinCool/tiktoken-calculator</a></li><li>How_to_count_tokens_with_tiktoken.ipynb: <ahref="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb">https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>tiktoken</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（五十四）在Keras中使用英文Roberta模型实现文本分类</title>
    <link href="/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E5%9B%9B%EF%BC%89%E5%9C%A8Keras%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%8B%B1%E6%96%87Roberta%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    <url>/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E5%9B%9B%EF%BC%89%E5%9C%A8Keras%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%8B%B1%E6%96%87Roberta%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>英文Roberta模型是2019年Facebook在论文<ahref="https://arxiv.org/pdf/1907.11692.pdf">RoBERTa: A RobustlyOptimized BERT PretrainingApproach</a>中新提出的预训练模型，其目的是改进BERT模型存在的一些问题，当时也刷新了一众NLP任务的榜单，达到SOTA效果，其模型和代码已开源，放在Github中的<code>fairseq</code>项目中。众所周知，英文Roberta模型使用Torch框架训练的，因此，其torch版本模型最为常见。</p><p>当然，torch模型也是可以转化为tensorflow模型的。本文将会介绍如何将原始torch版本的英文Roberta模型转化为tensorflow版本模型，并且Keras中使用tensorflow版本模型实现英语文本分类。</p><p>项目结构如下图所示：</p><figure><img src="/img/nlp54_1.png" alt="项目结构图" /><figcaption aria-hidden="true">项目结构图</figcaption></figure><h3 id="模型转化">模型转化</h3><p>本项目首先会将原始torch版本的英文Roberta模型转化为tensorflow版本模型，该部分代码主要参考Github项目<ahref="https://github.com/midori1/keras_roberta">keras_roberta</a>。</p><p>首先需下载Facebook发布在<code>fairseq</code>项目中的robertabase模型，其访问网址为: <ahref="https://github.com/pytorch/fairseq/blob/main/examples/roberta/README.md">https://github.com/pytorch/fairseq/blob/main/examples/roberta/README.md</a>。</p><figure><img src="/img/nlp54_2.png" alt="Roberta模型" /><figcaption aria-hidden="true">Roberta模型</figcaption></figure><p>运行<code>convert_roberta_to_tf.py</code>脚本，将torch模型转化为tensorflow模型。具体代码不在此给出，可以参考文章后续给出的Github项目地址。</p><p>在模型的tokenizer方面，将RobertaTokenizer改为GPT2Tokenizer，因为RobertaTokenizer是继承自GPT2Tokenizer的，两者相似性很高。测试原始torch模型和tensorflow模型的表现，代码如下（tf_roberta_demo.py）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> keras_roberta.roberta <span class="hljs-keyword">import</span> build_bert_model<br><span class="hljs-keyword">from</span> keras_roberta.tokenizer <span class="hljs-keyword">import</span> RobertaTokenizer<br><span class="hljs-keyword">from</span> fairseq.models.roberta <span class="hljs-keyword">import</span> RobertaModel <span class="hljs-keyword">as</span> FairseqRobertaModel<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> argparse<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    roberta_path = <span class="hljs-string">&#x27;roberta-base&#x27;</span><br>    tf_roberta_path = <span class="hljs-string">&#x27;tf_roberta_base&#x27;</span><br>    tf_ckpt_name = <span class="hljs-string">&#x27;tf_roberta_base.ckpt&#x27;</span><br>    vocab_path = <span class="hljs-string">&#x27;keras_roberta&#x27;</span><br><br>    config_path = os.path.join(tf_roberta_path, <span class="hljs-string">&#x27;bert_config.json&#x27;</span>)<br>    checkpoint_path = os.path.join(tf_roberta_path, tf_ckpt_name)<br>    <span class="hljs-keyword">if</span> os.path.splitext(checkpoint_path)[-<span class="hljs-number">1</span>] != <span class="hljs-string">&#x27;.ckpt&#x27;</span>:<br>        checkpoint_path += <span class="hljs-string">&#x27;.ckpt&#x27;</span><br><br>    gpt_bpe_vocab = os.path.join(vocab_path, <span class="hljs-string">&#x27;encoder.json&#x27;</span>)<br>    gpt_bpe_merge = os.path.join(vocab_path, <span class="hljs-string">&#x27;vocab.bpe&#x27;</span>)<br>    roberta_dict = os.path.join(roberta_path, <span class="hljs-string">&#x27;dict.txt&#x27;</span>)<br><br>    tokenizer = RobertaTokenizer(gpt_bpe_vocab, gpt_bpe_merge, roberta_dict)<br>    model = build_bert_model(config_path, checkpoint_path, roberta=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 建立模型，加载权重</span><br><br>    <span class="hljs-comment"># 编码测试</span><br>    text1 = <span class="hljs-string">&quot;hello, world!&quot;</span><br>    text2 = <span class="hljs-string">&quot;This is Roberta!&quot;</span><br>    sep = [tokenizer.sep_token]<br>    cls = [tokenizer.cls_token]<br>    <span class="hljs-comment"># 1. 先用&#x27;bpe_tokenize&#x27;将文本转换成bpe tokens</span><br>    tokens1 = cls + tokenizer.bpe_tokenize(text1) + sep<br>    tokens2 = sep + tokenizer.bpe_tokenize(text2) + sep<br>    <span class="hljs-comment"># 2. 最后转换成id</span><br>    token_ids1 = tokenizer.convert_tokens_to_ids(tokens1)<br>    token_ids2 = tokenizer.convert_tokens_to_ids(tokens2)<br>    token_ids = token_ids1 + token_ids2<br>    segment_ids = [<span class="hljs-number">0</span>] * <span class="hljs-built_in">len</span>(token_ids1) + [<span class="hljs-number">1</span>] * <span class="hljs-built_in">len</span>(token_ids2)<br>    <span class="hljs-built_in">print</span>(token_ids)<br>    <span class="hljs-built_in">print</span>(segment_ids)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\n ===== tf model predicting =====\n&#x27;</span>)<br>    our_output = model.predict([np.array([token_ids]), np.array([segment_ids])])<br>    <span class="hljs-built_in">print</span>(our_output)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\n ===== torch model predicting =====\n&#x27;</span>)<br>    roberta = FairseqRobertaModel.from_pretrained(roberta_path)<br>    roberta.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># disable dropout</span><br><br>    input_ids = roberta.encode(text1, text2).unsqueeze(<span class="hljs-number">0</span>)  <span class="hljs-comment"># batch of size 1</span><br>    <span class="hljs-built_in">print</span>(input_ids)<br>    their_output = roberta.model(input_ids, features_only=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]<br>    <span class="hljs-built_in">print</span>(their_output)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs subunit">[0, 42891, 6, 232, 328, 2, 2, 713, 16, 1738, 102, 328, 2]<br>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]<br><br> ===== tf model predicting =====<br>[[[<span class="hljs-string">-0</span>.01123665  0.05132651 <span class="hljs-string">-0</span>.02170264 ... <span class="hljs-string">-0</span>.03562857 <span class="hljs-string">-0</span>.02836962<br>   <span class="hljs-string">-0</span>.00519008]<br>  [ 0.04382067  0.07045364 <span class="hljs-string">-0</span>.00431021 ... <span class="hljs-string">-0</span>.04662359 <span class="hljs-string">-0</span>.10770167<br>    0.1121687 ]<br>  [ 0.06198474  0.05240346  0.11088232 ... <span class="hljs-string">-0</span>.08883709 <span class="hljs-string">-0</span>.02932207<br>   <span class="hljs-string">-0</span>.12898633]<br>  ...<br>  [<span class="hljs-string">-0</span>.00229368  0.045834    0.00811818 ... <span class="hljs-string">-0</span>.11751424 <span class="hljs-string">-0</span>.06718166<br>    0.04085271]<br>  [<span class="hljs-string">-0</span>.08509324 <span class="hljs-string">-0</span>.27506304 <span class="hljs-string">-0</span>.02425355 ... <span class="hljs-string">-0</span>.24215901 <span class="hljs-string">-0</span>.15481825<br>    0.17167582]<br>  [<span class="hljs-string">-0</span>.05180666  0.06384835 <span class="hljs-string">-0</span>.05997407 ... <span class="hljs-string">-0</span>.09398533 <span class="hljs-string">-0</span>.05159672<br>   <span class="hljs-string">-0</span>.03988626]]]<br><br> ===== torch model predicting =====<br>tensor([[    0, 42891,     6,   232,   328,     2,     2,   713,    16,  1738,<br>           102,   328,     2]])<br>tensor([[[<span class="hljs-string">-0</span>.0525,  0.0818, <span class="hljs-string">-0</span>.0170,  ..., <span class="hljs-string">-0</span>.0546, <span class="hljs-string">-0</span>.0569, <span class="hljs-string">-0</span>.0099],<br>         [<span class="hljs-string">-0</span>.0765, <span class="hljs-string">-0</span>.0568, <span class="hljs-string">-0</span>.1400,  ..., <span class="hljs-string">-0</span>.2612, <span class="hljs-string">-0</span>.0455,  0.2975],<br>         [<span class="hljs-string">-0</span>.0142,  0.1184,  0.0530,  ..., <span class="hljs-string">-0</span>.0844,  0.0199,  0.1340],<br>         ...,<br>         [<span class="hljs-string">-0</span>.0019,  0.1263, <span class="hljs-string">-0</span>.0787,  ..., <span class="hljs-string">-0</span>.3986, <span class="hljs-string">-0</span>.0626,  0.1870],<br>         [ 0.0127, <span class="hljs-string">-0</span>.2116,  0.0696,  ..., <span class="hljs-string">-0</span>.1622, <span class="hljs-string">-0</span>.1265,  0.0986],<br>         [<span class="hljs-string">-0</span>.0473,  0.0748, <span class="hljs-string">-0</span>.0419,  ..., <span class="hljs-string">-0</span>.0892, <span class="hljs-string">-0</span>.0595, <span class="hljs-string">-0</span>.0281]]],<br>       grad_fn=&lt;TransposeBackward0&gt;)<br></code></pre></td></tr></table></figure><p>可以看到，两者在tokenize时的token_ids是一致的。</p><h3 id="英语文本分类">英语文本分类</h3><p>接着我们需要看下转化为的tensorflow版本的Roberta模型在英语文本分类数据集上的效果了。</p><p>这里我们使用的是GLUE数据集中的<code>SST-2</code>。<code>SST-2</code>(TheStanford SentimentTreebank，斯坦福情感树库)，单句子分类任务，包含电影评论中的句子和它们情感的人类注释。这项任务是给定句子的情感，类别分为两类正面情感（positive，样本标签对应为1）和负面情感（negative，样本标签对应为0），并且只用句子级别的标签。也就是，本任务也是一个二分类任务，针对句子级别，分为正面和负面情感。关于该数据集的具体介绍可参考网址：<ahref="https://nlp.stanford.edu/sentiment/index.html">https://nlp.stanford.edu/sentiment/index.html</a>。</p><p><code>SST-2</code>数据集中训练集样本数量为67349，验证集样本数量为872，测试集样本数量为1820，数据存储格式为tsv，读取数据的代码如下:（utils/load_data.py）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_model_data</span>(<span class="hljs-params">file_path</span>):<br>    data = []<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        lines = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br>    <span class="hljs-keyword">for</span> i, line <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(lines):<br>        <span class="hljs-keyword">if</span> i:<br>            items = line.split(<span class="hljs-string">&#x27;\t&#x27;</span>)<br>            label = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>] <span class="hljs-keyword">if</span> <span class="hljs-built_in">int</span>(items[<span class="hljs-number">1</span>]) <span class="hljs-keyword">else</span> [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]<br>            data.append([label, items[<span class="hljs-number">0</span>]])<br>    <span class="hljs-keyword">return</span> data<br></code></pre></td></tr></table></figure><p>在tokenizer部分，我们采用GTP2Tokenizer，该部分代码如下（utils/roberta_tokenizer.py）:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># roberta tokenizer function for text pair</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenizer_encode</span>(<span class="hljs-params">tokenizer, text, max_seq_length</span>):<br>    sep = [tokenizer.sep_token]<br>    cls = [tokenizer.cls_token]<br>    <span class="hljs-comment"># 1. 先用&#x27;bpe_tokenize&#x27;将文本转换成bpe tokens</span><br>    tokens1 = cls + tokenizer.bpe_tokenize(text) + sep<br>    <span class="hljs-comment"># 2. 最后转换成id</span><br>    token_ids = tokenizer.convert_tokens_to_ids(tokens1)<br>    segment_ids = [<span class="hljs-number">0</span>] * <span class="hljs-built_in">len</span>(token_ids)<br>    pad_length = max_seq_length - <span class="hljs-built_in">len</span>(token_ids)<br>    <span class="hljs-keyword">if</span> pad_length &gt;= <span class="hljs-number">0</span>:<br>        token_ids += [<span class="hljs-number">0</span>] * pad_length<br>        segment_ids += [<span class="hljs-number">0</span>] * pad_length<br>    <span class="hljs-keyword">else</span>:<br>        token_ids = token_ids[:max_seq_length]<br>        segment_ids = segment_ids[:max_seq_length]<br><br>    <span class="hljs-keyword">return</span> token_ids, segment_ids<br></code></pre></td></tr></table></figure><p>创建模型如下（model_train.py）:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 构建模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_cls_model</span>():<br>    <span class="hljs-comment"># Roberta model</span><br>    roberta_model = build_bert_model(CONFIG_FILE_PATH, CHECKPOINT_FILE_PATH, roberta=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 建立模型，加载权重</span><br><br>    <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> roberta_model.layers:<br>        layer.trainable = <span class="hljs-literal">True</span><br><br>    cls_layer = Lambda(<span class="hljs-keyword">lambda</span> x: x[:, <span class="hljs-number">0</span>])(roberta_model.output)    <span class="hljs-comment"># 取出[CLS]对应的向量用来做分类</span><br>    p = Dense(<span class="hljs-number">2</span>, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>)(cls_layer)     <span class="hljs-comment"># 多分类</span><br><br>    model = Model(roberta_model.<span class="hljs-built_in">input</span>, p)<br>    model.<span class="hljs-built_in">compile</span>(<br>        loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>,<br>        optimizer=Adam(<span class="hljs-number">1e-5</span>),   <span class="hljs-comment"># 用足够小的学习率</span><br>        metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>]<br>    )<br><br>    <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></table></figure><p>模型参数如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型参数配置</span><br>EPOCH = <span class="hljs-number">10</span>              <span class="hljs-comment"># 训练轮次</span><br>BATCH_SIZE = <span class="hljs-number">64</span>         <span class="hljs-comment"># 批次数量</span><br>MAX_SEQ_LENGTH = <span class="hljs-number">80</span>     <span class="hljs-comment"># 最大长度</span><br></code></pre></td></tr></table></figure><p>模型训练完后，在验证数据集上的准确率（accuracy）为0.9415，F1值为0.9415，取得了不错效果。</p><h3 id="模型预测">模型预测</h3><p>我们对新样本进行模型预测（model_predict.py），预测结果如下：</p><blockquote><p>Awesome movie for everyone to watch. Animation was flawless. label:1, prob: 0.9999607</p></blockquote><blockquote><p>I almost balled my eyes out 5 times. Almost. Beautiful movie, veryinspiring. label: 1, prob: 0.9999519</p></blockquote><blockquote><p>Not even worth it. It's a movie that's too stupid for adults, and toocrappy for everyone. Skip if you're not 13, or even if you are. label:0, prob: 0.9999864</p></blockquote><h3 id="总结">总结</h3><p>本文介绍了如何将原始torch版本的英文Roberta模型转化为tensorflow版本模型，并且Keras中使用tensorflow版本模型实现英语文本分类。</p><p>本项目代码已放至Github，网址为:<ahref="https://github.com/percent4/keras_roberta_text_classificaiton">https://github.com/percent4/keras_roberta_text_classificaiton</a>。</p><p>感谢阅读，如有任何问题，欢迎大家交流~</p><h3 id="参考网址">参考网址</h3><ol type="1"><li><code>fairseq</code>: https://github.com/pytorch/fairseq</li><li><code>GLUE tasks</code>: https://gluebenchmark.com/tasks</li><li><code>SST-2</code>:https://nlp.stanford.edu/sentiment/index.html</li><li><code>keras_roberta</code>:https://github.com/midori1/keras_roberta</li><li><code>Roberta paper</code>:https://arxiv.org/pdf/1907.11692.pdf</li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>文本分类</tag>
      
      <tag>Roberta</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（五十三）抽取式词义消歧（WSD）</title>
    <link href="/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%B8%89%EF%BC%89%E6%8A%BD%E5%8F%96%E5%BC%8F%E8%AF%8D%E4%B9%89%E6%B6%88%E6%AD%A7%EF%BC%88WSD%EF%BC%89/"/>
    <url>/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%B8%89%EF%BC%89%E6%8A%BD%E5%8F%96%E5%BC%8F%E8%AF%8D%E4%B9%89%E6%B6%88%E6%AD%A7%EF%BC%88WSD%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在文章<ahref="https://percent4.github.io/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%B9%9D%EF%BC%89%E8%AF%8D%E4%B9%89%E6%B6%88%E5%B2%90%EF%BC%88WSD%EF%BC%89%E7%9A%84%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%9E%E7%8E%B0/">NLP入门（九）词义消岐（WSD）的简介与实现</a>中，笔者介绍了词义消歧的含义以及如何使用简单的算法来实现词义消歧。在本文中，笔者将介绍如何使用抽取式NLP模型来实现词义消歧（WSD），模型灵感来源于论文<ahref="https://www.researchgate.net/publication/359392427_ExtEnD_Extractive_Entity_Disambiguation">ExtEnD:Extractive Entity Disambiguation</a>。</p><p>所谓词义消岐，指的是在特定的语境中，识别出某个歧义词的正确含义，即通常所说的一词多义。比如，<strong>苹果</strong>一词在句子<code>我今天吃了一个苹果</code>和句子<code>苹果手机好用吗？</code>中的含义是不同的，词义消歧需要对同一词语判断其在特定语境下的含义。词义消歧与实体链接有分别又有联系，后面将会介绍。</p><p>在通常的NLP模型中，常常会把词义消歧任务当做文本分类去完成，取得了不错的效果。但论文<ahref="https://www.researchgate.net/publication/359392427_ExtEnD_Extractive_Entity_Disambiguation">ExtEnD:Extractive EntityDisambiguation</a>提出了一种新的范式，它通过抽取式NLP模型（即阅读理解模型）来完成词义消歧，也取得了不错的效果。</p><h3 id="词义消歧与实体链接">词义消歧与实体链接</h3><p>应当说，<code>词义消歧</code>属于<code>实体链接</code>中的一部分。在实体链接（EntityLinking）任务中，一般分为三个阶段：</p><ul><li>实体识别</li><li>候选词生成</li><li>候选词匹配</li></ul><p>在词义消歧中，同一词语的不同义项会作为候选词生成，在第三阶段的候选词匹配找到最接近的那个义项。我们以实体<code>本草纲目</code>为例，其在百度百科中共有15个义项，如下：</p><figure><img src="/img/nlp53_1.png" alt="百度百科中的本草纲目义项" /><figcaption aria-hidden="true">百度百科中的本草纲目义项</figcaption></figure><p>在特定的句子中，本草纲目的具体含义是可以确定的，看下面的例子：</p><figure><img src="/img/nlp53_2.png" alt="实体链接例子" /><figcaption aria-hidden="true">实体链接例子</figcaption></figure><p>在上述句子中，<code>本草纲目</code>的正确义项应该是中医典籍，这是一个典型的实体链接任务，也可当作词义消歧任务。</p><p>个人观点是，实体链接一般是将<code>实体</code>链接至图谱中的正确实体，而词义消歧稍微有点区别，绝大多数词语是图谱中的实体，但也有少部分仅仅是词语，而不是实体，比如汉语词语清风、指针等。因此，词义消歧可以通过实体链接很好地实现，但本文仅讨论如何通过抽取式NLP模型（新的范式）来实现词义消歧，以期该模型能在新的数据上有较好的表现。</p><h3 id="数据介绍">数据介绍</h3><p>截止今日，笔者通过假期时间，共构建了26个词语，327个义项，2889条标注样本。绝大多数样本均来自于百度百科。每个样本均会给出文本、mention（待消歧词语）、正确义项以及url（正确义项对应网址），比如：</p><table><thead><tr class="header"><th>文本</th><th>mention</th><th>正确义项</th><th>url</th></tr></thead><tbody><tr class="odd"><td>药圣李时珍和他的《本草纲目》</td><td>本草纲目</td><td>中医典籍</td><td>https://baike.baidu.com/item/本草纲目/15342</td></tr></tbody></table><p>将标注数据划分为训练集和测试集，比例为8:2，训练集共有个2233样本，测试集共有656个样本。</p><p>模型输入如下图：</p><figure><img src="/img/nlp53_3.png" alt="模型输入" /><figcaption aria-hidden="true">模型输入</figcaption></figure><p>文本中的mention需要用特殊符号标识出来，比如用<code>&lt;e&gt;</code>和<code>&lt;/e&gt;</code>标识，候选集集合组合输入为下一句，将<code>&lt;/ec&gt;</code>标识添加至每个义项的结尾。</p><h3 id="模型">模型</h3><p>一般使用<code>文本多分类</code>或者<code>文本多标签文本</code>这个模型范式来进行正确义项匹配。本文借鉴<code>Sapienza NLP Group, Sapienza University of Rome</code>在ACL2022论文<ahref="https://www.researchgate.net/publication/359392427_ExtEnD_Extractive_Entity_Disambiguation">《ExtEnD:Extractive EntityDisambiguation》</a>中给出的抽取式模型，使用较为简单的阅读理解模型（MRC）来实现。模型结构如下图所示：</p><figure><img src="/img/nlp53_4.png" alt="抽取式词义消歧模型" /><figcaption aria-hidden="true">抽取式词义消歧模型</figcaption></figure><p>对标注数据进行模型训练，文本最大长度为500，batchsize取16，训练12轮次，学习率取0.00001，在测试集上的<code>Exact Match</code>为0.9029。</p><h3 id="模型预测">模型预测</h3><h4 id="在原有词语义项上的预测结果">1. 在原有词语义项上的预测结果</h4><p>我们对标注过的词语<code>苹果</code>进行预测，其百度百科义项为：</p><p><img src="/img/nlp53_5.png" /></p><p>随便选取两个网上的句子进行消歧，结果如下：</p><blockquote><p>文本：【苹果的做法大全_苹果怎么做好吃_菜谱大全】_下厨房正确义项：蔷薇科苹果属植物</p></blockquote><blockquote><p>苹果2022财年Q2业绩:手机业务增长亮眼 转型初见成效-股票...正确义项：苹果产品公司</p></blockquote><h4 id="在新词语义项上的预测结果">2. 在新词语义项上的预测结果</h4><p>我们对未标注过的词语<code>南京</code>进行预测，其百度百科义项为：</p><p><img src="/img/nlp53_6.png" /></p><p>随便选取两个网上的句子进行消歧，结果如下：</p><blockquote><p>文本：南京的饮食以金陵菜著名，金陵菜是指以南京为中心，一直延伸到江西九江的菜系，是苏菜的四大代表菜之一。正确义项：江苏省辖地级市、省会</p></blockquote><blockquote><p>文本：影片制片人莱昂西斯是在2004年萌发拍摄纪录片《南京》的念头的。正确义项：美国2007年雨果·阿姆斯特朗主演的电影</p></blockquote><p>我们对未标注过的词语<code>平凡的世界</code>进行预测，其百度百科义项为：</p><p><img src="/img/nlp53_7.png" /></p><p>随便选取两个网上的句子进行消歧，结果如下：</p><blockquote><p>文本：《平凡的世界》:永恒的魅力--文史--中国作家网正确义项：路遥著长篇小说</p></blockquote><blockquote><p>文本：《平凡的世界》的主演是谁正确义项：2015年王雷、佟丽娅、袁弘主演电视剧</p></blockquote><p>我们对未标注过的词语<code>碧血剑</code>进行预测，其百度百科义项为：</p><p><img src="/img/nlp53_8.png" /></p><p>随便选取两个网上的句子进行消歧，结果如下：</p><blockquote><p>文本：《碧血剑》是当代作家金庸先生的长篇武侠小说。大家都知道金庸老先生的著名小说都被翻拍成了电视剧，《碧血剑》也不例外。正确义项：金庸创作长篇小说</p></blockquote><blockquote><p>文本：2000年版《碧血剑》是由李添胜监制，林家栋、佘诗曼、江华领衔主演的古装武侠电视剧。故事还原度并不是很高，这部剧中我真的很喜欢佘诗曼扮演的阿九啊！正确义项：2000年香港TVB版林家栋主演电视剧</p></blockquote><h3 id="总结">总结</h3><p>本项目已经开源至Github，网址为：<ahref="https://github.com/percent4/WSD_With_Text_Extraction">https://github.com/percent4/WSD_With_Text_Extraction</a>。</p><p>如有任何疑问，欢迎交流~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>词义消歧</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（五十二）在BERT模型中添加自己的词汇</title>
    <link href="/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%BA%8C%EF%BC%89%E5%9C%A8BERT%E6%A8%A1%E5%9E%8B%E4%B8%AD%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E8%AF%8D%E6%B1%87/"/>
    <url>/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%BA%8C%EF%BC%89%E5%9C%A8BERT%E6%A8%A1%E5%9E%8B%E4%B8%AD%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E8%AF%8D%E6%B1%87/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>不论是Tensorflow版本或者PyTorch版本的NLP预训练模型，我们都会在模型文件中看到<code>vocab.txt</code>文件，这个文件就是该预训练模型的词汇表。通常，模型本身都会自带词汇表文件，这是在模型预训练的时候训练得到的词汇表，具有代表性，一般不可随意更改。同时<code>vocab.txt</code>文件中也保留了一定数量的未使用（unuserd）词汇，用于添加新词。</p><figure><img src="/img/nlp52_1.png" alt="BERT中文版预训练模型" /><figcaption aria-hidden="true">BERT中文版预训练模型</figcaption></figure><p>本文将介绍如何在BERT模型中添加自己的词汇，其它预训练模型原理相同。</p><p>我们将通过三个常见的模块来介绍，分别是<code>keras-bert</code>，<code>transformers</code>,<code>tokenizer</code>。其中<code>keras-bert</code>是Keras框架实现的模块，<code>transformers</code>主要是PyTorch实现的模块，也可用于TensorFlow2.0版本以上，<code>tokenizer</code>是一个专门用于切分词（tokenize）的模块。</p><p>通常，往预训练模型中添加新词有两种实现方式，如下：</p><ul><li>直接在词汇表vocab.txt中替换[unused]</li><li>通过重构词汇矩阵来增加新词</li></ul><h3 id="keras-bert">keras-bert</h3><p>在<code>keras-bert</code>模块中，首先观察不添加新词时的切分词结果。我们以特殊标识<code>jjj</code>为例，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> Tokenizer<br><br><span class="hljs-comment"># 加载词典</span><br>dict_path = <span class="hljs-string">&#x27;./chinese_L-12_H-768_A-12/vocab.txt&#x27;</span><br>token_dict = &#123;&#125;<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(dict_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> reader:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> reader:<br>        token = line.strip()<br>        token_dict[token] = <span class="hljs-built_in">len</span>(token_dict)<br><br>tokenizer = Tokenizer(token_dict)<br>text = <span class="hljs-string">&#x27;jjj今天天气很好。&#x27;</span><br>tokens = tokenizer.tokenize(text)<br><span class="hljs-built_in">print</span>(tokens)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[&#x27;[<span class="hljs-name">CLS</span>]&#x27;, <span class="hljs-symbol">&#x27;jj</span>&#x27;, &#x27;##j&#x27;, <span class="hljs-symbol">&#x27;今</span>&#x27;, <span class="hljs-symbol">&#x27;天</span>&#x27;, <span class="hljs-symbol">&#x27;天</span>&#x27;, <span class="hljs-symbol">&#x27;气</span>&#x27;, <span class="hljs-symbol">&#x27;很</span>&#x27;, <span class="hljs-symbol">&#x27;好</span>&#x27;, <span class="hljs-symbol">&#x27;。</span>&#x27;, &#x27;[<span class="hljs-name">SEP</span>]&#x27;]<br></code></pre></td></tr></table></figure><p>可以看到，如果直接按照原有模型词汇表，则不会将特殊标识<code>jjj</code>作为整体切分，而是按照现有切分逻辑进行切分。</p><p>我们将模型词汇表文件中的<code>[unused1]</code>替换成<code>jjj</code>，则切分结果如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[&#x27;[<span class="hljs-name">CLS</span>]&#x27;, <span class="hljs-symbol">&#x27;jjj</span>&#x27;, <span class="hljs-symbol">&#x27;今</span>&#x27;, <span class="hljs-symbol">&#x27;天</span>&#x27;, <span class="hljs-symbol">&#x27;天</span>&#x27;, <span class="hljs-symbol">&#x27;气</span>&#x27;, <span class="hljs-symbol">&#x27;很</span>&#x27;, <span class="hljs-symbol">&#x27;好</span>&#x27;, <span class="hljs-symbol">&#x27;。</span>&#x27;, &#x27;[<span class="hljs-name">SEP</span>]&#x27;]<br></code></pre></td></tr></table></figure><p>或者不修改<code>vocab.txt</code>，在上述代码中将token_dict中将key<code>[unused1]</code>替换成<code>jjj</code>，比如：<code>token_dict['jjj'] = token_dict.pop('[unused1]')</code>。</p><p><code>bert4keras</code>模块添加新词同理。</p><h3 id="transformers">transformers</h3><p><code>transformers</code>模块添加新词也是上述两种方式，在词汇表vocab.txt中替换[unused]这种方式不再赘述，介绍如何通过重构词汇矩阵来增加新词，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer<br><br>tokenizer = BertTokenizer(<span class="hljs-string">&quot;./bert-base-chinese/vocab.txt&quot;</span>)<br>text = <span class="hljs-string">&#x27;jjj今天天气很好。&#x27;</span><br>tokens = tokenizer.tokenize(text)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;未添加新词前:&#x27;</span>, tokens)<br>tokenizer.add_tokens(<span class="hljs-string">&#x27;jjj&#x27;</span>)<br>tokens = tokenizer.tokenize(text)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;添加新词后:&#x27;</span>, tokens)<br></code></pre></td></tr></table></figure><p>输出结果结果如下：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs less">未添加新词前: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;jj&#x27;</span>, <span class="hljs-string">&#x27;##j&#x27;</span>, <span class="hljs-string">&#x27;今&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;气&#x27;</span>, <span class="hljs-string">&#x27;很&#x27;</span>, <span class="hljs-string">&#x27;好&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>]</span><br>添加新词后: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;jjj&#x27;</span>, <span class="hljs-string">&#x27;今&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;气&#x27;</span>, <span class="hljs-string">&#x27;很&#x27;</span>, <span class="hljs-string">&#x27;好&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>]</span><br></code></pre></td></tr></table></figure><p>需要注意的是，加载的模型需要略作调整，如下：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">model.resize<span class="hljs-constructor">_token_embeddings(<span class="hljs-params">len</span>(<span class="hljs-params">tokenizer</span>)</span>)<br></code></pre></td></tr></table></figure><h3 id="tokenizer">tokenizer</h3><p><code>tokenizer</code>模块添加新词也是上述两种方式，在词汇表vocab.txt中替换[unused]这种方式不再赘述，介绍如何通过重构词汇矩阵来增加新词，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> tokenizers <span class="hljs-keyword">import</span> BertWordPieceTokenizer<br>tokenizer = BertWordPieceTokenizer(<span class="hljs-string">&quot;./bert-base-chinese/vocab.txt&quot;</span>, lowercase=<span class="hljs-literal">True</span>)<br><br>context = <span class="hljs-string">&#x27;今天jjj天气很好。&#x27;</span><br>tokenized_context = tokenizer.encode(context)<br><span class="hljs-built_in">print</span>(tokenized_context.ids)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(tokenized_context.ids))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;未添加新词前:&quot;</span>, [tokenizer.id_to_token(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> tokenized_context.ids])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;词汇表大小:&quot;</span>, tokenizer.get_vocab_size())<br>tokenizer.add_special_tokens([<span class="hljs-string">&#x27;jjj&#x27;</span>])<br>tokenized_context = tokenizer.encode(context)<br><span class="hljs-built_in">print</span>(tokenized_context.ids)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(tokenized_context.ids))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;添加新词后:&quot;</span>, [tokenizer.id_to_token(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> tokenized_context.ids])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;词汇表大小:&quot;</span>, tokenizer.get_vocab_size())<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-attr">[101, 791, 1921, 11095, 8334, 1921, 3698, 2523, 1962, 511, 102]</span><br><span class="hljs-number">11</span><br>未添加新词前: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;今&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;jj&#x27;</span>, <span class="hljs-string">&#x27;##j&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;气&#x27;</span>, <span class="hljs-string">&#x27;很&#x27;</span>, <span class="hljs-string">&#x27;好&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]</span><br>词汇表大小: <span class="hljs-number">21128</span><br><span class="hljs-selector-attr">[101, 791, 1921, 21128, 1921, 3698, 2523, 1962, 511, 102]</span><br><span class="hljs-number">10</span><br>添加新词后: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;今&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;jjj&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;气&#x27;</span>, <span class="hljs-string">&#x27;很&#x27;</span>, <span class="hljs-string">&#x27;好&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]</span><br>词汇表大小: <span class="hljs-number">21129</span><br></code></pre></td></tr></table></figure><h3 id="问题探讨">问题探讨</h3><p>上述方式对于一般的新词，均可起效。但对于另一类特殊的新词，比如<code>&lt;e&gt;</code>,<code>&lt;/e&gt;</code>等，需要另加分析，我们以<code>tokenizer</code>模块进行分析，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> tokenizers <span class="hljs-keyword">import</span> BertWordPieceTokenizer<br>tokenizer = BertWordPieceTokenizer(<span class="hljs-string">&quot;./bert-base-chinese/vocab.txt&quot;</span>, lowercase=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># tokenizer.add_special_tokens([&#x27;&lt;e&gt;&#x27;, &#x27;&lt;/e&gt;&#x27;, &#x27;&lt;/ec&gt;&#x27;])</span><br><br>context = <span class="hljs-string">&#x27;&lt;e&gt;苹果&lt;/e&gt;树尽早疏蕾，能节省营养，利于坐大果，促果高桩。&#x27;</span><br>tokenized_context = tokenizer.encode(context)<br><span class="hljs-built_in">print</span>(tokenized_context.ids)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(tokenized_context.ids))<br><span class="hljs-built_in">print</span>([tokenizer.id_to_token(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> tokenized_context.ids])<br><span class="hljs-built_in">print</span>(tokenizer.get_vocab_size())<br></code></pre></td></tr></table></figure><p>我们在词汇表vocab.txt中替换[unused]，但不会起效，输出结果如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-name">101</span>, <span class="hljs-number">133</span>, <span class="hljs-number">147</span>, <span class="hljs-number">135</span>, <span class="hljs-number">5741</span>, <span class="hljs-number">3362</span>, <span class="hljs-number">133</span>, <span class="hljs-number">120</span>, <span class="hljs-number">147</span>, <span class="hljs-number">135</span>, <span class="hljs-number">3409</span>, <span class="hljs-number">2226</span>, <span class="hljs-number">3193</span>, <span class="hljs-number">4541</span>, <span class="hljs-number">5945</span>, <span class="hljs-number">8024</span>, <span class="hljs-number">5543</span>, <span class="hljs-number">5688</span>, <span class="hljs-number">4689</span>, <span class="hljs-number">5852</span>, <span class="hljs-number">1075</span>, <span class="hljs-number">8024</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">754</span>, <span class="hljs-number">1777</span>, <span class="hljs-number">1920</span>, <span class="hljs-number">3362</span>, <span class="hljs-number">8024</span>, <span class="hljs-number">914</span>, <span class="hljs-number">3362</span>, <span class="hljs-number">7770</span>, <span class="hljs-number">3445</span>, <span class="hljs-number">511</span>, <span class="hljs-number">102</span>]<br><span class="hljs-number">34</span><br>[&#x27;[<span class="hljs-name">CLS</span>]&#x27;, <span class="hljs-symbol">&#x27;&lt;</span>&#x27;, <span class="hljs-symbol">&#x27;e</span>&#x27;, <span class="hljs-symbol">&#x27;&gt;</span>&#x27;, <span class="hljs-symbol">&#x27;苹</span>&#x27;, <span class="hljs-symbol">&#x27;果</span>&#x27;, <span class="hljs-symbol">&#x27;&lt;</span>&#x27;, <span class="hljs-symbol">&#x27;/</span>&#x27;, <span class="hljs-symbol">&#x27;e</span>&#x27;, <span class="hljs-symbol">&#x27;&gt;</span>&#x27;, <span class="hljs-symbol">&#x27;树</span>&#x27;, <span class="hljs-symbol">&#x27;尽</span>&#x27;, <span class="hljs-symbol">&#x27;早</span>&#x27;, <span class="hljs-symbol">&#x27;疏</span>&#x27;, <span class="hljs-symbol">&#x27;蕾</span>&#x27;, <span class="hljs-symbol">&#x27;，</span>&#x27;, <span class="hljs-symbol">&#x27;能</span>&#x27;, <span class="hljs-symbol">&#x27;节</span>&#x27;, <span class="hljs-symbol">&#x27;省</span>&#x27;, <span class="hljs-symbol">&#x27;营</span>&#x27;, <span class="hljs-symbol">&#x27;养</span>&#x27;, <span class="hljs-symbol">&#x27;，</span>&#x27;, <span class="hljs-symbol">&#x27;利</span>&#x27;, <span class="hljs-symbol">&#x27;于</span>&#x27;, <span class="hljs-symbol">&#x27;坐</span>&#x27;, <span class="hljs-symbol">&#x27;大</span>&#x27;, <span class="hljs-symbol">&#x27;果</span>&#x27;, <span class="hljs-symbol">&#x27;，</span>&#x27;, <span class="hljs-symbol">&#x27;促</span>&#x27;, <span class="hljs-symbol">&#x27;果</span>&#x27;, <span class="hljs-symbol">&#x27;高</span>&#x27;, <span class="hljs-symbol">&#x27;桩</span>&#x27;, <span class="hljs-symbol">&#x27;。</span>&#x27;, &#x27;[<span class="hljs-name">SEP</span>]&#x27;]<br><span class="hljs-number">21128</span><br></code></pre></td></tr></table></figure><p>但<code>add_special_tokens</code>会起效，原因为<code>&lt;</code>,<code>e</code>,<code>&gt;</code>和<code>&lt;e&gt;</code>均存在于<code>vocab.txt</code>，但前三者的优先级高于<code>&lt;e&gt;</code>，而<code>add_special_tokens</code>会起效，却会使得词汇表大小增大，从而需另外调整模型size。</p><p>但是，如果同时在词汇表vocab.txt中替换[unused]，同时<code>add_special_tokens</code>，则新增词会起效，同时词汇表大小不变。</p><h3 id="总结">总结</h3><p>本文介绍如何在BERT模型中添加自己的词汇，其它预训练模型原理相同。同时，<code>tokenizer</code>也是一个不错的切分词的模块，建议读者有空可以尝试~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BERT</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（五十一）使用PyTorch训练多标签文本分类模型</title>
    <link href="/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%B8%80%EF%BC%89%E4%BD%BF%E7%94%A8PyTorch%E8%AE%AD%E7%BB%83%E5%A4%9A%E6%A0%87%E7%AD%BE%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/"/>
    <url>/NLP%EF%BC%88%E4%BA%94%E5%8D%81%E4%B8%80%EF%BC%89%E4%BD%BF%E7%94%A8PyTorch%E8%AE%AD%E7%BB%83%E5%A4%9A%E6%A0%87%E7%AD%BE%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将介绍如何使用PyTorch训练多标签文本分类模型。</p><p>所谓多标签文本分类，指的是文本可能会属于多个类别，而不是单个类别。与文本多分类的区别在于，文本多分类模型往往有多个类别，但文本至属于其中一个类别；而多标签文本分类也会有多个类别，但文本会属于其中多个类别。</p><h3 id="数据集">数据集</h3><p>本文演示的数据集为英语论文数据集，参考网址为：<ahref="https://datahack.analyticsvidhya.com/contest/janatahack-independence-day-2020-ml-hackathon">https://datahack.analyticsvidhya.com/contest/janatahack-independence-day-2020-ml-hackathon</a>，数据下载需翻墙，读者也可参看后续给出的项目Github。该论文数据集实际上是比赛数据，供选手尝试模型。本文所采用的数据集为英语，至于中文，其原理是一致的，稍微做调整即可。</p><p>该数据集给出论文的标题（TITLE）和摘要（ABSTRACT），来预测论文属于哪个主题。该数据集共有20972个训练样本，有六个主题，分别为：ComputerScience, Physics, Mathematics, Statistics, Quantitative Biology,Quantitative Finance。在此给出一个样例数据：</p><blockquote><p>TITLE : Many-Body Localization: Stability and Instability ABSTRACT:Rare regions with weak disorder (Griffiths regions) have the potentialto spoil localization. We describe a non-perturbative construction oflocal integrals of motion (LIOMs) for a weakly interacting spin chain inone dimension, under a physically reasonable assumption on thestatistics of eigenvalues. We discuss ideas about the situation inhigher dimensions, where one can no longer ensure that interactionsinvolving the Griffiths regions are much smaller than the typicalenergy-level spacing for such regions. We argue that ergodicity isrestored in dimension d &gt; 1, although equilibration should beextremely slow, similar to the dynamics of glasses. TOPICS: Physics,Mathematics</p></blockquote><h3 id="模型结构">模型结构</h3><p>本文给出的多标签文本分类模型使用预训练模型（BERT），下游网络结构较为简单，算是比较中庸但简单好用的模型方案，模型结构图如下：</p><figure><img src="/img/nlp51_1.png" alt="多标签文本分类结构图" /><figcaption aria-hidden="true">多标签文本分类结构图</figcaption></figure><p>该模型使用PyTorch的transformers模块来实现，代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BERTClass</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(BERTClass, self).__init__()<br>        self.l1 = transformers.BertModel.from_pretrained(MODEL_NAME_OR_PATH)<br>        self.l2 = torch.nn.Dropout(<span class="hljs-number">0.2</span>)<br>        self.l3 = torch.nn.Linear(HIDDEN_LAYER_SIZE, <span class="hljs-number">6</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, ids, mask, token_type_ids</span>):<br>        _, output_1 = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids)<br>        output_2 = self.l2(output_1)<br>        output = self.l3(output_2)<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><p>使用损失函数为<code>torch.nn.BCEWithLogitsLoss</code>，因而不需要在output层后加上sigmoid激活函数。</p><p>模型训练过程中，将训练数据随机分为训练集和测试集，两部分比例为8:2，同时模型参数设置如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型参数</span><br>MAX_LEN = <span class="hljs-number">128</span><span class="hljs-comment"># 文本最大长度</span><br>TRAIN_BATCH_SIZE = <span class="hljs-number">32</span><span class="hljs-comment"># 训练批次数量</span><br>VALID_BATCH_SIZE = <span class="hljs-number">32</span><span class="hljs-comment"># 测试批次数量</span><br>EPOCHS = <span class="hljs-number">10</span><span class="hljs-comment"># 训练轮数</span><br>LEARNING_RATE = <span class="hljs-number">1e-05</span><span class="hljs-comment"># 学习率</span><br><span class="hljs-comment"># 模型</span><br>MODEL_NAME_OR_PATH = <span class="hljs-string">&#x27;./bert-base-uncased&#x27;</span><span class="hljs-comment"># 预训练模型</span><br>HIDDEN_LAYER_SIZE = <span class="hljs-number">768</span><span class="hljs-comment"># 隐藏层维数</span><br></code></pre></td></tr></table></figure><h3 id="模型效果">模型效果</h3><p>笔者分别尝试使用<code>bert-base-uncased</code>和<code>bert-large-uncased</code>训练模型，并在测试数据上进行预测，在比赛官网上进行提交，结果如下表：</p><table><thead><tr class="header"><th>模型</th><th>max length</th><th>batch size</th><th>private score</th><th>rank</th></tr></thead><tbody><tr class="odd"><td>bert-base-uncased</td><td>128</td><td>32</td><td>0.8320</td><td>107</td></tr><tr class="even"><td>bert-large-uncased</td><td>128</td><td>16</td><td>0.8355</td><td>79</td></tr></tbody></table><p>看过一个rank为17的方案，其采用的是多个预训练模型训练后的集成，后接网络与笔者一致。</p><h3 id="总结">总结</h3><p>本项目已经开源，其Github网址为:<ahref="https://github.com/percent4/pytorch_english_mltc">https://github.com/percent4/pytorch_english_mltc</a>。后续将尝试该模型在中文多标签文本分类数据集上的效果，感谢大家阅读~</p><h3 id="参考网址">参考网址</h3><ol type="1"><li>https://jovian.ai/kyawkhaung/1-titles-only-for-medium</li><li>https://datahack.analyticsvidhya.com/contest/janatahack-independence-day-2020-ml-hackathon</li><li>Fine-tuned BERT Model for Multi-Label Tweets Classification:https://trec.nist.gov/pubs/trec28/papers/DICE_UPB.IS.pdf</li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>多标签分类</tag>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（五十）别名发现模型的初次尝试</title>
    <link href="/NLP%EF%BC%88%E4%BA%94%E5%8D%81%EF%BC%89%E5%88%AB%E5%90%8D%E5%8F%91%E7%8E%B0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%9D%E6%AC%A1%E5%B0%9D%E8%AF%95/"/>
    <url>/NLP%EF%BC%88%E4%BA%94%E5%8D%81%EF%BC%89%E5%88%AB%E5%90%8D%E5%8F%91%E7%8E%B0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%9D%E6%AC%A1%E5%B0%9D%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="引言">引言</h3><p>别名即同义词、近义词，是同一事物的不同称呼。在日常生活中，我们也常常用到别名，比如土豆的别名为马铃薯，KFC的别名为肯德基。在上文<ahref="https://blog.csdn.net/jclian91/article/details/121524964">关于知识图谱上下级概念建设的一点想法</a>中提及了上下级概念的描述及意义，本文将尝试着使用深度学习模型建立同义关系模型。</p><p>比如在下面的文本中：</p><blockquote><p>卡定沟：又名嘎定沟，位于西藏318国道拉萨至林芝段距八一镇24公里处，海拔2980米，地处雅鲁藏布江支流尼洋河畔</p></blockquote><p>我们可以发现别名为：<code>(卡定沟, 别名, 嘎定沟)</code>。本文使用深度学习方法去发现非结构化文本中的别名与简称（或称缩略语），即使用<code>关系抽取模型</code>作为别名发现的模型。本文的最大价值在于提供高质量的别名、简称的<code>标注语料</code>，以及笔者对于<code>别名发现模型</code>的一次尝试。</p><p>别名（或同义关系）知识图谱构建中是必不可少的一环，是扩充本体名称的重要手段。别名发现的意义如下：</p><ul><li>是对实体本身更好的理解，比如我们常常听说的<code>阿里巴巴</code>，其全名为<code>阿里巴巴网络技术有限公司</code>，借助别名可以知道这是一家科技公司</li><li>是构建知识图谱的重要一环，对本体的名称进一步扩充</li><li>对搜索体验的提升，比如用户搜索<code>马铃薯</code>，系统借助同义关系找到其别名：<code>土豆</code>，则可扩充用户的搜索为<code>马铃薯 土豆</code>；用户搜索<code>珠峰</code>，系统借助同义关系找到其全名：<code>珠穆朗玛峰</code>，则可扩充用户的搜索为<code>珠峰 珠穆朗玛峰</code>，这无疑能提升用户搜索体验，提升搜索效果。</li></ul><h3 id="语料构建">语料构建</h3><p>本文最大的贡献在于提供人工标注的高质量别名语料。</p><p>我们的语料来自于<code>CCF2019年关系抽取比赛数据</code>及<code>阅读理解数据WebQA &amp; SougouQA</code>，借助程序处理（关键词）及人工标注整理，目前共获取有效标注语料共4425条，具体说明如下：</p><table><thead><tr class="header"><th>文件名称</th><th>数据来源</th><th>标注样本数量</th></tr></thead><tbody><tr class="odd"><td>data/ccf2019_corpus.json</td><td>CCF2019年关系抽取比赛数据</td><td>3369</td></tr><tr class="even"><td>data/sougouqa_webqa_corpus.json</td><td>阅读理解数据（WebQA &amp; SougouQA）</td><td>1056</td></tr></tbody></table><h3 id="模型训练">模型训练</h3><p>本文采用文章<ahref="https://www.kexue.fm/archives/7161">用bert4keras做三元组抽取</a>中给出的关系抽取模型进行模型训练，其中训练集数据:测试集数据=8:2。</p><p>模型的参数设置为maxlen=200, batch_size=16, epoch=20,使用预训练模型为<code>哈工大的中文Roberta模型: chinese-RoBERTa-wwm-ext</code>，在GoogleColab平台上进行模型训练, 在测试集上的最好F1值为88.97%。</p><h3 id="别名发现">别名发现</h3><p>模型训练好之后，我们可以使用该模型对其它非结构化文本进行预测，并写入至Neo4j中进行观察。以下将给出几个抽取例子：</p><blockquote><p>杨桃,又名阳桃、羊桃、五棱子,学名“五敛子”,又因横切面如五角星,故国外又称之为“星梨”。杨桃原产地,传统认为产於东南亚的马来西亚等地。我国於汉朝就有栽培记载,今我国福建、广东、广西、云南等地;亚洲东南亚、印度;美洲巴西等热带地区均普遍栽培。...</p></blockquote><p>预测结果:</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[(<span class="hljs-string">&quot;杨桃&quot;</span>, <span class="hljs-string">&quot;别名&quot;</span>, <span class="hljs-string">&quot;阳桃&quot;</span>), (<span class="hljs-string">&quot;杨桃&quot;</span>, <span class="hljs-string">&quot;别名&quot;</span>, <span class="hljs-string">&quot;羊桃&quot;</span>), (<span class="hljs-string">&quot;杨桃&quot;</span>, <span class="hljs-string">&quot;别名&quot;</span>, <span class="hljs-string">&quot;五棱子&quot;</span>), (<span class="hljs-string">&quot;杨桃&quot;</span>, <span class="hljs-string">&quot;别名&quot;</span>, <span class="hljs-string">&quot;五敛子&quot;</span>), (<span class="hljs-string">&quot;杨桃&quot;</span>, <span class="hljs-string">&quot;别名&quot;</span>, <span class="hljs-string">&quot;星梨&quot;</span>)]<br></code></pre></td></tr></table></figure><p><img src="/img/nlp50_1.png" /></p><blockquote><p>英吉利海峡隧道(thechanneltunnel)又称英法海底隧道或欧洲隧道(eurotunnel)，是一条把英国英伦三岛连接往欧洲法国的铁路隧道，于1994年5月6日开通。</p></blockquote><p>预测结果:</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[(<span class="hljs-string">&quot;英吉利海峡隧道&quot;</span>, <span class="hljs-string">&quot;别名&quot;</span>, <span class="hljs-string">&quot;英法海底隧道&quot;</span>), (<span class="hljs-string">&quot;英吉利海峡隧道&quot;</span>, <span class="hljs-string">&quot;别名&quot;</span>, <span class="hljs-string">&quot;欧洲隧道&quot;</span>)]<br></code></pre></td></tr></table></figure><p><img src="/img/nlp50_2.png" /></p><blockquote><p>中科大是中国科学技术大学的简称，位于安徽省合肥市。</p></blockquote><p>预测结果：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[(<span class="hljs-symbol">&#x27;中国科学技术大学</span>&#x27;, <span class="hljs-symbol">&#x27;简称</span>&#x27;, <span class="hljs-symbol">&#x27;中科大</span>&#x27;)]<br></code></pre></td></tr></table></figure><p><img src="/img/nlp50_3.png" /></p><h3 id="总结">总结</h3><p>语料维护费时费力，因此可能会存在一定错误，如有问题，请及时指出。另外，语料并没有很全，后续需持续投入进行维护。</p><p>本文给出了一种<code>别名发现模型</code>的思路，希望后续关于这方面的资料和研究会越来越多，感谢阅读~</p><p>本文项目已开源，其Github地址为：<ahref="https://github.com/percent4/alias_find_system">https://github.com/percent4/alias_find_system</a>，欢迎大家参考~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>别名发现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（四十九）使用kenlm进行文本纠错</title>
    <link href="/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B9%9D%EF%BC%89%E4%BD%BF%E7%94%A8kenlm%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99/"/>
    <url>/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B9%9D%EF%BC%89%E4%BD%BF%E7%94%A8kenlm%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会介绍如何使用kenlm工具进行文本纠错。</p><p>kenlm是用C++编写的语言模型工具，可以方便、快速地计算n-gram。kenlm工具的首页网址为：<ahref="https://kheafield.com/code/kenlm/">https://kheafield.com/code/kenlm/</a>，该工具的Github网址为：<ahref="https://github.com/kpu/kenlm">https://github.com/kpu/kenlm</a>。</p><p>关于kenlm的安装，本文不再详细介绍，网上有很多这方面的介绍。安装完kenlm工具包后，其文件夹目录结构如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs bash">BUILDING<br>CMakeLists.txt<br>COPYING<br>COPYING.3<br>COPYING.LESSER.3<br>Doxyfile<br>GIT_REVISION<br>LICENSE<br>MANIFEST.<span class="hljs-keyword">in</span><br>README.md<br>build<br>clean_query_only.sh<br>cmake<br>compile_query_only.sh<br>include<br>lm<br>python<br>setup.py<br>util<br></code></pre></td></tr></table></figure><h3 id="模型训练">模型训练</h3><p>我们训练的语料为<code>people2014_words.txt</code>，来自百度网盘，访问网址为<ahref="https://pan.baidu.com/s/1971a5XLQsIpL0zL0zxuK2A#list/path=/">https://pan.baidu.com/s/1971a5XLQsIpL0zL0zxuK2A#list/path=%2F</a>。我们需要将原来已经分词好的文件（<code>people2014_words.txt</code>）改成单个字的文件（<code>people2014_chars.txt</code>），即每个字用空格隔开，python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;people2014_words.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;people2014_chars.txt&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> g:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> content:<br>        g.write(<span class="hljs-string">&quot; &quot;</span>.join(<span class="hljs-built_in">list</span>(<span class="hljs-string">&quot;&quot;</span>.join(line.split())))+<span class="hljs-string">&quot;\n&quot;</span>)<br></code></pre></td></tr></table></figure><p>改写后的文件前两行如下：</p><blockquote><p>1 . 手 指 长 度 一 项 2 0 0 8 年 在 期 刊 上 发 表 的 调 查 发 现 食指 比 无 名 指 短 的 女 性 可 能 有 比 其 他 女 性 高 两 倍 的 可 能 性患 上 在 膝 盖 处 的 关 节 炎 。 研 究 人 员 还 宣 称 ， 有 这 些 明 显男 性 特 征 的 女 性 更 加 容 易 雌 激 素 激 素 分 泌 水 平 低 ， 这 可能 会 对 关 节 炎 的 产 生 有 极 大 的 影 响 。 预 防 措 施 ： 加 强 锻炼 膝 盖 周 围 的 肌 肉 。 在 你 坐 着 的 时 候 ， 把 两 腿 伸 直 并 平行 于 地 面 ， 做 十 次 每 次 坚 持 5 — 1 0 秒 。</p></blockquote><p>我们将该文件放在build/result目录下。</p><p>切换至build文件夹所在目录，模型运行的运行命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/lmplz -o 3 --verbose_header --text ./result/people2014_chars.txt --arpa ./result/people2014corpus_chars.arps -S 4G<br></code></pre></td></tr></table></figure><p>运行参数解释：</p><ul><li>-o表示n-gram中n的数量，一般取3足够了，也可以取5；</li><li>-verbose_header:在生成的文件头位置加上统计信息；</li><li>--text表示输入的文本文件；--arpa表示输出的模型参数文件；</li><li>-S表示使用系统内存大小，<code>注意：需要设置合适的内存大小，不然可能会运行失败</code></li></ul><p>运行过程如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs bash">=== 1/5 Counting and sorting n-grams ===<br>Reading ~/work/kenlm/build/result/people2014_chars.txt<br>----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100<br>****************************************************************************************************<br>Unigram tokens 36092956 types 6914<br>=== 2/5 Calculating and sorting adjusted counts ===<br>Chain sizes: 1:82968 2:1493872896 3:2801011712<br>Statistics:<br>1 6914 D1=0.53084 D2=1.03394 D3+=1.4564<br>2 1159283 D1=0.625083 D2=1.08043 D3+=1.49998<br>3 6643214 D1=0.589546 D2=1.13123 D3+=1.52492<br>Memory estimate <span class="hljs-keyword">for</span> binary LM:<br><span class="hljs-built_in">type</span>     MB<br>probing 140 assuming -p 1.5<br>probing 147 assuming -r models -p 1.5<br>trie     48 without quantization<br>trie     23 assuming -q 8 -b 8 quantization <br>trie     46 assuming -a 22 array pointer compression<br>trie     22 assuming -a 22 -q 8 -b 8 array pointer compression and quantization<br>=== 3/5 Calculating and sorting initial probabilities ===<br>Chain sizes: 1:82968 2:18548528 3:132864280<br>----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100<br><span class="hljs-comment">####################################################################################################</span><br>=== 4/5 Calculating and writing order-interpolated probabilities ===<br>Chain sizes: 1:82968 2:18548528 3:132864280<br>----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100<br><span class="hljs-comment">####################################################################################################</span><br>=== 5/5 Writing ARPA model ===<br>----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100<br>****************************************************************************************************<br>Name:lmplz      VmPeak:4358320 kB       VmRSS:24136 kB  RSSMax:1112940 kB       user:13.5094    sys:2.38785     CPU:15.8973     real:15.2563<br></code></pre></td></tr></table></figure><p>运行完后会生成arps格式的模型文件，我们需要运行如下命令将模型文件进行压缩：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/build_binary ./result/people2014corpus_chars.arps ./result/people2014corpus_chars.klm<br></code></pre></td></tr></table></figure><p>运行完该命令后，就会生成klm格式的模型文件，模型文件体积大大减小，这也是我们所需要的的训练好后的模型文件。至此，我们已完成了使用kenlm训练n-gram模型。</p><h3 id="文本纠错">文本纠错</h3><p><code>pycorrector</code>模块支持使用自己训练好的kenlm模型进行纠错，参考网址：<ahref="https://github.com/shibing624/pycorrector">https://github.com/shibing624/pycorrector</a>。</p><p>演示的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pycorrector <span class="hljs-keyword">import</span> Corrector<br><br><span class="hljs-comment"># 加载训练好的kenlm模型</span><br>lm_path = <span class="hljs-string">&quot;~/work/kenlm/build/result/people2014corpus_chars.klm&quot;</span><br>model = Corrector(language_model_path=lm_path)<br><br><span class="hljs-comment"># 文本纠错</span><br>corrected_sent, detail = model.correct(<span class="hljs-string">&#x27;真麻烦你了。希望你们好好的跳无&#x27;</span>)<br><span class="hljs-built_in">print</span>(corrected_sent)<br><span class="hljs-built_in">print</span>(detail)<br></code></pre></td></tr></table></figure><p>我们对pycorrector中给出的5个样例句子进行纠错，结果如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs css">原句：真麻烦你了。希望你们好好的跳无<br>纠错后：真麻烦你了。希望你们好好的跳舞<br>纠错细节：<span class="hljs-selector-attr">[(<span class="hljs-string">&#x27;无&#x27;</span>, <span class="hljs-string">&#x27;舞&#x27;</span>, 14, 15)]</span><br></code></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs css">原句：少先队员因该为老人让坐<br>纠错后：少先队员应该为老人让坐<br>纠错细节：<span class="hljs-selector-attr">[(<span class="hljs-string">&#x27;因该&#x27;</span>, <span class="hljs-string">&#x27;应该&#x27;</span>, 4, 6)]</span><br></code></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs css">原句：机七学习是人工智能领遇最能体现智能的一个分知<br>纠错后：机器学习是人工智能领域最能体现智能的一个分知<br>纠错细节：<span class="hljs-selector-attr">[(<span class="hljs-string">&#x27;机七&#x27;</span>, <span class="hljs-string">&#x27;机器&#x27;</span>, 0, 2), (<span class="hljs-string">&#x27;领遇&#x27;</span>, <span class="hljs-string">&#x27;领域&#x27;</span>, 9, 11)]</span><br></code></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs css">原句：一只小鱼船浮在平净的河面上<br>纠错后：一只小鱼船夫在平静的河面上<br>纠错细节：<span class="hljs-selector-attr">[(<span class="hljs-string">&#x27;船浮&#x27;</span>, <span class="hljs-string">&#x27;船夫&#x27;</span>, 4, 6), (<span class="hljs-string">&#x27;平净&#x27;</span>, <span class="hljs-string">&#x27;平静&#x27;</span>, 7, 9)]</span><br></code></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs css">原句：我的家乡是有明的渔米之乡<br>纠错后：我的家乡是有名的鱼米之乡<br>纠错细节：<span class="hljs-selector-attr">[(<span class="hljs-string">&#x27;有明&#x27;</span>, <span class="hljs-string">&#x27;有名&#x27;</span>, 5, 7), (<span class="hljs-string">&#x27;渔米&#x27;</span>, <span class="hljs-string">&#x27;鱼米&#x27;</span>, 8, 10)]</span><br></code></pre></td></tr></table></figure><p>可以看到，训练好的kenlm模型对于常见的文本错误具有一定的纠错能力，但也有一些没有纠正过来。</p><p>因为使用的是n-gram模型，所以文本纠错的效果依赖于语料的质量及语料大小。</p><h3 id="总结">总结</h3><p>本文介绍了如何使用kenlm工具进行文本纠错。之所以写这篇文章，是因为网上人云亦云，很多文章都讲到使用kenlm训练n-gram模型时必须使用分词后的文件，但根据笔者自身的实践，发现分词后的文件并没有纠错能力，反而是单个字的文件进行训练有一定的纠错能力。希望大家不要迷信网上的所谓博客，还是要自己亲身实践下~</p><p>n-gram模型是文本纠错中的统计语言模型，属于较为简单的纠错方法，但有一定的使用价值，后续笔者将会为大家介绍更多的文本纠错相关内容，欢迎大家关注~</p><p>2021年7月26日于上海浦东，此日上海台风肆虐~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>文本纠错</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（四十八）文本纠错之获取形近字</title>
    <link href="/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E5%85%AB%EF%BC%89%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99%E4%B9%8B%E8%8E%B7%E5%8F%96%E5%BD%A2%E8%BF%91%E5%AD%97/"/>
    <url>/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E5%85%AB%EF%BC%89%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99%E4%B9%8B%E8%8E%B7%E5%8F%96%E5%BD%A2%E8%BF%91%E5%AD%97/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="简介">简介</h3><p>笔者最近在从事文本纠错的相关工作，颇有收获，因此记录于此。</p><p>文本纠错很大一部分工作在于纠正同音字、形近字，所谓形近字，是指字形相近的汉字。本文将介绍如何获取形近字。</p><p>获取形近字的算法如下：</p><ol type="1"><li>获取汉字库，将所有汉字转化为黑白图片；</li><li>获取每个汉字的向量表示（即将图片转化为向量）；</li><li>计算两个汉字的向量的余弦相似度，得到它们的字形相似度。</li></ol><p>下面将详细演示如何获取形近字。</p><h3 id="获取形近字">获取形近字</h3><p>我们从网上得到3500个汉字的txt文件（<code>all_3500_chars.txt</code>），通过pygame将汉字转化为100*100的黑白图片，Python程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> pygame<br><br>pygame.init()<br><span class="hljs-comment"># 获取3500个汉字</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;all_3500_chars.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    chars = f.read().strip()<br><br><span class="hljs-comment"># 通过pygame将汉字转化为黑白图片</span><br><span class="hljs-keyword">for</span> char <span class="hljs-keyword">in</span> chars:<br>    font = pygame.font.Font(<span class="hljs-string">&quot;C://Windows/Fonts/simkai.ttf&quot;</span>, <span class="hljs-number">100</span>)<br>    rtext = font.render(char, <span class="hljs-literal">True</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), (<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>))<br>    pygame.image.save(rtext, <span class="hljs-string">&quot;&#123;&#125;.png&quot;</span>.<span class="hljs-built_in">format</span>(char))<br></code></pre></td></tr></table></figure><p>前10个汉字为<code>一乙二十丁厂七卜人入</code>,其对应的黑白图片如下：</p><figure><img src="/img/nlp48_1.png" alt="前10个汉字图片" /><figcaption aria-hidden="true">前10个汉字图片</figcaption></figure><p>接着我们获取每个汉字的向量表示，并将这两个向量的余弦相似度作为对应汉字的余弦相似度，Python程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># get_similiar_char.py</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> operator <span class="hljs-keyword">import</span> itemgetter<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_img_2_list</span>(<span class="hljs-params">img_path</span>):<br>    <span class="hljs-comment"># 读取图片</span><br>    img = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), -<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 把图片转换为灰度模式</span><br>    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> [_[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> img.tolist()]<br><br><br><span class="hljs-comment"># 获取所有汉字的向量表示，以dict储存</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_all_char_vectors</span>():<br>    image_paths = [_ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> os.listdir(<span class="hljs-string">&quot;.&quot;</span>) <span class="hljs-keyword">if</span> _.endswith(<span class="hljs-string">&quot;png&quot;</span>)]<br>    img_vector_dict = &#123;&#125;<br>    <span class="hljs-keyword">for</span> image_path <span class="hljs-keyword">in</span> image_paths:<br>        img_vector_dict[image_path[<span class="hljs-number">0</span>]] = read_img_2_list(img_path=image_path)<br><br>    <span class="hljs-keyword">return</span> img_vector_dict<br><br><br><span class="hljs-comment"># 计算两个向量之间的余弦相似度</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cosine_similarity</span>(<span class="hljs-params">vector1, vector2</span>):<br>    dot_product = <span class="hljs-number">0.0</span><br>    normA = <span class="hljs-number">0.0</span><br>    normB = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> a, b <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(vector1, vector2):<br>        dot_product += a * b<br>        normA += a ** <span class="hljs-number">2</span><br>        normB += b ** <span class="hljs-number">2</span><br>    <span class="hljs-keyword">if</span> normA == <span class="hljs-number">0.0</span> <span class="hljs-keyword">or</span> normB == <span class="hljs-number">0.0</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> dot_product / ((normA**<span class="hljs-number">0.5</span>)*(normB**<span class="hljs-number">0.5</span>))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    img_vector_dict = get_all_char_vectors()<br><br>    <span class="hljs-comment"># 获取最接近的汉字</span><br>    similarity_dict = &#123;&#125;<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        match_char = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;输入汉字: &quot;</span>)<br>        match_vector = img_vector_dict[match_char]<br>        <span class="hljs-keyword">for</span> char, vector <span class="hljs-keyword">in</span> img_vector_dict.items():<br>            cosine_similar = cosine_similarity(match_vector, vector)<br>            similarity_dict[char] = cosine_similar<br>        <span class="hljs-comment"># 按相似度排序，取前10个</span><br>        sorted_similarity = <span class="hljs-built_in">sorted</span>(similarity_dict.items(), key=itemgetter(<span class="hljs-number">1</span>), reverse=<span class="hljs-literal">True</span>)<br>        <span class="hljs-built_in">print</span>([(char, <span class="hljs-built_in">round</span>(similarity, <span class="hljs-number">4</span>))<span class="hljs-keyword">for</span> char, similarity <span class="hljs-keyword">in</span> sorted_similarity[:<span class="hljs-number">10</span>]])<br></code></pre></td></tr></table></figure><p>我们尝试着输入<code>国、填、博</code>这三个字，得到的相近字形的汉字如下：</p><blockquote><p>输入汉字: 国 [('国', 1.0), ('固', 0.9493), ('团', 0.9432), ('困',0.9405), ('因', 0.9369), ('围', 0.9357), ('门', 0.9334), ('园', 0.9326),('同', 0.929), ('圆', 0.9261)] 输入汉字: 填 [('填', 1.0), ('慎',0.9522), ('坞', 0.9238), ('培', 0.9149), ('坎', 0.9133), ('块', 0.9101),('币', 0.9092), ('镇', 0.9077), ('埠', 0.9074), ('了', 0.9044)]输入汉字: 博 [('博', 1.0), ('傅', 0.9306), ('协', 0.9115), ('搏',0.907), ('惰', 0.9046), ('膊', 0.9029), ('愕', 0.9019), ('侯', 0.8999),('悴', 0.8997), ('怜', 0.8989)]</p></blockquote><h3 id="opencv读取文件名为汉字的图片">opencv读取文件名为汉字的图片</h3><p>在使用opencv读物文件名为汉字的图片时，读取的图片内容为None，我们以<code>一.png</code>为例，演示程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> cv2<br><br>image_path = <span class="hljs-string">&quot;一.png&quot;</span><br>img = cv2.imread(image_path, <span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(img, <span class="hljs-built_in">type</span>(img))<br></code></pre></td></tr></table></figure><p>输出结果为<code>None &lt;class 'NoneType'&gt;</code>。也就是说，opencv在读取带汉字的文件路径时会报错，解决办法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>image_path = <span class="hljs-string">&quot;一.png&quot;</span><br>img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), -<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(img.shape, <span class="hljs-built_in">type</span>(img))<br></code></pre></td></tr></table></figure><p>输出结果为<code>(100, 100, 3) &lt;class 'numpy.ndarray'&gt;</code>。</p><h3 id="总结">总结</h3><p>本文通过将汉字转化为图片，获取图片的向量表示来表征汉字，在获取形近字方面有着不错的效果。</p><p>我们可以通过更复杂的图片相似度算法来增强获得更好的形近字能力。</p><p>也有不少研究者，通过四角码、音形码等算法来获取形近字，取得了不错的效果。本文想法朴素，容易用程序实现，且效果也较为不错。</p><p>后面将继续记录笔者在文本纠错方面的尝试，欢迎大家继续阅读~</p><p>2021年6月29日于上海浦东，此日上海暑气逼人~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>文本纠错</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（四十七）常见的损失函数</title>
    <link href="/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B8%83%EF%BC%89%E5%B8%B8%E8%A7%81%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <url>/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B8%83%EF%BC%89%E5%B8%B8%E8%A7%81%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将给出NLP任务中一些常见的损失函数（LossFunction），并使用Keras、PyTorch给出具体例子。</p><p>在讲解具体的损失函数之前，我们有必要了解下什么是损失函数。所谓损失函数，指的是衡量<code>模型预测值y</code>与<code>真实标签Y</code>之间的差距的函数。本文将介绍的损失函数如下：</p><ul><li><p>Mean Squared Error（均方差损失函数）</p></li><li><p>Mean Absolute Error（绝对值损失函数）</p></li><li><p>Binary Cross Entropy（二元交叉熵损失函数）</p></li><li><p>Categorical Cross Entropy（多分类交叉熵损失函数）</p></li><li><p>Sparse Categorical CrossEntropy（稀疏多分类交叉熵损失函数）</p></li><li><p>Hingle Loss（合页损失函数）</p></li><li><p>......</p><p>以下将分别介绍上述损失函数，并介绍Keras和PyTorch中的例子。在此之前，我们分别导入Keras所需模块和PyTorch所需模块。Keras所需模块如下：</p></li><li><figure><img src="/img/nlp47_1.png" alt="导入Keras相关模块" /><figcaption aria-hidden="true">导入Keras相关模块</figcaption></figure></li></ul><p>PyTorch所需模块如下：</p><figure><img src="/img/nlp47_2.png" alt="PyTorch所需模块" /><figcaption aria-hidden="true">PyTorch所需模块</figcaption></figure><p>从导入模块来看，PyTorch更加简洁，在后面的部分中我们将持续比较这两种框架的差异。</p><h3 id="mean-squared-error">Mean Squared Error</h3><p>Mean SquaredError（MSE）为均方差损失函数，一般用于回归问题。我们用<spanclass="math inline">\(\widetilde{y}_{i}\)</span>表示样本预测值序列<spanclass="math inline">\(\{\widetilde{y}_{1},\widetilde{y}_{2},...,\widetilde{y}_{n}\}\)</span>中的第i个元素，用<spanclass="math inline">\(y_{i}\)</span>表示样本真实值序列<spanclass="math inline">\(\{y_{1},y_{2},...,y_{n}\}\)</span>中的第i个元素，则均方差损失函数MSE的计算公式如下：</p><p><spanclass="math display">\[MSE=\frac{1}{n}\sum_{i=1}^n(\widetilde{y}_{i}-y_{i})^{2}\]</span></p><p>Keras实现代码如下：</p><figure><img src="/img/nlp47_3.png" alt="Keras MSE" /><figcaption aria-hidden="true">Keras MSE</figcaption></figure><p>PyTorch实现代码如下：</p><figure><img src="/img/nlp47_4.png" alt="PyTorch MSE" /><figcaption aria-hidden="true">PyTorch MSE</figcaption></figure><h3 id="mean-absolute-error">Mean Absolute Error</h3><p>Mean AbsoluteError（MAE）为绝对值损失函数，一般用于回归问题。我们用<spanclass="math inline">\(\widetilde{y}_{i}\)</span>表示样本预测值序列<spanclass="math inline">\(\{\widetilde{y}_{1},\widetilde{y}_{2},...,\widetilde{y}_{n}\}\)</span>中的第i个元素，用<spanclass="math inline">\(y_{i}\)</span>表示样本真实值序列<spanclass="math inline">\(\{y_{1},y_{2},...,y_{n}\}\)</span>中的第i个元素，则绝对值损失函数MAE的计算公式如下：</p><p><spanclass="math display">\[MAE=\frac{1}{n}\sum_{i=1}^n|\widetilde{y}_{i}-y_{i}|\]</span></p><p>Keras实现代码如下：</p><figure><img src="/img/nlp47_5.png" alt="Keras MAE" /><figcaption aria-hidden="true">Keras MAE</figcaption></figure><p>PyTorch实现代码如下：</p><figure><img src="/img/nlp47_6.png" alt="PyTorch MAE" /><figcaption aria-hidden="true">PyTorch MAE</figcaption></figure><p>注意，在PyTorch中L1Loss中的L1表示为L1范数，即通常所说的绝对值，绝对值函数<spanclass="math inline">\(|x|\)</span>处处连续，但在x=0处不可导。</p><h3 id="binary-cross-entropy">Binary Cross Entropy</h3><p>Binary CrossEntropy（BCE）为二元交叉熵损失函数，一般用于二分类问题。我们用Y表示样本真实标签序列（每个值为0或者1），用<spanclass="math inline">\(\bar{Y}\)</span>表示样本预测标签序列（每个值为0-1之间的值），则BCE计算公式如下：</p><p><span class="math display">\[BCE=Y \cdot (-log(\bar{Y}))+(1-Y) \cdot(-log(1-\bar{Y}))\]</span></p><p>我们不在讲解具体的计算公式，如需具体的计算方式，可以参考文章<ahref="https://blog.csdn.net/jclian91/article/details/81224125">Sklearn中二分类问题的交叉熵计算</a>。</p><p>Keras实现代码如下：</p><figure><img src="/img/nlp47_7.png" alt="Keras BCE" /><figcaption aria-hidden="true">Keras BCE</figcaption></figure><p>PyTorch实现代码如下：</p><figure><img src="/img/nlp47_8.png" alt="PyTorch BCE" /><figcaption aria-hidden="true">PyTorch BCE</figcaption></figure><p>从上面的结果中可以看到Keras和PyTorch在实现BCE损失函数的差异，给定样本，Keras给出了每个样本的BCE，而PyTorch给出了所有样本BCE的平均值。更大的差异体现在<code>多分类交叉熵损失函数</code>。</p><h3 id="categorical-cross-entropy">Categorical Cross Entropy</h3><p>Categorical CrossEntropy（CCE）为多分类交叉熵损失函数，是BCE（二分类交叉熵损失函数）扩充至多分类情形时的损失函数。多分类交叉熵损失函数的数学公式如下：</p><p><spanclass="math display">\[CCE=-\frac{1}{N}\sum_{i=1}^{N}\sum_{c=1}^{C}1_{y_{i}\inC_{c}}log(p_{model}[y_{i}\in C_{c}])\]</span></p><p>其中N为样本数，C为类别数，<span class="math inline">\(1_{y_{i}\inC_{c}}\)</span>表示第i个样本属于第c个类别的值（0或1），<spanclass="math inline">\(p_{model}[y_{i}\inC_{c}]\)</span>表示模型预测的第i个样本属于第c个类别的概率值（0-1之间）。如需查看具体的计算方式，可以参考文章<ahref="https://blog.csdn.net/jclian91/article/details/81233277">多分类问题的交叉熵计算</a>。</p><p>Keras实现代码如下：</p><figure><img src="/img/nlp47_9.png" alt="Keras CCE" /><figcaption aria-hidden="true">Keras CCE</figcaption></figure><p>PyTorch中的CCE采用稀疏多分类交叉熵损失函数实现，因此直接查看稀疏多分类交叉熵损失函数部分即可。</p><h3 id="sparse-categorical-cross-entropy">Sparse Categorical CrossEntropy</h3><p>Sparse Categorical CrossEntropy（稀疏多分类交叉熵损失函数，SCCE）原理上和多分类交叉熵损失函数（CCE）一致，属于多分类问题的损失函数，不同之处在于多分类交叉熵损失函数中的真实样本值用one-hot向量来表示，其下标i为1，其余为0，表示属于第i个类别；而稀疏多分类交叉熵损失函数中真实样本直接用数字i表示，表示属于第i个类别。</p><p>Keras实现代码如下：</p><figure><img src="/img/nlp47_10.png" alt="Keras SCCE" /><figcaption aria-hidden="true">Keras SCCE</figcaption></figure><p>例子中一共四个样本，它们的真实样本标签为[2,2,0,1]，不是one-hot向量。</p><p>PyTorch中的SCCE实现代码与上述数学公式不太一致，有些微改动。我们先看例子如下：</p><figure><img src="/img/nlp47_11.png" alt="PyTorch SCCE" /><figcaption aria-hidden="true">PyTorch SCCE</figcaption></figure><p>这明显与Keras实现代码是不一致的。要解释这种差别，我们就要详细了解PyTorch是如何实现CCE损失函数的。</p><p>简单来说，PyTorch中的输入中的样本预测，不是softmax函数作用后的预测概率，而是softmax函数作用前的值。对该值分别用softmax函数、log函数、NLLLoss()函数作用就是PyTorch计算SCCE的方式。</p><p>在上面的例子中，y_pred_tmp是softmax函数作用前的值，是PyTorch计算SCCE的预测样本的输入，y_pred是softmax函数作用后的值，是sklearn模块、Keras计算SCCE的预测样本的输入。对y_pred_tmp、y_true使用softmax函数、log函数所得到的结果，与y_pred、y_true使用sklearn模块、Keras计算SCCE的结果一致，而对该结算结果再作用NLLLoss()，就是PyTorch计算SCCE的方式。</p><p>也许上面的解释还有点模糊，我们借助知乎上别人给出的一个例子也许能更好地理解PyTorch计算SCCE的方式，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br>x_input = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)   <span class="hljs-comment"># 随机生成输入</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;x_input:\n&#x27;</span>, x_input)<br>y_target = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>])    <span class="hljs-comment"># 设置输出具体值 print(&#x27;y_target\n&#x27;,y_target)</span><br><br><span class="hljs-comment"># 计算输入softmax，此时可以看到每一行加到一起结果都是1</span><br>softmax_func = nn.Softmax(dim=<span class="hljs-number">1</span>)<br>soft_output = softmax_func(x_input)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;soft_output:\n&#x27;</span>, soft_output)<br><br><span class="hljs-comment"># 在softmax的基础上取log</span><br>log_output = torch.log(soft_output)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;log_output:\n&#x27;</span>, log_output)<br><br><span class="hljs-comment"># 对比softmax与log的结合与nn.LogSoftmaxloss(负对数似然损失)的输出结果，发现两者是一致的。</span><br>logsoftmax_func = nn.LogSoftmax(dim=<span class="hljs-number">1</span>)<br>logsoftmax_output = logsoftmax_func(x_input)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;logsoftmax_output:\n&#x27;</span>, logsoftmax_output)<br><br><span class="hljs-comment"># pytorch中关于NLLLoss的默认参数配置为：reducetion=True、size_average=True</span><br>nllloss_func = nn.NLLLoss()<br>nlloss_output = nllloss_func(logsoftmax_output, y_target)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;nlloss_output:\n&#x27;</span>, nlloss_output)<br><br><span class="hljs-comment"># 直接使用pytorch中的loss_func=nn.CrossEntropyLoss()看与经过NLLLoss的计算是不是一样</span><br>crossentropyloss = nn.CrossEntropyLoss()<br>crossentropyloss_output = crossentropyloss(x_input, y_target)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;crossentropyloss_output:\n&#x27;</span>, crossentropyloss_output)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs subunit">x_input:<br> tensor([[ 0.1286,  1.1363,  0.5676],<br>        [ 1.0740, <span class="hljs-string">-0</span>.7359, <span class="hljs-string">-0</span>.6731],<br>        [ 0.7915, <span class="hljs-string">-0</span>.8525, <span class="hljs-string">-1</span>.2906]])<br>soft_output:<br> tensor([[0.1890, 0.5178, 0.2932],<br>        [0.7474, 0.1223, 0.1303],<br>        [0.7588, 0.1466, 0.0946]])<br>log_output:<br> tensor([[<span class="hljs-string">-1</span>.6659, <span class="hljs-string">-0</span>.6582, <span class="hljs-string">-1</span>.2269],<br>        [<span class="hljs-string">-0</span>.2911, <span class="hljs-string">-2</span>.1011, <span class="hljs-string">-2</span>.0382],<br>        [<span class="hljs-string">-0</span>.2760, <span class="hljs-string">-1</span>.9200, <span class="hljs-string">-2</span>.3581]])<br>logsoftmax_output:<br> tensor([[<span class="hljs-string">-1</span>.6659, <span class="hljs-string">-0</span>.6582, <span class="hljs-string">-1</span>.2269],<br>        [<span class="hljs-string">-0</span>.2911, <span class="hljs-string">-2</span>.1011, <span class="hljs-string">-2</span>.0382],<br>        [<span class="hljs-string">-0</span>.2760, <span class="hljs-string">-1</span>.9200, <span class="hljs-string">-2</span>.3581]])<br>nlloss_output:<br> tensor(0.9908)<br>crossentropyloss_output:<br> tensor(0.9908)<br></code></pre></td></tr></table></figure><h3 id="hingle-loss">Hingle Loss</h3><p>HingleLoss为合页损失函数，常用于分类问题。合页损失函数不仅要分类正确，而且确信度足够高时损失才是0，也就是说，合页损失函数对学习有更高的要求。一个常见的例子为SVM，其数学公式如下：</p><p><span class="math display">\[Hingle Loss=max(0, 1-y \cdot\widetilde{y})\]</span></p><p>其中<span class="math inline">\(y\)</span>为真实标签，<spanclass="math inline">\(\widetilde{y}\)</span>为预测标签。</p><p>Keras实现代码如下：</p><figure><img src="/img/nlp47_12.png" alt="Keras Hingle Loss" /><figcaption aria-hidden="true">Keras Hingle Loss</figcaption></figure><p>PyTorch中没有专门的HingleLoss实现函数，不过我们可以很轻松地自己实现，代码如下：</p><figure><img src="/img/nlp47_13.png" alt="PyTorch Hingle Loss" /><figcaption aria-hidden="true">PyTorch Hingle Loss</figcaption></figure><h3 id="总结">总结</h3><p>本文介绍了NLP任务中一些常见的损失函数（LossFunction），并使用Keras、PyTorch给出具体例子。</p><p>本文代码已上传至Github，地址为：<ahref="https://github.com/percent4/deep_learning_miscellaneous/tree/master/loss_function">https://github.com/percent4/deep_learning_miscellaneous/tree/master/loss_function</a>。</p><p>2021年4月24日于上海浦东，此日惠风和畅~</p><h3 id="参考网址">参考网址</h3><ol type="1"><li>How To Build Custom Loss Functions In Keras For Any UseCase：https://cnvrg.io/keras-custom-loss-functions/</li><li>Pytorch常用的交叉熵损失函数CrossEntropyLoss()详解：https://zhuanlan.zhihu.com/p/98785902</li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>损失函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（四十六）对抗训练的一次尝试</title>
    <link href="/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E5%85%AD%EF%BC%89%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/"/>
    <url>/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E5%85%AD%EF%BC%89%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>初次听说对抗训练是在一次实体识别比赛的赛后分享中，当时的一些概念，比如FocalLoss、对抗训练、模型融合、数据增强等都让我感到新奇，之后笔者自己也做了很多这方面的尝试。本文将分享笔者对于对抗训练（FGM）的一次尝试。</p><h3 id="什么是对抗训练">什么是对抗训练？</h3><p>提到“对抗”，相信大多数人的第一反应都是CV中的对抗生成网络(GAN)，殊不知，其实对抗也可以作为一种防御机制，并且经过简单的修改，便能用在NLP任务上，提高模型的泛化能力。GAN之父IanGoodfellow在15年的ICLR论文《Explaining and Harnessing AdversarialExamples》中第一次提出了对抗训练这个概念，简而言之，就是在原始输入样本<code>x</code>上加一个扰动<code>radv</code>，得到对抗样本后，用其进行训练。这在CV领域比较好理解，部分图片本身就是自带噪声的，比如手抖、光线不佳等，这就是天然的对抗样本，它们在模型训练的时候就是负样本，这些样本的加入能提升模型的鲁棒性。比如下面的经典例子：</p><figure><img src="/img/nlp46_1.png" alt="对抗训练的经典例子" /><figcaption aria-hidden="true">对抗训练的经典例子</figcaption></figure><p>从上面的例子中，我们可以看到一张置信度为55.7%的panda图片在加入了很小的随机扰动后，模型竟然识别为了gibbon。</p><p>对抗训练的一般原理可以用下面的最大最小化公式来体现：</p><figure><img src="/img/nlp46_2.png" alt="最大最小化公式" /><figcaption aria-hidden="true">最大最小化公式</figcaption></figure><p>其中D代表训练集，x代表输入，y代表标签，θ是模型参数，L(x,y;θ)是单个样本的loss，Δx是对抗扰动，Ω是扰动空间。Ω是扰动空间，Δx是对抗扰动，一般扰动空间都比较小，避免对原来样本的破坏。在训练集合D，选择合适的对抗扰动来使得当个样本的loss达到最大，同时，外层（<code>E(x,y)</code>）就是对神经网络的模型参数θ进行优化，使其最小化。这颇有一点攻与守的味道，有了随机扰动的加入，样本的loss要尽可能大，而训练的模型loss要尽可能小，从而使得模型有了更强的鲁棒性，避免样本的小扰动就造成模型推理的结果偏差。</p><h3 id="fgm">FGM</h3><p>FGM（Fast Gradient Method）是对抗学习的一种实现方式，可以与FGSM（FastGradient SignMethod）一起谈论。对于随机扰动Δx，FGM与FGSM的实现公式如下：</p><p><span class="math display">\[FGSM: \Delta{x}=\epsilon\cdot Sign(g) \\FGM: \Delta{x}=\epsilon\cdot (g/||g||_{2}) \\其中Sign为数学函数，||g||_{2}为g的L_{2}范数，g=\nabla_{x}L(x;y;\theta).\]</span></p><p>从上面的公式上可以看出，其增大样本loss的办法是使得样本x在梯度方向变大。</p><p>CV领域中，上面的FGM公式比较容易实现，因为图片的向量表示我们可以认为是连续的实数，而在NLP中，一般字或词的表示为One-hot向量，不好直接进行样本扰动。一种简单的想法是在wordEmbedding向量的时候进行扰动。Embedding层的输出是直接取自于Embedding参数矩阵的，因此我们可以直接对Embedding参数矩阵进行扰动。这样得到的对抗样本的多样性会少一些（因为不同样本的同一个token共用了相同的扰动），但仍然能起到正则化的作用，而且这样实现起来容易得多。</p><p>我们不必自己动手去实现上述的FGM，苏建林在bert4keras工具中已经实现了FGM的脚本，可以参考：<ahref="https://github.com/bojone/keras_adversarial_training">https://github.com/bojone/keras_adversarial_training</a>，这是Keras框架下的实现。而瓦特兰蒂斯在博客<ahref="https://fyubang.com/2019/10/15/adversarial-train/">【炼丹技巧】功守道：NLP中的对抗训练+PyTorch实现</a>中给出了Torch框架下的FGM实现。两者使用起来都非常方便。</p><p>下面将介绍笔者使用FGM在keras-bert模块中的实验。</p><h3 id="实验结果">实验结果</h3><p>笔者使用keras-bert模块实现了命名实体识别、文本多分类、文本多标签分类任务，如下：</p><ul><li><p><ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/">NLP（三十四）使用keras-bert实现序列标注任务</a></p></li><li><p><ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%BA%94%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">NLP（三十五）使用keras-bert实现文本多分类任务</a></p></li><li><p><ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">NLP（三十六）使用keras-bert实现文本多标签分类任务</a></p><p>我们将对比在同样的模型参数下，相同数据集在使用FGM前后的模型评估指标的对比：</p></li><li><p>人民日报实体识别任务（评估指标为micro avg f1-score）</p></li></ul><table><thead><tr class="header"><th>-</th><th>训练1</th><th>训练2</th><th>训练3</th><th>avg</th></tr></thead><tbody><tr class="odd"><td>使用FGM前</td><td>0.9276</td><td>0.9217</td><td>0.9252</td><td>0.9248</td></tr><tr class="even"><td>使用FGM后</td><td>0.9287</td><td>0.9273</td><td>0.9294</td><td>0.9285</td></tr></tbody></table><ul><li>时间识别任务（评估指标为micro avg f1-score）</li></ul><table><thead><tr class="header"><th>-</th><th>训练1</th><th>训练2</th><th>训练3</th><th>avg</th></tr></thead><tbody><tr class="odd"><td>使用FGM前</td><td>0.8926</td><td>0.8934</td><td>0.8820</td><td>0.8893</td></tr><tr class="even"><td>使用FGM后</td><td>0.9037</td><td>0.8798</td><td>0.8911</td><td>0.8915</td></tr></tbody></table><ul><li>搜狗数据集文本多分类模型（评估指标为micro avg f1-score）</li></ul><table><thead><tr class="header"><th>-</th><th>训练1</th><th>训练2</th><th>训练3</th><th>avg</th></tr></thead><tbody><tr class="odd"><td>使用FGM前</td><td>0.9778</td><td>0.9697</td><td>0.9657</td><td>0.9711</td></tr><tr class="even"><td>使用FGM后</td><td>0.9778</td><td>0.9838</td><td>0.9838</td><td>0.9818</td></tr></tbody></table><ul><li>THUCNews数据集文本多分类模型（评估指标为micro avg f1-score）</li></ul><table><thead><tr class="header"><th>-</th><th>训练1</th><th>训练2</th><th>训练3</th><th>avg</th></tr></thead><tbody><tr class="odd"><td>使用FGM前</td><td>0.9524</td><td>0.9621</td><td>0.9685</td><td>0.961</td></tr><tr class="even"><td>使用FGM后</td><td>0.9689</td><td>0.9723</td><td>0.9712</td><td>0.9708</td></tr></tbody></table><ul><li>事件类型文本多标签模型（评估指标为accuracy）</li></ul><table><thead><tr class="header"><th>-</th><th>训练1</th><th>训练2</th><th>训练3</th><th>avg</th></tr></thead><tbody><tr class="odd"><td>使用FGM前</td><td>0.8985</td><td>-</td><td>-</td><td>-</td></tr><tr class="even"><td>使用FGM后</td><td>0.9159</td><td>0.9192</td><td>0.9186</td><td>0.9179</td></tr></tbody></table><p>以上对比结果已经上传至Github，网址如下：</p><ul><li><p>命名实体识别：<ahref="https://github.com/percent4/keras_bert_sequence_labeling">https://github.com/percent4/keras_bert_sequence_labeling</a></p></li><li><p>文本多分类：<ahref="https://github.com/percent4/keras_bert_text_classification">https://github.com/percent4/keras_bert_text_classification</a></p></li><li><p>文本多标签文本：<ahref="https://github.com/percent4/keras_bert_multi_label_cls">https://github.com/percent4/keras_bert_multi_label_cls</a></p><p>总结经验为：</p></li></ul><ol type="1"><li>对抗训练FGM在很多NLP任务中可以有效提升模型效果，但代价是训练时间变长，一般是原来的1.5~2倍。</li><li>FGM一般在小样本数据集上的提升效果较为明显。</li><li>FGM并不一定总是能提升模型效果，比如笔者使用R-BERT在人物关系分类数据集上，使用FGM的效果反而变差了。</li></ol><h3 id="总结">总结</h3><p>本文主要介绍了对抗训练的概念，以及FGM实现方式和它在不同NLP任务上的模型效果对比。</p><p>最近笔者在使用keras bert实现多项选择阅读理解任务，但kerasbert比较吃显存，而且模型结构写起来比较麻烦且效果有点儿出入。而用PyTorch实现的transformers模块，使用方便而且效果也好，不得不说，Torch真香！这并不是说Keras不行，而是Torch确实使用起来很方便。这只是我现在的体会，不必过于较真。</p><p>感谢大家阅读~</p><p>2021年4月14日深夜于上海浦东，此日上海天色阴沉~</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>对抗训练浅谈：意义、方法和思考（附Keras实现）: <ahref="https://spaces.ac.cn/archives/7234">https://spaces.ac.cn/archives/7234</a></li><li>【炼丹技巧】功守道：NLP中的对抗训练 + PyTorch实现: <ahref="https://fyubang.com/2019/10/15/adversarial-train/">https://fyubang.com/2019/10/15/adversarial-train/</a></li><li>论文阅读：对抗训练（adversarial training）: <ahref="https://zhuanlan.zhihu.com/p/104040055">https://zhuanlan.zhihu.com/p/104040055</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>对抗训练</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（四十五）R-BERT在人物关系分类上的尝试及Keras代码复现</title>
    <link href="/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%94%EF%BC%89R-BERT%E5%9C%A8%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%B0%9D%E8%AF%95%E5%8F%8AKeras%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/"/>
    <url>/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%94%EF%BC%89R-BERT%E5%9C%A8%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E5%B0%9D%E8%AF%95%E5%8F%8AKeras%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将介绍关系分类模型<code>R-BERT</code>和该模型在人物关系数据集上的表现，以及该模型的Keras代码复现。</p><h3 id="关系分类任务">关系分类任务</h3><p>关系分类属于NLP任务中的文本分类，不同之处在于，关系分类提供了文本和实体。比如下面的例子：</p><blockquote><p>亲戚1837年6月20日，<e1>威廉四世</e1>辞世，他的侄女<e2>维多利亚</e2>即位。</p></blockquote><p>其中两个实体在文本中用<e1></e1>和<e2></e2>包围着，人物关系为亲戚。</p><p>在关系分类中，我们要注重文本特征，更要留意实体特征。常见的英文关系分类的数据集为<ahref="https://www.aclweb.org/anthology/S18-1117.pdf">SemEval 2010 Task8</a>、New York Times Corpus、WikiData dataset for Sentential RelationExtraction、NYT29、NYT24等，中文的关系分类数据集比较少，而且质量不高。</p><p>关于SemEval 2010 Task8数据集的实现模型及效果，可以参考：http://nlpprogress.com/english/relationship_extraction.html,其中常见的实现模型如下：</p><ul><li><p>Machince Learning: SVM, Word2Vec ...</p></li><li><p>Dependency Models: BRCNN, DRNN ...</p></li><li><p>CNN-based Models: Multi-Attention CNN, Attention CNN, PCNN+ATT...</p></li><li><p>BERT-based Models: R-BERT, Matching-the-Blanks ...</p><p>本文将介绍<code>R-BERT</code>模型。</p></li></ul><h3 id="模型介绍">模型介绍</h3><p><code>R-BERT</code>模型是Alibaba Group (U.S.)Inc的两位研究者在2019年5月的论文<ahref="https://arxiv.org/pdf/1905.08284.pdf">Enriching Pre-trainedLanguage Model with Entity Information for RelationClassification</a>，该模型在SemEval 2010 Task8数据集上的F1值为89.25%，只比现有的SOTA模型低了0.25%。</p><p><code>R-BERT</code>很好地融合了文本特征以及两个实体在文本中的特征，简单来说，该模型主要是BERT模型中的三个向量的融合：</p><ul><li><p>[CLS]对应的向量</p></li><li><p>实体1的平均向量</p></li><li><p>实体2的平均向量</p><p>下面将详细讲解<code>R-BERT</code>的具体模型结构。</p></li></ul><h3 id="模型结构">模型结构</h3><p><code>R-BERT</code>的具体模型结构如下图：</p><figure><img src="/img/nlp45_1.png" alt="R-BERT模型结构图" /><figcaption aria-hidden="true">R-BERT模型结构图</figcaption></figure><p>一图胜千言。从上述的模型结构图中，我们将模型结构分解步骤如下：</p><ol type="1"><li>将文本接入BERT模型，获取[CLS]token的对应向量、实体1的在BERT输出层中的平均向量、实体2的在BERT输出层中的平均向量；</li><li>将上述三个向量分别接Drouput层、Tanh激活层以及全连接层；</li><li>再将步骤2输出的三个向量进行拼接（concatenate）；</li><li>最后接Dropout层和全连接层，用Softmax作为多分类的激活函数。</li></ol><p>此外，需要注意的是，输入文本中没有[SEP]这个token。</p><p>论文中并没有给出更多的实现细节，需要深入到代码中去查看。网上已经有人给出了Torch框架的实现<code>R-BERT</code>的代码，参考网址为：https://github.com/monologg/R-BERT。</p><h3 id="torch实现">Torch实现</h3><p>Torch框架的实现<code>R-BERT</code>的代码（模型部分）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel, BertPreTrainedModel<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FCLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, output_dim, dropout_rate=<span class="hljs-number">0.0</span>, use_activation=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>(FCLayer, self).__init__()<br>        self.use_activation = use_activation<br>        self.dropout = nn.Dropout(dropout_rate)<br>        self.linear = nn.Linear(input_dim, output_dim)<br>        self.tanh = nn.Tanh()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.dropout(x)<br>        <span class="hljs-keyword">if</span> self.use_activation:<br>            x = self.tanh(x)<br>        <span class="hljs-keyword">return</span> self.linear(x)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RBERT</span>(<span class="hljs-title class_ inherited__">BertPreTrainedModel</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config, args</span>):<br>        <span class="hljs-built_in">super</span>(RBERT, self).__init__(config)<br>        self.bert = BertModel(config=config)  <span class="hljs-comment"># Load pretrained bert</span><br><br>        self.num_labels = config.num_labels<br><br>        self.cls_fc_layer = FCLayer(config.hidden_size, config.hidden_size, args.dropout_rate)<br>        self.entity_fc_layer = FCLayer(config.hidden_size, config.hidden_size, args.dropout_rate)<br>        self.label_classifier = FCLayer(<br>            config.hidden_size * <span class="hljs-number">3</span>,<br>            config.num_labels,<br>            args.dropout_rate,<br>            use_activation=<span class="hljs-literal">False</span>,<br>        )<br><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">entity_average</span>(<span class="hljs-params">hidden_output, e_mask</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Average the entity hidden state vectors (H_i ~ H_j)</span><br><span class="hljs-string">        :param hidden_output: [batch_size, j-i+1, dim]</span><br><span class="hljs-string">        :param e_mask: [batch_size, max_seq_len]</span><br><span class="hljs-string">                e.g. e_mask[0] == [0, 0, 0, 1, 1, 1, 0, 0, ... 0]</span><br><span class="hljs-string">        :return: [batch_size, dim]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        e_mask_unsqueeze = e_mask.unsqueeze(<span class="hljs-number">1</span>)  <span class="hljs-comment"># [b, 1, j-i+1]</span><br>        length_tensor = (e_mask != <span class="hljs-number">0</span>).<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>).unsqueeze(<span class="hljs-number">1</span>)  <span class="hljs-comment"># [batch_size, 1]</span><br><br>        <span class="hljs-comment"># [b, 1, j-i+1] * [b, j-i+1, dim] = [b, 1, dim] -&gt; [b, dim]</span><br>        sum_vector = torch.bmm(e_mask_unsqueeze.<span class="hljs-built_in">float</span>(), hidden_output).squeeze(<span class="hljs-number">1</span>)<br>        avg_vector = sum_vector.<span class="hljs-built_in">float</span>() / length_tensor.<span class="hljs-built_in">float</span>()  <span class="hljs-comment"># broadcasting</span><br>        <span class="hljs-keyword">return</span> avg_vector<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_ids, attention_mask, token_type_ids, labels, e1_mask, e2_mask</span>):<br>        outputs = self.bert(<br>            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids<br>        )  <span class="hljs-comment"># sequence_output, pooled_output, (hidden_states), (attentions)</span><br>        sequence_output = outputs[<span class="hljs-number">0</span>]<br>        pooled_output = outputs[<span class="hljs-number">1</span>]  <span class="hljs-comment"># [CLS]</span><br><br>        <span class="hljs-comment"># Average</span><br>        e1_h = self.entity_average(sequence_output, e1_mask)<br>        e2_h = self.entity_average(sequence_output, e2_mask)<br><br>        <span class="hljs-comment"># Dropout -&gt; tanh -&gt; fc_layer (Share FC layer for e1 and e2)</span><br>        pooled_output = self.cls_fc_layer(pooled_output)<br>        e1_h = self.entity_fc_layer(e1_h)<br>        e2_h = self.entity_fc_layer(e2_h)<br><br>        <span class="hljs-comment"># Concat -&gt; fc_layer</span><br>        concat_h = torch.cat([pooled_output, e1_h, e2_h], dim=-<span class="hljs-number">1</span>)<br>        logits = self.label_classifier(concat_h)<br><br>        outputs = (logits,) + outputs[<span class="hljs-number">2</span>:]  <span class="hljs-comment"># add hidden states and attention if they are here</span><br><br>        <span class="hljs-comment"># Softmax</span><br>        <span class="hljs-keyword">if</span> labels <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">if</span> self.num_labels == <span class="hljs-number">1</span>:<br>                loss_fct = nn.MSELoss()<br>                loss = loss_fct(logits.view(-<span class="hljs-number">1</span>), labels.view(-<span class="hljs-number">1</span>))<br>            <span class="hljs-keyword">else</span>:<br>                loss_fct = nn.CrossEntropyLoss()<br>                loss = loss_fct(logits.view(-<span class="hljs-number">1</span>, self.num_labels), labels.view(-<span class="hljs-number">1</span>))<br><br>            outputs = (loss,) + outputs<br><br>        <span class="hljs-keyword">return</span> outputs<br></code></pre></td></tr></table></figure><p>该项目是在SemEval 2010 Task8数据集实现的，笔者将其在自己的人物关系分类数据集上进行测试，最终在测试集上的评估结果如下：</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gcode"><span class="hljs-attr"># Model: chinese-roberta-wwm-ext, weighted avgage F1</span> = <span class="hljs-number">85.35</span><span class="hljs-meta">%</span><br><span class="hljs-attr"># Model: chinese-roberta-wwm-ext-large, weighted avgage F1</span> = <span class="hljs-number">87.22</span><span class="hljs-meta">%</span><br></code></pre></td></tr></table></figure><p>Model: chinese-roberta-wwm-ext-large, 详细的评估结果如下：</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs crystal">                precision    recall  f1-score   support<br><br>     unknown      <span class="hljs-number">0.8756</span>    <span class="hljs-number">0.8421</span>    <span class="hljs-number">0.8585</span>       <span class="hljs-number">209</span><br>         上下级    <span class="hljs-number">0.7297</span>    <span class="hljs-number">0.8710</span>    <span class="hljs-number">0.7941</span>        <span class="hljs-number">31</span><br>          亲戚     <span class="hljs-number">0.8421</span>    <span class="hljs-number">0.6667</span>    <span class="hljs-number">0.7442</span>        <span class="hljs-number">24</span><br>        兄弟姐妹    <span class="hljs-number">0.8333</span>    <span class="hljs-number">0.8824</span>    <span class="hljs-number">0.8571</span>        <span class="hljs-number">34</span><br>          合作     <span class="hljs-number">0.9074</span>    <span class="hljs-number">0.8305</span>    <span class="hljs-number">0.8673</span>        <span class="hljs-number">59</span><br>          同人     <span class="hljs-number">0.9744</span>    <span class="hljs-number">0.9744</span>    <span class="hljs-number">0.9744</span>        <span class="hljs-number">39</span><br>          同学     <span class="hljs-number">0.9130</span>    <span class="hljs-number">0.8750</span>    <span class="hljs-number">0.8936</span>        <span class="hljs-number">24</span><br>          同门     <span class="hljs-number">0.9630</span>    <span class="hljs-number">1.0000</span>    <span class="hljs-number">0.9811</span>        <span class="hljs-number">26</span><br>          夫妻     <span class="hljs-number">0.8372</span>    <span class="hljs-number">0.9114</span>    <span class="hljs-number">0.8727</span>        <span class="hljs-number">79</span><br>          好友     <span class="hljs-number">0.8438</span>    <span class="hljs-number">0.9000</span>    <span class="hljs-number">0.8710</span>        <span class="hljs-number">30</span><br>          师生     <span class="hljs-number">0.8378</span>    <span class="hljs-number">0.8378</span>    <span class="hljs-number">0.8378</span>        <span class="hljs-number">37</span><br>          情侣     <span class="hljs-number">0.8125</span>    <span class="hljs-number">0.8387</span>    <span class="hljs-number">0.8254</span>        <span class="hljs-number">31</span><br>          父母     <span class="hljs-number">0.8931</span>    <span class="hljs-number">0.9141</span>    <span class="hljs-number">0.9035</span>       <span class="hljs-number">128</span><br>          祖孙     <span class="hljs-number">0.9545</span>    <span class="hljs-number">0.8400</span>    <span class="hljs-number">0.8936</span>        <span class="hljs-number">25</span><br><br>    accuracy                         <span class="hljs-number">0.8724</span>       <span class="hljs-number">776</span><br>   <span class="hljs-function"><span class="hljs-keyword">macro</span> <span class="hljs-title">avg</span></span>     <span class="hljs-number">0.8727</span>    <span class="hljs-number">0.8703</span>    <span class="hljs-number">0.8696</span>       <span class="hljs-number">776</span><br>weighted avg     <span class="hljs-number">0.8743</span>    <span class="hljs-number">0.8724</span>    <span class="hljs-number">0.8722</span>       <span class="hljs-number">776</span><br></code></pre></td></tr></table></figure><p><code>R-BERT</code>模型在人物关系数据集上的Github项目为<ahref="https://github.com/percent4/R-BERT_for_people_relation_extraction">R-BERT_for_people_relation_extraction</a>。下面将介绍<code>R-BERT</code>模型的Keras框架复现。</p><h3 id="keras复现">Keras复现</h3><p><code>R-BERT</code>模型的Keras框架复现（模型部分）的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># main architecture of R-BERT</span><br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model<br><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> plot_model<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Input, Lambda, Dense, Dropout, concatenate, Dot<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> load_trained_model_from_checkpoint<br><br><br><span class="hljs-comment"># model structure of R-BERT</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RBERT</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config_path, checkpoint_path, maxlen, num_labels</span>):<br>        self.config_path = config_path<br>        self.checkpoint_path = checkpoint_path<br>        self.maxlen = maxlen<br>        self.num_labels = num_labels<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">create_model</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># BERT model</span><br>        bert_model = load_trained_model_from_checkpoint(self.config_path, self.checkpoint_path, seq_len=<span class="hljs-literal">None</span>)<br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> bert_model.layers:<br>            layer.trainable = <span class="hljs-literal">True</span><br>        x1_in = Input(shape=(self.maxlen,))<br>        x2_in = Input(shape=(self.maxlen,))<br>        bert_layer = bert_model([x1_in, x2_in])<br><br>        <span class="hljs-comment"># get three vectors</span><br>        cls_layer = Lambda(<span class="hljs-keyword">lambda</span> x: x[:, <span class="hljs-number">0</span>])(bert_layer)    <span class="hljs-comment"># 取出[CLS]对应的向量</span><br>        e1_mask = Input(shape=(self.maxlen,))<br>        e2_mask = Input(shape=(self.maxlen,))<br>        e1_layer = self.entity_average(bert_layer, e1_mask)  <span class="hljs-comment"># 取出实体1对应的向量</span><br>        e2_layer = self.entity_average(bert_layer, e2_mask)  <span class="hljs-comment"># 取出实体2对应的向量</span><br><br>        <span class="hljs-comment"># dropout -&gt; linear -&gt; concatenate</span><br>        output_dim = cls_layer.shape[-<span class="hljs-number">1</span>].value<br>        cls_fc_layer = self.crate_fc_layer(cls_layer, output_dim, dropout_rate=<span class="hljs-number">0.1</span>)<br>        e1_fc_layer = self.crate_fc_layer(e1_layer, output_dim, dropout_rate=<span class="hljs-number">0.1</span>)<br>        e2_fc_layer = self.crate_fc_layer(e2_layer, output_dim, dropout_rate=<span class="hljs-number">0.1</span>)<br>        concat_layer = concatenate([cls_fc_layer, e1_fc_layer, e2_fc_layer], axis=-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># FC layer for classification</span><br>        output = Dense(self.num_labels, activation=<span class="hljs-string">&quot;softmax&quot;</span>)(concat_layer)<br>        model = Model([x1_in, x2_in, e1_mask, e2_mask], output)<br>        model.summary()<br>        <span class="hljs-keyword">return</span> model<br><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">crate_fc_layer</span>(<span class="hljs-params">input_layer, output_dim, dropout_rate=<span class="hljs-number">0.0</span>, activation_func=<span class="hljs-string">&quot;tanh&quot;</span></span>):<br>        dropout_layer = Dropout(rate=dropout_rate)(input_layer)<br>        linear_layer = Dense(output_dim, activation=activation_func)(dropout_layer)<br>        <span class="hljs-keyword">return</span> linear_layer<br><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">entity_average</span>(<span class="hljs-params">hidden_output, e_mask</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Average the entity hidden state vectors (H_i ~ H_j)</span><br><span class="hljs-string">        :param hidden_output: BERT hidden output</span><br><span class="hljs-string">        :param e_mask:</span><br><span class="hljs-string">                e.g. e_mask[0] == [0, 0, 0, 1, 1, 1, 0, 0, ... 0]/num_of_ones</span><br><span class="hljs-string">        :return: entity average layer</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        avg_layer = Dot(axes=<span class="hljs-number">1</span>)([e_mask, hidden_output])<br>        <span class="hljs-keyword">return</span> avg_layer<br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p><code>R-BERT</code>模型再次见证了BERT等预训练模型的强大。该模型的实现思路比较简单，也取得了很不错的效果，是关系分类任务的一大突破。</p><p>当然对笔者来说，也有种重要的意义：第一次自己复现了论文代码，虽然有Torch代码可以参考。</p><p>本文分享到此结束，感谢阅读~</p><p>2021年4月1日于上海杨浦，此日大雾迷城~</p><h3 id="参考文献">参考文献</h3><ul><li>NLP-progress Relation Extraction:http://nlpprogress.com/english/relationship_extraction.html</li><li>Huggingface Transformers:https://github.com/huggingface/transformers</li><li>https://github.com/wang-h/bert-relation-classification</li><li>R-BERT: https://github.com/monologg/R-BERT</li><li>Enriching Pre-trained Language Model with Entity Information forRelation Classification: https://arxiv.org/pdf/1905.08284.pdf</li><li>Chinese-BERT-wwm: https://github.com/ymcui/Chinese-BERT-wwm</li></ul>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BERT</tag>
      
      <tag>NLP</tag>
      
      <tag>关系分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（四十四）使用keras-bert加载BERT模型的两种方法</title>
    <link href="/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%8A%A0%E8%BD%BDBERT%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/"/>
    <url>/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%8A%A0%E8%BD%BDBERT%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><code>keras-bert</code>是Keras框架加载BERT模型的Python第三方模块，在之前的文章中，笔者介绍了如何使用<code>keras-bret</code>来实现不同的NLP任务，比如：</p><ul><li><p><ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/">NLP（三十四）使用keras-bert实现序列标注任务</a></p></li><li><p><ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%BA%94%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">NLP（三十五）使用keras-bert实现文本多分类任务</a></p></li><li><p><ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">NLP（三十六）使用keras-bert实现文本多标签分类任务</a></p></li><li><p><ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%B8%83%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E8%8B%B1%E8%AF%AD%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/">NLP（三十七）使用keras-bert实现英语序列标注任务</a></p></li><li><p><ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%B9%9D%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%AE%8C%E5%BD%A2%E5%A1%AB%E7%A9%BA%E5%8F%8A%E7%AE%80%E5%8D%95%E7%9A%84%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99%E5%8A%9F%E8%83%BD/">NLP（三十九）使用keras-bert实现完形填空及简单的文本纠错功能</a></p></li><li><p><ahref="https://blog.csdn.net/jclian91/article/details/115219543">NLP（四十二）人物关系分类的再次尝试</a></p><p>本文将介绍两种使用<code>keras-bert</code>加载BERT模型的方法。使用的Python环境如下：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">python==3.7.0<br>tensorflow==1.14.0<br>Keras==2.2.4<br>keras-bert==0.83.0<br></code></pre></td></tr></table></figure><p>加载的模型为Google官方发布的BERT中文预训练模型。创建的模型为<code>BERT+Bi-LSTM+CRF</code>，其中对BERT进行微调。</p><h3 id="方法1">方法1</h3><p>方法1的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model<br><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> plot_model<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> load_trained_model_from_checkpoint<br><span class="hljs-keyword">from</span> keras_contrib.layers <span class="hljs-keyword">import</span> CRF<br><br><br><span class="hljs-comment"># 创建BERT-BiLSTM-CRF模型</span><br>model_path = <span class="hljs-string">&quot;./chinese_L-12_H-768_A-12/&quot;</span><br>bert = load_trained_model_from_checkpoint(<br>    model_path + <span class="hljs-string">&quot;bert_config.json&quot;</span>,<br>    model_path + <span class="hljs-string">&quot;bert_model.ckpt&quot;</span>,<br>    seq_len=<span class="hljs-number">128</span><br>)<br><span class="hljs-comment"># make bert layer trainable</span><br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> bert.layers:<br>    layer.trainable = <span class="hljs-literal">True</span><br><br>x1 = Input(shape=(<span class="hljs-literal">None</span>,))<br>x2 = Input(shape=(<span class="hljs-literal">None</span>,))<br>bert_out = bert([x1, x2])<br>lstm_out = Bidirectional(LSTM(<span class="hljs-number">64</span>,<br>                              return_sequences=<span class="hljs-literal">True</span>,<br>                              dropout=<span class="hljs-number">0.2</span>,<br>                              recurrent_dropout=<span class="hljs-number">0.2</span>))(bert_out)<br>crf_out = CRF(<span class="hljs-number">8</span>, sparse_target=<span class="hljs-literal">True</span>)(lstm_out)<br>model = Model([x1, x2], crf_out)<br>model.summary()<br>plot_model(model, to_file=<span class="hljs-string">&quot;model.png&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出的模型结构如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>__<br><span class="hljs-section">Layer (type)                    Output Shape         Param #     Connected to                     </span><br><span class="hljs-section">==================================================================================================</span><br>input<span class="hljs-emphasis">_1 (InputLayer)            (None, None)         0                                            </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span>_<br>input<span class="hljs-emphasis">_2 (InputLayer)            (None, None)         0                                            </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span>_<br>model<span class="hljs-emphasis">_2 (Model)                 multiple             101382144   input_</span>1[<span class="hljs-string">0</span>][<span class="hljs-symbol">0</span>]                    <br><span class="hljs-code">                                                                 input_2[0][0]                    </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">bidirectional_1 (Bidirectional) (None, None, 128)    426496      model_2[1][0]                    </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">crf_1 (CRF)                     (None, None, 8)      1112        bidirectional_1[0][0]            </span><br><span class="hljs-code">==================================================================================================</span><br><span class="hljs-code">Total params: 101,809,752</span><br><span class="hljs-code">Trainable params: 101,809,752</span><br><span class="hljs-code">Non-trainable params: 0</span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br></code></pre></td></tr></table></figure><figure><img src="/img/nlp44_1.png" alt="模型结构示意图" /><figcaption aria-hidden="true">模型结构示意图</figcaption></figure><p>可以看到，该方法加载BERT，会把BERT模型整体当做一个输出形状为multiple的层，我们无法得知BERT模型的具体层信息，好处是我们的模型结构会显得比较简单（略去了BERT的细节）。</p><h3 id="方法2">方法2</h3><p>方法2加载BERT模型的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model<br><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> plot_model<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> load_trained_model_from_checkpoint<br><span class="hljs-keyword">from</span> keras_contrib.layers <span class="hljs-keyword">import</span> CRF<br><br><br><span class="hljs-comment"># 创建BERT-BiLSTM-CRF模型</span><br>model_path = <span class="hljs-string">&quot;./chinese_L-12_H-768_A-12/&quot;</span><br>bert = load_trained_model_from_checkpoint(<br>    model_path + <span class="hljs-string">&quot;bert_config.json&quot;</span>,<br>    model_path + <span class="hljs-string">&quot;bert_model.ckpt&quot;</span>,<br>    seq_len=<span class="hljs-number">128</span><br>)<br><span class="hljs-comment"># make bert layer trainable</span><br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> bert.layers:<br>    layer.trainable = <span class="hljs-literal">True</span><br><br>lstm_out = Bidirectional(LSTM(<span class="hljs-number">64</span>,<br>                              return_sequences=<span class="hljs-literal">True</span>,<br>                              dropout=<span class="hljs-number">0.2</span>,<br>                              recurrent_dropout=<span class="hljs-number">0.2</span>))(bert.output)<br>crf_out = CRF(<span class="hljs-number">8</span>, sparse_target=<span class="hljs-literal">True</span>)(lstm_out)<br>model = Model(bert.<span class="hljs-built_in">input</span>, crf_out)<br>model.summary()<br>plot_model(model, to_file=<span class="hljs-string">&quot;model.png&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出的模型结构如下：</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Layer (type)                    Output Shape         Param #     Connected to                     </span><br><span class="hljs-quote">==================================================================================================</span><br><span class="hljs-quote">Input-Token (InputLayer)        (None, 128)          0                                            </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Input-Segment (InputLayer)      (None, 128)          0                                            <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Embedding-Token (TokenEmbedding [(None, 128, 768), ( 16226304    Input-Token[0][0]                </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            </span><br><span class="hljs-quote">                                                                 Embedding-Segment[0][0]          </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Embedding-Position (PositionEmb (None, 128, 768)     98304       Embedding-Token-Segment[0][0]    <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             </span><br><span class="hljs-quote">                                                                 Encoder-1-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-</span><br><span class="hljs-quote">                                                                 Encoder-1-FeedForward-Dropout[0][</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">                                                                 Encoder-2-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-</span><br><span class="hljs-quote">                                                                 Encoder-2-FeedForward-Dropout[0][</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">                                                                 Encoder-3-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-</span><br><span class="hljs-quote">                                                                 Encoder-3-FeedForward-Dropout[0][</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">                                                                 Encoder-4-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-</span><br><span class="hljs-quote">                                                                 Encoder-4-FeedForward-Dropout[0][</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">                                                                 Encoder-5-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-</span><br><span class="hljs-quote">                                                                 Encoder-5-FeedForward-Dropout[0][</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">                                                                 Encoder-6-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-</span><br><span class="hljs-quote">                                                                 Encoder-6-FeedForward-Dropout[0][</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">                                                                 Encoder-7-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-</span><br><span class="hljs-quote">                                                                 Encoder-7-FeedForward-Dropout[0][</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">                                                                 Encoder-8-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-</span><br><span class="hljs-quote">                                                                 Encoder-8-FeedForward-Dropout[0][</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">                                                                 Encoder-9-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-</span><br><span class="hljs-quote">                                                                 Encoder-9-FeedForward-Dropout[0][</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] </span><br><span class="hljs-quote">                                                                 Encoder-10-MultiHeadSelfAttention</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention</span><br><span class="hljs-quote">                                                                 Encoder-10-FeedForward-Dropout[0]</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]</span><br><span class="hljs-quote">                                                                 Encoder-11-MultiHeadSelfAttention</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention</span><br><span class="hljs-quote">                                                                 Encoder-11-FeedForward-Dropout[0]</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]</span><br><span class="hljs-quote">                                                                 Encoder-12-MultiHeadSelfAttention</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention<br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention</span><br><span class="hljs-quote">                                                                 Encoder-12-FeedForward-Dropout[0]</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] <br><span class="hljs-quote">__________________________________________________________________________________________________</span><br><span class="hljs-quote">bidirectional_1 (Bidirectional) (None, 128, 128)     426496      Encoder-12-FeedForward-Norm[0][0]</span><br><span class="hljs-quote">__________________________________________________________________________________________________</span><br>crf<span class="hljs-emphasis">_1 (CRF)                     (None, 128, 8)       1112        bidirectional_1[0][0]            </span><br><span class="hljs-emphasis">==================================================================================================</span><br><span class="hljs-emphasis">Total params: 101,809,752</span><br><span class="hljs-emphasis">Trainable params: 101,809,752</span><br><span class="hljs-emphasis">Non-trainable params: 0</span><br><span class="hljs-emphasis">__________________________________________________________________________________________________</span><br></code></pre></td></tr></table></figure><figure><img src="/img/nlp44_2.png" alt="模型结构示意图" /><figcaption aria-hidden="true">模型结构示意图</figcaption></figure><p>可以看到，该方法加载BERT模型，可以完整地看到BERT具体层信息，而不是把BERT模型当成一个层来看，更像是BERTfinetune的感觉。</p><h3 id="总结">总结</h3><p>本文较为简单，介绍了两种使用<code>keras-bert</code>加载BERT模型的方法。之所以笔者在此介绍这些加载方法，是为了后续方便使用对抗训练FGM来增加模型效果，FGM对抗训练需要我们对Embedding层做扰动。</p><p>本文到此结束，感谢大家的阅读~</p><p>2021年3月31日于上海浦东~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BERT</tag>
      
      <tag>NLP</tag>
      
      <tag>keras-bert</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（四十三）模型调参技巧之Warmup and Decay</title>
    <link href="/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B8%89%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7%E4%B9%8BWarmup-and-Decay/"/>
    <url>/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B8%89%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7%E4%B9%8BWarmup-and-Decay/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Warmup and Decay是深度学习中模型调参的常用trick。本文将简单介绍Warmupand Decay以及如何在keras_bert中使用它们。</p><h3 id="什么是warmup-and-decay">什么是warmup and decay？</h3><p>Warmup and Decay是模型训练过程中，一种学习率（learningrate）的调整策略。</p><p>Warmup是在ResNet论文中提到的一种学习率预热的方法，它在训练开始的时候先选择使用一个较小的学习率，训练了一些epoches或者steps(比如4个epoches,10000steps),再修改为预先设置的学习来进行训练。</p><p>同理，Decay是学习率衰减方法，它指定在训练到一定epoches或者steps后，按照线性或者余弦函数等方式，将学习率降低至指定值。一般，使用Warmupand Decay，学习率会遵循从小到大，再减小的规律。</p><p>由于刚开始训练时,模型的权重(weights)是随机初始化的，此时若选择一个较大的学习率,可能带来模型的不稳定(振荡)，选择Warmup预热学习率的方式，可以使得开始训练的几个epoches或者一些steps内学习率较小,在预热的小学习率下，模型可以慢慢趋于稳定，等模型相对稳定后再选择预先设置的学习率进行训练,使得模型收敛速度变得更快，模型效果更佳。而当模型训到一定阶段后（比如10个epoch），模型的分布就已经比较固定了，或者说能学到的新东西就比较少了。如果还沿用较大的学习率，就会破坏这种稳定性，用我们通常的话说，就是已经接近损失函数的局部最优值点了，为了靠近这个局部最优值点，我们就要慢慢来。</p><h3id="如何在keras_bert中使用warmup-and-decay">如何在keras_bert中使用Warmupand Decay？</h3><p>在keras_bert中，提供了优化器AdamWarmup类，其参数定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">AdamWarmup</span>(keras.optimizers.Optimizer):<br>    <span class="hljs-string">&quot;&quot;&quot;Adam optimizer with warmup.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Default parameters follow those provided in the original paper.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    # Arguments</span><br><span class="hljs-string">        decay_steps: Learning rate will decay linearly to zero in decay steps.</span><br><span class="hljs-string">        warmup_steps: Learning rate will increase linearly to lr in first warmup steps.</span><br><span class="hljs-string">        learning_rate: float &gt;= 0. Learning rate.</span><br><span class="hljs-string">        beta_1: float, 0 &lt; beta &lt; 1. Generally close to 1.</span><br><span class="hljs-string">        beta_2: float, 0 &lt; beta &lt; 1. Generally close to 1.</span><br><span class="hljs-string">        epsilon: float &gt;= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.</span><br><span class="hljs-string">        weight_decay: float &gt;= 0. Weight decay.</span><br><span class="hljs-string">        weight_decay_pattern: A list of strings. The substring of weight names to be decayed.</span><br><span class="hljs-string">                              All weights will be decayed if it is None.</span><br><span class="hljs-string">        amsgrad: boolean. Whether to apply the AMSGrad variant of this</span><br><span class="hljs-string">            algorithm from the paper &quot;On the Convergence of Adam and</span><br><span class="hljs-string">            Beyond&quot;.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, decay_steps, warmup_steps, min_lr=<span class="hljs-number">0.0</span>,</span><br><span class="hljs-params">                 learning_rate=<span class="hljs-number">0.001</span>, beta_1=<span class="hljs-number">0.9</span>, beta_2=<span class="hljs-number">0.999</span>,</span><br><span class="hljs-params">                 epsilon=<span class="hljs-literal">None</span>, weight_decay=<span class="hljs-number">0.</span>, weight_decay_pattern=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                 amsgrad=<span class="hljs-literal">False</span>, **kwargs</span>):<br></code></pre></td></tr></table></figure><p>在这个类中，我们需要指定<code>decay_steps</code>，<code>warmup_steps</code>，<code>learning_rate</code>，<code>min_lr</code>，其含义为模型在训练<code>warmup_steps</code>后，将学习率逐渐增加至<code>learning_rate</code>，在训练<code>decay_steps</code>后，将学习率逐渐线性地降低至<code>min_lr</code>。</p><p>以下为Warmup预热学习率以及学习率预热完成后衰减(sin or expdecay)的曲线图：</p><figure><img src="/img/nlp43_1.png" alt="学习率Warmup and Decay示意图" /><figcaption aria-hidden="true">学习率Warmup and Decay示意图</figcaption></figure><p>在keras_bert的官方文档中，给出了使用Warmup andDecay的代码例子，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> AdamWarmup, calc_train_steps<br><br>train_x = np.random.standard_normal((<span class="hljs-number">1024</span>, <span class="hljs-number">100</span>))<br><br>total_steps, warmup_steps = calc_train_steps(<br>    num_example=train_x.shape[<span class="hljs-number">0</span>],<br>    batch_size=<span class="hljs-number">32</span>,<br>    epochs=<span class="hljs-number">10</span>,<br>    warmup_proportion=<span class="hljs-number">0.1</span>,<br>)<br><br>optimizer = AdamWarmup(total_steps, warmup_steps, lr=<span class="hljs-number">1e-3</span>, min_lr=<span class="hljs-number">1e-5</span>)<br></code></pre></td></tr></table></figure><h3 id="warmup-and-decay实战">Warmup and Decay实战</h3><p>笔者在文章<ahref="https://percent4.github.io/2023/07/10/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/">NLP（三十四）使用keras-bert实现序列标注任务</a>中，在使用keras-bert训练序列标注模型时，学习率调整策略使用了<code>ReduceLROnPlateau</code>，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">reduce_lr = ReduceLROnPlateau(monitor=<span class="hljs-string">&#x27;val_loss&#x27;</span>, min_delta=<span class="hljs-number">0.0004</span>, patience=<span class="hljs-number">2</span>, factor=<span class="hljs-number">0.1</span>, min_lr=<span class="hljs-number">1e-6</span>,<br>                                  mode=<span class="hljs-string">&#x27;auto&#x27;</span>,<br>                                  verbose=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>在三个数据集上的评估结果如下：</p><ul><li><p>人民日报命名实体识别数据集：micro avg F1=0.9182</p></li><li><p>时间识别数据集：micro avg F1=0.8587</p></li><li><p>CLUENER细粒度实体识别数据集：micro avg F1=0.7603</p><p>我们将学习率调整策略修改为Warmup andDecay（模型其他参数不变，数据集不变），代码如下：</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># add warmup</span><br>    total_steps, warmup_steps = calc_train_steps(<br>        num_example=<span class="hljs-built_in">len</span>(input_train),<br>        batch_size=BATCH_SIZE,<br>        epochs=EPOCH,<br>        warmup_proportion=<span class="hljs-number">0.2</span>,<br>    )<br>    optimizer = AdamWarmup(total_steps, warmup_steps, lr=<span class="hljs-number">1e-4</span>, min_lr=<span class="hljs-number">1e-7</span>)<br>    model = BertBilstmCRF(max_seq_length=MAX_SEQ_LEN, lstm_dim=<span class="hljs-number">64</span>).create_model()<br>    model.<span class="hljs-built_in">compile</span>(<br>        optimizer=optimizer,<br>        loss=crf_loss,<br>        metrics=[crf_accuracy]<br>    )<br></code></pre></td></tr></table></figure><p>使用该trick，在三个数据集上的评估结果如下：</p><ul><li>人民日报命名实体识别数据集</li></ul><table><thead><tr class="header"><th>学习率调整</th><th>预测1</th><th>预测2</th><th>预测3</th><th>avg</th></tr></thead><tbody><tr class="odd"><td>Warmup</td><td>0.9276</td><td>0.9217</td><td>0.9252</td><td>0.9248</td></tr></tbody></table><ul><li>时间识别数据集</li></ul><table><thead><tr class="header"><th>学习率调整</th><th>预测1</th><th>预测2</th><th>预测3</th><th>avg</th></tr></thead><tbody><tr class="odd"><td>Warmup</td><td>0.8926</td><td>0.8934</td><td>0.8820</td><td>0.8893</td></tr></tbody></table><ul><li>CLUENER细粒度实体识别数据集</li></ul><table><thead><tr class="header"><th>学习率调整</th><th>预测1</th><th>预测2</th><th>预测3</th><th>avg</th></tr></thead><tbody><tr class="odd"><td>Warmup</td><td>0.7612</td><td>0.7629</td><td>0.7607</td><td>0.7616</td></tr></tbody></table><p>可以看到，使用了Warmup andDecay，模型在不同的数据集上均有不同程度的效果提升。</p><p>本项目已经开源，代码地址为：<ahref="https://github.com/percent4/keras_bert_sequence_labeling">https://github.com/percent4/keras_bert_sequence_labeling</a>。</p><p>本文到此结束，感谢大家的阅读~</p><p>2021年3月27日于上海浦东~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>Warmup and Decay</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（四十二）人物关系分类的再次尝试</title>
    <link href="/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%8C%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E7%9A%84%E5%86%8D%E6%AC%A1%E5%B0%9D%E8%AF%95/"/>
    <url>/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%8C%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E7%9A%84%E5%86%8D%E6%AC%A1%E5%B0%9D%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>两周前的周末，笔者决定对人物关系分类进行再次尝试。</p><p>为什么说是再次尝试呢？因为笔者之前已经写过一篇文章<ahref="https://blog.csdn.net/jclian91/article/details/104380371">NLP（二十一）人物关系抽取的一次实战</a>，当时的标注数据大约2900条，使用的模型也比较简单，为BERT+Bi-GRU+Attention+FC结构，其中BERT用作特征提取，该模型在原有数据集上的F1为79%。</p><p>经过笔者一年断断续续的努力，现在的标注样本已经达到3900多条。鉴于笔者已做过BERT微调相关工作，当然希望在此数据集上进行再次尝试。</p><p>现有的人物关系数据集大约3900多条，分布如下图：</p><figure><img src="/img/nlp42_1.png" alt="人物关系分布图" /><figcaption aria-hidden="true">人物关系分布图</figcaption></figure><p>首先，我们只使用BERT分类模型，对输入数据进行格式改造，进行简单地尝试。</p><p>我们以样本<code>亲戚  1837年6月20日，威廉四世辞世，他的侄女维多利亚即位。</code>为例，其中<code>亲戚</code>为人物关系，<code>威廉四世</code>为实体1，<code>维多利亚</code>为实体2，来演示输入的文本格式。下面的部分我们统一使用<code>chinese-RoBERTa-wwm-ext</code>作为预训练模型，数据集分为训练集和测试集，比例为8:2。</p><p>第一种方法，我们与文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%80%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%AE%9E%E6%88%98/">NLP（二十一）人物关系抽取的一次实战</a>一样，在文本中将实体1替换为同样数量的<code>#</code>，实体2替换为同样数量的<code>#</code>，再将实体1、实体2、文本用<code>$</code>连接，输入格式为：<code>威廉四世$维多利亚$1837年6月20日，####辞世，他的侄女####即位。</code>。使用BERT+Bi-GRU+Attention+FC模型，在测试集上的评估结果如下：</p><table><thead><tr class="header"><th>模型名称</th><th>训练1</th><th>训练2</th><th>训练3</th><th>训练4</th><th>训练5</th><th>Avg</th></tr></thead><tbody><tr class="odd"><td>BiGRU+Attention</td><td>0.7726</td><td>0.7974</td><td>0.7935</td><td>0.7908</td><td>0.7941</td><td>0.7897</td></tr></tbody></table><p>第二种方法，输入格式与第一种方法一致。使用文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%BA%94%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">NLP（三十五）使用keras-bert实现文本多分类任务</a>中的多分类模型进行训练，在测试集上的评估结果如下：</p><table><thead><tr class="header"><th>模型名称</th><th>训练1</th><th>训练2</th><th>训练3</th><th>训练4</th><th>训练5</th><th>Avg</th></tr></thead><tbody><tr class="odd"><td>Bert_cls</td><td>0.8246</td><td>0.8110</td><td>0.8282</td><td>0.8448</td><td>0.8218</td><td>0.8260</td></tr></tbody></table><p>可以看到，有了预训练模型的帮助，模型效果有了显著提升，F1值平均高了3.6%。</p><p>第三种方法，在文本中将实体用<code>#</code>包围，输入格式为：<code>1837年6月20日，#威廉四世#辞世，他的侄女#维多利亚#即位。</code>使用BERT_cls模型，在测试集上的评估结果如下：</p><table><thead><tr class="header"><th>模型名称</th><th>训练1</th><th>训练2</th><th>训练3</th><th>训练4</th><th>训练5</th><th>Avg</th></tr></thead><tbody><tr class="odd"><td>Bert_cls2（实体用#围绕）</td><td>0.8175</td><td>0.8259</td><td>0.8275</td><td>0.8335</td><td>0.8299</td><td>0.8269</td></tr></tbody></table><p>可以看到，该输入格式与第二种方法相比，在模型效果上并没有太大的提升。</p><p>也许，是时候尝试新的模型了。</p><p>上周一晚上，笔者无意中看到一篇论文，名称为<ahref="https://arxiv.org/pdf/1905.08284.pdf">Enriching Pre-trainedLanguage Model with Entity Information for RelationClassification</a>，顾名思义为使用实体信息将预训练模型用于关系分类（RC）。其模型结构如下图：</p><figure><img src="/img/nlp42_1.png" alt="R-BERT模型结构图" /><figcaption aria-hidden="true">R-BERT模型结构图</figcaption></figure><p>该模型被称为<code>R-BERT</code>，模型结构在此不多介绍，后面有机会再介绍。在Github上有<code>R-BERT</code>模型的Torch框架实现方式，在<code>Semeval 2010 Task 8 Dataset</code>取得了不错的效果。</p><p>笔者将<code>R-BERT</code>用于人物关系分类数据集中，在测试集上的评估结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Model</span>: chinese-roberta-wwm-ext, weighted avgage F1 = <span class="hljs-number">85</span>.<span class="hljs-number">35</span>%<br></code></pre></td></tr></table></figure><p>该项目笔者已上传至Github，网址为：<ahref="https://github.com/percent4/R-BERT_for_people_relation_extraction">https://github.com/percent4/R-BERT_for_people_relation_extraction</a>。</p><p>本周，笔者下定决心使用Keras实现<code>R-BERT</code>。第一天，无果。第二天，实现关键Keras层的突破，进行简单模型训练，发现离Torch版本的结果尚有一定差距。第三天，对照Torch版本，不断调整模型，加入Warmup机制，发现终于取得了与Torch版本一样的效果。在测试集上的评估结果如下：</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-comment"># Model: chinese-RoBERTa-wwm-ext, weighted avgage F1 = 85.27%</span><br>              precision    recall  f1-score   support<br><br>     unknown     <span class="hljs-number">0.7930</span>    <span class="hljs-number">0.8612</span>    <span class="hljs-number">0.8257</span>       <span class="hljs-number">209</span><br>         上下级     <span class="hljs-number">0.7188</span>    <span class="hljs-number">0.7419</span>    <span class="hljs-number">0.7302</span>        <span class="hljs-number">31</span><br>          亲戚     <span class="hljs-number">0.8824</span>    <span class="hljs-number">0.6250</span>    <span class="hljs-number">0.7317</span>        <span class="hljs-number">24</span><br>        兄弟姐妹     <span class="hljs-number">0.8378</span>    <span class="hljs-number">0.9118</span>    <span class="hljs-number">0.8732</span>        <span class="hljs-number">34</span><br>          合作     <span class="hljs-number">0.8600</span>    <span class="hljs-number">0.7288</span>    <span class="hljs-number">0.7890</span>        <span class="hljs-number">59</span><br>          同人     <span class="hljs-number">1.0000</span>    <span class="hljs-number">0.9487</span>    <span class="hljs-number">0.9737</span>        <span class="hljs-number">39</span><br>          同学     <span class="hljs-number">0.8800</span>    <span class="hljs-number">0.9167</span>    <span class="hljs-number">0.8980</span>        <span class="hljs-number">24</span><br>          同门     <span class="hljs-number">0.9615</span>    <span class="hljs-number">0.9615</span>    <span class="hljs-number">0.9615</span>        <span class="hljs-number">26</span><br>          夫妻     <span class="hljs-number">0.8333</span>    <span class="hljs-number">0.8861</span>    <span class="hljs-number">0.8589</span>        <span class="hljs-number">79</span><br>          好友     <span class="hljs-number">0.8065</span>    <span class="hljs-number">0.8333</span>    <span class="hljs-number">0.8197</span>        <span class="hljs-number">30</span><br>          师生     <span class="hljs-number">0.8857</span>    <span class="hljs-number">0.8378</span>    <span class="hljs-number">0.8611</span>        <span class="hljs-number">37</span><br>          情侣     <span class="hljs-number">0.9231</span>    <span class="hljs-number">0.7742</span>    <span class="hljs-number">0.8421</span>        <span class="hljs-number">31</span><br>          父母     <span class="hljs-number">0.9062</span>    <span class="hljs-number">0.9062</span>    <span class="hljs-number">0.9062</span>       <span class="hljs-number">128</span><br>          祖孙     <span class="hljs-number">0.9524</span>    <span class="hljs-number">0.8000</span>    <span class="hljs-number">0.8696</span>        <span class="hljs-number">25</span><br><br>    accuracy                         <span class="hljs-number">0.8531</span>       <span class="hljs-number">776</span><br>   <span class="hljs-function"><span class="hljs-keyword">macro</span> <span class="hljs-title">avg</span></span>     <span class="hljs-number">0.8743</span>    <span class="hljs-number">0.8381</span>    <span class="hljs-number">0.8529</span>       <span class="hljs-number">776</span><br>weighted avg     <span class="hljs-number">0.8566</span>    <span class="hljs-number">0.8531</span>    <span class="hljs-number">0.8527</span>       <span class="hljs-number">776</span><br></code></pre></td></tr></table></figure><p>该项目已上传至Github，网址为：<ahref="https://github.com/percent4/Keras_R_BERT">https://github.com/percent4/Keras_R_BERT</a>。后面有机会笔者再详细介绍。</p><p>至此，笔者不仅用Keras实现了R-BERT，并且比最初的BERT+Bi-GRU+Attention+FC模型，在测试集上的F1值提升了6.3%。</p><p>实现模型的过程是痛苦的，笔者一度想放弃，但当模型成功复现后，那种快乐，是简单枯燥的工作中的一抹绚丽的阳光！这也是笔者第一次复现模型，虽然只是深度学习框架不同，但对我来说是极其重要的一步！</p><p>最近又发现一个很不错的关系分类的模型：<code>Mul-BERT</code>，但由于该模型的论文并未公布，Github也没有公开源码，笔者只好按自己的理解，简单地实现了近似<code>Mul-BERT</code>模型，已上传至Github，网址为：<ahref="https://github.com/percent4/Keras_quasi_Mul_BERT">https://github.com/percent4/Keras_quasi_Mul_BERT</a>。等论文出来后，再用Keras去复现<code>Mul-BERT</code>模型。</p><p>本文到此结束，感谢阅读~</p><p>2021年3月25日于上海浦东，此日阳光明媚~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>关系分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（四十一）使用HuggingFace翻译模型的一次尝试</title>
    <link href="/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B8%80%EF%BC%89%E4%BD%BF%E7%94%A8HuggingFace%E7%BF%BB%E8%AF%91%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/"/>
    <url>/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B8%80%EF%BC%89%E4%BD%BF%E7%94%A8HuggingFace%E7%BF%BB%E8%AF%91%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将如何如何使用HuggingFace中的翻译模型。</p><p>HuggingFace是NLP领域中响当当的团体，它在预训练模型方面作出了很多接触的工作，并开源了许多预训练模型和已经针对具体某个NLP人物训练好的直接可以使用的模型。本文将使用HuggingFace提供的可直接使用的翻译模型。</p><p>HuggingFace的翻译模型可参考网址：<ahref="https://huggingface.co/models?pipeline_tag=translation">https://huggingface.co/models?pipeline_tag=translation</a>，该部分模型中的绝大部分是由Helsinki-NLP（Language Technology ResearchGroup at the University of Helsinki）机构开源，模型数量为1333个。</p><h3 id="模型使用">模型使用</h3><p>笔者将在PyTorch框架下使用HuggingFace的<code>中译英模型</code>和<code>英译中模型</code>。其中<code>中译英模型</code>的模型名称为：opus-mt-zh-en，下载网址为：<ahref="https://huggingface.co/Helsinki-NLP/opus-mt-zh-en/tree/main">https://huggingface.co/Helsinki-NLP/opus-mt-zh-en/tree/main</a>；<code>英译中模型</code>的模型名称为opus-mt-en-zh，下载网址为：<ahref="https://huggingface.co/Helsinki-NLP/opus-mt-en-zh/tree/main">https://huggingface.co/Helsinki-NLP/opus-mt-en-zh/tree/main</a>。</p><p>首先我们先尝试<code>中译英模型</code>，即把中文翻译成英语，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSeq2SeqLM<br><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./opus-mt-zh-en&quot;</span>)<br><br>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;./opus-mt-zh-en&quot;</span>)<br><br>text = <span class="hljs-string">&quot;从时间上看，中国空间站的建造比国际空间站晚20多年。&quot;</span><br><span class="hljs-comment"># Tokenize the text</span><br>batch = tokenizer.prepare_seq2seq_batch(src_texts=[text])<br><br><span class="hljs-comment"># Make sure that the tokenized text does not exceed the maximum</span><br><span class="hljs-comment"># allowed size of 512</span><br>batch[<span class="hljs-string">&quot;input_ids&quot;</span>] = batch[<span class="hljs-string">&quot;input_ids&quot;</span>][:, :<span class="hljs-number">512</span>]<br>batch[<span class="hljs-string">&quot;attention_mask&quot;</span>] = batch[<span class="hljs-string">&quot;attention_mask&quot;</span>][:, :<span class="hljs-number">512</span>]<br><br><span class="hljs-comment"># Perform the translation and decode the output</span><br>translation = model.generate(**batch)<br>result = tokenizer.batch_decode(translation, skip_special_tokens=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>翻译结果如下：</p><figure class="highlight smalltalk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">[<span class="hljs-comment">&quot;In terms of time, the Chinese space station was built more than 20 years later than the International Space Station.&quot;</span>]<br></code></pre></td></tr></table></figure><p>接着我们先尝试<code>英译中模型</code>，即把英文翻译成汉语，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSeq2SeqLM<br><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./opus-mt-en-zh&quot;</span>)<br><br>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;./opus-mt-en-zh&quot;</span>)<br><br>text = <span class="hljs-string">&quot;In terms of time, the Chinese space station was built more than 20 years later than the International Space Station.&quot;</span><br><span class="hljs-comment"># Tokenize the text</span><br>batch = tokenizer.prepare_seq2seq_batch(src_texts=[text])<br><br><span class="hljs-comment"># Make sure that the tokenized text does not exceed the maximum</span><br><span class="hljs-comment"># allowed size of 512</span><br>batch[<span class="hljs-string">&quot;input_ids&quot;</span>] = batch[<span class="hljs-string">&quot;input_ids&quot;</span>][:, :<span class="hljs-number">512</span>]<br>batch[<span class="hljs-string">&quot;attention_mask&quot;</span>] = batch[<span class="hljs-string">&quot;attention_mask&quot;</span>][:, :<span class="hljs-number">512</span>]<br><br><span class="hljs-comment"># Perform the translation and decode the output</span><br>translation = model.generate(**batch)<br>result = tokenizer.batch_decode(translation, skip_special_tokens=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>翻译结果如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-symbol">&#x27;就时间而言</span>,中国空间站的建造比国际空间站晚了20多年。&#x27;]<br></code></pre></td></tr></table></figure><p>有了HuggingFace的transformers模块，我们使用起这些模型相当方便，同时也有很不错的翻译效果。</p><h3 id="模型解释">模型解释</h3><p>接着我们再接触一款工具，名称为<code>shap</code>。<code>shap</code>是Python开发的一个模型解释包，可以任何机器学习模型的输出。其名称来源于SHapleyAdditiveexPlanation，在合作博弈论的启发下SHAP构建一个加性的解释模型，所有的特征都视为“贡献者”。对于每个预测样本，模型都产生一个预测值，SHAPvalue就是该样本中每个特征所分配到的数值。</p><p>我们尝试着使用<code>shap</code>模块来对翻译模型进行解释，可以看到<code>shap</code>可视化效果非常棒的解释界面，如下：</p><figure><img src="/img/nlp41_1.png" alt="中译英模型代码" /><figcaption aria-hidden="true">中译英模型代码</figcaption></figure><p>默认输出结果为翻译结果，如下：</p><figure><img src="/img/nlp41_2.png" alt="默认输出结果" /><figcaption aria-hidden="true">默认输出结果</figcaption></figure><p>模型解释的热力图效果如下：</p><figure><img src="/img/nlp41_3.png" alt="模型解释的热力图效果" /><figcaption aria-hidden="true">模型解释的热力图效果</figcaption></figure><p>从热力图中我们可以发现，空间站这个词语被翻译成space station。</p><p>同样，我们可以看到<code>英译中模型</code>的热力图解释效果，如下：</p><figure><img src="/img/nlp41_4.png" alt="英译中模型的热力图解释效果" /><figcaptionaria-hidden="true"><code>英译中模型</code>的热力图解释效果</figcaption></figure><p>本次分享到此结束，感谢大家阅读~</p><p>2021年3月10日于上海浦东~</p><h3 id="参考网址">参考网址</h3><ol type="1"><li>HuggingFace translation model: <ahref="https://huggingface.co/models?filter=zh&amp;pipeline_tag=translation">https://huggingface.co/models?filter=zh&amp;pipeline_tag=translation</a></li><li>Text to Text Explanation: Machine Translation Example: <ahref="https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/translation/Machine%20Translation%20Explanation%20Demo.html">https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/translation/Machine%20Translation%20Explanation%20Demo.html</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>机器翻译</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（四十）利用seqeval模块获取序列实体识别结果</title>
    <link href="/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%EF%BC%89%E5%88%A9%E7%94%A8seqeval%E6%A8%A1%E5%9D%97%E8%8E%B7%E5%8F%96%E5%BA%8F%E5%88%97%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E7%BB%93%E6%9E%9C/"/>
    <url>/NLP%EF%BC%88%E5%9B%9B%E5%8D%81%EF%BC%89%E5%88%A9%E7%94%A8seqeval%E6%A8%A1%E5%9D%97%E8%8E%B7%E5%8F%96%E5%BA%8F%E5%88%97%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E7%BB%93%E6%9E%9C/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%89%EF%BC%89%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9D%97seqeval%E7%9A%84%E4%BD%BF%E7%94%A8/">NLP（二十三）序列标注算法评估模块seqeval的使用</a>中，笔者首次介绍了<code>seqeval</code>模块，它可以帮助我们很好地完成序列标注算法的模型效果评估，并且能在Keras模型训练过程中引入。</p><p>其实，在<code>seqeval</code>模块中还有一个<code>get_entities</code>函数，它能帮助我们迅速地从一个标注序列中获取完整实体，支持常规的BIO、BMESO等标注方式。让我们来看下该函数的源代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_entities</span>(<span class="hljs-params">seq, suffix=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Gets entities from sequence.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        seq (list): sequence of labels.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        list: list of (chunk_type, chunk_start, chunk_end).</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Example:</span><br><span class="hljs-string">        &gt;&gt;&gt; from seqeval.metrics.sequence_labeling import get_entities</span><br><span class="hljs-string">        &gt;&gt;&gt; seq = [&#x27;B-PER&#x27;, &#x27;I-PER&#x27;, &#x27;O&#x27;, &#x27;B-LOC&#x27;]</span><br><span class="hljs-string">        &gt;&gt;&gt; get_entities(seq)</span><br><span class="hljs-string">        [(&#x27;PER&#x27;, 0, 1), (&#x27;LOC&#x27;, 3, 3)]</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># for nested list</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(<span class="hljs-built_in">isinstance</span>(s, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> seq):<br>        seq = [item <span class="hljs-keyword">for</span> sublist <span class="hljs-keyword">in</span> seq <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> sublist + [<span class="hljs-string">&#x27;O&#x27;</span>]]<br><br>    prev_tag = <span class="hljs-string">&#x27;O&#x27;</span><br>    prev_type = <span class="hljs-string">&#x27;&#x27;</span><br>    begin_offset = <span class="hljs-number">0</span><br>    chunks = []<br>    <span class="hljs-keyword">for</span> i, chunk <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(seq + [<span class="hljs-string">&#x27;O&#x27;</span>]):<br>        <span class="hljs-keyword">if</span> suffix:<br>            tag = chunk[-<span class="hljs-number">1</span>]<br>            type_ = chunk.split(<span class="hljs-string">&#x27;-&#x27;</span>)[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">else</span>:<br>            tag = chunk[<span class="hljs-number">0</span>]<br>            type_ = chunk.split(<span class="hljs-string">&#x27;-&#x27;</span>)[-<span class="hljs-number">1</span>]<br><br>        <span class="hljs-keyword">if</span> end_of_chunk(prev_tag, tag, prev_type, type_):<br>            chunks.append((prev_type, begin_offset, i-<span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">if</span> start_of_chunk(prev_tag, tag, prev_type, type_):<br>            begin_offset = i<br>        prev_tag = tag<br>        prev_type = type_<br><br>    <span class="hljs-keyword">return</span> chunks<br></code></pre></td></tr></table></figure><p>该函数的输入为标注序列，输出结果为实体列表，包含实体类型、实体开始下标和结束下标。</p><p>我们以文章<ahref="https://percent4.github.io/2023/07/08/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AD%EF%BC%89pyltp%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/">NLP入门（六）pyltp的介绍与使用</a>中的命名实体识别程序为例，同时采用自己提取标注序列中的实体识别信息和使用seqeval模块提取标注序列中的实体识别信息两种方式，实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> Segmentor, Postagger<br><br><span class="hljs-comment"># 分词</span><br>cws_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;ltp_v3.4/cws.model&#x27;</span>)  <span class="hljs-comment"># 分词模型路径，模型名称为`cws.model`</span><br>lexicon_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;ltp_v3.4/lexicon.txt&#x27;</span>)  <span class="hljs-comment"># 参数lexicon是自定义词典的文件路径</span><br><br>segmentor = Segmentor()<br>segmentor.load_with_lexicon(cws_model_path, lexicon_path)<br><br>sent = <span class="hljs-string">&quot;据韩联社12月28日反映，美国防部发言人杰夫·莫莱尔27日表示，美国防部长盖茨将于2011年1月14日访问韩国。&quot;</span><br><span class="hljs-comment"># sent = &quot;记者4日从中国航空工业集团有限公司获悉，AG600项目研制加速推进，001架机在成功完成陆上、水上、海上首飞之后，于3月4日在湖北荆门漳河机场完成灭火任务系统首次科研试飞，飞机状态良好。&quot;</span><br><span class="hljs-comment"># sent = &quot;大临铁路通车当天，81岁的佤族老人田学明专程赶到临沧站，观看列车发车。“我最大的梦想，就是有一天火车能开进阿佤山。今天，我的梦想终于实现了！”&quot;</span><br>words = segmentor.segment(sent)  <span class="hljs-comment"># 分词</span><br><br><span class="hljs-comment"># 词性标注</span><br>pos_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;ltp_v3.4/pos.model&#x27;</span>)  <span class="hljs-comment"># 词性标注模型路径，模型名称为`pos.model`</span><br><br>postagger = Postagger()  <span class="hljs-comment"># 初始化实例</span><br>postagger.load(pos_model_path)  <span class="hljs-comment"># 加载模型</span><br>postags = postagger.postag(words)  <span class="hljs-comment"># 词性标注</span><br><br><br>ner_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;ltp_v3.4/ner.model&#x27;</span>)   <span class="hljs-comment"># 命名实体识别模型路径，模型名称为`pos.model`</span><br><br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> NamedEntityRecognizer<br>recognizer = NamedEntityRecognizer() <span class="hljs-comment"># 初始化实例</span><br>recognizer.load(ner_model_path)  <span class="hljs-comment"># 加载模型</span><br>netags = <span class="hljs-built_in">list</span>(recognizer.recognize(words, postags))  <span class="hljs-comment"># 命名实体识别</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(words))<br><span class="hljs-built_in">print</span>(netags)<br><br><span class="hljs-comment"># 用自己的方法提取识别结果中的人名，地名，组织机构名</span><br>persons, places, orgs = <span class="hljs-built_in">set</span>(), <span class="hljs-built_in">set</span>(), <span class="hljs-built_in">set</span>()<br>i = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> tag, word <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(netags, words):<br>    j = i<br>    <span class="hljs-comment"># 人名</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;Nh&#x27;</span> <span class="hljs-keyword">in</span> tag:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;S&#x27;</span>):<br>            persons.add(word)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;B&#x27;</span>):<br>            union_person = word<br>            <span class="hljs-keyword">while</span> netags[j] != <span class="hljs-string">&#x27;E-Nh&#x27;</span>:<br>                j += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> j &lt; <span class="hljs-built_in">len</span>(words):<br>                    union_person += words[j]<br>            persons.add(union_person)<br>    <span class="hljs-comment"># 地名</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;Ns&#x27;</span> <span class="hljs-keyword">in</span> tag:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;S&#x27;</span>):<br>            places.add(word)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;B&#x27;</span>):<br>            union_place = word<br>            <span class="hljs-keyword">while</span> netags[j] != <span class="hljs-string">&#x27;E-Ns&#x27;</span>:<br>                j += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> j &lt; <span class="hljs-built_in">len</span>(words):<br>                    union_place += words[j]<br>            places.add(union_place)<br>    <span class="hljs-comment"># 机构名</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;Ni&#x27;</span> <span class="hljs-keyword">in</span> tag:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;S&#x27;</span>):<br>            orgs.add(word)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;B&#x27;</span>):<br>            union_org = word<br>            <span class="hljs-keyword">while</span> netags[j] != <span class="hljs-string">&#x27;E-Ni&#x27;</span>:<br>                j += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> j &lt; <span class="hljs-built_in">len</span>(words):<br>                    union_org += words[j]<br>            orgs.add(union_org)<br><br>    i += <span class="hljs-number">1</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;人名：&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>.join(persons))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;地名：&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>.join(places))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;组织机构：&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>.join(orgs))<br><br><span class="hljs-comment"># 用seqeval提取识别结果中的人名，地名，组织机构名</span><br><span class="hljs-keyword">from</span> seqeval.metrics.sequence_labeling <span class="hljs-keyword">import</span> get_entities<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br>seq_result = get_entities(netags)<br>words = <span class="hljs-built_in">list</span>(words)<br>ner_result_dict = defaultdict(<span class="hljs-built_in">list</span>)<br><span class="hljs-keyword">for</span> seq_res <span class="hljs-keyword">in</span> seq_result:<br>    ner_result_dict[seq_res[<span class="hljs-number">0</span>]].append(<span class="hljs-string">&quot;&quot;</span>.join(words[seq_res[<span class="hljs-number">1</span>]:seq_res[<span class="hljs-number">2</span>]+<span class="hljs-number">1</span>]))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;人名：&#x27;</span>, ner_result_dict[<span class="hljs-string">&quot;Nh&quot;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;地名：&#x27;</span>, ner_result_dict[<span class="hljs-string">&quot;Ns&quot;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;组织机构：&#x27;</span>, ner_result_dict[<span class="hljs-string">&quot;Ni&quot;</span>])<br><br><span class="hljs-comment"># 释放模型</span><br>segmentor.release()<br>postagger.release()<br>recognizer.release()<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;据&#x27;</span>, <span class="hljs-string">&#x27;韩联社&#x27;</span>, <span class="hljs-string">&#x27;12月&#x27;</span>, <span class="hljs-string">&#x27;28日&#x27;</span>, <span class="hljs-string">&#x27;反映&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;美&#x27;</span>, <span class="hljs-string">&#x27;国防部&#x27;</span>, <span class="hljs-string">&#x27;发言人&#x27;</span>, <span class="hljs-string">&#x27;杰夫·莫莱尔&#x27;</span>, <span class="hljs-string">&#x27;27日&#x27;</span>, <span class="hljs-string">&#x27;表示&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;美&#x27;</span>, <span class="hljs-string">&#x27;国防部长&#x27;</span>, <span class="hljs-string">&#x27;盖茨&#x27;</span>, <span class="hljs-string">&#x27;将&#x27;</span>, <span class="hljs-string">&#x27;于&#x27;</span>, <span class="hljs-string">&#x27;2011年&#x27;</span>, <span class="hljs-string">&#x27;1月&#x27;</span>, <span class="hljs-string">&#x27;14日&#x27;</span>, <span class="hljs-string">&#x27;访问&#x27;</span>, <span class="hljs-string">&#x27;韩国&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>]</span><br><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Ni&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-Ni&#x27;</span>, <span class="hljs-string">&#x27;E-Ni&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Nh&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Ns&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Nh&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Ns&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]</span><br>人名： 盖茨，杰夫·莫莱尔<br>地名： 韩国，美<br>组织机构： 美国防部，韩联社<br>人名： <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;杰夫·莫莱尔&#x27;</span>, <span class="hljs-string">&#x27;盖茨&#x27;</span>]</span><br>地名： <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;美&#x27;</span>, <span class="hljs-string">&#x27;韩国&#x27;</span>]</span><br>组织机构： <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;韩联社&#x27;</span>, <span class="hljs-string">&#x27;美国防部&#x27;</span>]</span><br></code></pre></td></tr></table></figure><p>我们再尝试两个句子，识别结果如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;记者&#x27;</span>, <span class="hljs-string">&#x27;4日&#x27;</span>, <span class="hljs-string">&#x27;从&#x27;</span>, <span class="hljs-string">&#x27;中国&#x27;</span>, <span class="hljs-string">&#x27;航空&#x27;</span>, <span class="hljs-string">&#x27;工业&#x27;</span>, <span class="hljs-string">&#x27;集团&#x27;</span>, <span class="hljs-string">&#x27;有限公司&#x27;</span>, <span class="hljs-string">&#x27;获悉&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;AG600&#x27;</span>, <span class="hljs-string">&#x27;项目&#x27;</span>, <span class="hljs-string">&#x27;研制&#x27;</span>, <span class="hljs-string">&#x27;加速&#x27;</span>, <span class="hljs-string">&#x27;推进&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;001架机&#x27;</span>, <span class="hljs-string">&#x27;在&#x27;</span>, <span class="hljs-string">&#x27;成功&#x27;</span>, <span class="hljs-string">&#x27;完成&#x27;</span>, <span class="hljs-string">&#x27;陆上&#x27;</span>, <span class="hljs-string">&#x27;、&#x27;</span>, <span class="hljs-string">&#x27;水上&#x27;</span>, <span class="hljs-string">&#x27;、&#x27;</span>, <span class="hljs-string">&#x27;海上&#x27;</span>, <span class="hljs-string">&#x27;首&#x27;</span>, <span class="hljs-string">&#x27;飞&#x27;</span>, <span class="hljs-string">&#x27;之后&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;于&#x27;</span>, <span class="hljs-string">&#x27;3月&#x27;</span>, <span class="hljs-string">&#x27;4日&#x27;</span>, <span class="hljs-string">&#x27;在&#x27;</span>, <span class="hljs-string">&#x27;湖北&#x27;</span>, <span class="hljs-string">&#x27;荆门&#x27;</span>, <span class="hljs-string">&#x27;漳河&#x27;</span>, <span class="hljs-string">&#x27;机场&#x27;</span>, <span class="hljs-string">&#x27;完成&#x27;</span>, <span class="hljs-string">&#x27;灭火&#x27;</span>, <span class="hljs-string">&#x27;任务&#x27;</span>, <span class="hljs-string">&#x27;系统&#x27;</span>, <span class="hljs-string">&#x27;首&#x27;</span>, <span class="hljs-string">&#x27;次&#x27;</span>, <span class="hljs-string">&#x27;科研&#x27;</span>, <span class="hljs-string">&#x27;试飞&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;飞机&#x27;</span>, <span class="hljs-string">&#x27;状态&#x27;</span>, <span class="hljs-string">&#x27;良好&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>]</span><br><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-Ni&#x27;</span>, <span class="hljs-string">&#x27;I-Ni&#x27;</span>, <span class="hljs-string">&#x27;I-Ni&#x27;</span>, <span class="hljs-string">&#x27;I-Ni&#x27;</span>, <span class="hljs-string">&#x27;E-Ni&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-Ns&#x27;</span>, <span class="hljs-string">&#x27;I-Ns&#x27;</span>, <span class="hljs-string">&#x27;I-Ns&#x27;</span>, <span class="hljs-string">&#x27;E-Ns&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]</span><br>人名： <br>地名： 湖北荆门漳河机场<br>组织机构： 中国航空工业集团有限公司<br>人名： <span class="hljs-selector-attr">[]</span><br>地名： <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;湖北荆门漳河机场&#x27;</span>]</span><br>组织机构： <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;中国航空工业集团有限公司&#x27;</span>]</span><br></code></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;大临铁路&#x27;</span>, <span class="hljs-string">&#x27;通车&#x27;</span>, <span class="hljs-string">&#x27;当天&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;81&#x27;</span>, <span class="hljs-string">&#x27;岁&#x27;</span>, <span class="hljs-string">&#x27;的&#x27;</span>, <span class="hljs-string">&#x27;佤族&#x27;</span>, <span class="hljs-string">&#x27;老人&#x27;</span>, <span class="hljs-string">&#x27;田学明&#x27;</span>, <span class="hljs-string">&#x27;专程&#x27;</span>, <span class="hljs-string">&#x27;赶到&#x27;</span>, <span class="hljs-string">&#x27;临沧站&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;观看&#x27;</span>, <span class="hljs-string">&#x27;列车&#x27;</span>, <span class="hljs-string">&#x27;发车&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>, <span class="hljs-string">&#x27;“&#x27;</span>, <span class="hljs-string">&#x27;我&#x27;</span>, <span class="hljs-string">&#x27;最&#x27;</span>, <span class="hljs-string">&#x27;大&#x27;</span>, <span class="hljs-string">&#x27;的&#x27;</span>, <span class="hljs-string">&#x27;梦想&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;就&#x27;</span>, <span class="hljs-string">&#x27;是&#x27;</span>, <span class="hljs-string">&#x27;有&#x27;</span>, <span class="hljs-string">&#x27;一&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;火车&#x27;</span>, <span class="hljs-string">&#x27;能&#x27;</span>, <span class="hljs-string">&#x27;开进&#x27;</span>, <span class="hljs-string">&#x27;阿佤山&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>, <span class="hljs-string">&#x27;今天&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;我&#x27;</span>, <span class="hljs-string">&#x27;的&#x27;</span>, <span class="hljs-string">&#x27;梦想&#x27;</span>, <span class="hljs-string">&#x27;终于&#x27;</span>, <span class="hljs-string">&#x27;实现&#x27;</span>, <span class="hljs-string">&#x27;了&#x27;</span>, <span class="hljs-string">&#x27;！&#x27;</span>, <span class="hljs-string">&#x27;”&#x27;</span>]</span><br><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Nh&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Ns&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]</span><br>人名： 田学明<br>地名： 阿佤山<br>组织机构： <br>人名： <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;田学明&#x27;</span>]</span><br>地名： <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;阿佤山&#x27;</span>]</span><br>组织机构： <span class="hljs-selector-attr">[]</span><br></code></pre></td></tr></table></figure><p>从上我们可以发现：</p><ul><li><p>使用seqeval的实现方式与自己的实现方式效果一致；</p></li><li><p>seqeval的实现方式更加简洁高效，从代码上看，seqeval只需3-4行代码，而自己实现需20-30行代码。</p><p>本文介绍了如何使用seqeval模块快速地从标注序列中提取实体识别结果，这是我们在做命名实体识别任务时经常会碰到的问题，使用seqeval能够提升我们的工作效果，使代码更加简洁优雅。</p><p>本次分享到此结束，感谢大家阅读~</p><p>2021年3月5日于上海杨浦</p></li></ul>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（三十九）使用keras-bert实现完形填空及简单的文本纠错功能</title>
    <link href="/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%B9%9D%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%AE%8C%E5%BD%A2%E5%A1%AB%E7%A9%BA%E5%8F%8A%E7%AE%80%E5%8D%95%E7%9A%84%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99%E5%8A%9F%E8%83%BD/"/>
    <url>/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%B9%9D%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%AE%8C%E5%BD%A2%E5%A1%AB%E7%A9%BA%E5%8F%8A%E7%AE%80%E5%8D%95%E7%9A%84%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99%E5%8A%9F%E8%83%BD/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在之前的系列文章中，笔者介绍了如何使用keras-bert来调用BERT模型，实现文本多分类，文本多标签分类以及序列标注任务，文章如下：</p><ul><li><ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/">NLP（三十四）使用keras-bert实现序列标注任务</a></li><li></li><li><ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%BA%94%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">NLP（三十五）使用keras-bert实现文本多分类任务</a></li><li></li><li><ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">NLP（三十六）使用keras-bert实现文本多标签分类任务</a></li></ul><p>在本文中，笔者将介绍如何使用keras-bert来调用BERT模型使用完形填空及简单的文本纠错功能。</p><h3 id="完形填空">完形填空</h3><p>首先，我们来了解下什么是完形填空。所谓完形填空，指的是将句子中缺失的单词（或字）补充成正确的单词（或字）。举个简单的例子：</p><figure><img src="/img/nlp39_1.png" alt="完形填空的例子" /><figcaption aria-hidden="true">完形填空的例子</figcaption></figure><p>在上图中，第一行是原始句子，第二行是需要完形填空的句子，在这里我们把闵行区的行字缺失掉，即MASK掉，第三行为补充的汉字：行。</p><p>在BERT模型中，它的任务是由两个自监督任务组成，即MLM和NSP。我们需要了解下MLM。</p><p>MLM的全称是Masked LanguageModel，所谓MLM是指在训练的时候随即从输入预料上mask掉一些单词，然后通过的上下文预测该单词，该任务非常像我们在中学时期经常做的完形填空。</p><p>在BERT的实验中，15%的WordPieceToken会被随机Mask掉。在训练模型时，一个句子会被多次喂到模型中用于参数学习，但是Google并没有在每次都mask掉这些单词，而是在确定要Mask掉的单词之后，80%的时候会直接替换为[Mask]，10%的时候将其替换为其它任意单词，10%的时候会保留原始Token。</p><p>基于BERT模型的这个特性，我们尝试着利用keras-bert来调用它解决完形填空问题。实现完形填空的代码（<code>cloze_predict.py</code>）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> Tokenizer<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> load_trained_model_from_checkpoint<br><br><span class="hljs-comment"># 加载词典</span><br>dict_path = <span class="hljs-string">&#x27;./chinese_L-12_H-768_A-12/vocab.txt&#x27;</span><br>token_dict = &#123;&#125;<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(dict_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> reader:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> reader:<br>        token = line.strip()<br>        token_dict[token] = <span class="hljs-built_in">len</span>(token_dict)<br><br>id_token_dict = &#123;v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> token_dict.items()&#125;<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">OurTokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_tokenize</span>(<span class="hljs-params">self, text</span>):<br>        R = []<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> text:<br>            <span class="hljs-keyword">if</span> c <span class="hljs-keyword">in</span> self._token_dict:<br>                R.append(c)<br>            <span class="hljs-keyword">else</span>:<br>                R.append(<span class="hljs-string">&#x27;[UNK]&#x27;</span>)<br>        <span class="hljs-keyword">return</span> R<br><br><br>tokenizer = OurTokenizer(token_dict)<br><br><span class="hljs-comment"># 加载模型</span><br>model_path = <span class="hljs-string">&quot;./chinese_L-12_H-768_A-12/&quot;</span><br>bert_model = load_trained_model_from_checkpoint(<br>    model_path + <span class="hljs-string">&quot;bert_config.json&quot;</span>,<br>    model_path + <span class="hljs-string">&quot;bert_model.ckpt&quot;</span>,<br>    training=<span class="hljs-literal">True</span><br>)<br><span class="hljs-comment"># bert_model.summary()</span><br><br><br><span class="hljs-comment"># 完形填空，预测MASK的字符</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_mask_character</span>(<span class="hljs-params">start_string, mask_num, end_string</span>):<br>    string = <span class="hljs-built_in">list</span>(start_string) + [<span class="hljs-string">&#x27;MASK&#x27;</span>] * mask_num + <span class="hljs-built_in">list</span>(end_string)<br>    token_ids, segment_ids = tokenizer.encode(string, max_len=<span class="hljs-number">512</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(mask_num):<br>        token_ids[<span class="hljs-built_in">len</span>(start_string)+i+<span class="hljs-number">1</span>] = tokenizer._token_dict[<span class="hljs-string">&#x27;[MASK]&#x27;</span>]<br><br>    <span class="hljs-comment"># mask</span><br>    masks = [<span class="hljs-number">0</span>] * <span class="hljs-number">512</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(mask_num):<br>        masks[<span class="hljs-built_in">len</span>(start_string)+i+<span class="hljs-number">1</span>] = <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># 模型预测被mask掉的部分</span><br>    predicts = bert_model.predict([np.array([token_ids]), np.array([segment_ids]), np.array([masks])])[<span class="hljs-number">0</span>]<br>    pred_indice = predicts[<span class="hljs-number">0</span>][<span class="hljs-built_in">len</span>(start_string)+<span class="hljs-number">1</span>:<span class="hljs-built_in">len</span>(start_string)+mask_num+<span class="hljs-number">1</span>].argmax(axis=<span class="hljs-number">1</span>).tolist()<br>    <span class="hljs-keyword">return</span> [id_token_dict[_] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> pred_indice]<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># 原句1： 白云山，位于广东省广州市白云区，为南粤名山之一，自古就有“羊城第一秀”之称。</span><br>    start_str1 = <span class="hljs-string">&quot;白云山，位于&quot;</span><br>    end_str1 = <span class="hljs-string">&quot;广州市白云区，为南粤名山之一，自古就有“羊城第一秀”之称。&quot;</span><br>    pred_chars = get_mask_character(start_str1, <span class="hljs-number">3</span>, end_str1)<br>    <span class="hljs-built_in">print</span>(pred_chars)<br><br>    <span class="hljs-comment"># 原句2：首先，从市值看，腾讯和阿里市值已经有2500亿，而百度才500多亿，是BAT体量中最小的一家公司。</span><br>    start_str2 = <span class="hljs-string">&quot;首先，从&quot;</span><br>    end_str2 = <span class="hljs-string">&quot;看，腾讯和阿里市值已经有2500亿，而百度才500多亿，是BAT体量中最小的一家公司。&quot;</span><br>    pred_chars = get_mask_character(start_str2, <span class="hljs-number">2</span>, end_str2)<br>    <span class="hljs-built_in">print</span>(pred_chars)<br><br>    <span class="hljs-comment"># 原句3：特斯拉CEO埃隆·马斯克的个人净资产升至1850亿美元，超越亚马逊CEO贝索斯荣登全球第一大富豪。</span><br>    start_str3 = <span class="hljs-string">&quot;特斯拉CEO埃隆·马斯克的个人净资产升至1850亿美元，超越亚马逊CEO贝索斯荣登&quot;</span><br>    end_str3 = <span class="hljs-string">&quot;第一大富豪。&quot;</span><br>    pred_chars = get_mask_character(start_str3, <span class="hljs-number">2</span>, end_str3)<br>    <span class="hljs-built_in">print</span>(pred_chars)<br><br>    <span class="hljs-comment"># 原句4：我在上海闵行区工作。</span><br>    start_str4 = <span class="hljs-string">&quot;我在上海闵&quot;</span><br>    end_str4 = <span class="hljs-string">&quot;区工作。&quot;</span><br>    pred_chars = get_mask_character(start_str4, <span class="hljs-number">1</span>, end_str4)<br>    <span class="hljs-built_in">print</span>(pred_chars)<br></code></pre></td></tr></table></figure><p>注意keras-bert来调用BERT时，如果需要开启MLM和NSP任务时，需要将training设置为True，然后再调用MLM模型对文本中MASK掉的部分进行预测。运行脚本的输出结果如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-symbol">&#x27;广</span>&#x27;, <span class="hljs-symbol">&#x27;东</span>&#x27;, <span class="hljs-symbol">&#x27;省</span>&#x27;]<br>[<span class="hljs-symbol">&#x27;市</span>&#x27;, <span class="hljs-symbol">&#x27;值</span>&#x27;]<br>[<span class="hljs-symbol">&#x27;全</span>&#x27;, <span class="hljs-symbol">&#x27;球</span>&#x27;]<br>[<span class="hljs-symbol">&#x27;行</span>&#x27;]<br></code></pre></td></tr></table></figure><h3 id="简单的文本纠错功能">简单的文本纠错功能</h3><p>基于上述的完形填空，我们还可以完成简单的文本纠错功能，前提是我们已经知道文本的哪个字是错误的，并且进行一对一纠错，即把这个字纠正为正确的字，并不会将其去掉或者添加其它字。我们的思路是这样的：在知道文本中的哪个字是错误的之后，将其MASK掉，转化为完形填空任务，从而预测出MASK掉的字作为纠正后的字。</p><p>实现简单的文本纠错功能的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># 该脚本使用BERT的mask技术进行文本纠错</span><br><span class="hljs-keyword">from</span> cloze_predict <span class="hljs-keyword">import</span> get_mask_character<br><br>sentence = <span class="hljs-string">&quot;我要去埃及金子塔玩。&quot;</span>  <span class="hljs-comment"># 金子塔中的子为错别字</span><br>sentence = <span class="hljs-string">&quot;白云山，位于广东省广州市白云区，为南粤名山之一，自古就有“羊城第一秀”只称。&quot;</span>  <span class="hljs-comment"># 只称中的只为错别字</span><br>sentence = <span class="hljs-string">&quot;请把这个快递送到上海市闵航区。&quot;</span>  <span class="hljs-comment"># 闵航区中的航为错别字</span><br>sentence = <span class="hljs-string">&quot;少先队员因该为老人让坐&quot;</span>  <span class="hljs-comment"># 因该中的因为错别字</span><br>sentence = <span class="hljs-string">&quot;随然今天很热&quot;</span>  <span class="hljs-comment"># 随然中的随为错别字</span><br>sentence = <span class="hljs-string">&quot;我生病了,咳数了好几天&quot;</span>  <span class="hljs-comment"># 咳数中的数为错别字</span><br>sentence = <span class="hljs-string">&quot;一群罗威纳犬宝宝打架，场面感忍。&quot;</span>  <span class="hljs-comment"># 感忍中的忍为错别字</span><br>wrong_char_index = sentence.index(<span class="hljs-string">&quot;忍&quot;</span>)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sentence)):<br>    <span class="hljs-keyword">if</span> i == wrong_char_index:<br>        start_string = sentence[:i]<br>        end_string = sentence[i+<span class="hljs-number">1</span>:]<br>        pred_char = get_mask_character(start_string, <span class="hljs-number">1</span>, end_string)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;wrong char: &#123;&#125;, correct char: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(sentence[i], pred_char[<span class="hljs-number">0</span>]))<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arduino">wrong <span class="hljs-type">char</span>: 忍, correct <span class="hljs-type">char</span>: 人<br></code></pre></td></tr></table></figure><p>这种文本纠错方式利用了BERT的MLM模型来实现的，有一定的效果，但不能作为文本纠错的完美实现方式，只是作为文本纠错的一种实现方式，实际上，现实中的文本纠错是由多种模型组成的复杂策略实现的，还得考虑效果和运行效率等因素。另外，真正的文本纠错还应当能指出文本中哪个字错了并对其纠错，本文只考虑了后一步，而没有指出文本中哪个字错了，只能算文本纠错的一次尝试。</p><h3 id="总结">总结</h3><p>本文给出的脚本已上传至Github，网址为：https://github.com/percent4/keras_bert_cloze，上面有更多的例子，欢迎大家参考~</p><p>感谢大家的阅读~</p><p>2021.1.24于上海浦东</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>keras-bert</tag>
      
      <tag>完形填空</tag>
      
      <tag>文本纠错</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（三十八）使用keras-bert调用ALBERT模型实现文本分类、文本多标签分类、序列标注任务</title>
    <link href="/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E8%B0%83%E7%94%A8ALBERT%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E3%80%81%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E3%80%81%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/"/>
    <url>/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E8%B0%83%E7%94%A8ALBERT%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E3%80%81%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E3%80%81%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在系列文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/">NLP（三十四）使用keras-bert实现序列标注任务</a>、<ahref="https://percent4.github.io/2023/07/10/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%BA%94%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">NLP（三十五）使用keras-bert实现文本多分类任务</a>、<ahref="https://percent4.github.io/2023/07/10/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/">NLP（三十六）使用keras-bert实现文本多标签分类任务</a>中，笔者介绍了如何使用keras-bert模块来调用BERT等模型来实现文本分类、文本多标签分类、序列标注任务。</p><p>在系列文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%8C%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB/">NLP（二十二）利用ALBERT实现文本二分类</a>、<ahref="https://percent4.github.io/2023/07/09/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%94%EF%BC%89%E5%AE%9E%E7%8E%B0ALBERT-Bi-LSTM-CRF%E6%A8%A1%E5%9E%8B/">NLP（二十五）实现ALBERT+Bi-LSTM+CRF模型</a>、<ahref="https://percent4.github.io/2023/07/09/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%85%AB%EF%BC%89%E5%A4%9A%E6%A0%87%E7%AD%BE%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">NLP（二十八）多标签文本分类</a>中，笔者将ALBERT模型作为特征向量提取工具，实现了文本分类、文本多标签分类、序列标注任务。</p><p>本文将会介绍如何使用keras-bert调用ALBERT模型实现文本分类、文本多标签分类、序列标注任务，其模型效果比单纯将ALBERT模型作为特征向量提取工具的效果肯定来得好。</p><p>使用keras-bert调用ALBERT模型实现文本多分类任务的Github项目网址：<ahref="https://github.com/percent4/keras_albert_text_classification">https://github.com/percent4/keras_albert_text_classification</a>。</p><p>使用keras-bert调用ALBERT模型实现文本多标签分类任务的Github项目网址：<ahref="https://github.com/percent4/keras_albert_multi_label_cls">https://github.com/percent4/keras_albert_multi_label_cls</a>。</p><p>使用keras-bert调用ALBERT模型实现序列标注任务的Github项目网址：<ahref="https://github.com/percent4/keras_albert_sequence_labeling">https://github.com/percent4/keras_albert_sequence_labeling</a>。</p><h3id="如何使用keras-bert调用albert模型">如何使用keras-bert调用ALBERT模型</h3><p>keras-bert模块的设计之初是为了支持BERT系列模型，它并不支持ALBERT模型。但在开源世界Github中有个项目名为<code>keras_albert_model</code>，其网址为：<ahref="https://github.com/TinkerMob/keras_albert_model">https://github.com/TinkerMob/keras_albert_model</a>，利用这个项目，我们可以做到让keras-bert支持ALBERT模型。</p><p>下载该项目中的albert.py脚本，我们使用如下示例代码来调用ALBERT-tiny模型，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> albert <span class="hljs-keyword">import</span> load_brightmart_albert_zh_checkpoint<br><br>model = load_brightmart_albert_zh_checkpoint(<span class="hljs-string">&#x27;albert_xlarge_zh_183k&#x27;</span>, training=<span class="hljs-literal">False</span>)<br>model.summary()<br></code></pre></td></tr></table></figure><p>输出的albert-tiny模型结构如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>__<br><span class="hljs-section">Layer (type)                    Output Shape         Param #     Connected to                     </span><br><span class="hljs-section">==================================================================================================</span><br>Input-Token (InputLayer)        (None, 512)          0                                            <br><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>__<br>Input-Segment (InputLayer)      (None, 512)          0                                            <br><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>__<br>Embed-Token (AdaptiveEmbedding) [<span class="hljs-string">(None, 512, 312), ( 2744320     Input-Token[0</span>][<span class="hljs-symbol">0</span>]                <br><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>__<br>Embed-Segment (Embedding)       (None, 512, 312)     624         Input-Segment[<span class="hljs-string">0</span>][<span class="hljs-symbol">0</span>]              <br><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>__<br>Embed-Token-Segment (Add)       (None, 512, 312)     0           Embed-Token[<span class="hljs-string">0</span>][<span class="hljs-symbol">0</span>]                <br><span class="hljs-code">                                                                 Embed-Segment[0][0]              </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Embedding-Position (PositionEmb (None, 512, 312)     159744      Embed-Token-Segment[0][0]        </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Embedding-Norm (LayerNormalizat (None, 512, 312)     624         Embedding-Position[0][0]         </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Attention (MultiHeadAttention)  (None, 512, 312)     390624      Embedding-Norm[0][0]             </span><br><span class="hljs-code">                                                                 Feed-Forward-Normal[0][0]        </span><br><span class="hljs-code">                                                                 Feed-Forward-Normal[1][0]        </span><br><span class="hljs-code">                                                                 Feed-Forward-Normal[2][0]        </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Attention-Add-1 (Add)           (None, 512, 312)     0           Embedding-Norm[0][0]             </span><br><span class="hljs-code">                                                                 Attention[0][0]                  </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Attention-Normal (LayerNormaliz (None, 512, 312)     624         Attention-Add-1[0][0]            </span><br><span class="hljs-code">                                                                 Attention-Add-2[0][0]            </span><br><span class="hljs-code">                                                                 Attention-Add-3[0][0]            </span><br><span class="hljs-code">                                                                 Attention-Add-4[0][0]            </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Feed-Forward (FeedForward)      (None, 512, 312)     780312      Attention-Normal[0][0]           </span><br><span class="hljs-code">                                                                 Attention-Normal[1][0]           </span><br><span class="hljs-code">                                                                 Attention-Normal[2][0]           </span><br><span class="hljs-code">                                                                 Attention-Normal[3][0]           </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Feed-Forward-Add-1 (Add)        (None, 512, 312)     0           Attention-Normal[0][0]           </span><br><span class="hljs-code">                                                                 Feed-Forward[0][0]               </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Feed-Forward-Normal (LayerNorma (None, 512, 312)     624         Feed-Forward-Add-1[0][0]         </span><br><span class="hljs-code">                                                                 Feed-Forward-Add-2[0][0]         </span><br><span class="hljs-code">                                                                 Feed-Forward-Add-3[0][0]         </span><br><span class="hljs-code">                                                                 Feed-Forward-Add-4[0][0]         </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Attention-Add-2 (Add)           (None, 512, 312)     0           Feed-Forward-Normal[0][0]        </span><br><span class="hljs-code">                                                                 Attention[1][0]                  </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Feed-Forward-Add-2 (Add)        (None, 512, 312)     0           Attention-Normal[1][0]           </span><br><span class="hljs-code">                                                                 Feed-Forward[1][0]               </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Attention-Add-3 (Add)           (None, 512, 312)     0           Feed-Forward-Normal[1][0]        </span><br><span class="hljs-code">                                                                 Attention[2][0]                  </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Feed-Forward-Add-3 (Add)        (None, 512, 312)     0           Attention-Normal[2][0]           </span><br><span class="hljs-code">                                                                 Feed-Forward[2][0]               </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Attention-Add-4 (Add)           (None, 512, 312)     0           Feed-Forward-Normal[2][0]        </span><br><span class="hljs-code">                                                                 Attention[3][0]                  </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">Feed-Forward-Add-4 (Add)        (None, 512, 312)     0           Attention-Normal[3][0]           </span><br><span class="hljs-code">                                                                 Feed-Forward[3][0]               </span><br><span class="hljs-code">==================================================================================================</span><br><span class="hljs-code">Total params: 4,077,496</span><br><span class="hljs-code">Trainable params: 0</span><br><span class="hljs-code">Non-trainable params: 4,077,496</span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br></code></pre></td></tr></table></figure><p>有了它，我们可以在keras-bert模块中轻松愉快地调用ALBERT模型了。以下为keras-bert调用ALBERT模型，实现文本多分类、文本多标签分类以及序列标注任务，其代码与之前的keras-bert调用BERT模型的代码大体一致，只不过在加载预训练模型的时候需要<code>keras_albert_model</code>项目的帮助。</p><p>以下将不再给出具体的项目代码，而只是给出keras-bert在调用ALBERT模型时，在不同NLP任务的表现，即模型评估效果。</p><h3 id="文本多分类">文本多分类</h3><p>使用Keras和ALBERT实现文本多分类任务，其中对ALBERT进行微调。数据集为sougou小分类数据集。模型参数为batch_size= 8, maxlen = 300, epoch=3。</p><ul><li>albert-tiny的模型评估结果</li></ul><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs crystal">                precision   recall    f1-score   support<br><br>          体育     <span class="hljs-number">0.9700</span>    <span class="hljs-number">0.9798</span>    <span class="hljs-number">0.9749</span>        <span class="hljs-number">99</span><br>          健康     <span class="hljs-number">0.9278</span>    <span class="hljs-number">0.9091</span>    <span class="hljs-number">0.9184</span>        <span class="hljs-number">99</span><br>          军事     <span class="hljs-number">0.9899</span>    <span class="hljs-number">0.9899</span>    <span class="hljs-number">0.9899</span>        <span class="hljs-number">99</span><br>          教育     <span class="hljs-number">0.8585</span>    <span class="hljs-number">0.9192</span>    <span class="hljs-number">0.8878</span>        <span class="hljs-number">99</span><br>          汽车     <span class="hljs-number">1.0000</span>    <span class="hljs-number">0.9394</span>    <span class="hljs-number">0.9688</span>        <span class="hljs-number">99</span><br><br>    accuracy                         <span class="hljs-number">0.9475</span>       <span class="hljs-number">495</span><br>   <span class="hljs-function"><span class="hljs-keyword">macro</span> <span class="hljs-title">avg</span></span>     <span class="hljs-number">0.9492</span>    <span class="hljs-number">0.9475</span>    <span class="hljs-number">0.9479</span>       <span class="hljs-number">495</span><br>weighted avg     <span class="hljs-number">0.9492</span>    <span class="hljs-number">0.9475</span>    <span class="hljs-number">0.9479</span>       <span class="hljs-number">495</span><br></code></pre></td></tr></table></figure><ul><li>albert_base_zh_additional_36k_steps的模型评估结果</li></ul><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs crystal">              precision    recall  f1-score   support<br><br>          体育     <span class="hljs-number">0.9802</span>    <span class="hljs-number">1.0000</span>    <span class="hljs-number">0.9900</span>        <span class="hljs-number">99</span><br>          健康     <span class="hljs-number">0.9684</span>    <span class="hljs-number">0.9293</span>    <span class="hljs-number">0.9485</span>        <span class="hljs-number">99</span><br>          军事     <span class="hljs-number">1.0000</span>    <span class="hljs-number">0.9899</span>    <span class="hljs-number">0.9949</span>        <span class="hljs-number">99</span><br>          教育     <span class="hljs-number">0.8739</span>    <span class="hljs-number">0.9798</span>    <span class="hljs-number">0.9238</span>        <span class="hljs-number">99</span><br>          汽车     <span class="hljs-number">1.0000</span>    <span class="hljs-number">0.9091</span>    <span class="hljs-number">0.9524</span>        <span class="hljs-number">99</span><br><br>    accuracy                         <span class="hljs-number">0.9616</span>       <span class="hljs-number">495</span><br>   <span class="hljs-function"><span class="hljs-keyword">macro</span> <span class="hljs-title">avg</span></span>     <span class="hljs-number">0.9645</span>    <span class="hljs-number">0.9616</span>    <span class="hljs-number">0.9619</span>       <span class="hljs-number">495</span><br>weighted avg     <span class="hljs-number">0.9645</span>    <span class="hljs-number">0.9616</span>    <span class="hljs-number">0.9619</span>       <span class="hljs-number">495</span><br></code></pre></td></tr></table></figure><ul><li>lbert_xlarge_zh_183k的模型评估结果</li></ul><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs crystal">              precision    recall  f1-score   support<br><br>          体育     <span class="hljs-number">0.9898</span>    <span class="hljs-number">0.9798</span>    <span class="hljs-number">0.9848</span>        <span class="hljs-number">99</span><br>          健康     <span class="hljs-number">0.9412</span>    <span class="hljs-number">0.9697</span>    <span class="hljs-number">0.9552</span>        <span class="hljs-number">99</span><br>          军事     <span class="hljs-number">0.9706</span>    <span class="hljs-number">1.0000</span>    <span class="hljs-number">0.9851</span>        <span class="hljs-number">99</span><br>          教育     <span class="hljs-number">0.9300</span>    <span class="hljs-number">0.9394</span>    <span class="hljs-number">0.9347</span>        <span class="hljs-number">99</span><br>          汽车     <span class="hljs-number">0.9892</span>    <span class="hljs-number">0.9293</span>    <span class="hljs-number">0.9583</span>        <span class="hljs-number">99</span><br><br>    accuracy                         <span class="hljs-number">0.9636</span>       <span class="hljs-number">495</span><br>   <span class="hljs-function"><span class="hljs-keyword">macro</span> <span class="hljs-title">avg</span></span>     <span class="hljs-number">0.9642</span>    <span class="hljs-number">0.9636</span>    <span class="hljs-number">0.9636</span>       <span class="hljs-number">495</span><br>weighted avg     <span class="hljs-number">0.9642</span>    <span class="hljs-number">0.9636</span>    <span class="hljs-number">0.9636</span>       <span class="hljs-number">495</span><br></code></pre></td></tr></table></figure><h3 id="文本多标签">文本多标签</h3><p>使用采用Keras和ALBERT实现文本多标签分类任务,其中对ALBERT进行微调。以2020语言与智能技术竞赛：事件抽取任务中的数据作为多分类标签的样例数据，借助多标签分类模型来解决。模型参数为batch_size= 16, maxlen = 256, epoch=10。</p><ul><li>albert-tiny的模型评估结果</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache">   <span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9488</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8606</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9025</span>      <span class="hljs-number">1657</span><br>   <span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9446</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8084</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8589</span>      <span class="hljs-number">1657</span><br><span class="hljs-attribute">weighted</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9460</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8606</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8955</span>      <span class="hljs-number">1657</span><br> <span class="hljs-attribute">samples</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">8932</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8795</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8799</span>      <span class="hljs-number">1657</span><br><br><span class="hljs-attribute">accuracy</span>:  <span class="hljs-number">0</span>.<span class="hljs-number">828437917222964</span><br><span class="hljs-attribute">hamming</span> loss:  <span class="hljs-number">0</span>.<span class="hljs-number">0031631919482386773</span><br></code></pre></td></tr></table></figure><ul><li>albert_base_zh_additional_36k_steps的模型评估结果</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache">   <span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9471</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9294</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9382</span>      <span class="hljs-number">1657</span><br>   <span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9416</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9105</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9208</span>      <span class="hljs-number">1657</span><br><span class="hljs-attribute">weighted</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9477</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9294</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9362</span>      <span class="hljs-number">1657</span><br> <span class="hljs-attribute">samples</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9436</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9431</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9379</span>      <span class="hljs-number">1657</span><br><br><span class="hljs-attribute">accuracy</span>:  <span class="hljs-number">0</span>.<span class="hljs-number">8931909212283045</span><br><span class="hljs-attribute">hamming</span> loss:  <span class="hljs-number">0</span>.<span class="hljs-number">0020848310567936736</span><br></code></pre></td></tr></table></figure><h3 id="序列标注">序列标注</h3><p>使用本项目采用Keras和ALBERT实现序列标注，其中对ALBERT进行微调。数据集为人民日报命名实体识别数据集、时间识别数据集、CLUENER细粒度实体识别数据集。</p><ul><li>人民日报命名实体识别数据集</li></ul><p>1.1 albert-tiny</p><p>模型参数：MAX_SEQ_LEN=128, BATCH_SIZE=32, EPOCH=10</p><p>运行model_evaluate.py,模型评估结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache">           <span class="hljs-attribute">precision</span>    recall  f1-score   support<br><br>      <span class="hljs-attribute">LOC</span>     <span class="hljs-number">0</span>.<span class="hljs-number">8266</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8171</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8218</span>      <span class="hljs-number">3658</span><br>      <span class="hljs-attribute">ORG</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7289</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7863</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7565</span>      <span class="hljs-number">2185</span><br>      <span class="hljs-attribute">PER</span>     <span class="hljs-number">0</span>.<span class="hljs-number">8865</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8712</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8788</span>      <span class="hljs-number">1864</span><br><br><span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">8111</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8215</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8163</span>      <span class="hljs-number">7707</span><br><span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">8134</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8215</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8171</span>      <span class="hljs-number">7707</span><br></code></pre></td></tr></table></figure><p>1.2 albert-base</p><p>模型参数：MAX_SEQ_LEN=128, BATCH_SIZE=32, EPOCH=10</p><p>运行model_evaluate.py,模型评估结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache">           <span class="hljs-attribute">precision</span>    recall  f1-score   support<br><br>      <span class="hljs-attribute">LOC</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9032</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8671</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8848</span>      <span class="hljs-number">3658</span><br>      <span class="hljs-attribute">PER</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9270</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9067</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9167</span>      <span class="hljs-number">1864</span><br>      <span class="hljs-attribute">ORG</span>     <span class="hljs-number">0</span>.<span class="hljs-number">8445</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8549</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8497</span>      <span class="hljs-number">2185</span><br><br><span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">8917</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8732</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8824</span>      <span class="hljs-number">7707</span><br><span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">8923</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8732</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8826</span>      <span class="hljs-number">7707</span><br></code></pre></td></tr></table></figure><ul><li>时间识别数据集</li></ul><p>2.1 albert-tiny</p><p>模型参数：MAX_SEQ_LEN=256, BATCH_SIZE=8, EPOCH=10</p><p>运行model_evaluate.py,模型评估结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache">           <span class="hljs-attribute">precision</span>    recall  f1-score   support<br><br>     <span class="hljs-attribute">TIME</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7924</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8481</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8193</span>       <span class="hljs-number">441</span><br><br><span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">7924</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8481</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8193</span>       <span class="hljs-number">441</span><br><span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">7924</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8481</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8193</span>       <span class="hljs-number">441</span><br></code></pre></td></tr></table></figure><p>2.2 albert-base</p><p>模型参数：MAX_SEQ_LEN=256, BATCH_SIZE=8, EPOCH=10</p><p>运行model_evaluate.py,模型评估结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache">           <span class="hljs-attribute">precision</span>    recall  f1-score   support<br><br>     <span class="hljs-attribute">TIME</span>     <span class="hljs-number">0</span>.<span class="hljs-number">8136</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8413</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8272</span>       <span class="hljs-number">441</span><br><br><span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">8136</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8413</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8272</span>       <span class="hljs-number">441</span><br><span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">8136</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8413</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8272</span>       <span class="hljs-number">441</span><br></code></pre></td></tr></table></figure><ul><li>CLUENER细粒度实体识别数据集</li></ul><p>3.1 albert-tiny</p><p>模型参数：MAX_SEQ_LEN=128, BATCH_SIZE=32, EPOCH=10</p><p>运行model_evaluate.py,模型评估结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs apache">              <span class="hljs-attribute">precision</span>    recall  f1-score   support<br><br>     <span class="hljs-attribute">company</span>     <span class="hljs-number">0</span>.<span class="hljs-number">5745</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6639</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6160</span>       <span class="hljs-number">366</span><br><span class="hljs-attribute">organization</span>     <span class="hljs-number">0</span>.<span class="hljs-number">5677</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6337</span>    <span class="hljs-number">0</span>.<span class="hljs-number">5989</span>       <span class="hljs-number">344</span><br>        <span class="hljs-attribute">game</span>     <span class="hljs-number">0</span>.<span class="hljs-number">6616</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7561</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7057</span>       <span class="hljs-number">287</span><br>    <span class="hljs-attribute">position</span>     <span class="hljs-number">0</span>.<span class="hljs-number">6478</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7012</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6734</span>       <span class="hljs-number">425</span><br>  <span class="hljs-attribute">government</span>     <span class="hljs-number">0</span>.<span class="hljs-number">6237</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7336</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6742</span>       <span class="hljs-number">244</span><br>        <span class="hljs-attribute">name</span>     <span class="hljs-number">0</span>.<span class="hljs-number">6520</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7894</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7141</span>       <span class="hljs-number">451</span><br>       <span class="hljs-attribute">movie</span>     <span class="hljs-number">0</span>.<span class="hljs-number">6164</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6533</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6343</span>       <span class="hljs-number">150</span><br>       <span class="hljs-attribute">scene</span>     <span class="hljs-number">0</span>.<span class="hljs-number">5166</span>    <span class="hljs-number">0</span>.<span class="hljs-number">5477</span>    <span class="hljs-number">0</span>.<span class="hljs-number">5317</span>       <span class="hljs-number">199</span><br>        <span class="hljs-attribute">book</span>     <span class="hljs-number">0</span>.<span class="hljs-number">6140</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6908</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6502</span>       <span class="hljs-number">152</span><br>     <span class="hljs-attribute">address</span>     <span class="hljs-number">0</span>.<span class="hljs-number">4071</span>    <span class="hljs-number">0</span>.<span class="hljs-number">4698</span>    <span class="hljs-number">0</span>.<span class="hljs-number">4362</span>       <span class="hljs-number">364</span><br><br>   <span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">5884</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6687</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6260</span>      <span class="hljs-number">2982</span><br>   <span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">5881</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6687</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6255</span>      <span class="hljs-number">2982</span><br></code></pre></td></tr></table></figure><p>3.2 albert-base</p><p>模型参数：MAX_SEQ_LEN=128, BATCH_SIZE=32, EPOCH=10</p><p>运行model_evaluate.py,模型评估结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs apache">              <span class="hljs-attribute">precision</span>    recall  f1-score   support<br><br>        <span class="hljs-attribute">name</span>     <span class="hljs-number">0</span>.<span class="hljs-number">8419</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8381</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8400</span>       <span class="hljs-number">451</span><br>     <span class="hljs-attribute">company</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7161</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7650</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7398</span>       <span class="hljs-number">366</span><br>    <span class="hljs-attribute">position</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7205</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7459</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7329</span>       <span class="hljs-number">425</span><br>     <span class="hljs-attribute">address</span>     <span class="hljs-number">0</span>.<span class="hljs-number">5473</span>    <span class="hljs-number">0</span>.<span class="hljs-number">5879</span>    <span class="hljs-number">0</span>.<span class="hljs-number">5669</span>       <span class="hljs-number">364</span><br>        <span class="hljs-attribute">game</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7033</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8258</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7596</span>       <span class="hljs-number">287</span><br>        <span class="hljs-attribute">book</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7931</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7566</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7744</span>       <span class="hljs-number">152</span><br>       <span class="hljs-attribute">scene</span>     <span class="hljs-number">0</span>.<span class="hljs-number">6243</span>    <span class="hljs-number">0</span>.<span class="hljs-number">5930</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6082</span>       <span class="hljs-number">199</span><br><span class="hljs-attribute">organization</span>     <span class="hljs-number">0</span>.<span class="hljs-number">6711</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7297</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6992</span>       <span class="hljs-number">344</span><br>       <span class="hljs-attribute">movie</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7051</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7333</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7190</span>       <span class="hljs-number">150</span><br>  <span class="hljs-attribute">government</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7567</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8156</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7850</span>       <span class="hljs-number">244</span><br><br>   <span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">7078</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7441</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7255</span>      <span class="hljs-number">2982</span><br>   <span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">7093</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7441</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7257</span>      <span class="hljs-number">2982</span><br></code></pre></td></tr></table></figure><h3id="不同版本albert模型与bert模型的参数对比">不同版本ALBERT模型与BERT模型的参数对比</h3><p>以文本多分类任务为例，我们的数据集为sougou小分类数据集，文本最大长度为300，不同版本ALBERT模型与BERT模型的参数为：</p><table><thead><tr class="header"><th>model name</th><th>Total params</th><th>Trainable params</th></tr></thead><tbody><tr class="odd"><td>albert_tiny</td><td>4,079,061</td><td>4,079,061</td></tr><tr class="even"><td>albert_base_zh_additional_36k_steps</td><td>10,290,693</td><td>10,290,693</td></tr><tr class="odd"><td>albert_xlarge_zh_183k</td><td>54,391,813</td><td>54,391,813</td></tr><tr class="even"><td>chinese_L-12_H-768_A-12</td><td>101,680,901</td><td>101,680,901</td></tr></tbody></table><p>通过上述对比，我们不难发现，即使是ALBERT的large模型，其参数量也比BERT的base版本来的少，这是由于ALBERT模型的结构决定的。</p><h3 id="总结">总结</h3><p>本文介绍了如何使用keras-bert调用ALBERT模型实现文本分类、文本多标签分类、序列标注任务，其Github项目地址已经在文章开头给出。</p><p>在模型评估时，不少任务都未给出albert_xlarge_zh_183k模型的评估结果，这是由于GPU机器的性能限制，而不是笔者不愿做或偷懒，希望读者理解，同时也希望读者能有机会弥补这个遗憾。</p><p>感谢大家的阅读，也感谢所有为开源项目作出贡献的人~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>keras-bert</tag>
      
      <tag>序列标注</tag>
      
      <tag>文本分类</tag>
      
      <tag>ALBERT</tag>
      
      <tag>多标签分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Flask中的JWT认证</title>
    <link href="/Flask%E4%B8%AD%E7%9A%84JWT%E8%AE%A4%E8%AF%81/"/>
    <url>/Flask%E4%B8%AD%E7%9A%84JWT%E8%AE%A4%E8%AF%81/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>HTTP认证方式：</p><ul><li>Basic</li><li>Bearer</li><li>JWT（JSON Web Token）</li></ul><p>JWT的结构：</p><p><img src="https://raw.githubusercontent.com/breatheco-de/content/master/src/assets/images/jwt-token-structure.png" alt=""></p><table><thead><tr><th style="text-align:left">Section name</th><th style="text-align:left">meaning</th></tr></thead><tbody><tr><td style="text-align:left">HEADER</td><td style="text-align:left">The first part stores the type of token and the encryption algorithm</td></tr><tr><td style="text-align:left">PAYLOAD</td><td style="text-align:left">The second part has the data that identifies the user: it can be its ID, user name, etc.</td></tr><tr><td style="text-align:left">SIGNATURE</td><td style="text-align:left">Digital signature, which is generated with the previous two sections, and it allows you to verify if the content has been modified.</td></tr></tbody></table><p>示例Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @place: Pudong, Shanghai </span><br><span class="hljs-comment"># @contact: lianmingjie@shanda.com</span><br><span class="hljs-comment"># @file: jwt_test.py</span><br><span class="hljs-comment"># @time: 2023/7/4 17:29</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, jsonify, request<br><br><span class="hljs-keyword">from</span> flask_jwt_extended <span class="hljs-keyword">import</span> create_access_token<br><span class="hljs-keyword">from</span> flask_jwt_extended <span class="hljs-keyword">import</span> get_jwt_identity<br><span class="hljs-keyword">from</span> flask_jwt_extended <span class="hljs-keyword">import</span> jwt_required<br><span class="hljs-keyword">from</span> flask_jwt_extended <span class="hljs-keyword">import</span> JWTManager<br><br>app = Flask(__name__)<br><br><span class="hljs-comment"># 设置 Flask-JWT-Extended 插件的秘钥</span><br>app.config[<span class="hljs-string">&quot;JWT_SECRET_KEY&quot;</span>] = <span class="hljs-string">&quot;super-secret&quot;</span>  <span class="hljs-comment"># 设置 jwt 的秘钥</span><br>jwt = JWTManager(app)<br><br><br><span class="hljs-comment"># 创建一个路由来验证登录的用户并返回JWT</span><br><span class="hljs-comment"># create_access_token() 函数用来生成实际的JWT token.</span><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/login&quot;</span>, methods=[<span class="hljs-string">&quot;POST&quot;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">login</span>():<br>    username = request.json.get(<span class="hljs-string">&quot;username&quot;</span>, <span class="hljs-literal">None</span>)<br>    password = request.json.get(<span class="hljs-string">&quot;password&quot;</span>, <span class="hljs-literal">None</span>)<br>    <span class="hljs-keyword">if</span> username <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;admin1&quot;</span>, <span class="hljs-string">&quot;admin2&quot;</span>, <span class="hljs-string">&quot;admin3&quot;</span>] <span class="hljs-keyword">or</span> password != <span class="hljs-string">&quot;123456&quot;</span>:<br>        <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&quot;msg&quot;</span>: <span class="hljs-string">&quot;Bad username or password&quot;</span>&#125;), <span class="hljs-number">401</span><br><br>    <span class="hljs-comment"># 传入身份信息创建 access_token</span><br>    access_token = create_access_token(identity=username)<br>    <span class="hljs-keyword">return</span> jsonify(access_token=<span class="hljs-string">&#x27;Bearer &#x27;</span> + access_token)<br><br><br><span class="hljs-comment"># 使用 jwt_required 保护请求视图，如果在请求中不存在jwt token将无法访问。</span><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/protected&quot;</span>, methods=[<span class="hljs-string">&quot;GET&quot;</span>]</span>)</span><br><span class="hljs-meta">@jwt_required()</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">protected</span>():<br>    <span class="hljs-comment"># 使用 get_jwt_identity 访问当前用户的身份</span><br>    current_user = get_jwt_identity()<br>    <span class="hljs-keyword">return</span> jsonify(logged_in_as=current_user), <span class="hljs-number">200</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    app.run(debug=<span class="hljs-literal">True</span>)<br><br></code></pre></td></tr></table></figure><p>创建JWT：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl --location <span class="hljs-string">&#x27;http://127.0.0.1:5000/login&#x27;</span> \<br>--header <span class="hljs-string">&#x27;Content-Type: application/json&#x27;</span> \<br>--data <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">    &quot;username&quot;: &quot;admin3&quot;,</span><br><span class="hljs-string">    &quot;password&quot;: &quot;123456&quot;</span><br><span class="hljs-string">&#125;&#x27;</span><br></code></pre></td></tr></table></figure><p>验证JWT：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl --location <span class="hljs-string">&#x27;http://127.0.0.1:5000/protected&#x27;</span> \<br>--header <span class="hljs-string">&#x27;Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmcmVzaCI6ZmFsc2UsImlhdCI6MTY4ODQ2Mzg5OCwianRpIjoiZDU1NDdjMGQtZjc2Zi00MTA3LThhNTAtYWZmN2I4NTIxMzEzIiwidHlwZSI6ImFjY2VzcyIsInN1YiI6ImFkbWluMyIsIm5iZiI6MTY4ODQ2Mzg5OCwiZXhwIjoxNjg4NDY0Nzk4fQ.hFUJNHF9ULv_tWK31ttOhHMp_-azevG6VyJRsiUcMcM&#x27;</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>草稿</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flask</tag>
      
      <tag>HTTP认证</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Flask计数器</title>
    <link href="/Flask%E8%AE%A1%E6%95%B0%E5%99%A8/"/>
    <url>/Flask%E8%AE%A1%E6%95%B0%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计数器实现方式：</p><ol><li>使用session</li><li>使用多线程</li><li>使用内存数据库，如redis</li></ol><ul><li>使用session</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, jsonify, session<br><br>app = Flask(__name__)<br>app.secret_key = <span class="hljs-string">&#x27;test&#x27;</span><br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/index&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">news</span>():<br>    <span class="hljs-keyword">if</span> session.get(<span class="hljs-string">&#x27;click&#x27;</span>, <span class="hljs-literal">None</span>) <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        session[<span class="hljs-string">&#x27;click&#x27;</span>] = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">else</span>:<br>        session[<span class="hljs-string">&#x27;click&#x27;</span>] += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> jsonify(click=session[<span class="hljs-string">&#x27;click&#x27;</span>])<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    app.run()<br><br></code></pre></td></tr></table></figure><ul><li>使用多线程</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, jsonify<br><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Value<br><br>app = Flask(__name__)<br>counter = Value(<span class="hljs-string">&#x27;i&#x27;</span>, <span class="hljs-number">0</span>)  <span class="hljs-comment"># i表示有符号整数</span><br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/index&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">news</span>():<br>    <span class="hljs-keyword">with</span> counter.get_lock():<br>        counter.value += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> jsonify(click=counter.value)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    app.run()<br><br></code></pre></td></tr></table></figure><ul><li>使用redis</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> redis<br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, jsonify<br><br><br>app = Flask(__name__)<br><span class="hljs-comment"># redis connection</span><br>kv_store = redis.Redis(host=<span class="hljs-string">&#x27;0.0.0.0&#x27;</span>, port=<span class="hljs-number">6379</span>, db=<span class="hljs-number">0</span>)<br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/index&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">news</span>():<br>    c = kv_store.incr(<span class="hljs-string">&#x27;count&#x27;</span>)<br>    <span class="hljs-keyword">return</span> jsonify(count=c)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    app.run()<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>草稿</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flask</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（三十七）使用keras-bert实现英语序列标注任务</title>
    <link href="/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%B8%83%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E8%8B%B1%E8%AF%AD%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/"/>
    <url>/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%B8%83%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E8%8B%B1%E8%AF%AD%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/">NLP（三十四）使用keras-bert实现序列标注任务</a>中，我们已经用keras-bert模块实现了中文序列标注任务，其中对BERT进行微调。当前，我们也可以顺便实现下英语序列标注任务。</p><p>本文将介绍如何使用keras-bert实现英语序列标注任务。</p><h3 id="一个小测试">一个小测试</h3><p>使用keras-bert实现英语序列标注任务的代码，大体上与文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/">NLP（三十四）使用keras-bert实现序列标注任务</a>中的相似，但英语序列标注有其特殊之处。其特殊之处在于，BERT会将复杂的英语单词拆分成多个简单英语单词，进行tokenize.</p><p>下面给出一个例子。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> Tokenizer<br><br><span class="hljs-comment"># 读取词典</span><br>dict_path = <span class="hljs-string">&#x27;./uncased_L-12_H-768_A-12/vocab.txt&#x27;</span><br>token_dict = &#123;&#125;<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(dict_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> reader:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> reader:<br>        token = line.strip()<br>        token_dict[token] = <span class="hljs-built_in">len</span>(token_dict)<br><br>id_token_dict = &#123;v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> token_dict.items()&#125;<br>tokenizer = Tokenizer(token_dict=token_dict)<br><br><span class="hljs-comment"># tokenize</span><br>code = tokenizer.encode(<span class="hljs-string">&quot;A man waits in the arrivals hall at Heathrow Airport in London.&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;ids: &quot;</span>, code[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;type_ids: &quot;</span>, code[<span class="hljs-number">1</span>])<br>encode_text = [id_token_dict[_] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> code[<span class="hljs-number">0</span>]]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;encode_text: &quot;</span>, encode_text)<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs prolog">ids:  [<span class="hljs-number">101</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">2158</span>, <span class="hljs-number">18074</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">25470</span>, <span class="hljs-number">2534</span>, <span class="hljs-number">2012</span>, <span class="hljs-number">9895</span>, <span class="hljs-number">10524</span>, <span class="hljs-number">3199</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">2414</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>]<br>type_ids:  [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>encode_text:  [<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;man&#x27;</span>, <span class="hljs-string">&#x27;waits&#x27;</span>, <span class="hljs-string">&#x27;in&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;arrivals&#x27;</span>, <span class="hljs-string">&#x27;hall&#x27;</span>, <span class="hljs-string">&#x27;at&#x27;</span>, <span class="hljs-string">&#x27;heath&#x27;</span>, <span class="hljs-string">&#x27;##row&#x27;</span>, <span class="hljs-string">&#x27;airport&#x27;</span>, <span class="hljs-string">&#x27;in&#x27;</span>, <span class="hljs-string">&#x27;london&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]<br></code></pre></td></tr></table></figure><p>可以看到，在句子中单词<code>Heathrow</code>被拆分成了两个token<code>heath</code>和<code>##row</code>，这是BERT英语预训练模型在tokenize时的特殊之处。</p><p>基于上述原因，我们原来的标注序列：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-symbol">&#x27;a</span>&#x27;, <span class="hljs-symbol">&#x27;man</span>&#x27;, <span class="hljs-symbol">&#x27;waits</span>&#x27;, <span class="hljs-symbol">&#x27;in</span>&#x27;, <span class="hljs-symbol">&#x27;the</span>&#x27;, <span class="hljs-symbol">&#x27;arrivals</span>&#x27;, <span class="hljs-symbol">&#x27;hall</span>&#x27;, <span class="hljs-symbol">&#x27;at</span>&#x27;, <span class="hljs-symbol">&#x27;heathrow</span>&#x27;, <span class="hljs-symbol">&#x27;airport</span>&#x27;, <span class="hljs-symbol">&#x27;in</span>&#x27;, <span class="hljs-symbol">&#x27;london</span>&#x27;, <span class="hljs-symbol">&#x27;.</span>&#x27;]<br>[<span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;B-LOC</span>&#x27;, <span class="hljs-symbol">&#x27;I-LOC</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;B-LOC</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;]<br></code></pre></td></tr></table></figure><p>在进入英语序列标注时，应当变成如下序列：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[&#x27;[<span class="hljs-name">CLS</span>]&#x27;, <span class="hljs-symbol">&#x27;a</span>&#x27;, <span class="hljs-symbol">&#x27;man</span>&#x27;, <span class="hljs-symbol">&#x27;waits</span>&#x27;, <span class="hljs-symbol">&#x27;in</span>&#x27;, <span class="hljs-symbol">&#x27;the</span>&#x27;, <span class="hljs-symbol">&#x27;arrivals</span>&#x27;, <span class="hljs-symbol">&#x27;hall</span>&#x27;, <span class="hljs-symbol">&#x27;at</span>&#x27;, <span class="hljs-symbol">&#x27;heath</span>&#x27;, &#x27;##row&#x27;, <span class="hljs-symbol">&#x27;airport</span>&#x27;, <span class="hljs-symbol">&#x27;in</span>&#x27;, <span class="hljs-symbol">&#x27;london</span>&#x27;, <span class="hljs-symbol">&#x27;.</span>&#x27;, &#x27;[<span class="hljs-name">SEP</span>]&#x27;]<br>[<span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;B-LOC</span>&#x27;, <span class="hljs-symbol">&#x27;B-LOC</span>&#x27;, <span class="hljs-symbol">&#x27;I-LOC</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;B-LOC</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;]<br></code></pre></td></tr></table></figure><p>也就是说，拆分后的多个简单英语单词的序列标注标签将会跟随原先复杂单词的标签。</p><h3 id="数据集">数据集</h3><p>本文将会在两个英语命名实体识别的数据集上进行测试。</p><ol type="1"><li><p><ahref="https://www.clips.uantwerpen.be/conll2003/ner/">Conll2003</a></p><p>conll2003.train 14987条数据和conll2003.test3466条数据，共4种标签：</p><ul class="task-list"><li><label><input type="checkbox" checked="" />LOC</label></li><li><label><input type="checkbox" checked="" />PER</label></li><li><label><input type="checkbox" checked="" />ORG</label></li><li><label><input type="checkbox" checked="" />MISC</label></li></ul></li><li><p><ahref="https://noisy-text.github.io/2017/emerging-rare-entities.html">wnut17</a></p><p>wnut17.train 3394条数据和wnut17.test 1009条数据，共6种标签：</p><ul class="task-list"><li><label><input type="checkbox" checked="" />Person</label></li><li><label><input type="checkbox" checked="" />Location (including GPE,facility)</label></li><li><label><input type="checkbox" checked="" />Corporation</label></li><li><label><input type="checkbox" checked="" />Consumer good (tangiblegoods, or well-defined services)</label></li><li><label><input type="checkbox" checked="" />Creative work (song,movie, book, and so on)</label></li><li><label><input type="checkbox" checked="" />Group (subsuming musicband, sports team, and non-corporate organisations)</label></li></ul></li></ol><h3 id="模型评估">模型评估</h3><p>英语序列标注使用keras-bert进行模型训练、评估和预测的代码与文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/">NLP（三十四）使用keras-bert实现序列标注任务</a>中的相似，本文不再详细给出，感兴趣的读者可以参考Github的实现代码：<ahref="https://github.com/percent4/keras_bert_english_sequence_labeling">https://github.com/percent4/keras_bert_english_sequence_labeling</a>。 我们利用上述模型，在两个数据集上的评估结果如下：</p><ul><li>Conll2003</li></ul><p>模型参数：uncased_L-12_H-768_A-12, MAX_SEQ_LEN=128, BATCH_SIZE=32,EPOCH=10</p><p>运行model_evaluate.py,模型评估结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache">           <span class="hljs-attribute">precision</span>    recall  f1-score   support<br><br>      <span class="hljs-attribute">PER</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9650</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9577</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9613</span>      <span class="hljs-number">1842</span><br>      <span class="hljs-attribute">ORG</span>     <span class="hljs-number">0</span>.<span class="hljs-number">8889</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8770</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8829</span>      <span class="hljs-number">1341</span><br>     <span class="hljs-attribute">MISC</span>     <span class="hljs-number">0</span>.<span class="hljs-number">8156</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8395</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8274</span>       <span class="hljs-number">922</span><br>      <span class="hljs-attribute">LOC</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9286</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9271</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9278</span>      <span class="hljs-number">1837</span><br><br><span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9129</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9116</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9123</span>      <span class="hljs-number">5942</span><br><span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9134</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9116</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9125</span>      <span class="hljs-number">5942</span><br></code></pre></td></tr></table></figure><p><ahref="https://github.com/sebastianruder/NLP-progress/blob/master/english/named_entity_recognition.md">最新SOTA结果的F1值为94.3%.</a></p><ul><li>wnut17</li></ul><p>模型参数：uncased_L-12_H-768_A-12, MAX_SEQ_LEN=128, BATCH_SIZE=20,EPOCH=10</p><p>运行model_evaluate.py,模型评估结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs apache">             <span class="hljs-attribute">precision</span>    recall  f1-score   support<br><br>       <span class="hljs-attribute">work</span>     <span class="hljs-number">0</span>.<span class="hljs-number">2069</span>    <span class="hljs-number">0</span>.<span class="hljs-number">0571</span>    <span class="hljs-number">0</span>.<span class="hljs-number">0896</span>       <span class="hljs-number">105</span><br>     <span class="hljs-attribute">person</span>     <span class="hljs-number">0</span>.<span class="hljs-number">6599</span>    <span class="hljs-number">0</span>.<span class="hljs-number">4830</span>    <span class="hljs-number">0</span>.<span class="hljs-number">5577</span>       <span class="hljs-number">470</span><br>    <span class="hljs-attribute">product</span>     <span class="hljs-number">0</span>.<span class="hljs-number">3333</span>    <span class="hljs-number">0</span>.<span class="hljs-number">0965</span>    <span class="hljs-number">0</span>.<span class="hljs-number">1497</span>       <span class="hljs-number">114</span><br>   <span class="hljs-attribute">location</span>     <span class="hljs-number">0</span>.<span class="hljs-number">5070</span>    <span class="hljs-number">0</span>.<span class="hljs-number">4865</span>    <span class="hljs-number">0</span>.<span class="hljs-number">4966</span>        <span class="hljs-number">74</span><br>      <span class="hljs-attribute">group</span>     <span class="hljs-number">0</span>.<span class="hljs-number">1500</span>    <span class="hljs-number">0</span>.<span class="hljs-number">1538</span>    <span class="hljs-number">0</span>.<span class="hljs-number">1519</span>        <span class="hljs-number">39</span><br><span class="hljs-attribute">corporation</span>     <span class="hljs-number">0</span>.<span class="hljs-number">1935</span>    <span class="hljs-number">0</span>.<span class="hljs-number">1765</span>    <span class="hljs-number">0</span>.<span class="hljs-number">1846</span>        <span class="hljs-number">34</span><br><br>  <span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">5328</span>    <span class="hljs-number">0</span>.<span class="hljs-number">3489</span>    <span class="hljs-number">0</span>.<span class="hljs-number">4217</span>       <span class="hljs-number">837</span><br>  <span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">5016</span>    <span class="hljs-number">0</span>.<span class="hljs-number">3489</span>    <span class="hljs-number">0</span>.<span class="hljs-number">4033</span>       <span class="hljs-number">837</span><br></code></pre></td></tr></table></figure><h3 id="bert模型效果对比">BERT模型效果对比</h3><p>Google对BERT进行优化，又开放了几个小版本的BERT英语预训练模型，如下：</p><figure><img src="/img/nlp37_1.png" alt="BERT英语各版本模型" /><figcaption aria-hidden="true">BERT英语各版本模型</figcaption></figure><p>我们在Conll2003数据集上，模型参数为MAX_SEQ_LEN=128, BATCH_SIZE=32,EPOCH=10，对比结果如下：</p><table><thead><tr class="header"><th>模型名称</th><th>P</th><th>R</th><th>F1</th></tr></thead><tbody><tr class="odd"><td>BERT-Small</td><td>0.8744</td><td>0.8859</td><td>0.8801</td></tr><tr class="even"><td>BERT-Medium</td><td>0.9052</td><td>0.9031</td><td>0.9041</td></tr><tr class="odd"><td>BERT-Base</td><td>0.9129</td><td>0.9116</td><td>0.9123</td></tr></tbody></table><h3 id="总结">总结</h3><p>本文采用keras-bert实现了英语序列标注任务，其中对BERT进行微调。本项目已经上传至Github，网址为：<ahref="https://github.com/percent4/keras_bert_english_sequence_labeling">https://github.com/percent4/keras_bert_english_sequence_labeling</a>。</p><p>后续将介绍如何使用keras-bert加载ALBERT模型，并实现文本多分类、文本多标签任务和序列标注任务，欢迎关注~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>keras-bert</tag>
      
      <tag>序列标注</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（三十六）使用keras-bert实现文本多标签分类任务</title>
    <link href="/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/"/>
    <url>/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%85%AD%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会介绍如何使用keras-bert实现文本多标签分类任务，其中对BERT进行<code>微调</code>。</p><h3 id="项目结构">项目结构</h3><p>本项目的项目结构如下：</p><figure><img src="/img/nlp36_1.png" alt="项目结构" /><figcaption aria-hidden="true">项目结构</figcaption></figure><p>其中依赖的Python第三方模块如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">pandas==0.23.4<br>Keras==2.3.1<br>keras_bert==0.83.0<br>numpy==1.16.4<br></code></pre></td></tr></table></figure><h3 id="数据集介绍">数据集介绍</h3><p>本文采用的数据集与文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%85%AB%EF%BC%89%E5%A4%9A%E6%A0%87%E7%AD%BE%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">NLP（二十八）多标签文本分类</a>中的一致，以事件抽取比赛的数据集为参考，形成文本与事件类型的多标签数据集，一共为65种事件类型。样例数据（csv格式）如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">label,content<br>司法行为-起诉|组织关系-裁员,最近，一位前便利蜂员工就因公司违规裁员，将便利蜂所在的公司虫极科技（北京）有限公司告上法庭。<br>组织关系-裁员,思科上海大规模裁员人均可获赔100万官方澄清事实<br>组织关系-裁员,日本巨头面临危机，已裁员1000多人，苹果也救不了它！<br>组织关系-裁员|组织关系-解散,在硅谷镀金失败的造车新势力们：蔚来裁员、奇点被偷窃、拜腾解散<br></code></pre></td></tr></table></figure><p>在label中，每个事件类型用|隔开。</p><p>在该数据集中，训练集一共11958个样本，测试集一共1498个样本。</p><h3 id="模型训练">模型训练</h3><p>模型训练的脚本model_train.py的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> codecs<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> load_trained_model_from_checkpoint, Tokenizer<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model<br><span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> Adam<br><br><span class="hljs-comment"># 建议长度&lt;=510</span><br>maxlen = <span class="hljs-number">256</span><br>BATCH_SIZE = <span class="hljs-number">8</span><br>config_path = <span class="hljs-string">&#x27;./chinese_L-12_H-768_A-12/bert_config.json&#x27;</span><br>checkpoint_path = <span class="hljs-string">&#x27;./chinese_L-12_H-768_A-12/bert_model.ckpt&#x27;</span><br>dict_path = <span class="hljs-string">&#x27;./chinese_L-12_H-768_A-12/vocab.txt&#x27;</span><br><br><br>token_dict = &#123;&#125;<br><span class="hljs-keyword">with</span> codecs.<span class="hljs-built_in">open</span>(dict_path, <span class="hljs-string">&#x27;r&#x27;</span>, <span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> reader:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> reader:<br>        token = line.strip()<br>        token_dict[token] = <span class="hljs-built_in">len</span>(token_dict)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">OurTokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_tokenize</span>(<span class="hljs-params">self, text</span>):<br>        R = []<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> text:<br>            <span class="hljs-keyword">if</span> c <span class="hljs-keyword">in</span> self._token_dict:<br>                R.append(c)<br>            <span class="hljs-keyword">else</span>:<br>                R.append(<span class="hljs-string">&#x27;[UNK]&#x27;</span>)   <span class="hljs-comment"># 剩余的字符是[UNK]</span><br>        <span class="hljs-keyword">return</span> R<br><br><br>tokenizer = OurTokenizer(token_dict)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_padding</span>(<span class="hljs-params">X, padding=<span class="hljs-number">0</span></span>):<br>    L = [<span class="hljs-built_in">len</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X]<br>    ML = <span class="hljs-built_in">max</span>(L)<br>    <span class="hljs-keyword">return</span> np.array([<br>        np.concatenate([x, [padding] * (ML - <span class="hljs-built_in">len</span>(x))]) <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(x) &lt; ML <span class="hljs-keyword">else</span> x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X<br>    ])<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataGenerator</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data, batch_size=BATCH_SIZE</span>):<br>        self.data = data<br>        self.batch_size = batch_size<br>        self.steps = <span class="hljs-built_in">len</span>(self.data) // self.batch_size<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(self.data) % self.batch_size != <span class="hljs-number">0</span>:<br>            self.steps += <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.steps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            idxs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(self.data)))<br>            np.random.shuffle(idxs)<br>            X1, X2, Y = [], [], []<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> idxs:<br>                d = self.data[i]<br>                text = d[<span class="hljs-number">0</span>][:maxlen]<br>                x1, x2 = tokenizer.encode(first=text)<br>                y = d[<span class="hljs-number">1</span>]<br>                X1.append(x1)<br>                X2.append(x2)<br>                Y.append(y)<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(X1) == self.batch_size <span class="hljs-keyword">or</span> i == idxs[-<span class="hljs-number">1</span>]:<br>                    X1 = seq_padding(X1)<br>                    X2 = seq_padding(X2)<br>                    Y = seq_padding(Y)<br>                    <span class="hljs-keyword">yield</span> [X1, X2], Y<br>                    [X1, X2, Y] = [], [], []<br><br><br><span class="hljs-comment"># 构建模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_cls_model</span>(<span class="hljs-params">num_labels</span>):<br>    bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, seq_len=<span class="hljs-literal">None</span>)<br><br>    <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> bert_model.layers:<br>        layer.trainable = <span class="hljs-literal">True</span><br><br>    x1_in = Input(shape=(<span class="hljs-literal">None</span>,))<br>    x2_in = Input(shape=(<span class="hljs-literal">None</span>,))<br><br>    x = bert_model([x1_in, x2_in])<br>    cls_layer = Lambda(<span class="hljs-keyword">lambda</span> x: x[:, <span class="hljs-number">0</span>])(x)    <span class="hljs-comment"># 取出[CLS]对应的向量用来做分类</span><br>    p = Dense(num_labels, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>)(cls_layer)     <span class="hljs-comment"># 多分类</span><br><br>    model = Model([x1_in, x2_in], p)<br>    model.<span class="hljs-built_in">compile</span>(<br>        loss=<span class="hljs-string">&#x27;binary_crossentropy&#x27;</span>,<br>        optimizer=Adam(<span class="hljs-number">1e-5</span>), <span class="hljs-comment"># 用足够小的学习率</span><br>        metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>]<br>    )<br>    model.summary()<br><br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br><br>    <span class="hljs-comment"># 数据处理, 读取训练集和测试集</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;begin data processing...&quot;</span>)<br>    train_df = pd.read_csv(<span class="hljs-string">&quot;data/train.csv&quot;</span>).fillna(value=<span class="hljs-string">&quot;&quot;</span>)<br>    test_df = pd.read_csv(<span class="hljs-string">&quot;data/test.csv&quot;</span>).fillna(value=<span class="hljs-string">&quot;&quot;</span>)<br><br>    select_labels = train_df[<span class="hljs-string">&quot;label&quot;</span>].unique()<br>    labels = []<br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> select_labels:<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;|&quot;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> label:<br>            <span class="hljs-keyword">if</span> label <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> labels:<br>                labels.append(label)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> label.split(<span class="hljs-string">&quot;|&quot;</span>):<br>                <span class="hljs-keyword">if</span> _ <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> labels:<br>                    labels.append(_)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;label.json&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(json.dumps(<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)), labels)), ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">2</span>))<br><br>    train_data = []<br>    test_data = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(train_df.shape[<span class="hljs-number">0</span>]):<br>        label, content = train_df.iloc[i, :]<br>        label_id = [<span class="hljs-number">0</span>] * <span class="hljs-built_in">len</span>(labels)<br>        <span class="hljs-keyword">for</span> j, _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels):<br>            <span class="hljs-keyword">for</span> separate_label <span class="hljs-keyword">in</span> label.split(<span class="hljs-string">&quot;|&quot;</span>):<br>                <span class="hljs-keyword">if</span> _ == separate_label:<br>                    label_id[j] = <span class="hljs-number">1</span><br>        train_data.append((content, label_id))<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(test_df.shape[<span class="hljs-number">0</span>]):<br>        label, content = test_df.iloc[i, :]<br>        label_id = [<span class="hljs-number">0</span>] * <span class="hljs-built_in">len</span>(labels)<br>        <span class="hljs-keyword">for</span> j, _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels):<br>            <span class="hljs-keyword">for</span> separate_label <span class="hljs-keyword">in</span> label.split(<span class="hljs-string">&quot;|&quot;</span>):<br>                <span class="hljs-keyword">if</span> _ == separate_label:<br>                    label_id[j] = <span class="hljs-number">1</span><br>        test_data.append((content, label_id))<br><br>    <span class="hljs-comment"># print(train_data[:10])</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;finish data processing!&quot;</span>)<br><br>    <span class="hljs-comment"># 模型训练</span><br>    model = create_cls_model(<span class="hljs-built_in">len</span>(labels))<br>    train_D = DataGenerator(train_data)<br>    test_D = DataGenerator(test_data)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;begin model training...&quot;</span>)<br>    model.fit_generator(<br>        train_D.__iter__(),<br>        steps_per_epoch=<span class="hljs-built_in">len</span>(train_D),<br>        epochs=<span class="hljs-number">10</span>,<br>        validation_data=test_D.__iter__(),<br>        validation_steps=<span class="hljs-built_in">len</span>(test_D)<br>    )<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;finish model training!&quot;</span>)<br><br>    <span class="hljs-comment"># 模型保存</span><br>    model.save(<span class="hljs-string">&#x27;multi-label-ee.h5&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Model saved!&quot;</span>)<br><br>    result = model.evaluate_generator(test_D.__iter__(), steps=<span class="hljs-built_in">len</span>(test_D))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;模型评估结果:&quot;</span>, result)<br></code></pre></td></tr></table></figure><p>模型结构如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>__<br><span class="hljs-section">Layer (type)                    Output Shape         Param #     Connected to                     </span><br><span class="hljs-section">==================================================================================================</span><br>input<span class="hljs-emphasis">_1 (InputLayer)            (None, None)         0                                            </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span>_<br>input<span class="hljs-emphasis">_2 (InputLayer)            (None, None)         0                                            </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span>_<br>model<span class="hljs-emphasis">_2 (Model)                 (None, None, 768)    101677056   input_</span>1[<span class="hljs-string">0</span>][<span class="hljs-symbol">0</span>]                    <br><span class="hljs-code">                                                                 input_2[0][0]                    </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">dense_1 (Dense)                 (None, 65)           49985       lambda_1[0][0]                   </span><br><span class="hljs-code">==================================================================================================</span><br><span class="hljs-code">Total params: 101,727,041</span><br><span class="hljs-code">Trainable params: 101,727,041</span><br><span class="hljs-code">Non-trainable params: 0</span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br></code></pre></td></tr></table></figure><p>从中我们可以发现，该模型结构与文章<ahref="https://blog.csdn.net/jclian91/article/details/111742576">NLP（三十五）使用keras-bert实现文本多分类任务</a>中给出的文本多分类模型结构大体一致，修改之处在于BERT后接的网络结构，所接的依然是dense层，但激活函数采用sigmoid函数，同时损失函数为binary_crossentropy。就其本质而言，该模型结构是对输出的65个结果采用0-1分类，故而激活函数采用sigmoid，这当然是文本多分类模型转化为多标签标签的最便捷方式，但不足之处在于，该模型并未考虑标签之间的依赖关系。</p><h3 id="模型评估">模型评估</h3><p>模型评估脚本model_evaluate.py的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @Time : 2020/12/23 15:28</span><br><span class="hljs-comment"># @Author : Jclian91</span><br><span class="hljs-comment"># @File : model_evaluate.py</span><br><span class="hljs-comment"># @Place : Yangpu, Shanghai</span><br><span class="hljs-comment"># 模型评估脚本,利用hamming_loss作为多标签分类的评估指标，该值越小模型效果越好</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> get_custom_objects<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> hamming_loss, classification_report<br><br><span class="hljs-keyword">from</span> model_train <span class="hljs-keyword">import</span> token_dict, OurTokenizer<br><br>maxlen = <span class="hljs-number">256</span><br><br><span class="hljs-comment"># 加载训练好的模型</span><br>model = load_model(<span class="hljs-string">&quot;multi-label-ee.h5&quot;</span>, custom_objects=get_custom_objects())<br>tokenizer = OurTokenizer(token_dict)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;label.json&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    label_dict = json.loads(f.read())<br><br><br><span class="hljs-comment"># 对单句话进行预测</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_single_text</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-comment"># 利用BERT进行tokenize</span><br>    text = text[:maxlen]<br>    x1, x2 = tokenizer.encode(first=text)<br>    X1 = x1 + [<span class="hljs-number">0</span>] * (maxlen - <span class="hljs-built_in">len</span>(x1)) <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(x1) &lt; maxlen <span class="hljs-keyword">else</span> x1<br>    X2 = x2 + [<span class="hljs-number">0</span>] * (maxlen - <span class="hljs-built_in">len</span>(x2)) <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(x2) &lt; maxlen <span class="hljs-keyword">else</span> x2<br><br>    <span class="hljs-comment"># 模型预测并输出预测结果</span><br>    prediction = model.predict([[X1], [X2]])<br>    one_hot = np.where(prediction &gt; <span class="hljs-number">0.5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">return</span> one_hot, <span class="hljs-string">&quot;|&quot;</span>.join([label_dict[<span class="hljs-built_in">str</span>(i)] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(one_hot)) <span class="hljs-keyword">if</span> one_hot[i]])<br><br><br><span class="hljs-comment"># 模型评估</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>():<br>    test_df = pd.read_csv(<span class="hljs-string">&quot;data/test.csv&quot;</span>).fillna(value=<span class="hljs-string">&quot;&quot;</span>)<br>    true_y_list, pred_y_list = [], []<br>    true_label_list, pred_label_list = [], []<br>    common_cnt = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(test_df.shape[<span class="hljs-number">0</span>]):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;predict %d samples&quot;</span> % (i+<span class="hljs-number">1</span>))<br>        true_label, content = test_df.iloc[i, :]<br>        true_y = [<span class="hljs-number">0</span>] * <span class="hljs-built_in">len</span>(label_dict.keys())<br>        <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> label_dict.items():<br>            <span class="hljs-keyword">if</span> value <span class="hljs-keyword">in</span> true_label:<br>                true_y[<span class="hljs-built_in">int</span>(key)] = <span class="hljs-number">1</span><br><br>        pred_y, pred_label = predict_single_text(content)<br>        <span class="hljs-keyword">if</span> true_label == pred_label:<br>            common_cnt += <span class="hljs-number">1</span><br>        true_y_list.append(true_y)<br>        pred_y_list.append(pred_y)<br>        true_label_list.append(true_label)<br>        pred_label_list.append(pred_label)<br><br>    <span class="hljs-comment"># F1值</span><br>    <span class="hljs-built_in">print</span>(classification_report(true_y_list, pred_y_list, digits=<span class="hljs-number">4</span>))<br>    <span class="hljs-keyword">return</span> true_label_list, pred_label_list, hamming_loss(true_y_list, pred_y_list), common_cnt/<span class="hljs-built_in">len</span>(true_y_list)<br><br><br>true_labels, pred_labels, h_loss, accuracy = evaluate()<br>df = pd.DataFrame(&#123;<span class="hljs-string">&quot;y_true&quot;</span>: true_labels, <span class="hljs-string">&quot;y_pred&quot;</span>: pred_labels&#125;)<br>df.to_csv(<span class="hljs-string">&quot;pred_result.csv&quot;</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;accuracy: &quot;</span>, accuracy)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;hamming loss: &quot;</span>, h_loss)<br></code></pre></td></tr></table></figure><p>HammingLoss为多标签分类所特有的评估方式，其值越小代表多标签分类模型的效果越好。运行上述模型评估代码，输出结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache">   <span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9341</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9578</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9458</span>      <span class="hljs-number">1657</span><br>   <span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9336</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9462</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9370</span>      <span class="hljs-number">1657</span><br><span class="hljs-attribute">weighted</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9367</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9578</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9456</span>      <span class="hljs-number">1657</span><br> <span class="hljs-attribute">samples</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9520</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9672</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9531</span>      <span class="hljs-number">1657</span><br><br><span class="hljs-attribute">accuracy</span>:  <span class="hljs-number">0</span>.<span class="hljs-number">8985313751668892</span><br><span class="hljs-attribute">hamming</span> loss:  <span class="hljs-number">0</span>.<span class="hljs-number">001869158878504673</span><br></code></pre></td></tr></table></figure><p>在这里，笔者希望与之前的文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%85%AB%EF%BC%89%E5%A4%9A%E6%A0%87%E7%AD%BE%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">NLP（二十八）多标签文本分类</a>中的模型对比一下。当时采用的模型为用ALBERT提取特征向量，再用Bi-GRU+Attention+FCN进行分类，模型结构如下：</p><figure><img src="/img/nlp36_2.png" alt="Bi-GRU+Attention+FCN" /><figcaption aria-hidden="true">Bi-GRU+Attention+FCN</figcaption></figure><p>对该模型同样采用上述评估办法，输出的结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache">   <span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9424</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8292</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8822</span>      <span class="hljs-number">1657</span><br>   <span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">8983</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7218</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7791</span>      <span class="hljs-number">1657</span><br><span class="hljs-attribute">weighted</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9308</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8292</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8669</span>      <span class="hljs-number">1657</span><br> <span class="hljs-attribute">samples</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">8675</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8496</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8517</span>      <span class="hljs-number">1657</span><br><span class="hljs-attribute">accuracy</span>:  <span class="hljs-number">0</span>.<span class="hljs-number">7983978638184246</span><br><span class="hljs-attribute">hamming</span> loss:  <span class="hljs-number">0</span>.<span class="hljs-number">0037691280681934887</span><br></code></pre></td></tr></table></figure><p>可以发现，采用BERT微调的模型，在accuracy方面高出了约10%，各种F1值高出约5%-10%，HammingLoss也小了很多。因此，BERT微调的模型比之前的模型效果好很多。</p><h3 id="总结">总结</h3><p>本项目已经开源，Github地址为：<ahref="https://github.com/percent4/keras_bert_multi_label_cls">https://github.com/percent4/keras_bert_multi_label_cls</a>。</p><p>2020年12月27日于上海浦东</p><h3 id="参考文章">参考文章</h3><ol type="1"><li>NLP（二十八）多标签文本分类：https://blog.csdn.net/jclian91/article/details/105386190</li><li>NLP（三十五）使用keras-bert实现文本多分类任务：https://blog.csdn.net/jclian91/article/details/111742576</li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>keras-bert</tag>
      
      <tag>多标签分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（三十五）使用keras-bert实现文本多分类任务</title>
    <link href="/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%BA%94%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/"/>
    <url>/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%BA%94%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E5%A4%9A%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会介绍如何使用keras-bert实现文本多分类任务，其中对BERT进行<code>微调</code>。</p><h3 id="项目结构">项目结构</h3><figure><img src="/img/nlp35_1.png" alt="keras-bert文本多分类项目结构" /><figcaption aria-hidden="true">keras-bert文本多分类项目结构</figcaption></figure><p>其中依赖的Python第三方模块如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">pandas==0.23.4<br>Keras==2.3.1<br>keras_bert==0.83.0<br>numpy==1.16.4<br></code></pre></td></tr></table></figure><h3 id="数据集">数据集</h3><p>本文采用的多分类数据集为sougou小分类数据集和THUCNews数据集，简介如下：</p><ul><li>sougou小分类数据集</li></ul><p>共有5个类别，分别为体育、健康、军事、教育、汽车。划分为训练集和测试集，其中训练集每个分类800条样本，测试集每个分类100条样本。</p><ul><li>THUCNews数据集</li></ul><p>共有10个分类，类别为：体育, 财经, 房产, 家居, 教育, 科技, 时尚, 时政,游戏, 娱乐。数据集划分为：训练集: 5000 * 10，测试集: 1000 * 10。</p><h3 id="模型训练">模型训练</h3><p>模型训练脚本model_train.py的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> codecs<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> load_trained_model_from_checkpoint, Tokenizer<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model<br><span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> Adam<br><br><span class="hljs-comment"># 建议长度&lt;=510</span><br>maxlen = <span class="hljs-number">300</span><br>BATCH_SIZE = <span class="hljs-number">8</span><br>config_path = <span class="hljs-string">&#x27;./chinese_L-12_H-768_A-12/bert_config.json&#x27;</span><br>checkpoint_path = <span class="hljs-string">&#x27;./chinese_L-12_H-768_A-12/bert_model.ckpt&#x27;</span><br>dict_path = <span class="hljs-string">&#x27;./chinese_L-12_H-768_A-12/vocab.txt&#x27;</span><br><br><br>token_dict = &#123;&#125;<br><span class="hljs-keyword">with</span> codecs.<span class="hljs-built_in">open</span>(dict_path, <span class="hljs-string">&#x27;r&#x27;</span>, <span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> reader:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> reader:<br>        token = line.strip()<br>        token_dict[token] = <span class="hljs-built_in">len</span>(token_dict)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">OurTokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_tokenize</span>(<span class="hljs-params">self, text</span>):<br>        R = []<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> text:<br>            <span class="hljs-keyword">if</span> c <span class="hljs-keyword">in</span> self._token_dict:<br>                R.append(c)<br>            <span class="hljs-keyword">else</span>:<br>                R.append(<span class="hljs-string">&#x27;[UNK]&#x27;</span>)   <span class="hljs-comment"># 剩余的字符是[UNK]</span><br>        <span class="hljs-keyword">return</span> R<br><br><br>tokenizer = OurTokenizer(token_dict)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_padding</span>(<span class="hljs-params">X, padding=<span class="hljs-number">0</span></span>):<br>    L = [<span class="hljs-built_in">len</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X]<br>    ML = <span class="hljs-built_in">max</span>(L)<br>    <span class="hljs-keyword">return</span> np.array([<br>        np.concatenate([x, [padding] * (ML - <span class="hljs-built_in">len</span>(x))]) <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(x) &lt; ML <span class="hljs-keyword">else</span> x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X<br>    ])<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataGenerator</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data, batch_size=BATCH_SIZE</span>):<br>        self.data = data<br>        self.batch_size = batch_size<br>        self.steps = <span class="hljs-built_in">len</span>(self.data) // self.batch_size<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(self.data) % self.batch_size != <span class="hljs-number">0</span>:<br>            self.steps += <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.steps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            idxs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(self.data)))<br>            np.random.shuffle(idxs)<br>            X1, X2, Y = [], [], []<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> idxs:<br>                d = self.data[i]<br>                text = d[<span class="hljs-number">0</span>][:maxlen]<br>                x1, x2 = tokenizer.encode(first=text)<br>                y = d[<span class="hljs-number">1</span>]<br>                X1.append(x1)<br>                X2.append(x2)<br>                Y.append(y)<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(X1) == self.batch_size <span class="hljs-keyword">or</span> i == idxs[-<span class="hljs-number">1</span>]:<br>                    X1 = seq_padding(X1)<br>                    X2 = seq_padding(X2)<br>                    Y = seq_padding(Y)<br>                    <span class="hljs-keyword">yield</span> [X1, X2], Y<br>                    [X1, X2, Y] = [], [], []<br><br><br><span class="hljs-comment"># 构建模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_cls_model</span>(<span class="hljs-params">num_labels</span>):<br>    bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, seq_len=<span class="hljs-literal">None</span>)<br><br>    <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> bert_model.layers:<br>        layer.trainable = <span class="hljs-literal">True</span><br><br>    x1_in = Input(shape=(<span class="hljs-literal">None</span>,))<br>    x2_in = Input(shape=(<span class="hljs-literal">None</span>,))<br><br>    x = bert_model([x1_in, x2_in])<br>    cls_layer = Lambda(<span class="hljs-keyword">lambda</span> x: x[:, <span class="hljs-number">0</span>])(x)    <span class="hljs-comment"># 取出[CLS]对应的向量用来做分类</span><br>    p = Dense(num_labels, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>)(cls_layer)     <span class="hljs-comment"># 多分类</span><br><br>    model = Model([x1_in, x2_in], p)<br>    model.<span class="hljs-built_in">compile</span>(<br>        loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>,<br>        optimizer=Adam(<span class="hljs-number">1e-5</span>),   <span class="hljs-comment"># 用足够小的学习率</span><br>        metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>]<br>    )<br>    <span class="hljs-comment"># model.summary()</span><br><br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br><br>    <span class="hljs-comment"># 数据处理, 读取训练集和测试集</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;begin data processing...&quot;</span>)<br>    train_df = pd.read_csv(<span class="hljs-string">&quot;data/cnews/cnews_train.csv&quot;</span>).fillna(value=<span class="hljs-string">&quot;&quot;</span>)<br>    test_df = pd.read_csv(<span class="hljs-string">&quot;data/cnews/cnews_test.csv&quot;</span>).fillna(value=<span class="hljs-string">&quot;&quot;</span>)<br><br>    labels = train_df[<span class="hljs-string">&quot;label&quot;</span>].unique()<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;label.json&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(json.dumps(<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)), labels)), ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">2</span>))<br><br>    train_data = []<br>    test_data = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(train_df.shape[<span class="hljs-number">0</span>]):<br>        label, content = train_df.iloc[i, :]<br>        label_id = [<span class="hljs-number">0</span>] * <span class="hljs-built_in">len</span>(labels)<br>        <span class="hljs-keyword">for</span> j, _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels):<br>            <span class="hljs-keyword">if</span> _ == label:<br>                label_id[j] = <span class="hljs-number">1</span><br>        train_data.append((content, label_id))<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(test_df.shape[<span class="hljs-number">0</span>]):<br>        label, content = test_df.iloc[i, :]<br>        label_id = [<span class="hljs-number">0</span>] * <span class="hljs-built_in">len</span>(labels)<br>        <span class="hljs-keyword">for</span> j, _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels):<br>            <span class="hljs-keyword">if</span> _ == label:<br>                label_id[j] = <span class="hljs-number">1</span><br>        test_data.append((content, label_id))<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;finish data processing!&quot;</span>)<br><br>    <span class="hljs-comment"># 模型训练</span><br>    model = create_cls_model(<span class="hljs-built_in">len</span>(labels))<br>    train_D = DataGenerator(train_data)<br>    test_D = DataGenerator(test_data)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;begin model training...&quot;</span>)<br>    model.fit_generator(<br>        train_D.__iter__(),<br>        steps_per_epoch=<span class="hljs-built_in">len</span>(train_D),<br>        epochs=<span class="hljs-number">3</span>,<br>        validation_data=test_D.__iter__(),<br>        validation_steps=<span class="hljs-built_in">len</span>(test_D)<br>    )<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;finish model training!&quot;</span>)<br><br>    <span class="hljs-comment"># 模型保存</span><br>    model.save(<span class="hljs-string">&#x27;cls_cnews.h5&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Model saved!&quot;</span>)<br><br>    result = model.evaluate_generator(test_D.__iter__(), steps=<span class="hljs-built_in">len</span>(test_D))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;模型评估结果:&quot;</span>, result)<br></code></pre></td></tr></table></figure><p>其中模型结构如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>__<br><span class="hljs-section">Layer (type)                    Output Shape         Param #     Connected to                     </span><br><span class="hljs-section">==================================================================================================</span><br>input<span class="hljs-emphasis">_1 (InputLayer)            (None, None)         0                                            </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span>_<br>input<span class="hljs-emphasis">_2 (InputLayer)            (None, None)         0                                            </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span>_<br>model<span class="hljs-emphasis">_2 (Model)                 (None, None, 768)    101677056   input_</span>1[<span class="hljs-string">0</span>][<span class="hljs-symbol">0</span>]                    <br><span class="hljs-code">                                                                 input_2[0][0]                    </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">dense_1 (Dense)                 (None, 10)           7690        lambda_1[0][0]                   </span><br><span class="hljs-code">==================================================================================================</span><br><span class="hljs-code">Total params: 101,684,746</span><br><span class="hljs-code">Trainable params: 101,684,746</span><br><span class="hljs-code">Non-trainable params: 0</span><br></code></pre></td></tr></table></figure><p>在上述模型中，我们取取出[CLS]对应的向量，后接全连接层，激活函数采用Softmax函数，就完成多分类模型的搭建了，非常简单方便。</p><h3 id="模型评估">模型评估</h3><p>模型评估脚本model_evaluate.py的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># 模型评估脚本</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> get_custom_objects<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br><span class="hljs-keyword">from</span> model_train <span class="hljs-keyword">import</span> token_dict, OurTokenizer<br><br>maxlen = <span class="hljs-number">300</span><br><br><span class="hljs-comment"># 加载训练好的模型</span><br>model = load_model(<span class="hljs-string">&quot;cls_cnews.h5&quot;</span>, custom_objects=get_custom_objects())<br>tokenizer = OurTokenizer(token_dict)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;label.json&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    label_dict = json.loads(f.read())<br><br><br><span class="hljs-comment"># 对单句话进行预测</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_single_text</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-comment"># 利用BERT进行tokenize</span><br>    text = text[:maxlen]<br>    x1, x2 = tokenizer.encode(first=text)<br>    X1 = x1 + [<span class="hljs-number">0</span>] * (maxlen - <span class="hljs-built_in">len</span>(x1)) <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(x1) &lt; maxlen <span class="hljs-keyword">else</span> x1<br>    X2 = x2 + [<span class="hljs-number">0</span>] * (maxlen - <span class="hljs-built_in">len</span>(x2)) <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(x2) &lt; maxlen <span class="hljs-keyword">else</span> x2<br><br>    <span class="hljs-comment"># 模型预测并输出预测结果</span><br>    predicted = model.predict([[X1], [X2]])<br>    y = np.argmax(predicted[<span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">return</span> label_dict[<span class="hljs-built_in">str</span>(y)]<br><br><br><span class="hljs-comment"># 模型评估</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>():<br>    test_df = pd.read_csv(<span class="hljs-string">&quot;data/cnews/cnews_test.csv&quot;</span>).fillna(value=<span class="hljs-string">&quot;&quot;</span>)<br>    true_y_list, pred_y_list = [], []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(test_df.shape[<span class="hljs-number">0</span>]):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;predict %d samples&quot;</span> % (i+<span class="hljs-number">1</span>))<br>        true_y, content = test_df.iloc[i, :]<br>        pred_y = predict_single_text(content)<br>        true_y_list.append(true_y)<br>        pred_y_list.append(pred_y)<br><br>    <span class="hljs-keyword">return</span> classification_report(true_y_list, pred_y_list, digits=<span class="hljs-number">4</span>)<br><br><br>output_data = evaluate()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;model evaluate result:\n&quot;</span>)<br><span class="hljs-built_in">print</span>(output_data)<br></code></pre></td></tr></table></figure><p>运行上述代码，对两个数据集进行评估，结果如下：</p><ul><li>sougou数据集</li></ul><p>模型参数: batch_size = 8, maxlen = 256, epoch=10</p><p>评估结果:</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs crystal">                  precision    recall  f1-score   support<br><br>          体育     <span class="hljs-number">0.9802</span>    <span class="hljs-number">1.0000</span>    <span class="hljs-number">0.9900</span>        <span class="hljs-number">99</span><br>          健康     <span class="hljs-number">0.9495</span>    <span class="hljs-number">0.9495</span>    <span class="hljs-number">0.9495</span>        <span class="hljs-number">99</span><br>          军事     <span class="hljs-number">1.0000</span>    <span class="hljs-number">1.0000</span>    <span class="hljs-number">1.0000</span>        <span class="hljs-number">99</span><br>          教育     <span class="hljs-number">0.9307</span>    <span class="hljs-number">0.9495</span>    <span class="hljs-number">0.9400</span>        <span class="hljs-number">99</span><br>          汽车     <span class="hljs-number">0.9895</span>    <span class="hljs-number">0.9495</span>    <span class="hljs-number">0.9691</span>        <span class="hljs-number">99</span><br><br>    accuracy                         <span class="hljs-number">0.9697</span>       <span class="hljs-number">495</span><br>   <span class="hljs-function"><span class="hljs-keyword">macro</span> <span class="hljs-title">avg</span></span>     <span class="hljs-number">0.9700</span>    <span class="hljs-number">0.9697</span>    <span class="hljs-number">0.9697</span>       <span class="hljs-number">495</span><br>weighted avg     <span class="hljs-number">0.9700</span>    <span class="hljs-number">0.9697</span>    <span class="hljs-number">0.9697</span>       <span class="hljs-number">495</span><br></code></pre></td></tr></table></figure><ul><li>THUCNews数据集</li></ul><p>模型参数: batch_size = 8, maxlen = 300, epoch=3</p><p>评估结果:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs yaml">                <span class="hljs-string">precision</span>    <span class="hljs-string">recall</span>  <span class="hljs-string">f1-score</span>   <span class="hljs-string">support</span><br><br>          <span class="hljs-string">体育</span>     <span class="hljs-number">0.9970</span>    <span class="hljs-number">0.9990</span>    <span class="hljs-number">0.9980</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">娱乐</span>     <span class="hljs-number">0.9890</span>    <span class="hljs-number">0.9890</span>    <span class="hljs-number">0.9890</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">家居</span>     <span class="hljs-number">0.9949</span>    <span class="hljs-number">0.7820</span>    <span class="hljs-number">0.8757</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">房产</span>     <span class="hljs-number">0.8006</span>    <span class="hljs-number">0.8710</span>    <span class="hljs-number">0.8343</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">教育</span>     <span class="hljs-number">0.9753</span>    <span class="hljs-number">0.9480</span>    <span class="hljs-number">0.9615</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">时尚</span>     <span class="hljs-number">0.9708</span>    <span class="hljs-number">0.9980</span>    <span class="hljs-number">0.9842</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">时政</span>     <span class="hljs-number">0.9318</span>    <span class="hljs-number">0.9560</span>    <span class="hljs-number">0.9437</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">游戏</span>     <span class="hljs-number">0.9851</span>    <span class="hljs-number">0.9950</span>    <span class="hljs-number">0.9900</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">科技</span>     <span class="hljs-number">0.9689</span>    <span class="hljs-number">0.9970</span>    <span class="hljs-number">0.9828</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">财经</span>     <span class="hljs-number">0.9377</span>    <span class="hljs-number">0.9930</span>    <span class="hljs-number">0.9645</span>      <span class="hljs-number">1000</span><br><br>    <span class="hljs-string">accuracy</span>                         <span class="hljs-number">0.9528</span>     <span class="hljs-number">10000</span><br>   <span class="hljs-string">macro</span> <span class="hljs-string">avg</span>     <span class="hljs-number">0.9551</span>    <span class="hljs-number">0.9528</span>    <span class="hljs-number">0.9524</span>     <span class="hljs-number">10000</span><br><span class="hljs-string">weighted</span> <span class="hljs-string">avg</span>     <span class="hljs-number">0.9551</span>    <span class="hljs-number">0.9528</span>    <span class="hljs-number">0.9524</span>     <span class="hljs-number">10000</span><br></code></pre></td></tr></table></figure><h3 id="模型预测">模型预测</h3><p>模型预测脚本model_predict.py的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @Time : 2020/12/23 15:28</span><br><span class="hljs-comment"># @Author : Jclian91</span><br><span class="hljs-comment"># @File : model_predict.py</span><br><span class="hljs-comment"># @Place : Yangpu, Shanghai</span><br><span class="hljs-comment"># 模型预测脚本</span><br><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">from</span> model_train <span class="hljs-keyword">import</span> token_dict, OurTokenizer<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> get_custom_objects<br><br>maxlen = <span class="hljs-number">256</span><br><br><span class="hljs-comment"># 加载训练好的模型</span><br>model = load_model(<span class="hljs-string">&quot;cls_sougou.h5&quot;</span>, custom_objects=get_custom_objects())<br>tokenizer = OurTokenizer(token_dict)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;label.json&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    label_dict = json.loads(f.read())<br><br>s_time = time.time()<br><span class="hljs-comment"># 预测示例语句</span><br>text = <span class="hljs-string">&quot;说到硬派越野SUV，你会想起哪些车型？是被称为“霸道”的丰田 普拉多 (配置 | 询价) ，还是被叫做“山猫”的帕杰罗，亦或者是“渣男专车”奔驰大G、&quot;</span> \<br>       <span class="hljs-string">&quot;“沙漠王子”途乐。总之，随着世界各国越来越重视对环境的保护，那些大排量的越野SUV在不久的将来也会渐渐消失在我们的视线之中，所以与其错过，&quot;</span> \<br>       <span class="hljs-string">&quot;不如趁着还年轻，在有生之年里赶紧去入手一台能让你心仪的硬派越野SUV。而今天我想要来跟你们聊的，正是全球公认的十大硬派越野SUV，&quot;</span> \<br>       <span class="hljs-string">&quot;越野迷们看完之后也不妨思考一下，到底哪款才是你的菜，下面话不多说，赶紧开始吧。&quot;</span><br><br><br><span class="hljs-comment"># 利用BERT进行tokenize</span><br>text = text[:maxlen]<br>x1, x2 = tokenizer.encode(first=text)<br><br>X1 = x1 + [<span class="hljs-number">0</span>] * (maxlen-<span class="hljs-built_in">len</span>(x1)) <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(x1) &lt; maxlen <span class="hljs-keyword">else</span> x1<br>X2 = x2 + [<span class="hljs-number">0</span>] * (maxlen-<span class="hljs-built_in">len</span>(x2)) <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(x2) &lt; maxlen <span class="hljs-keyword">else</span> x2<br><br><span class="hljs-comment"># 模型预测并输出预测结果</span><br>predicted = model.predict([[X1], [X2]])<br>y = np.argmax(predicted[<span class="hljs-number">0</span>])<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;原文: %s&quot;</span> % text)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;预测标签: %s&quot;</span> % label_dict[<span class="hljs-built_in">str</span>(y)])<br>e_time = time.time()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;cost time:&quot;</span>, e_time-s_time)<br></code></pre></td></tr></table></figure><p>我们在新的样本上进行模型预测。</p><ul><li>sougou数据集</li></ul><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">原文: 说到硬派越野SUV，你会想起哪些车型？是被称为“霸道”的丰田 普拉多 (配置 | 询价) ，还是被叫做“山猫”的帕杰罗，亦或者是“渣男专车”奔驰大G、“沙漠王子”途乐。总之，随着世界各国越来越重视对环境的保护，那些大排量的越野SUV在不久的将来也会渐渐消失在我们的视线之中，所以与其错过，不如趁着还年轻，在有生之年里赶紧去入手一台能让你心仪的硬派越野SUV。而今天我想要来跟你们聊的，正是全球公认的十大硬派越野SUV，越野迷们看完之后也不妨思考一下，到底哪款才是你的菜，下面话不多说，赶紧开始吧。</span><br><span class="hljs-section">预测标签: 汽车</span><br><br><span class="hljs-section">原文: 【#美30架战机在阿拉斯加海岸大象漫步#】据美国艾尔森空军基地网站消息称，近日美国空军30架战斗机和2架空中加油机自艾尔森空军基地起飞，在阿拉斯加海岸完成了”大象漫步“式的演习。</span><br><span class="hljs-section">预测标签: 军事</span><br><br><span class="hljs-section">原文: “十三五”期间，我国义务教育三科统编教材实现所有年级全覆盖；普通高中三科统编教材已覆盖20个省份，预计2022年前实现所有省份全覆盖，2025年实现所有年级全覆盖。昨日，在教育部新闻发布会上，教育部教材局局长田慧生透露，义务教育课程方案和各学科课程标准修订明年完成。</span><br><span class="hljs-section">预测标签: 教育</span><br></code></pre></td></tr></table></figure><ul><li>THUCNews数据集</li></ul><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">原文: 北京时间12月26日,2020-21赛季NBA圣诞大战如约上演。在一场焦点对决中，洛杉矶湖人在主场与达拉斯独行侠遭遇。全场打完，湖人138-115轻取独行侠，拿到赛季首胜，同时也送给对手2连败。</span><br><span class="hljs-section">预测标签: 体育</span><br><br><span class="hljs-section">原文: 近两年来，手机屏幕就开始不断升级，高刷新率也成为一种趋势，就算性能做的再好，手机屏幕不能流畅真实的展现出来，也会很大程度上影响使用感受，所以屏幕就是手机硬件的窗户，可以预见未来的高端手机在冲击性能的同时，必然会对提高对屏幕的要求。</span><br><span class="hljs-section">预测标签: 科技</span><br><br><span class="hljs-section">原文: 松江佘山板块已太久没有豪宅入市，令区域内不少高端置业客寂寞难耐。不过好在，不久前火爆登场的国贸佘山原墅一下子满足了这类客户的需求。  无论是社区规划、产品户型、装修配置，还是设计手法，相较于周边千万级别墅，国贸佘山原墅也是不逞多让，更令人惊喜的是别墅的品质却仅需公寓的价格！</span><br><span class="hljs-section">预测标签: 房产</span><br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本项目已经开源，Github地址为： <ahref="https://github.com/percent4/keras_bert_text_classification">https://github.com/percent4/keras_bert_text_classification</a>。</p><p>后续将会介绍如何使用keras-bert实现文本多标签分类任务。</p><p>2020年12月26日于上海浦东</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>keras-bert</tag>
      
      <tag>文本分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（三十四）使用keras-bert实现序列标注任务</title>
    <link href="/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/"/>
    <url>/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E5%9B%9B%EF%BC%89%E4%BD%BF%E7%94%A8keras-bert%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>对于不同的NLP任务，使用BERT等预训练模型进行微调无疑是使用它们的最佳方式。在网上已经有不少的项目，或者使用TensorFlow，或者使用Keras，或者使用PyTorch对BERT进行微调。本系列文章将致力于应用keras-bert对BERT进行微调，完成基础的NLP任务，比如文本多分类、文本多标签分类以及序列标注等。</p><p>keras-bert是Python的第三方模块，它方便我们使用Keras来调用BERT，借助几行代码就可以轻松地完成模型构建，能依据不同的文本任务进行模型训练，获得不错的效果。</p><p>本文将介绍如何keras-bert实现序列标注任务。</p><h3 id="项目结构">项目结构</h3><p>本项目结构如下：</p><figure><img src="/img/nlp34_1.png" alt="项目结构" /><figcaption aria-hidden="true">项目结构</figcaption></figure><p>所使用的Python第三方模块如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">keras_bert==0.83.0<br>Keras==2.2.4<br>seqeval==0.0.10<br>keras_contrib==2.0.8<br>matplotlib==3.3.1<br>numpy==1.16.4<br>Flask==1.1.2<br></code></pre></td></tr></table></figure><h3 id="代码分析">代码分析</h3><p>在util.py脚本中，我们设置了训练集和测试集的路径以及模型参数，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># 数据相关的配置</span><br>event_type = <span class="hljs-string">&quot;example&quot;</span><br><br>train_file_path = <span class="hljs-string">&quot;./data/%s.train&quot;</span> % event_type<br>test_file_path = <span class="hljs-string">&quot;./data/%s.test&quot;</span> % event_type<br><br><span class="hljs-comment"># 模型相关的配置</span><br>MAX_SEQ_LEN = <span class="hljs-number">128</span>   <span class="hljs-comment"># 输入的文本最大长度</span><br>BATCH_SIZE = <span class="hljs-number">32</span>     <span class="hljs-comment"># 模型训练的BATCH SIZE</span><br>EPOCH = <span class="hljs-number">10</span>          <span class="hljs-comment"># 模型训练的轮次</span><br></code></pre></td></tr></table></figure><p>数据集的格式为BIO标注序列，每个样本用空行隔开，每行为一个字符加标签，example数据集（<code>人民日报实体识别数据集</code>）格式示例如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">海 O<br>钓 O<br>比 O<br>赛 O<br>地 O<br>点 O<br>在 O<br>厦 B-LOC<br>门 I-LOC<br>与 O<br>金 B-LOC<br>门 I-LOC<br>之 O<br>间 O<br>的 O<br>海 O<br>域 O<br>。 O<br></code></pre></td></tr></table></figure><p>load_data.py为数据读取脚本，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> json<br><br><span class="hljs-keyword">from</span> util <span class="hljs-keyword">import</span> train_file_path, event_type<br><br><br><span class="hljs-comment"># 读取数据集</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_data</span>(<span class="hljs-params">file_path</span>):<br>    <span class="hljs-comment"># 读取数据集</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br>    <span class="hljs-comment"># 读取空行所在的行号</span><br>    index = [-<span class="hljs-number">1</span>]<br>    index.extend([i <span class="hljs-keyword">for</span> i, _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(content) <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27; &#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> _])<br>    index.append(<span class="hljs-built_in">len</span>(content))<br><br>    <span class="hljs-comment"># 按空行分割，读取原文句子及标注序列</span><br>    sentences, tags = [], []<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(index)-<span class="hljs-number">1</span>):<br>        sent, tag = [], []<br>        segment = content[index[j]+<span class="hljs-number">1</span>: index[j+<span class="hljs-number">1</span>]]<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> segment:<br>            sent.append(line.split()[<span class="hljs-number">0</span>])<br>            tag.append(line.split()[-<span class="hljs-number">1</span>])<br><br>        sentences.append(<span class="hljs-string">&#x27;&#x27;</span>.join(sent))<br>        tags.append(tag)<br><br>    <span class="hljs-comment"># 去除空的句子及标注序列，一般放在末尾</span><br>    sentences = [_ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> sentences <span class="hljs-keyword">if</span> _]<br>    tags = [_ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> tags <span class="hljs-keyword">if</span> _]<br><br>    <span class="hljs-keyword">return</span> sentences, tags<br><br><br><span class="hljs-comment"># 读取训练集数据</span><br><span class="hljs-comment"># 将标签转换成id</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">label2id</span>():<br><br>    _, train_tags = read_data(train_file_path)<br><br>    <span class="hljs-comment"># 标签转换成id，并保存成文件</span><br>    unique_tags = []<br>    <span class="hljs-keyword">for</span> seq <span class="hljs-keyword">in</span> train_tags:<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> seq:<br>            <span class="hljs-keyword">if</span> _ <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> unique_tags <span class="hljs-keyword">and</span> _ != <span class="hljs-string">&quot;O&quot;</span>:<br>                unique_tags.append(_)<br><br>    label_id_dict = &#123;<span class="hljs-string">&quot;O&quot;</span>: <span class="hljs-number">0</span>&#125;<br>    label_id_dict.update(<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(unique_tags, <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(unique_tags)+<span class="hljs-number">1</span>))))<br><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;%s_label2id.json&quot;</span> % event_type, <span class="hljs-string">&quot;w&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> g:<br>        g.write(json.dumps(label_id_dict, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">2</span>))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    label2id()<br><br></code></pre></td></tr></table></figure><p>以example.train为例，运行上述脚本，会生成标签文件example_label2id.json，如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;O&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;B-LOC&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;I-LOC&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;B-PER&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;I-PER&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;B-ORG&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">5</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;I-ORG&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">6</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>model.py为模型结构脚本，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> load_trained_model_from_checkpoint<br><span class="hljs-keyword">from</span> keras_contrib.layers <span class="hljs-keyword">import</span> CRF<br><span class="hljs-keyword">from</span> keras_contrib.losses <span class="hljs-keyword">import</span> crf_loss<br><span class="hljs-keyword">from</span> keras_contrib.metrics <span class="hljs-keyword">import</span> crf_accuracy<br><br><span class="hljs-keyword">from</span> util <span class="hljs-keyword">import</span> event_type<br><br><br><span class="hljs-comment"># 创建BERT-BiLSTM-CRF模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BertBilstmCRF</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, max_seq_length, lstm_dim</span>):<br>        self.max_seq_length = max_seq_length<br>        self.lstmDim = lstm_dim<br>        self.label = self.load_label()<br><br>    <span class="hljs-comment"># 抽取的标签</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">load_label</span>(<span class="hljs-params">self</span>):<br>        label_path = <span class="hljs-string">&quot;./&#123;&#125;_label2id.json&quot;</span>.<span class="hljs-built_in">format</span>(event_type)<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(label_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f_label:<br>            label = json.loads(f_label.read())<br><br>        <span class="hljs-keyword">return</span> label<br><br>    <span class="hljs-comment"># 模型</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">create_model</span>(<span class="hljs-params">self</span>):<br>        model_path = <span class="hljs-string">&quot;./chinese_L-12_H-768_A-12/&quot;</span><br>        bert = load_trained_model_from_checkpoint(<br>            model_path + <span class="hljs-string">&quot;bert_config.json&quot;</span>,<br>            model_path + <span class="hljs-string">&quot;bert_model.ckpt&quot;</span>,<br>            seq_len=self.max_seq_length<br>        )<br>        <span class="hljs-comment"># make bert layer trainable</span><br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> bert.layers:<br>            layer.trainable = <span class="hljs-literal">True</span><br>        x1 = Input(shape=(<span class="hljs-literal">None</span>,))<br>        x2 = Input(shape=(<span class="hljs-literal">None</span>,))<br>        bert_out = bert([x1, x2])<br>        lstm_out = Bidirectional(LSTM(self.lstmDim,<br>                                      return_sequences=<span class="hljs-literal">True</span>,<br>                                      dropout=<span class="hljs-number">0.2</span>,<br>                                      recurrent_dropout=<span class="hljs-number">0.2</span>))(bert_out)<br>        crf_out = CRF(<span class="hljs-built_in">len</span>(self.label), sparse_target=<span class="hljs-literal">True</span>)(lstm_out)<br>        model = Model([x1, x2], crf_out)<br>        model.summary()<br>        model.<span class="hljs-built_in">compile</span>(<br>            optimizer=Adam(<span class="hljs-number">1e-4</span>),<br>            loss=crf_loss,<br>            metrics=[crf_accuracy]<br>        )<br>        <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></table></figure><p>模型为<code>BERT+BiLSTM+CRF</code>，其中对BERT进行<code>微调</code>，模型结构（以example数据集为例）如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>__<br><span class="hljs-section">Layer (type)                    Output Shape         Param #     Connected to                     </span><br><span class="hljs-section">==================================================================================================</span><br>input<span class="hljs-emphasis">_3 (InputLayer)            (None, None)         0                                            </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span>_<br>input<span class="hljs-emphasis">_4 (InputLayer)            (None, None)         0                                            </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span>_<br>model<span class="hljs-emphasis">_5 (Model)                 multiple             101382144   input_</span>3[<span class="hljs-string">0</span>][<span class="hljs-symbol">0</span>]                    <br><span class="hljs-code">                                                                 input_4[0][0]                    </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">bidirectional_2 (Bidirectional) (None, None, 200)    695200      model_5[1][0]                    </span><br><span class="hljs-code">__________________________________________________________________________________________________</span><br><span class="hljs-code">crf_2 (CRF)                     (None, None, 7)      1470        bidirectional_2[0][0]            </span><br><span class="hljs-code">==================================================================================================</span><br><span class="hljs-code">Total params: 102,078,814</span><br><span class="hljs-code">Trainable params: 102,078,814</span><br><span class="hljs-code">Non-trainable params: 0</span><br></code></pre></td></tr></table></figure><h3 id="数据集介绍">数据集介绍</h3><p>本文将会对三个实体识别的数据集进行测试，以下是三个数据集的简单介绍。</p><ol type="1"><li>人民日报命名实体识别数据集（example.train 28046条数据和example.test4636条数据），共3种标签：地点（LOC）, 人名（PER）, 组织机构（ORG）</li><li>时间识别数据集（time.train 1700条数据和time.test300条数据），共1种标签：TIME</li><li>CLUENER细粒度实体识别数据集（cluener.train 10748条数据和cluener.test1343条数据），共10种标签：地址（address），书名（book），公司（company），游戏（game），政府（goverment），电影（movie），姓名（name），组织机构（organization），职位（position），景点（scene）</li></ol><h3 id="模型训练">模型训练</h3><p>模型训练的脚本model_train.py的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> keras.preprocessing.sequence <span class="hljs-keyword">import</span> pad_sequences<br><span class="hljs-keyword">from</span> keras.callbacks <span class="hljs-keyword">import</span> EarlyStopping<br><span class="hljs-keyword">from</span> keras.callbacks <span class="hljs-keyword">import</span> ReduceLROnPlateau<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> Tokenizer<br><br><span class="hljs-keyword">from</span> util <span class="hljs-keyword">import</span> event_type<br><span class="hljs-keyword">from</span> util <span class="hljs-keyword">import</span> MAX_SEQ_LEN, BATCH_SIZE, EPOCH, train_file_path, test_file_path<br><span class="hljs-keyword">from</span> load_data <span class="hljs-keyword">import</span> read_data<br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> BertBilstmCRF<br><br><br><span class="hljs-comment"># 读取label2id字典</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;&#123;&#125;_label2id.json&quot;</span>.<span class="hljs-built_in">format</span>(event_type), <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> h:<br>    label_id_dict = json.loads(h.read())<br><br>id_label_dict = &#123;v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> label_id_dict.items()&#125;<br><br><br><span class="hljs-comment"># 载入数据</span><br>config_path = <span class="hljs-string">&#x27;./chinese_L-12_H-768_A-12/bert_config.json&#x27;</span><br>checkpoint_path = <span class="hljs-string">&#x27;./chinese_L-12_H-768_A-12/bert_model.ckpt&#x27;</span><br>dict_path = <span class="hljs-string">&#x27;./chinese_L-12_H-768_A-12/vocab.txt&#x27;</span><br><br><br>token_dict = &#123;&#125;<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(dict_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> reader:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> reader:<br>        token = line.strip()<br>        token_dict[token] = <span class="hljs-built_in">len</span>(token_dict)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">OurTokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_tokenize</span>(<span class="hljs-params">self, text</span>):<br>        R = []<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> text:<br>            <span class="hljs-keyword">if</span> c <span class="hljs-keyword">in</span> self._token_dict:<br>                R.append(c)<br>            <span class="hljs-keyword">else</span>:<br>                R.append(<span class="hljs-string">&#x27;[UNK]&#x27;</span>)   <span class="hljs-comment"># 剩余的字符是[UNK]</span><br>        <span class="hljs-keyword">return</span> R<br><br><br>tokenizer = OurTokenizer(token_dict)<br><br><br><span class="hljs-comment"># 预处理输入数据</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">PreProcessInputData</span>(<span class="hljs-params">text</span>):<br>    word_labels = []<br>    seq_types = []<br>    <span class="hljs-keyword">for</span> sequence <span class="hljs-keyword">in</span> text:<br>        code = tokenizer.encode(first=sequence, max_len=MAX_SEQ_LEN)<br>        word_labels.append(code[<span class="hljs-number">0</span>])<br>        seq_types.append(code[<span class="hljs-number">1</span>])<br>    <span class="hljs-keyword">return</span> word_labels, seq_types<br><br><br><span class="hljs-comment"># 预处理结果数据</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">PreProcessOutputData</span>(<span class="hljs-params">text</span>):<br>    tags = []<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> text:<br>        tag = [<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> line:<br>            tag.append(<span class="hljs-built_in">int</span>(label_id_dict[item.strip()]))<br>        tag.append(<span class="hljs-number">0</span>)<br>        tags.append(tag)<br><br>    pad_tags = pad_sequences(tags, maxlen=MAX_SEQ_LEN, padding=<span class="hljs-string">&quot;post&quot;</span>, truncating=<span class="hljs-string">&quot;post&quot;</span>)<br>    result_tags = np.expand_dims(pad_tags, <span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> result_tags<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># 读取训练集和测试集数据</span><br>    input_train, result_train = read_data(train_file_path)<br>    input_test, result_test = read_data(test_file_path)<br>    <span class="hljs-keyword">for</span> sent, tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(input_train[:<span class="hljs-number">10</span>], result_train[:<span class="hljs-number">10</span>]):<br>        <span class="hljs-built_in">print</span>(sent, tag)<br>    <span class="hljs-keyword">for</span> sent, tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(input_test[:<span class="hljs-number">10</span>], result_test[:<span class="hljs-number">10</span>]):<br>        <span class="hljs-built_in">print</span>(sent, tag)<br><br>    <span class="hljs-comment"># 训练集</span><br>    input_train_labels, input_train_types = PreProcessInputData(input_train)<br>    result_train = PreProcessOutputData(result_train)<br>    <span class="hljs-comment"># 测试集</span><br>    input_test_labels, input_test_types = PreProcessInputData(input_test)<br>    result_test = PreProcessOutputData(result_test)<br>    early_stopping = EarlyStopping(monitor=<span class="hljs-string">&#x27;val_loss&#x27;</span>, min_delta=<span class="hljs-number">0.0001</span>, patience=<span class="hljs-number">3</span>, verbose=<span class="hljs-number">1</span>, mode=<span class="hljs-string">&#x27;auto&#x27;</span>)<br>    reduce_lr = ReduceLROnPlateau(monitor=<span class="hljs-string">&#x27;val_loss&#x27;</span>, min_delta=<span class="hljs-number">0.0004</span>, patience=<span class="hljs-number">2</span>, factor=<span class="hljs-number">0.1</span>, min_lr=<span class="hljs-number">1e-6</span>,<br>                                  mode=<span class="hljs-string">&#x27;auto&#x27;</span>,<br>                                  verbose=<span class="hljs-number">1</span>)<br>    model = BertBilstmCRF(max_seq_length=MAX_SEQ_LEN, lstm_dim=<span class="hljs-number">64</span>).create_model()<br>    history = model.fit(x=[input_train_labels, input_train_types],<br>                        y=result_train,<br>                        batch_size=BATCH_SIZE,<br>                        epochs=EPOCH,<br>                        validation_data=[[input_test_labels, input_test_types], result_test],<br>                        verbose=<span class="hljs-number">1</span>,<br>                        callbacks=[early_stopping, reduce_lr],<br>                        shuffle=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># 保存模型</span><br>    model.save(<span class="hljs-string">&quot;&#123;&#125;_ner.h5&quot;</span>.<span class="hljs-built_in">format</span>(event_type))<br><br>    <span class="hljs-comment"># 绘制loss和acc图像</span><br>    plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    epochs = <span class="hljs-built_in">len</span>(history.history[<span class="hljs-string">&#x27;loss&#x27;</span>])<br>    plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;loss&#x27;</span>], label=<span class="hljs-string">&#x27;loss&#x27;</span>)<br>    plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;val_loss&#x27;</span>], label=<span class="hljs-string">&#x27;val_loss&#x27;</span>)<br>    plt.legend()<br><br>    plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>    epochs = <span class="hljs-built_in">len</span>(history.history[<span class="hljs-string">&#x27;crf_accuracy&#x27;</span>])<br>    plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;crf_accuracy&#x27;</span>], label=<span class="hljs-string">&#x27;crf_accuracy&#x27;</span>)<br>    plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;val_crf_accuracy&#x27;</span>], label=<span class="hljs-string">&#x27;val_crf_accuracy&#x27;</span>)<br>    plt.legend()<br>    plt.savefig(<span class="hljs-string">&quot;%s_loss_acc.png&quot;</span> % event_type)<br></code></pre></td></tr></table></figure><p>模型使用的预训练模型为BERT中文预训练文件：chinese_L-12_H-768_A-12。</p><p>分别对上述三个数据集进行模型训练，结果汇总如下：</p><h4 id="人民日报命名实体识别数据集">人民日报命名实体识别数据集</h4><p>模型参数：MAX_SEQ_LEN=128, BATCH_SIZE=32, EPOCH=10</p><figure><img src="/img/nlp34_2.png" alt="loss和acc图" /><figcaption aria-hidden="true">loss和acc图</figcaption></figure><h4 id="时间识别数据集">时间识别数据集</h4><p>模型参数：MAX_SEQ_LEN=256, BATCH_SIZE=8, EPOCH=10</p><figure><img src="/img/nlp34_3.png" alt="loss和acc图" /><figcaption aria-hidden="true">loss和acc图</figcaption></figure><h4 id="cluener细粒度实体识别数据集">CLUENER细粒度实体识别数据集</h4><p>模型参数：MAX_SEQ_LEN=128, BATCH_SIZE=32, EPOCH=10</p><figure><img src="/img/nlp34_4.png" alt="loss和acc图" /><figcaption aria-hidden="true">loss和acc图</figcaption></figure><h3 id="模型评估">模型评估</h3><p>模型评估脚本model_evaluate.py脚本的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># 利用seqeval模块对序列标注的结果进行评估</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> get_custom_objects<br><span class="hljs-keyword">from</span> keras_contrib.layers <span class="hljs-keyword">import</span> CRF<br><span class="hljs-keyword">from</span> keras_contrib.losses <span class="hljs-keyword">import</span> crf_loss<br><span class="hljs-keyword">from</span> keras_contrib.metrics <span class="hljs-keyword">import</span> crf_accuracy<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> classification_report<br><br><span class="hljs-keyword">from</span> load_data <span class="hljs-keyword">import</span> read_data<br><span class="hljs-keyword">from</span> util <span class="hljs-keyword">import</span> event_type, test_file_path<br><span class="hljs-keyword">from</span> model_train <span class="hljs-keyword">import</span> PreProcessInputData, id_label_dict<br><br>custom_objects = get_custom_objects()<br><span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> &#123;<span class="hljs-string">&#x27;CRF&#x27;</span>: CRF, <span class="hljs-string">&#x27;crf_loss&#x27;</span>: crf_loss, <span class="hljs-string">&#x27;crf_accuracy&#x27;</span>: crf_accuracy&#125;.items():<br>    custom_objects[key] = value<br>model = load_model(<span class="hljs-string">&quot;%s_ner.h5&quot;</span> % event_type, custom_objects=custom_objects)<br><br><br><span class="hljs-comment"># 对单句话进行预测</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_single_sentence</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-comment"># 测试句子</span><br>    word_labels, seq_types = PreProcessInputData([text])<br>    <span class="hljs-comment"># 模型预测</span><br>    predicted = model.predict([word_labels, seq_types])<br>    y = np.argmax(predicted[<span class="hljs-number">0</span>], axis=<span class="hljs-number">1</span>)<br>    predict_tag = [id_label_dict[_] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> y]<br>    <span class="hljs-keyword">return</span> predict_tag[<span class="hljs-number">1</span>:-<span class="hljs-number">1</span>]<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># 读取测试集数据</span><br>    input_test, result_test = read_data(test_file_path)<br>    <span class="hljs-keyword">for</span> sent, tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(input_test[:<span class="hljs-number">10</span>], result_test[:<span class="hljs-number">10</span>]):<br>        <span class="hljs-built_in">print</span>(sent, tag)<br><br>    <span class="hljs-comment"># 测试集</span><br>    i = <span class="hljs-number">1</span><br>    true_tag_list = []<br>    pred_tag_list = []<br>    <span class="hljs-keyword">for</span> test_text, true_tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(input_test, result_test):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Predict %d samples&quot;</span> % i)<br>        pred_tag = predict_single_sentence(text=test_text)<br>        true_tag_list.append(true_tag)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(true_tag) &lt;= <span class="hljs-built_in">len</span>(pred_tag):<br>            pred_tag_list.append(pred_tag[:<span class="hljs-built_in">len</span>(true_tag)])<br>        <span class="hljs-keyword">else</span>:<br>            pred_tag_list.append(pred_tag+[<span class="hljs-string">&quot;O&quot;</span>]*(<span class="hljs-built_in">len</span>(true_tag)-<span class="hljs-built_in">len</span>(pred_tag)))<br>        i += <span class="hljs-number">1</span><br><br>    <span class="hljs-built_in">print</span>(classification_report(true_tag_list, pred_tag_list, digits=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><p>分别对上述三个数据集进行模型评估（模型参数同上），结果汇总如下：</p><ul><li>人民日报命名实体识别数据集</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache">             <span class="hljs-attribute">precision</span>  recall    f1-score   support<br>      <span class="hljs-attribute">LOC</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9330</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8986</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9155</span>      <span class="hljs-number">3658</span><br>      <span class="hljs-attribute">ORG</span>     <span class="hljs-number">0</span>.<span class="hljs-number">8881</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8902</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8891</span>      <span class="hljs-number">2185</span><br>      <span class="hljs-attribute">PER</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9692</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9469</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9579</span>      <span class="hljs-number">1864</span><br><br><span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9287</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9079</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9182</span>      <span class="hljs-number">7707</span><br><span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9291</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9079</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9183</span>      <span class="hljs-number">7707</span><br></code></pre></td></tr></table></figure><ul><li>时间识别数据集</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache">            <span class="hljs-attribute">precision</span>   recall  f1-score   support<br>     <span class="hljs-attribute">TIME</span>     <span class="hljs-number">0</span>.<span class="hljs-number">8428</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8753</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8587</span>       <span class="hljs-number">441</span><br><br><span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">8428</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8753</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8587</span>       <span class="hljs-number">441</span><br><span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">8428</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8753</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8587</span>       <span class="hljs-number">441</span><br></code></pre></td></tr></table></figure><ul><li>CLUENER细粒度实体识别数据集</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs apache">                <span class="hljs-attribute">precision</span>  recall    f1-score   support<br>        <span class="hljs-attribute">name</span>     <span class="hljs-number">0</span>.<span class="hljs-number">8476</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8758</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8615</span>       <span class="hljs-number">451</span><br>       <span class="hljs-attribute">scene</span>     <span class="hljs-number">0</span>.<span class="hljs-number">6569</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6734</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6650</span>       <span class="hljs-number">199</span><br>    <span class="hljs-attribute">position</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7455</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7788</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7618</span>       <span class="hljs-number">425</span><br><span class="hljs-attribute">organization</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7377</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7849</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7606</span>       <span class="hljs-number">344</span><br>        <span class="hljs-attribute">game</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7423</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8432</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7896</span>       <span class="hljs-number">287</span><br>     <span class="hljs-attribute">address</span>     <span class="hljs-number">0</span>.<span class="hljs-number">6070</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6236</span>    <span class="hljs-number">0</span>.<span class="hljs-number">6152</span>       <span class="hljs-number">364</span><br>     <span class="hljs-attribute">company</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7264</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7978</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7604</span>       <span class="hljs-number">366</span><br>       <span class="hljs-attribute">movie</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7687</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7533</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7609</span>       <span class="hljs-number">150</span><br>  <span class="hljs-attribute">government</span>     <span class="hljs-number">0</span>.<span class="hljs-number">7860</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8279</span>    <span class="hljs-number">0</span>.<span class="hljs-number">8064</span>       <span class="hljs-number">244</span><br>        <span class="hljs-attribute">book</span>     <span class="hljs-number">0</span>.<span class="hljs-number">8041</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7829</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7933</span>       <span class="hljs-number">152</span><br><br>   <span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">7419</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7797</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7603</span>      <span class="hljs-number">2982</span><br>   <span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">7420</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7797</span>    <span class="hljs-number">0</span>.<span class="hljs-number">7601</span>      <span class="hljs-number">2982</span><br></code></pre></td></tr></table></figure><p>可以看到，<code>BERT+BiLSTM+CRF（对BERT进行微调）</code>的模型效果是相当不错的，在某种程序上是可以作为baseline的。</p><h3 id="模型预测">模型预测</h3><p>模型预测脚本model_predict.py的脚本代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> keras_bert <span class="hljs-keyword">import</span> get_custom_objects<br><span class="hljs-keyword">from</span> keras_contrib.layers <span class="hljs-keyword">import</span> CRF<br><span class="hljs-keyword">from</span> keras_contrib.losses <span class="hljs-keyword">import</span> crf_loss<br><span class="hljs-keyword">from</span> keras_contrib.metrics <span class="hljs-keyword">import</span> crf_accuracy<br><br><span class="hljs-keyword">from</span> util <span class="hljs-keyword">import</span> event_type<br><span class="hljs-keyword">from</span> model_train <span class="hljs-keyword">import</span> PreProcessInputData, id_label_dict<br><br><br><span class="hljs-comment"># 将BIO标签转化为方便阅读的json格式</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">bio_to_json</span>(<span class="hljs-params">string, tags</span>):<br>    item = &#123;<span class="hljs-string">&quot;string&quot;</span>: string, <span class="hljs-string">&quot;entities&quot;</span>: []&#125;<br>    entity_name = <span class="hljs-string">&quot;&quot;</span><br>    entity_start = <span class="hljs-number">0</span><br>    iCount = <span class="hljs-number">0</span><br>    entity_tag = <span class="hljs-string">&quot;&quot;</span><br><br>    <span class="hljs-keyword">for</span> c_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">min</span>(<span class="hljs-built_in">len</span>(string), <span class="hljs-built_in">len</span>(tags))):<br>        c, tag = string[c_idx], tags[c_idx]<br>        <span class="hljs-keyword">if</span> c_idx &lt; <span class="hljs-built_in">len</span>(tags)-<span class="hljs-number">1</span>:<br>            tag_next = tags[c_idx+<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">else</span>:<br>            tag_next = <span class="hljs-string">&#x27;&#x27;</span><br><br>        <span class="hljs-keyword">if</span> tag[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;B&#x27;</span>:<br>            entity_tag = tag[<span class="hljs-number">2</span>:]<br>            entity_name = c<br>            entity_start = iCount<br>            <span class="hljs-keyword">if</span> tag_next[<span class="hljs-number">2</span>:] != entity_tag:<br>                item[<span class="hljs-string">&quot;entities&quot;</span>].append(&#123;<span class="hljs-string">&quot;word&quot;</span>: c, <span class="hljs-string">&quot;start&quot;</span>: iCount, <span class="hljs-string">&quot;end&quot;</span>: iCount + <span class="hljs-number">1</span>, <span class="hljs-string">&quot;type&quot;</span>: tag[<span class="hljs-number">2</span>:]&#125;)<br>        <span class="hljs-keyword">elif</span> tag[<span class="hljs-number">0</span>] == <span class="hljs-string">&quot;I&quot;</span>:<br>            <span class="hljs-keyword">if</span> tag[<span class="hljs-number">2</span>:] != tags[c_idx-<span class="hljs-number">1</span>][<span class="hljs-number">2</span>:] <span class="hljs-keyword">or</span> tags[c_idx-<span class="hljs-number">1</span>][<span class="hljs-number">2</span>:] == <span class="hljs-string">&#x27;O&#x27;</span>:<br>                tags[c_idx] = <span class="hljs-string">&#x27;O&#x27;</span><br>                <span class="hljs-keyword">pass</span><br>            <span class="hljs-keyword">else</span>:<br>                entity_name = entity_name + c<br>                <span class="hljs-keyword">if</span> tag_next[<span class="hljs-number">2</span>:] != entity_tag:<br>                    item[<span class="hljs-string">&quot;entities&quot;</span>].append(&#123;<span class="hljs-string">&quot;word&quot;</span>: entity_name, <span class="hljs-string">&quot;start&quot;</span>: entity_start, <span class="hljs-string">&quot;end&quot;</span>: iCount + <span class="hljs-number">1</span>, <span class="hljs-string">&quot;type&quot;</span>: entity_tag&#125;)<br>                    entity_name = <span class="hljs-string">&#x27;&#x27;</span><br>        iCount += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> item<br><br><br><span class="hljs-comment"># 加载训练好的模型</span><br>custom_objects = get_custom_objects()<br><span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> &#123;<span class="hljs-string">&#x27;CRF&#x27;</span>: CRF, <span class="hljs-string">&#x27;crf_loss&#x27;</span>: crf_loss, <span class="hljs-string">&#x27;crf_accuracy&#x27;</span>: crf_accuracy&#125;.items():<br>    custom_objects[key] = value<br>model = load_model(<span class="hljs-string">&quot;%s_ner.h5&quot;</span> % event_type, custom_objects=custom_objects)<br><br><span class="hljs-comment"># 测试句子</span><br>text = <span class="hljs-string">&quot;经过工作人员两天的反复验证、严密测算，记者昨天从上海中心大厦得到确认：被誉为上海中心大厦“定楼神器”的阻尼器，在8月10日出现自2016年正式启用以来的最大摆幅。&quot;</span><br>word_labels, seq_types = PreProcessInputData([text])<br><br><span class="hljs-comment"># 模型预测</span><br>predicted = model.predict([word_labels, seq_types])<br>y = np.argmax(predicted[<span class="hljs-number">0</span>], axis=<span class="hljs-number">1</span>)<br>tag = [id_label_dict[_] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> y]<br><br><span class="hljs-comment"># 输出预测结果</span><br>result = bio_to_json(text, tag[<span class="hljs-number">1</span>:-<span class="hljs-number">1</span>])<br>pprint(result)<br></code></pre></td></tr></table></figure><p>在新样本上进行预测，输出的效果也很不错，示例预测结果如下：</p><ul><li>人民日报命名实体识别数据集</li></ul><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs 1c">&#123;&#x27;entities&#x27;: [&#123;&#x27;end&#x27;: <span class="hljs-number">17</span>, &#x27;start&#x27;: <span class="hljs-number">16</span>, &#x27;type&#x27;: &#x27;LOC&#x27;, &#x27;word&#x27;: &#x27;欧&#x27;&#125;,<br>              &#123;&#x27;end&#x27;: <span class="hljs-number">50</span>, &#x27;start&#x27;: <span class="hljs-number">48</span>, &#x27;type&#x27;: &#x27;LOC&#x27;, &#x27;word&#x27;: &#x27;英国&#x27;&#125;,<br>              &#123;&#x27;end&#x27;: <span class="hljs-number">63</span>, &#x27;start&#x27;: <span class="hljs-number">62</span>, &#x27;type&#x27;: &#x27;LOC&#x27;, &#x27;word&#x27;: &#x27;欧&#x27;&#125;,<br>              &#123;&#x27;end&#x27;: <span class="hljs-number">72</span>, &#x27;start&#x27;: <span class="hljs-number">69</span>, &#x27;type&#x27;: &#x27;PER&#x27;, &#x27;word&#x27;: &#x27;卡梅伦&#x27;&#125;,<br>              &#123;&#x27;end&#x27;: <span class="hljs-number">78</span>, &#x27;start&#x27;: <span class="hljs-number">73</span>, &#x27;type&#x27;: &#x27;PER&#x27;, &#x27;word&#x27;: &#x27;特雷莎·梅&#x27;&#125;,<br>              &#123;&#x27;end&#x27;: <span class="hljs-number">86</span>, &#x27;start&#x27;: <span class="hljs-number">85</span>, &#x27;type&#x27;: &#x27;LOC&#x27;, &#x27;word&#x27;: &#x27;欧&#x27;&#125;,<br>              &#123;&#x27;end&#x27;: <span class="hljs-number">102</span>, &#x27;start&#x27;: <span class="hljs-number">95</span>, &#x27;type&#x27;: &#x27;PER&#x27;, &#x27;word&#x27;: &#x27;鲍里斯·约翰逊&#x27;&#125;],<br> &#x27;string&#x27;: &#x27;当<span class="hljs-number">2016</span>年6月24日凌晨，“脱欧”公投的最后一张选票计算完毕，占投票总数52%的支持选票最终让英国开始了一段长达4年的“脱欧”进程，其间卡梅伦、特雷莎·梅相继离任，“脱欧”最终在第三位首相鲍里斯·约翰逊任内完成。&#x27;&#125;<br></code></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<span class="hljs-string">&#x27;entities&#x27;</span>: [&#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;ORG&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;台湾“立法院&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">30</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">29</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;台&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">38</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">35</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;PER&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;蔡英文&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">66</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">64</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;台湾&#x27;</span>&#125;],<br> <span class="hljs-string">&#x27;string&#x27;</span>: <span class="hljs-string">&#x27;台湾“立法院”“莱猪（含莱克多巴胺的猪肉）”表决大战落幕，台当局领导人蔡英文24日晚在脸书发文宣称，“开放市场的决定，将会是未来台湾国际经贸走向世界的关键决定”。&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<span class="hljs-string">&#x27;entities&#x27;</span>: [&#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;印度&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">14</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">12</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;南海&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">27</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">25</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;印度&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">30</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">28</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;越南&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">45</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">43</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;印度&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">49</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">47</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;PER&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;莫迪&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">53</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">51</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;南海&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">90</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">88</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;南海&#x27;</span>&#125;],<br> <span class="hljs-string">&#x27;string&#x27;</span>: <span class="hljs-string">&#x27;最近一段时间，印度政府在南海问题上接连发声。在近期印度、越南两国举行的线上总理峰会上，印度总理莫迪声称南海行为准则“不应损害该地区其他国家或第三方的利益”，两国总理还强调了所谓南海“航行自由”的重要性。&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><ul><li>时间识别数据集</li></ul><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<span class="hljs-string">&#x27;entities&#x27;</span>: [&#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">8</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;TIME&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;去年11月30日&#x27;</span>&#125;],<br> <span class="hljs-string">&#x27;string&#x27;</span>: <span class="hljs-string">&#x27;去年11月30日，李先生来到茶店子东街一家银行取钱，准备购买家具。输入密码后，&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<span class="hljs-string">&#x27;entities&#x27;</span>: [&#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">19</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">10</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;TIME&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;上世纪80年代之前&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">24</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">20</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;TIME&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;去年9月&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">47</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">45</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;TIME&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;3年&#x27;</span>&#125;],<br> <span class="hljs-string">&#x27;string&#x27;</span>: <span class="hljs-string">&#x27;苏北大量农村住房建于上世纪80年代之前。去年9月，江苏省决定全面改善苏北农民住房条件，计划3年内改善30万户，作为决胜全面建成小康社会补短板的重要举措。&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs 1c">&#123;&#x27;entities&#x27;: [&#123;&#x27;end&#x27;: <span class="hljs-number">8</span>, &#x27;start&#x27;: <span class="hljs-number">6</span>, &#x27;type&#x27;: &#x27;TIME&#x27;, &#x27;word&#x27;: &#x27;两天&#x27;&#125;,<br>              &#123;&#x27;end&#x27;: <span class="hljs-number">23</span>, &#x27;start&#x27;: <span class="hljs-number">21</span>, &#x27;type&#x27;: &#x27;TIME&#x27;, &#x27;word&#x27;: &#x27;昨天&#x27;&#125;,<br>              &#123;&#x27;end&#x27;: <span class="hljs-number">61</span>, &#x27;start&#x27;: <span class="hljs-number">56</span>, &#x27;type&#x27;: &#x27;TIME&#x27;, &#x27;word&#x27;: &#x27;8月10日&#x27;&#125;,<br>              &#123;&#x27;end&#x27;: <span class="hljs-number">69</span>, &#x27;start&#x27;: <span class="hljs-number">64</span>, &#x27;type&#x27;: &#x27;TIME&#x27;, &#x27;word&#x27;: &#x27;<span class="hljs-number">2016</span>年&#x27;&#125;],<br> &#x27;string&#x27;: &#x27;经过工作人员两天的反复验证、严密测算，记者昨天从上海中心大厦得到确认：被誉为上海中心大厦“定楼神器”的阻尼器，在8月10日出现自<span class="hljs-number">2016</span>年正式启用以来的最大摆幅。&#x27;&#125;<br></code></pre></td></tr></table></figure><ul><li>CLUENER细粒度实体识别数据集</li></ul><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<span class="hljs-string">&#x27;entities&#x27;</span>: [&#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;organization&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;四川敦煌学&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">13</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">11</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;scene&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;丹棱&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">44</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">41</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;name&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;胡文和&#x27;</span>&#125;],<br> <span class="hljs-string">&#x27;string&#x27;</span>: <span class="hljs-string">&#x27;四川敦煌学”。近年来，丹棱县等地一些不知名的石窟迎来了海内外的游客，他们随身携带着胡文和的著作。&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<span class="hljs-string">&#x27;entities&#x27;</span>: [&#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">19</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">14</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;address&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;茶店子东街&#x27;</span>&#125;],<br> <span class="hljs-string">&#x27;string&#x27;</span>: <span class="hljs-string">&#x27;去年11月30日，李先生来到茶店子东街一家银行取钱，准备购买家具。输入密码后，&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<span class="hljs-string">&#x27;entities&#x27;</span>: [&#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;name&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;罗伯茨&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">10</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;movie&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;《逃跑新娘》&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">23</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">16</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;movie&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;《理发师佐翰》&#x27;</span>&#125;,<br>              &#123;<span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">38</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">32</span>, <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;name&#x27;</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;亚当·桑德勒&#x27;</span>&#125;],<br> <span class="hljs-string">&#x27;string&#x27;</span>: <span class="hljs-string">&#x27;罗伯茨的《逃跑新娘》不相伯仲；而《理发师佐翰》让近年来顺风顺水的亚当·桑德勒首尝冲过1亿＄&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本项目已经开源，Github地址为：<ahref="https://github.com/percent4/keras_bert_sequence_labeling">https://github.com/percent4/keras_bert_sequence_labeling</a>。</p><p>后续将会继续介绍如何使用keras-bert实现文本多分类和文本多标签分类，欢迎大家关注~</p><p>最后，还想感谢一下所有致力于开源项目的同仁们，感谢你们的努力，感谢你们的付出，感谢你们的铺路。</p><p>2020年12月26日于上海浦东</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>keras-bert</tag>
      
      <tag>序列标注</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（三十三）利用CRF实现中文分词</title>
    <link href="/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%B8%89%EF%BC%89%E5%88%A9%E7%94%A8CRF%E5%AE%9E%E7%8E%B0%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/"/>
    <url>/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%B8%89%EF%BC%89%E5%88%A9%E7%94%A8CRF%E5%AE%9E%E7%8E%B0%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会讲述如何利用CRF模型来实现中文分词。</p><p>所谓中文分词，就是将连续的中文汉字序列按照一定的规范重新组合成词序列的过程。关于CRF模型的介绍以及CRF实现工具CRF++的使用方法，读者可以参考文章<ahref="https://percent4.github.io/2023/07/08/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8CRF-%E5%AE%9E%E7%8E%B0%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB-NER/">NLP入门（八）使用CRF++实现命名实体识别(NER)</a>。</p><p>以下将详细讲述如何使用CRF++来实现中文分词。</p><h3 id="语料选择">语料选择</h3><p>中分分词的语料，这里选择人民日报分词语料和微软中文分词语料，语料的下载方式可以参看文章最后给出的Github地址。</p><p>我们将语料加工成CRF++支持的格式，以句子<code>迈向充满希望的新世纪——一九九八年新年讲话（附图片１张）</code>为例，我们加工后的结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs bash">迈nB-Char<br>向nI-Char<br>充nB-Char<br>满nI-Char<br>希nB-Char<br>望nI-Char<br>的nB-Char<br>新nB-Char<br>世nB-Char<br>纪nI-Char<br>—nB-Char<br>—nI-Char<br>一nB-Char<br>九nI-Char<br>九nI-Char<br>八nI-Char<br>年nI-Char<br>新nB-Char<br>年nI-Char<br>讲nB-Char<br>话nI-Char<br>（nB-Char<br>附nB-Char<br>图nB-Char<br>片nI-Char<br>１nB-Char<br>张nB-Char<br>）nB-Char<br></code></pre></td></tr></table></figure><p>这里需要稍作说明，即我们的标签体系采用最简单的<code>BI</code>体系，将词语的开头用<code>B-Char</code>标签表示，词语的中间和结尾用<code>I-Char</code>表示。</p><p>语料总共约10w多个样本，我们将数据集分为训练集（train.txt）和测试集（predict.txt），比例为9:1。</p><h3 id="模型训练">模型训练</h3><p>我们对训练集进行训练，训练的CRF++的模板与文章<ahref="https://percent4.github.io/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8CRF-%E5%AE%9E%E7%8E%B0%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB-NER/">NLP入门（八）使用CRF++实现命名实体识别(NER)</a>中一样。训练的命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">crf_learn  -f 3 -c 4.0 template train.data model -t<br></code></pre></td></tr></table></figure><p>训练后的过程如下： <img src="/img/nlp33_1.png"alt="CRF模型训练过程" /></p><h3 id="模型评估">模型评估</h3><p>下面我们将借助序列评估模块<code>seqeval</code>对分词模型的预测能力进行评估。</p><p>我们先用以下命令生成模型预测文件（<code>crf_pred.txt</code>）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">crf_test -m model predict.txt &gt; crf_pred.txt<br></code></pre></td></tr></table></figure><p>接着，我们使用如下脚本进行模型评估：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> f1_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> precision_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> recall_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> classification_report<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;crf_pred.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br>y_pred = []<br>y_true = []<br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> content:<br>    <span class="hljs-keyword">if</span> line:<br>        y_pred.append(line.split(<span class="hljs-string">&quot;\t&quot;</span>)[-<span class="hljs-number">1</span>])<br>        y_true.append(line.split(<span class="hljs-string">&quot;\t&quot;</span>)[-<span class="hljs-number">2</span>])<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;accuary: &quot;</span>, accuracy_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;p: &quot;</span>, precision_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;r: &quot;</span>, recall_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;f1: &quot;</span>, f1_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;classification report: &quot;</span>)<br><span class="hljs-built_in">print</span>(classification_report(y_true, y_pred))<br></code></pre></td></tr></table></figure><p>模型评估的结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">accuary:  0.96405717503858<br>p:  0.9184067155248071<br>r:  0.9206969935013926<br>f1:  0.9195504284452864<br>classification report: <br>           precision    recall  f1-score   support<br><br>     Char       0.92      0.92      0.92    350075<br><br>micro avg       0.92      0.92      0.92    350075<br>macro avg       0.92      0.92      0.92    350075<br></code></pre></td></tr></table></figure><p>可以发现，Char字段的F1值92%，相当不错的结果。</p><h3 id="模型预测">模型预测</h3><p>接下来，我们利用上面训练好的CRF模型，对新的句子进行预测，看看其在新句子上的分词能力。</p><p>我们的预测脚本如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br>text = <span class="hljs-string">&quot;上海野生动物园群熊伤人事件救援画面曝光&quot;</span><br><br><span class="hljs-comment"># 生成待预测的文本</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;predict.data&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> g:<br>    <span class="hljs-keyword">for</span> char <span class="hljs-keyword">in</span> text:<br>        g.write(<span class="hljs-string">&quot;%s\tn\tB-Char\n&quot;</span> % char)<br><br><span class="hljs-comment"># 利用CRF模型，调用命令行进行预测</span><br>os.system(<span class="hljs-string">&quot;crf_test -m model predict.data &gt; predict_new.txt&quot;</span>)<br><br><span class="hljs-comment"># 处理预测后的进行，并将其加工成中文分词后的结果</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;predict_new.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br>predict_tags = []<br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> content:<br>    predict_tags.append(line.split(<span class="hljs-string">&quot;\t&quot;</span>)[-<span class="hljs-number">1</span>])<br><br>words = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(predict_tags)):<br>    word = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> predict_tags[i] == <span class="hljs-string">&quot;B-Char&quot;</span>:<br>        word += text[i]<br>        j = i + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> j &lt; <span class="hljs-built_in">len</span>(text) <span class="hljs-keyword">and</span> predict_tags[j] == <span class="hljs-string">&quot;I-Char&quot;</span>:<br>            word += text[j]<br>            j += <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">if</span> word:<br>        words.append(word)<br><br><span class="hljs-comment"># 输出预测结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;原句:%s&quot;</span> % text)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;分词结果:%s&quot;</span> % (<span class="hljs-string">&quot;/&quot;</span>.join(words)))<br></code></pre></td></tr></table></figure></p><p>我们从新闻中选择10个句子，对其进行分词，结果如下：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs awk">原句:上海野生动物园群熊伤人事件救援画面曝光<br>分词结果:上海<span class="hljs-regexp">/野生动物园/</span>群<span class="hljs-regexp">/熊/</span>伤<span class="hljs-regexp">/人/</span>事件<span class="hljs-regexp">/救援/</span>画面/曝光<br><br>原句:浙江正筹划疫苗接种工作，当地相关部门：仍仅限于紧急接种小部分人群<br>分词结果:浙江<span class="hljs-regexp">/正/</span>筹划<span class="hljs-regexp">/疫苗/</span>接种<span class="hljs-regexp">/工作/</span>，<span class="hljs-regexp">/当地/</span>相关<span class="hljs-regexp">/部门/</span>：<span class="hljs-regexp">/仍/</span>仅<span class="hljs-regexp">/限于/</span>紧急<span class="hljs-regexp">/接种/</span>小部分/人群<br><br>原句:亚阿停火<span class="hljs-number">4</span>分钟又开炮？在法亚美尼亚人抗议 阿塞拜疆使馆前举旗<br>分词结果:亚阿<span class="hljs-regexp">/停火/</span><span class="hljs-number">4</span><span class="hljs-regexp">/分钟/</span>又<span class="hljs-regexp">/开炮/</span>？<span class="hljs-regexp">/在/</span>法<span class="hljs-regexp">/亚美尼亚/</span>人<span class="hljs-regexp">/抗议/</span>阿塞拜疆<span class="hljs-regexp">/使馆/</span>前/举旗<br><br>原句:土耳其被曝秘密试射俄制S400防空导弹 美方高层放出狠话<br>分词结果:土耳其<span class="hljs-regexp">/被/</span>曝<span class="hljs-regexp">/秘密/</span>试<span class="hljs-regexp">/射/</span>俄<span class="hljs-regexp">/制/</span>S<span class="hljs-regexp">/4/</span><span class="hljs-number">0</span><span class="hljs-regexp">/0/</span>防空<span class="hljs-regexp">/导弹/</span>美<span class="hljs-regexp">/方/</span>高层<span class="hljs-regexp">/放/</span>出/狠话<br><br>原句:国家税务总局稽查局副局长林枫接受纪律审查和监察调查<br>分词结果:国家税务总局<span class="hljs-regexp">/稽查局/</span>副<span class="hljs-regexp">/局长/</span>林<span class="hljs-regexp">/枫/</span>接受<span class="hljs-regexp">/纪律/</span>审查<span class="hljs-regexp">/和/</span>监察/调查<br><br>原句:科技助力产业兴 澜沧旧貌换新颜<br>分词结果:科技<span class="hljs-regexp">/助力/</span>产业<span class="hljs-regexp">/兴/</span>澜沧<span class="hljs-regexp">/旧貌/</span>换/新颜<br><br>原句:羊毛党不过是流量<br>分词结果:羊毛<span class="hljs-regexp">/党/</span>不过是/流量<br><br>原句:广西龙胜金秋梯田美如画<br>分词结果:广西<span class="hljs-regexp">/龙/</span>胜<span class="hljs-regexp">/金秋/</span>梯田<span class="hljs-regexp">/美/</span>如/画<br><br>原句:早在上映第四天，《姜子牙》累计票房就已经高达<span class="hljs-number">10.36</span>亿，后来单日票房一路下跌，最低时跌至<span class="hljs-number">500</span>万左右，是同档期对手《我和我的家乡》的五分之一，甚至还不及小成本电影《一点就到家》，位列国庆档新片倒数第二。用“断崖式下跌”来形容这部国漫新作的单日票房走向毫不为过。<br>分词结果:早<span class="hljs-regexp">/在/</span>上映<span class="hljs-regexp">/第四天/</span>，<span class="hljs-regexp">/《/</span>姜子牙<span class="hljs-regexp">/》/</span>累计<span class="hljs-regexp">/票房/</span>就<span class="hljs-regexp">/已经/</span>高<span class="hljs-regexp">/达/</span><span class="hljs-number">10</span><span class="hljs-regexp">/./</span><span class="hljs-number">3</span><span class="hljs-regexp">/6亿/</span>，<span class="hljs-regexp">/后来/</span>单<span class="hljs-regexp">/日/</span>票房<span class="hljs-regexp">/一路/</span>下跌<span class="hljs-regexp">/，/</span>最低<span class="hljs-regexp">/时/</span>跌<span class="hljs-regexp">/至/</span><span class="hljs-number">5</span><span class="hljs-regexp">/0/</span><span class="hljs-number">0</span>万<span class="hljs-regexp">/左右/</span>，<span class="hljs-regexp">/是/</span>同<span class="hljs-regexp">/档期/</span>对手<span class="hljs-regexp">/《/</span>我<span class="hljs-regexp">/和/</span>我<span class="hljs-regexp">/的/</span>家乡<span class="hljs-regexp">/》/</span>的<span class="hljs-regexp">/五分之一/</span>，<span class="hljs-regexp">/甚至/</span>还<span class="hljs-regexp">/不及/</span>小<span class="hljs-regexp">/成本/</span>电影<span class="hljs-regexp">/《/</span>一点<span class="hljs-regexp">/就/</span>到<span class="hljs-regexp">/家/</span>》<span class="hljs-regexp">/，/</span>位<span class="hljs-regexp">/列国庆档/</span>新<span class="hljs-regexp">/片/</span>倒数<span class="hljs-regexp">/第二/</span>。<span class="hljs-regexp">/用/</span>“<span class="hljs-regexp">/断崖式/</span>下跌<span class="hljs-regexp">/”/</span>来<span class="hljs-regexp">/形容/</span>这<span class="hljs-regexp">/部/</span>国<span class="hljs-regexp">/漫/</span>新作<span class="hljs-regexp">/的/</span>单<span class="hljs-regexp">/日/</span>票房<span class="hljs-regexp">/走向/</span>毫不<span class="hljs-regexp">/为/</span>过/。<br><br>原句:<span class="hljs-number">15</span>日，莘庄工业区新时代文明实践的“大本营”——坐落于颛盛路<span class="hljs-number">745</span>号的莘庄工业区新时代文明实践分中心正式落成。<br>分词结果:<span class="hljs-number">1</span><span class="hljs-regexp">/5日/</span>，莘庄<span class="hljs-regexp">/工业区/</span>新时代<span class="hljs-regexp">/文明/</span>实践<span class="hljs-regexp">/的/</span>“<span class="hljs-regexp">/大本营/</span>”<span class="hljs-regexp">/——/</span>坐落<span class="hljs-regexp">/于/</span>颛盛<span class="hljs-regexp">/路/</span><span class="hljs-number">7</span><span class="hljs-regexp">/4/</span><span class="hljs-number">5</span>号<span class="hljs-regexp">/的莘庄/</span>工业区<span class="hljs-regexp">/新时代/</span>文明<span class="hljs-regexp">/实践/</span>分<span class="hljs-regexp">/中心/</span>正式<span class="hljs-regexp">/落成/</span>。<br></code></pre></td></tr></table></figure><h3 id="添加用户词典">添加用户词典</h3><p>从上面的结果可以看出，CRF模型实现的中文分词模型效果确实不错，但也存在着一些词语没有被切分正确的情况，比如伤人、S400、林枫、羊毛党、龙胜、国庆档、颛盛路、745号等词。</p><p>笔者将会模仿结巴分词等模块，实现用户词典功能。</p><p>假设我们的用户词典文件为<code>user_dict.txt</code>，加上用户词典后的预测脚本如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> os<br>text = <span class="hljs-string">&quot;上海野生动物园群熊伤人事件救援画面曝光&quot;</span><br><br><span class="hljs-comment"># 生成待预测的文本</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;predict.data&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> g:<br>    <span class="hljs-keyword">for</span> char <span class="hljs-keyword">in</span> text:<br>        g.write(<span class="hljs-string">&quot;%s\tn\tB-Char\n&quot;</span> % char)<br><br><span class="hljs-comment"># 利用CRF模型，调用命令行进行预测</span><br>os.system(<span class="hljs-string">&quot;crf_test -m model predict.data &gt; predict_new.txt&quot;</span>)<br><br><span class="hljs-comment"># 处理预测后的进行，并将其加工成中文分词后的结果</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;predict_new.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br>predict_tags = []<br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> content:<br>    predict_tags.append(line.split(<span class="hljs-string">&quot;\t&quot;</span>)[-<span class="hljs-number">1</span>])<br><br><span class="hljs-comment"># 通过修改预测标签实现用户词典功能</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;user_dict.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> h:<br>    user_words = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> h.readlines()]<br><br><span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> user_words:<br>    t = <span class="hljs-built_in">len</span>(word)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(text)-t):<br>        <span class="hljs-keyword">if</span> text[i:i+t] == word:<br>            predict_tags[i] = <span class="hljs-string">&quot;B-Char&quot;</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i+<span class="hljs-number">1</span>, i+t):<br>                predict_tags[j] = <span class="hljs-string">&quot;I-Char&quot;</span><br>            <span class="hljs-keyword">if</span> i+t+<span class="hljs-number">1</span> &lt; <span class="hljs-built_in">len</span>(text):<br>                predict_tags[i+t+<span class="hljs-number">1</span>] = <span class="hljs-string">&quot;I-Char&quot;</span><br><br><span class="hljs-comment"># 对预测标签进行后处理，得到中文分词后的结果</span><br>words = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(predict_tags)):<br>    word = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> predict_tags[i] == <span class="hljs-string">&quot;B-Char&quot;</span>:<br>        word += text[i]<br>        j = i + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> j &lt; <span class="hljs-built_in">len</span>(text) <span class="hljs-keyword">and</span> predict_tags[j] == <span class="hljs-string">&quot;I-Char&quot;</span>:<br>            word += text[j]<br>            j += <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">if</span> word:<br>        words.append(word)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;原句:%s&quot;</span> % text)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;分词结果:%s&quot;</span> % (<span class="hljs-string">&quot;/&quot;</span>.join(words)))<br></code></pre></td></tr></table></figure><p>添加用户词典后，中文分词的结果如下：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs awk">原句:上海野生动物园群熊伤人事件救援画面曝光<br>分词结果:上海<span class="hljs-regexp">/野生动物园/</span>群<span class="hljs-regexp">/熊/</span>伤人<span class="hljs-regexp">/事件/</span>救援<span class="hljs-regexp">/画面/</span>曝光<br><br>原句:土耳其被曝秘密试射俄制S400防空导弹 美方高层放出狠话<br>分词结果:土耳其<span class="hljs-regexp">/被/</span>曝<span class="hljs-regexp">/秘密/</span>试<span class="hljs-regexp">/射/</span>俄<span class="hljs-regexp">/制/</span>S400<span class="hljs-regexp">/防空/</span>导弹<span class="hljs-regexp">/美/</span>方<span class="hljs-regexp">/高层/</span>放<span class="hljs-regexp">/出/</span>狠话<br> <br>原句:国家税务总局稽查局副局长林枫接受纪律审查和监察调查<br>分词结果:国家税务总局<span class="hljs-regexp">/稽查局/</span>副<span class="hljs-regexp">/局长/</span>林枫<span class="hljs-regexp">/接受/</span>纪律<span class="hljs-regexp">/审查/</span>和<span class="hljs-regexp">/监察/</span>调查<br><br>原句:羊毛党不过是流量<br>分词结果:羊毛党<span class="hljs-regexp">/不过是/</span>流量<br><br>原句:广西龙胜金秋梯田美如画<br>分词结果:广西<span class="hljs-regexp">/龙胜/</span>金秋<span class="hljs-regexp">/梯田/</span>美<span class="hljs-regexp">/如/</span>画<br><br>原句:早在上映第四天，《姜子牙》累计票房就已经高达<span class="hljs-number">10.36</span>亿，后来单日票房一路下跌，最低时跌至<span class="hljs-number">500</span>万左右，是同档期对手《我和我的家乡》的五分之一，甚至还不及小成本电影《一点就到家》，位列国庆档新片倒数第二。用“断崖式下跌”来形容这部国漫新作的单日票房走向毫不为过。<br>分词结果:早<span class="hljs-regexp">/在/</span>上映<span class="hljs-regexp">/第四天/</span>，<span class="hljs-regexp">/《/</span>姜子牙<span class="hljs-regexp">/》/</span>累计<span class="hljs-regexp">/票房/</span>就<span class="hljs-regexp">/已经/</span>高<span class="hljs-regexp">/达/</span><span class="hljs-number">10</span><span class="hljs-regexp">/./</span><span class="hljs-number">3</span><span class="hljs-regexp">/6亿/</span>，<span class="hljs-regexp">/后来/</span>单<span class="hljs-regexp">/日/</span>票房<span class="hljs-regexp">/一路/</span>下跌<span class="hljs-regexp">/，/</span>最低<span class="hljs-regexp">/时/</span>跌<span class="hljs-regexp">/至/</span><span class="hljs-number">5</span><span class="hljs-regexp">/0/</span><span class="hljs-number">0</span>万<span class="hljs-regexp">/左右/</span>，<span class="hljs-regexp">/是/</span>同<span class="hljs-regexp">/档期/</span>对手<span class="hljs-regexp">/《/</span>我<span class="hljs-regexp">/和/</span>我<span class="hljs-regexp">/的/</span>家乡<span class="hljs-regexp">/》/</span>的<span class="hljs-regexp">/五分之一/</span>，<span class="hljs-regexp">/甚至/</span>还<span class="hljs-regexp">/不及/</span>小<span class="hljs-regexp">/成本/</span>电影<span class="hljs-regexp">/《/</span>一点<span class="hljs-regexp">/就/</span>到<span class="hljs-regexp">/家/</span>》<span class="hljs-regexp">/，/</span>位<span class="hljs-regexp">/列/</span>国庆档<span class="hljs-regexp">/新片/</span>倒数<span class="hljs-regexp">/第二/</span>。<span class="hljs-regexp">/用/</span>“<span class="hljs-regexp">/断崖式/</span>下跌<span class="hljs-regexp">/”/</span>来<span class="hljs-regexp">/形容/</span>这<span class="hljs-regexp">/部/</span>国<span class="hljs-regexp">/漫/</span>新作<span class="hljs-regexp">/的/</span>单<span class="hljs-regexp">/日/</span>票房<span class="hljs-regexp">/走向/</span>毫不<span class="hljs-regexp">/为/</span>过/。<br> <br>原句:<span class="hljs-number">15</span>日，莘庄工业区新时代文明实践的“大本营”——坐落于颛盛路<span class="hljs-number">745</span>号的莘庄工业区新时代文明实践分中心正式落成。<br>分词结果:<span class="hljs-number">1</span><span class="hljs-regexp">/5日/</span>，莘庄<span class="hljs-regexp">/工业区/</span>新时代<span class="hljs-regexp">/文明/</span>实践<span class="hljs-regexp">/的/</span>“<span class="hljs-regexp">/大本营/</span>”<span class="hljs-regexp">/——/</span>坐落<span class="hljs-regexp">/于/</span>颛盛路<span class="hljs-regexp">/745号/</span>的莘庄<span class="hljs-regexp">/工业区/</span>新时代<span class="hljs-regexp">/文明/</span>实践<span class="hljs-regexp">/分/</span>中心<span class="hljs-regexp">/正式/</span>落成/。<br></code></pre></td></tr></table></figure><p>可以看到，用户词典功能也已经生效了。</p><h3 id="总结">总结</h3><p>本次分享利用CRF实现了中文分词这个最基本的NLP任务。</p><p>本文对应的Github地址为：<ahref="https://github.com/percent4/CRF-Chinese-Word-Segment">https://github.com/percent4/CRF-Chinese-Word-Segment</a>。</p><p>感谢大家的阅读~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>CRF</tag>
      
      <tag>分词</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（三十二）利用doccano进行文档标注</title>
    <link href="/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%BA%8C%EF%BC%89%E5%88%A9%E7%94%A8doccano%E8%BF%9B%E8%A1%8C%E6%96%87%E6%A1%A3%E6%A0%87%E6%B3%A8/"/>
    <url>/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%BA%8C%EF%BC%89%E5%88%A9%E7%94%A8doccano%E8%BF%9B%E8%A1%8C%E6%96%87%E6%A1%A3%E6%A0%87%E6%B3%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>doccano是一个开源的文本标注工具，适合于机器学习和深度学习的使用者，提供了文档分类、序列标注和sequencetosequence任务的标注，操作简单，上手也快，界面友好，能够让你在几个小时内建立一个可实际训练的数据集。</p><p>doccano的Github访问网址为：<ahref="https://github.com/doccano/doccano">https://github.com/doccano/doccano</a>。</p><h3 id="安装方式">安装方式</h3><p>doccano的安装也比较简单，我们可以通过Docker很方便地完成安装。</p><p>首先，先从Github上下载该项目，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git <span class="hljs-built_in">clone</span> https://github.com/doccano/doccano.git<br>$ <span class="hljs-built_in">cd</span> doccano<br></code></pre></td></tr></table></figure><p>接着，使用docker-compose来启动该项目，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker-compose -f docker-compose.prod.yml up -d<br></code></pre></td></tr></table></figure><p>这时候docker-compose会先拉取镜像，然后在后台启动整个程序。</p><p>在浏览器中输入<code>http://localhost:3000</code>即可访问该服务，首次创建项目需要输入账号和密码，在<code>docker-compose.yml</code>文件中已经设置过了。</p><h3 id="使用举例">使用举例</h3><p>本文将演示如何使用doccano来进行序列标注方面的人工标注。</p><p>首先我们创建一个标注项目，名称为<code>example_tagging_platform</code>，项目类型选择<code>Sequence Labeling</code>，如下页面：</p><figure><img src="/img/nlp32_1.png" alt="创建标注任务" /><figcaption aria-hidden="true">创建标注任务</figcaption></figure><p>假设我们需要标注的实体标签为<code>时间</code>、<code>人物</code>、<code>职位</code>和<code>公司</code>。我们可以先创建标签，选择标签颜色，如下页面：</p><figure><img src="/img/nlp32_2.png" alt="创建标签" /><figcaption aria-hidden="true">创建标签</figcaption></figure><p>其中的k,c,p,t分别是这些标签的标注快捷键，我们在真实标注的时候，选择好标注文字后再按这些快捷键可以快速完成标注。</p><p>接着我们上传标注文档。假设我们的标注文档格式为txt，一行就是一个标注样本，那么在Dataset选择上传数据（ImportDataset ）的时候，可以选择PlainText。当然也可以选择其它格式的上传文档，比如Json，但需要按照指定格式来。</p><figure><img src="/img/nlp32_3.png" alt="上传文档" /><figcaption aria-hidden="true">上传文档</figcaption></figure><p>我们上传的txt文档（a.txt）内容如下：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs dns">“我们欣喜地看到，科创板和香港联交所推出了一系列改革和创新的举措，为新经济公司能更好地获得资本市场支持包括国际资本支持创造了良好条件，我们很高兴能有机会参与其中。”蚂蚁集团董事长井贤栋说。<br><span class="hljs-number">7</span>月<span class="hljs-number">20</span>日，支付宝母公司蚂蚁集团宣布，启动在香港联合交易所有限公司主板寻求同步发行上市的计划，以进一步支持服务业数字化升级做大内需，加强全球合作助力全球可持续发展，以及支持公司加大技术研发和创新。<br>记者从官方获悉，小鹏汽车于今日宣布完成了近<span class="hljs-number">5</span>亿美元(约<span class="hljs-number">35</span>亿元人民币)C+轮融资，投资方包括Aspex、Coatue、高瓴资本和红杉中国等投资机构。<br>作为百度的总部，百度大厦于<span class="hljs-number">2009年11月17</span>日投入使用，就承载了百度所有的辉煌。<br></code></pre></td></tr></table></figure><p>上传后的界面如下：</p><figure><img src="/img/nlp32_4.png" alt="上传后的界面" /><figcaption aria-hidden="true">上传后的界面</figcaption></figure><p>点击左上方的<code>Start Annotation</code>即可开始标注。如下图：</p><figure><img src="/img/nlp32_5.png" alt="利用doccano进行标注" /><figcaption aria-hidden="true">利用doccano进行标注</figcaption></figure><p>当我们完成部分（或全部）数据的标注时，可以在<code>Statistics</code>中查看标注文档数量，每个标签的标注数量以及每个用户的标注文档数量，如下页面：</p><figure><img src="/img/nlp32_6.png" alt="标注统计" /><figcaption aria-hidden="true">标注统计</figcaption></figure><p>本次演示到此结束。</p><p>笔者在实际使用的时候，发现doccano确实是一个不错的标注工具。它还有很多强大的功能，比如它可以记忆当前的标注文档，当你退出页面再次访问时，点击<code>Start Annotation</code>按钮即可从上次标注的文档开始进行标注。同时，它还支持多人协同标注和检查机制，非常好用。</p><p>本次分享到此结束~</p><p>大家以后如果有文档标注的任务，不妨可以试试用doccano~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>NLP工具</tag>
      
      <tag>doccano</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（三十一）短语的语序问题</title>
    <link href="/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%B8%80%EF%BC%89%E7%9F%AD%E8%AF%AD%E7%9A%84%E8%AF%AD%E5%BA%8F%E9%97%AE%E9%A2%98/"/>
    <url>/NLP%EF%BC%88%E4%B8%89%E5%8D%81%E4%B8%80%EF%BC%89%E7%9F%AD%E8%AF%AD%E7%9A%84%E8%AF%AD%E5%BA%8F%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>所谓的短语的语序问题，即给定一个打乱顺序的短语，我们要按照语义信息将其重新组合，新的语序通顺的短语。</p><p>举个简单例子，比如我们在识别验证码中的文字的时候，识别出来的文字分别为“哲”，“思”，“学”，“想”，那么重合调整语序后形成的短语应该为“哲学思想”。</p><p>这样的问题也会经常出现，除了验证码识别，还有语音识别等。解决这类的语序问题，我们通常会用到统计方面的语言模型（LanguageModel，LM），常见的有N-gram问题等。</p><p>下面将讲述n-gram问题的解决办法。</p><h3 id="原理篇">原理篇</h3><p>N-gram模型是一种语言模型，语言模型是一个基于概率的判别模型，它的输入是一句话（单词的顺序序列），输出是这句话的概率，即这些单词的联合概率（jointprobability）。</p><p>假设一个句子由n个词组成：<span class="math inline">\(S=(w_{1}, w_{2},...,w_{n-1},w_{n})\)</span>，如何衡量这些词的联合概率呢？我们不妨假设每一个词语<spanclass="math inline">\(w_{i}\)</span>都依赖于前<spanclass="math inline">\(i-1\)</span>个词语的影响，则联合概率如下：</p><p><spanclass="math display">\[p(S)=p(w_{1}w_{2}...w_{n-1}w_{n})=p(w_{1})p(w_{2}|w_{1})...p(w_{n}|w_{1}w_{2}...w_{n-1})\]</span></p><p>上述的假设是合情合理的，但实际我们在计算的过程中，会发现参数空间过大和数据稀疏等问题，尤其是<spanclass="math inline">\(i\)</span>值越大，前<spanclass="math inline">\(i-1\)</span>个的组合情况越少，甚至为0。</p><p>为了避免上述问题，我们需要<code>马尔科夫假设</code>，即一个词的出现仅与它之前的N个词有关。如果一个词的出现仅依赖于前一个词，那么为<code>Bi-gram</code>的情形（N=2），公式如下：</p><p><spanclass="math display">\[p(S)=p(w_{1}w_{2}...w_{n-1}w_{n})=p(w_{1})p(w_{2}|w_{1})...p(w_{n}|w_{n-1})\]</span></p><p>如果一个词的出现仅依赖于前两个词，那么为<code>Tri-gram</code>的情形（N=3），公式如下：</p><p><spanclass="math display">\[p(S)=p(w_{1}w_{2}...w_{n-1}w_{n})=p(w_{1})p(w_{2}|w_{1})p(w_{3}|w_{2}w_{1})...p(w_{n}|w_{n-1}w_{n-2})\]</span></p><p>在实际我们计算上述等式最后面的值时，可以用频数来代替（这是根据条件概率得到的），比如：</p><p><spanclass="math display">\[p(w_{n}|w_{n-1})=C(w_{n-1}w_{n})/C(w_{n-1})\]</span></p><p><spanclass="math display">\[p(w_{n}|w_{n-1}w_{n-2})=C(w_{n-2}w_{n-1}w_{n})/C(w_{n-2}w_{n-1})\]</span></p><p>其中，<span class="math inline">\(C(w_{n-1}w_{n})\)</span>表示<spanclass="math inline">\(w_{n-1}w_{n}\)</span>一起在文章中出现的概率，其余类似。</p><h3 id="实战篇">实战篇</h3><p>根据上面的原理，我们来解决短语的语序问题。</p><p>首先，我们需要语料，语料就用人民日报的NER语料，前几行如下：</p><blockquote><p>海钓比赛地点在厦门与金门之间的海域。这座依山傍水的博物馆由国内一流的设计师主持设计，整个建筑群精美而恢宏。在发达国家，急救保险十分普及，已成为社会保障体系的重要组成部分。日俄两国国内政局都充满变数，尽管日俄关系目前是历史最佳时期，但其脆弱性不言自明。克马尔的女儿让娜今年读五年级，她所在的班上有30多名同学，该班的“家委会”由10名家长组成。</p></blockquote><p>解决短语的语序问题的脚本代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020/5/18 4:04 下午</span><br><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> permutations<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><span class="hljs-keyword">from</span> operator <span class="hljs-keyword">import</span> itemgetter<br><br><span class="hljs-comment"># read corpus data in sentence format</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;corpus.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br><span class="hljs-comment"># random characters input order</span><br>string = <span class="hljs-string">&quot;哲学思想&quot;</span><br><span class="hljs-comment"># string = &quot;景德镇陶瓷&quot;</span><br><span class="hljs-comment"># string = &quot;突出贡献&quot;</span><br><span class="hljs-comment"># string = &quot;哈萨克斯坦&quot;</span><br><span class="hljs-comment"># string = &quot;管理局&quot;</span><br><span class="hljs-comment"># string = &quot;博物馆&quot;</span><br><span class="hljs-comment"># string = &quot;北京大学&quot;</span><br><span class="hljs-comment"># string = &quot;浦东发展银行&quot;</span><br><span class="hljs-comment"># string = &quot;世界杯决赛&quot;</span><br>word_list = <span class="hljs-built_in">set</span>(<span class="hljs-built_in">list</span>(string))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;模拟输入:&quot;</span>, word_list)<br>candidate_list = <span class="hljs-built_in">list</span>(permutations(word_list, r=<span class="hljs-built_in">len</span>(word_list)))<br><br><span class="hljs-comment"># check if a character in the corpus</span><br><span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> word_list:<br>    <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> <span class="hljs-string">&quot;&quot;</span>.join(content):<br>        <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">&quot;%s不在语料库中！&quot;</span> % word)<br><br><span class="hljs-comment"># Language Model</span><br>word_prob_dict = &#123;&#125;<br><span class="hljs-keyword">for</span> candidate <span class="hljs-keyword">in</span> candidate_list:<br>    candidate = <span class="hljs-built_in">list</span>(candidate)<br>    prob = <span class="hljs-string">&quot;&quot;</span>.join(content).count(candidate[<span class="hljs-number">0</span>])/<span class="hljs-built_in">len</span>(<span class="hljs-string">&quot;&quot;</span>.join(content))<br>    <span class="hljs-comment"># 2-gram</span><br>    <span class="hljs-comment"># prob = Count(W_&#123;i&#125;W_&#123;i-1&#125;)/Count(W_&#123;i-1&#125;)</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(candidate)):<br>        char_cnt = <span class="hljs-string">&quot;&quot;</span>.join(content).count(candidate[i-<span class="hljs-number">1</span>])<br>        word_cnt = <span class="hljs-string">&quot;&quot;</span>.join(content).count(<span class="hljs-string">&quot;&quot;</span>.join(candidate[i-<span class="hljs-number">1</span>:i+<span class="hljs-number">1</span>]))<br>        prob *= (word_cnt/char_cnt)<br>        <span class="hljs-keyword">if</span> prob == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">break</span><br><br>    word_prob_dict[<span class="hljs-string">&quot;&quot;</span>.join(candidate)] = prob<br><br><span class="hljs-comment"># recognize result</span><br><span class="hljs-comment"># pprint(word_prob_dict)</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;最终输出结果:&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">sorted</span>(word_prob_dict.items(), key=itemgetter(<span class="hljs-number">1</span>), reverse=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><blockquote><p>模拟输入: {'思', '想', '哲', '学'} 最终输出结果: ('哲学思想',4.851640701745029e-08)</p></blockquote><blockquote><p>模拟输入: {'陶', '镇', '德', '瓷', '景'} 最终输出结果: ('景德镇陶瓷',4.402324066467249e-12)</p></blockquote><blockquote><p>模拟输入: {'贡', '出', '突', '献'} 最终输出结果: ('突出贡献',4.4461494672771407e-07)</p></blockquote><blockquote><p>模拟输入: {'坦', '克', '萨', '斯', '哈'} 最终输出结果: ('哈萨克斯坦',4.65260719191311e-09)</p></blockquote><blockquote><p>模拟输入: {'理', '局', '管'} 最终输出结果: ('管理局',4.5911913512038205e-06)</p></blockquote><blockquote><p>模拟输入: {'馆', '物', '博'} 最终输出结果: ('博物馆',5.9318486186358995e-06)</p></blockquote><blockquote><p>模拟输入: {'大', '京', '北', '学'} 最终输出结果: ('北京大学',3.491890788613219e-06)</p></blockquote><blockquote><p>模拟输入: {'银', '行', '发', '东', '浦', '展'} 最终输出结果:('浦东发展银行', 2.8403362134844498e-11)</p></blockquote><blockquote><p>模拟输入: {'决', '世', '界', '杯', '赛'} 最终输出结果: ('世界杯决赛',6.28999814981479e-07)</p></blockquote><h3 id="总结">总结</h3><p>上面的代码只是给出了如何解决短语的语序问题的一个实现思路，实际我们在应用的过程中还需要考虑以下问题：</p><ul><li><p>语料大小，本文示例语料较小，只有3万多句话，语料越大，识别的效果一般也越好；</p></li><li><p>短语的长度，一般短语越长，识别的时间也越长，如何优化识别算法，从而使得识别时间更短；</p></li><li><p>平滑处理，本例中不考虑分母为0的情形，实际应用中我们还需要考虑分母为0的情形，此时需要做平滑处理。</p><p>本次分享到此结束，感谢大家的阅读~</p></li></ul>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>语言模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（三十）利用ALBERT和机器学习来做文本分类</title>
    <link href="/NLP%EF%BC%88%E4%B8%89%E5%8D%81%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%A5%E5%81%9A%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    <url>/NLP%EF%BC%88%E4%B8%89%E5%8D%81%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%A5%E5%81%9A%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文的灵感来自于<ahref="http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time">AVisual Guide to Using BERT for the First Time</a>，其作者为JayAlammar，访问网址为：http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time。</p><p>在文本分类中，有两个大的思路，一个是机器学习，主要是利用n-gram等特征将文本转化为特征向量，这种方法便于操作和理解，但是忽略了文本本身的语义信息；另一个是深度学习，主要是利用word2vec作为特征提取，加之CNN或RNN等深度学习模型来进行分类，尤其是BERT等预训练模型出来了，在小样本上做finetune即可取得不错的效果，能在很大程度上提取出文本的语义信息，但这种方法不便于操作和理解。</p><p>一个简单的想法便是，我们可以利用预训练模型对文本做特征提取，然后在调用机器学习中的分类模型来进行分类，这样做思路是清晰的，操作较为复杂，便于理解，同时又不会丢失训练模型中的语义信息。</p><p>本文以ALBERT作为文本的特征提取，用机器学习中的逻辑回归（LR）、朴素贝叶斯（NB）、支持向量机（SVM）等模型来进行文本。注意，本文仅作为文本分类方面的尝试，具体在实际的文本分类任务中还需要具体分析。</p><p>本文的数据来源可以参考文章：<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%8C%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB/">NLP（二十二）利用ALBERT实现文本二分类</a>，一共是300条训练数据和80条测试数据，用于区分文本是否是属于政治上的出访类事件。</p><p>在这里我们使用ALBERT已经训练好的文件albert_tiny，借鉴BERT的调用方法，我们在这里给出albert_zh模块，能够让ALBERT提取文本的特征，具体代码不在这里给出，有兴趣的读者可以访问该项目的Github地址：<ahref="https://github.com/percent4/ALBERT_text_classification">https://github.com/percent4/ALBERT_text_classification</a>。</p><p>注意，本文中并没有给出文本预处理的代码，有兴趣的读者可以参考该项目的Github地址。在特征提取过程中，Albert_tiny模型给出的向量维度为312，我们的模型训练代码（ml_model_train.py）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020/5/15 3:44 下午</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression <span class="hljs-keyword">as</span> LR<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix, accuracy_score, classification_report<br><span class="hljs-keyword">from</span> sklearn.externals <span class="hljs-keyword">import</span> joblib<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC<br><span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> GaussianNB<br><br><span class="hljs-keyword">from</span> load_data <span class="hljs-keyword">import</span> train_df, test_df<br><span class="hljs-keyword">from</span> albert_zh.extract_feature <span class="hljs-keyword">import</span> BertVector<br><br><span class="hljs-comment"># 读取文件并进行转换</span><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;REDUCE_MEAN&quot;</span>, max_seq_len=<span class="hljs-number">200</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;begin encoding&#x27;</span>)<br>f = <span class="hljs-keyword">lambda</span> text: bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br>train_df[<span class="hljs-string">&#x27;x&#x27;</span>] = train_df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(f)<br>test_df[<span class="hljs-string">&#x27;x&#x27;</span>] = test_df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(f)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;end encoding&#x27;</span>)<br><br>x_train = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> train_df[<span class="hljs-string">&#x27;x&#x27;</span>]])<br>x_test = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> test_df[<span class="hljs-string">&#x27;x&#x27;</span>]])<br>y_train = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> train_df[<span class="hljs-string">&#x27;label&#x27;</span>]])<br>y_test = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> test_df[<span class="hljs-string">&#x27;label&#x27;</span>]])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;x_train: &#x27;</span>, x_train.shape)<br><br><span class="hljs-comment"># Logistic Regression</span><br>lr = LR(random_state=<span class="hljs-number">123</span>)<br>lr.fit(x_train, y_train)<br><br>y_pred = lr.predict(x_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Logistic Regression Model&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;混淆矩阵&quot;</span>, confusion_matrix(y_true=y_test, y_pred=y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;正确率：&quot;</span>, accuracy_score(y_test, y_pred))<br><span class="hljs-built_in">print</span>(classification_report(y_true=y_test, y_pred=y_pred, digits=<span class="hljs-number">4</span>))<br><br><span class="hljs-comment"># 保存模型</span><br>joblib.dump(lr, <span class="hljs-string">&quot;lr.model&quot;</span>)<br><br><span class="hljs-comment"># Naive Bayes Model</span><br>gnb = GaussianNB()<br>gnb.fit(x_train, y_train)<br>y_pred = gnb.predict(x_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nNaive Bayes Model&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;混淆矩阵&quot;</span>, confusion_matrix(y_true=y_test, y_pred=y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;正确率：&quot;</span>, accuracy_score(y_test, y_pred))<br><span class="hljs-built_in">print</span>(classification_report(y_true=y_test, y_pred=y_pred, digits=<span class="hljs-number">4</span>))<br><br><span class="hljs-comment"># SVM model</span><br>svc = SVC(kernel=<span class="hljs-string">&quot;rbf&quot;</span>)<br>svc.fit(x_train, y_train)<br>y_pred = svc.predict(x_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nSVM Model&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;混淆矩阵&quot;</span>, confusion_matrix(y_true=y_test, y_pred=y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;正确率：&quot;</span>, accuracy_score(y_test, y_pred))<br><span class="hljs-built_in">print</span>(classification_report(y_true=y_test, y_pred=y_pred, digits=<span class="hljs-number">4</span>))<br><br>joblib.dump(svc, <span class="hljs-string">&quot;svc.model&quot;</span>)<br></code></pre></td></tr></table></figure><p>让我们来简单的理一下思路，我们的训练集合测试集数据集为<code>train_df</code>和<code>test_df</code>，包含文本内容和标签等，然后用ALBERT提取文本特征，再尝试用逻辑回归、朴素贝叶斯、支持向量机等机器学习模型来进行分类。分类后的输出结果如下：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs lua">Logistic Regression Model<br>混淆矩阵 <span class="hljs-string">[[33  5]</span><br><span class="hljs-string"> [ 2 40]]</span><br>正确率： <span class="hljs-number">0.9125</span><br>              precision    recall  f1-score   support<br><br>           <span class="hljs-number">0</span>     <span class="hljs-number">0.9429</span>    <span class="hljs-number">0.8684</span>    <span class="hljs-number">0.9041</span>        <span class="hljs-number">38</span><br>           <span class="hljs-number">1</span>     <span class="hljs-number">0.8889</span>    <span class="hljs-number">0.9524</span>    <span class="hljs-number">0.9195</span>        <span class="hljs-number">42</span><br><br>   micro avg     <span class="hljs-number">0.9125</span>    <span class="hljs-number">0.9125</span>    <span class="hljs-number">0.9125</span>        <span class="hljs-number">80</span><br>   macro avg     <span class="hljs-number">0.9159</span>    <span class="hljs-number">0.9104</span>    <span class="hljs-number">0.9118</span>        <span class="hljs-number">80</span><br>weighted avg     <span class="hljs-number">0.9145</span>    <span class="hljs-number">0.9125</span>    <span class="hljs-number">0.9122</span>        <span class="hljs-number">80</span><br><br><br>Naive Bayes Model<br>混淆矩阵 <span class="hljs-string">[[37  1]</span><br><span class="hljs-string"> [ 1 41]]</span><br>正确率： <span class="hljs-number">0.975</span><br>              precision    recall  f1-score   support<br><br>           <span class="hljs-number">0</span>     <span class="hljs-number">0.9737</span>    <span class="hljs-number">0.9737</span>    <span class="hljs-number">0.9737</span>        <span class="hljs-number">38</span><br>           <span class="hljs-number">1</span>     <span class="hljs-number">0.9762</span>    <span class="hljs-number">0.9762</span>    <span class="hljs-number">0.9762</span>        <span class="hljs-number">42</span><br><br>   micro avg     <span class="hljs-number">0.9750</span>    <span class="hljs-number">0.9750</span>    <span class="hljs-number">0.9750</span>        <span class="hljs-number">80</span><br>   macro avg     <span class="hljs-number">0.9749</span>    <span class="hljs-number">0.9749</span>    <span class="hljs-number">0.9749</span>        <span class="hljs-number">80</span><br>weighted avg     <span class="hljs-number">0.9750</span>    <span class="hljs-number">0.9750</span>    <span class="hljs-number">0.9750</span>        <span class="hljs-number">80</span><br><br>SVM Model<br>混淆矩阵 <span class="hljs-string">[[35  3]</span><br><span class="hljs-string"> [ 1 41]]</span><br>正确率： <span class="hljs-number">0.95</span><br>              precision    recall  f1-score   support<br><br>           <span class="hljs-number">0</span>     <span class="hljs-number">0.9722</span>    <span class="hljs-number">0.9211</span>    <span class="hljs-number">0.9459</span>        <span class="hljs-number">38</span><br>           <span class="hljs-number">1</span>     <span class="hljs-number">0.9318</span>    <span class="hljs-number">0.9762</span>    <span class="hljs-number">0.9535</span>        <span class="hljs-number">42</span><br><br>   micro avg     <span class="hljs-number">0.9500</span>    <span class="hljs-number">0.9500</span>    <span class="hljs-number">0.9500</span>        <span class="hljs-number">80</span><br>   macro avg     <span class="hljs-number">0.9520</span>    <span class="hljs-number">0.9486</span>    <span class="hljs-number">0.9497</span>        <span class="hljs-number">80</span><br>weighted avg     <span class="hljs-number">0.9510</span>    <span class="hljs-number">0.9500</span>    <span class="hljs-number">0.9499</span>        <span class="hljs-number">80</span><br></code></pre></td></tr></table></figure><p>可以看到，上述三种模型在这个文本分类的任务上都取得了不错的效果，比在之前的文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%8C%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB/">NLP（二十二）利用ALBERT实现文本二分类</a>中的ALBERT作为特征提取，DNN作为分类模型的效果要更好些。</p><p>最后，让我们用保存的支持向量机模型对新文本进行预测，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020/5/15 4:23 下午</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.externals <span class="hljs-keyword">import</span> joblib<br><span class="hljs-keyword">from</span> albert_zh.extract_feature <span class="hljs-keyword">import</span> BertVector<br><br><span class="hljs-comment"># 读取文件并进行转换</span><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;REDUCE_MEAN&quot;</span>, max_seq_len=<span class="hljs-number">200</span>)<br>f = <span class="hljs-keyword">lambda</span> text: bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># predict</span><br><span class="hljs-comment"># 预测语句</span><br>texts = [<span class="hljs-string">&#x27;在访问限制中，用户可以选择禁用iPhone的功能，包括Siri、iTunes购买功能、安装/删除应用等，甚至还可以让iPhone变成一台功能手机。以下是访问限制具体可以实现的一些功能&#x27;</span>,<br>         <span class="hljs-string">&#x27;IT之家4月23日消息 近日，谷歌在其官方论坛发布消息表示，他们为Android Auto添加了一项新功能：可以访问完整联系人列表。用户现在可以通过在Auto的电话拨号界面中打开左上角的菜单访问完整的联系人列表。值得注意的是，这一功能仅支持在车辆停止时使用。&#x27;</span>,<br>         <span class="hljs-string">&#x27;要通过telnet 访问路由器，需要先通过console 口对路由器进行基本配置，例如：IP地址、密码等。&#x27;</span>,<br>         <span class="hljs-string">&#x27;IT之家3月26日消息 近日反盗版的国际咨询公司MUSO发布了2017年的年度报告，其中的数据显示，去年盗版资源网站访问量达到了3000亿次，比前一年（2016年）提高了1.6%。美国是访问盗版站点次数最多的国家，共有279亿次访问；其后分别是俄罗斯、印度和巴西，中国位列第18。&#x27;</span>,<br>         <span class="hljs-string">&#x27;应葡萄牙议会邀请，全国人大常委会副委员长吉炳轩率团于12月14日至16日访问葡萄牙，会见副议长费利佩、社会党副总书记卡内罗。&#x27;</span>,<br>         <span class="hljs-string">&#x27;2月26日至3月2日，应香港特区政府“内地贵宾访港计划”邀请，省委常委、常务副省长陈向群赴港考察访问，重点围绕“香港所长、湖南所需”，与特区政府相关部门和机构深入交流，推动湖南与香港交流合作取得新进展。&#x27;</span>,<br>         <span class="hljs-string">&#x27;目前A站已经恢复了访问，可以直接登录，网页加载正常，视频已经可以正常播放。&#x27;</span>,<br>         <span class="hljs-string">&#x27;难民署特使安吉丽娜·朱莉6月8日结束了对哥伦比亚和委内瑞拉边境地区的难民营地为期两天的访问，她对哥伦比亚人民展现的人道主义和勇气表示赞扬。&#x27;</span>,<br>         <span class="hljs-string">&#x27;据《南德意志报》报道，德国总理默克尔计划明年1月就前往安卡拉，和土耳其总统埃尔多安进行会谈。&#x27;</span>,<br>         <span class="hljs-string">&#x27;Win7电脑提示无线适配器或访问点有问题怎么办?很多用户在使用无线网连接上网时，发现无线网显示已连接，但旁边却出现了一个黄色感叹号，无法进行网络操作，通过诊断提示电脑无线适配器或访问点有问题，且处于未修复状态，这该怎么办呢?下面小编就和大家分享下Win7电脑提示无线适配器或访问点有问题的解决方法。&#x27;</span>,<br>         <span class="hljs-string">&#x27;2019年10月13日至14日，外交部副部长马朝旭访问智利，会见智利外长里韦拉，同智利总统外事顾问萨拉斯举行会谈，就智利举办亚太经合组织（APEC）第二十七次领导人非正式会议等深入交换意见。&#x27;</span>,<br>         <span class="hljs-string">&#x27;未开发所有安全组之前访问，FTP可以链接上，但是打开会很慢，需要1-2分钟才能链接上&#x27;</span>,<br>         <span class="hljs-string">&#x27;win7系统电脑的用户，在连接WIFI网络网上时，有时候会遇到突然上不了网，查看连接的WIFI出现“有限的访问权限”的文字提示。&#x27;</span>,<br>         <span class="hljs-string">&#x27;联合国秘书长潘基文８日访问了日本福岛县，与当地灾民交流并访问了一所高中。&#x27;</span>,<br>         <span class="hljs-string">&#x27;正在中国访问的巴巴多斯总理斯图尔特１５日在陕西西安参观访问。&#x27;</span>,<br>         <span class="hljs-string">&#x27;据外媒报道,当地时间10日,美国白宫发声明称,美国总统特朗普将于2月底访问印度,与印度总理莫迪进行战略对话。&#x27;</span>,<br>         <span class="hljs-string">&#x27;2月28日，唐山曹妃甸蓝色海洋科技有限公司董事长赵力军等一行5人到黄海水产研究所交流访问。黄海水产研究所副所长辛福言及相关部门负责人、专家等参加了会议。&#x27;</span>,<br>         <span class="hljs-string">&#x27;2018年7月2日，莫斯科孔子文化促进会会长姜彦彬，常务副会长陈国建，在中国著名留俄油画大师牟克教授的陪同下，访问了莫斯科国立苏里科夫美术学院，受到第一副校长伊戈尔·戈尔巴秋克先生接待。&#x27;</span><br>         <span class="hljs-string">&#x27;据外媒报道，当地时间26日晚，阿尔及利亚总统特本抵达沙特阿拉伯，进行为期三天的访问。两国领导人预计将就国家间合作和地区发展进行磋商。&#x27;</span>,<br>         <span class="hljs-string">&#x27;与标准Mozy一样，Stash文件夹为用户提供了对其备份文件的基于云的访问，但是它们还使他们可以随时，跨多个设备(包括所有计算机，智能手机和平板电脑)访问它们。换句话说，使用浏览器的任何人都可以同时查看文件(如果需要)。操作系统和设备品牌无关。&#x27;</span>,<br>         <span class="hljs-string">&#x27;研究表明，每个网页的平均预期寿命为44至100天。当用户通过浏览器访问已消失的网页时，就会看到「Page Not Found」的错误信息。对于这种情况，相信大多数人也只能不了了之。不过有责任心的组织——互联网档案馆为了提供更可靠的Web服务，它联手Brave浏览器专门针对此类网页提供了一键加载存档页面的功能。&#x27;</span>,<br>         <span class="hljs-string">&#x27;据外媒报道，土耳其总统府于当地时间2日表示，土耳其总统埃尔多安计划于5日对俄罗斯进行为期一天的访问。&#x27;</span>,<br>         <span class="hljs-string">&#x27;3日，根据三星电子的消息，李在镕副会长这天访问了位于韩国庆尚北道龟尾市的三星电子工厂。&#x27;</span>,<br>         <span class="hljs-string">&quot;通过你本机ip 和 2375端口访问测试是否成功。&quot;</span>,<br>         <span class="hljs-string">&quot;方济各弗朗西斯教皇访问泰国，在泰国曼谷朱拉隆功大学举行会议，并与泰国佛教宗教领袖谈话。&quot;</span>]<br><br><span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts:<br>    vec = np.array([f(text)])<br>    svc = joblib.load(<span class="hljs-string">&quot;svc.model&quot;</span>)<br>    y_predict = svc.predict(vec)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;句子: %s \n 预测类别: %s&quot;</span> % (text, y_predict))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs less">句子: 在访问限制中，用户可以选择禁用<span class="hljs-selector-tag">iPhone</span>的功能，包括<span class="hljs-selector-tag">Siri</span>、<span class="hljs-selector-tag">iTunes</span>购买功能、安装/删除应用等，甚至还可以让<span class="hljs-selector-tag">iPhone</span>变成一台功能手机。以下是访问限制具体可以实现的一些功能 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;0&#x27;</span>]</span><br>句子: <span class="hljs-selector-tag">IT</span>之家<span class="hljs-number">4</span>月<span class="hljs-number">23</span>日消息 近日，谷歌在其官方论坛发布消息表示，他们为<span class="hljs-selector-tag">Android</span> <span class="hljs-selector-tag">Auto</span>添加了一项新功能：可以访问完整联系人列表。用户现在可以通过在<span class="hljs-selector-tag">Auto</span>的电话拨号界面中打开左上角的菜单访问完整的联系人列表。值得注意的是，这一功能仅支持在车辆停止时使用。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;0&#x27;</span>]</span><br>句子: 要通过<span class="hljs-selector-tag">telnet</span> 访问路由器，需要先通过<span class="hljs-selector-tag">console</span> 口对路由器进行基本配置，例如：<span class="hljs-selector-tag">IP</span>地址、密码等。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;0&#x27;</span>]</span><br>句子: <span class="hljs-selector-tag">IT</span>之家<span class="hljs-number">3</span>月<span class="hljs-number">26</span>日消息 近日反盗版的国际咨询公司<span class="hljs-selector-tag">MUSO</span>发布了<span class="hljs-number">2017</span>年的年度报告，其中的数据显示，去年盗版资源网站访问量达到了<span class="hljs-number">3000</span>亿次，比前一年（<span class="hljs-number">2016</span>年）提高了<span class="hljs-number">1.6%</span>。美国是访问盗版站点次数最多的国家，共有<span class="hljs-number">279</span>亿次访问；其后分别是俄罗斯、印度和巴西，中国位列第<span class="hljs-number">18</span>。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;0&#x27;</span>]</span><br>句子: 应葡萄牙议会邀请，全国人大常委会副委员长吉炳轩率团于<span class="hljs-number">12</span>月<span class="hljs-number">14</span>日至<span class="hljs-number">16</span>日访问葡萄牙，会见副议长费利佩、社会党副总书记卡内罗。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: <span class="hljs-number">2</span>月<span class="hljs-number">26</span>日至<span class="hljs-number">3</span>月<span class="hljs-number">2</span>日，应香港特区政府“内地贵宾访港计划”邀请，省委常委、常务副省长陈向群赴港考察访问，重点围绕“香港所长、湖南所需”，与特区政府相关部门和机构深入交流，推动湖南与香港交流合作取得新进展。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: 目前<span class="hljs-selector-tag">A</span>站已经恢复了访问，可以直接登录，网页加载正常，视频已经可以正常播放。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;0&#x27;</span>]</span><br>句子: 难民署特使安吉丽娜·朱莉<span class="hljs-number">6</span>月<span class="hljs-number">8</span>日结束了对哥伦比亚和委内瑞拉边境地区的难民营地为期两天的访问，她对哥伦比亚人民展现的人道主义和勇气表示赞扬。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: 据《南德意志报》报道，德国总理默克尔计划明年<span class="hljs-number">1</span>月就前往安卡拉，和土耳其总统埃尔多安进行会谈。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: <span class="hljs-selector-tag">Win7</span>电脑提示无线适配器或访问点有问题怎么办?很多用户在使用无线网连接上网时，发现无线网显示已连接，但旁边却出现了一个黄色感叹号，无法进行网络操作，通过诊断提示电脑无线适配器或访问点有问题，且处于未修复状态，这该怎么办呢?下面小编就和大家分享下<span class="hljs-selector-tag">Win7</span>电脑提示无线适配器或访问点有问题的解决方法。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;0&#x27;</span>]</span><br>句子: <span class="hljs-number">2019</span>年<span class="hljs-number">10</span>月<span class="hljs-number">13</span>日至<span class="hljs-number">14</span>日，外交部副部长马朝旭访问智利，会见智利外长里韦拉，同智利总统外事顾问萨拉斯举行会谈，就智利举办亚太经合组织（<span class="hljs-selector-tag">APEC</span>）第二十七次领导人非正式会议等深入交换意见。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: 未开发所有安全组之前访问，<span class="hljs-selector-tag">FTP</span>可以链接上，但是打开会很慢，需要<span class="hljs-number">1</span><span class="hljs-selector-tag">-2</span>分钟才能链接上 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;0&#x27;</span>]</span><br>句子: <span class="hljs-selector-tag">win7</span>系统电脑的用户，在连接<span class="hljs-selector-tag">WIFI</span>网络网上时，有时候会遇到突然上不了网，查看连接的<span class="hljs-selector-tag">WIFI</span>出现“有限的访问权限”的文字提示。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;0&#x27;</span>]</span><br>句子: 联合国秘书长潘基文８日访问了日本福岛县，与当地灾民交流并访问了一所高中。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: 正在中国访问的巴巴多斯总理斯图尔特１５日在陕西西安参观访问。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: 据外媒报道,当地时间<span class="hljs-number">10</span>日,美国白宫发声明称,美国总统特朗普将于<span class="hljs-number">2</span>月底访问印度,与印度总理莫迪进行战略对话。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: <span class="hljs-number">2</span>月<span class="hljs-number">28</span>日，唐山曹妃甸蓝色海洋科技有限公司董事长赵力军等一行<span class="hljs-number">5</span>人到黄海水产研究所交流访问。黄海水产研究所副所长辛福言及相关部门负责人、专家等参加了会议。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: <span class="hljs-number">2018</span>年<span class="hljs-number">7</span>月<span class="hljs-number">2</span>日，莫斯科孔子文化促进会会长姜彦彬，常务副会长陈国建，在中国著名留俄油画大师牟克教授的陪同下，访问了莫斯科国立苏里科夫美术学院，受到第一副校长伊戈尔·戈尔巴秋克先生接待。据外媒报道，当地时间<span class="hljs-number">26</span>日晚，阿尔及利亚总统特本抵达沙特阿拉伯，进行为期三天的访问。两国领导人预计将就国家间合作和地区发展进行磋商。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: 与标准<span class="hljs-selector-tag">Mozy</span>一样，<span class="hljs-selector-tag">Stash</span>文件夹为用户提供了对其备份文件的基于云的访问，但是它们还使他们可以随时，跨多个设备(包括所有计算机，智能手机和平板电脑)访问它们。换句话说，使用浏览器的任何人都可以同时查看文件(如果需要)。操作系统和设备品牌无关。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;0&#x27;</span>]</span><br>句子: 研究表明，每个网页的平均预期寿命为<span class="hljs-number">44</span>至<span class="hljs-number">100</span>天。当用户通过浏览器访问已消失的网页时，就会看到「<span class="hljs-selector-tag">Page</span> <span class="hljs-selector-tag">Not</span> <span class="hljs-selector-tag">Found</span>」的错误信息。对于这种情况，相信大多数人也只能不了了之。不过有责任心的组织——互联网档案馆为了提供更可靠的<span class="hljs-selector-tag">Web</span>服务，它联手<span class="hljs-selector-tag">Brave</span>浏览器专门针对此类网页提供了一键加载存档页面的功能。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;0&#x27;</span>]</span><br>句子: 据外媒报道，土耳其总统府于当地时间<span class="hljs-number">2</span>日表示，土耳其总统埃尔多安计划于<span class="hljs-number">5</span>日对俄罗斯进行为期一天的访问。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: <span class="hljs-number">3</span>日，根据三星电子的消息，李在镕副会长这天访问了位于韩国庆尚北道龟尾市的三星电子工厂。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br>句子: 通过你本机<span class="hljs-selector-tag">ip</span> 和 <span class="hljs-number">2375</span>端口访问测试是否成功。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;0&#x27;</span>]</span><br>句子: 方济各弗朗西斯教皇访问泰国，在泰国曼谷朱拉隆功大学举行会议，并与泰国佛教宗教领袖谈话。 <br> 预测类别: <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;1&#x27;</span>]</span><br></code></pre></td></tr></table></figure><p>0表示不是政治意义上的出访，1代表是。所有的新文本(新文本中都含有<code>访问</code>这个词语)都分类正确。</p><p>本文作为笔者的一次尝试，因此写得比较简单，有兴趣的读者可以移步本项目的Github地址：<ahref="https://github.com/percent4/ALBERT_text_classification">https://github.com/percent4/ALBERT_text_classification</a>。</p><p>感谢大家的阅读，如有问题，敬请批评指正~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>文本分类</tag>
      
      <tag>ALBERT</tag>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（二十九）一步一步，理解Self-Attention</title>
    <link href="/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B9%9D%EF%BC%89%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%EF%BC%8C%E7%90%86%E8%A7%A3Self-Attention/"/>
    <url>/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B9%9D%EF%BC%89%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%EF%BC%8C%E7%90%86%E8%A7%A3Self-Attention/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文大部分内容翻译自<ahref="https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a">IllustratedSelf-Attention, Step-by-step guide to self-attention with illustrationsand code</a>，仅用于学习，如有翻译不当之处，敬请谅解！</p><h3id="什么是self-attention自注意力机制">什么是Self-Attention（自注意力机制）？</h3><p>如果你在想Self-Attention（自注意力机制）是否和Attention（注意力机制）相似，那么答案是肯定的。它们本质上属于同一个概念，拥有许多共同的数学运算。</p><p>一个Self-Attention模块拥有n个输入，返回n个输出。这么模块里面发生了什么？从非专业角度看，Self-Attention（自注意力机制）允许输入之间互相作用（“self”部分），寻找出谁更应该值得注意（“attention”部分）。输出的结果是这些互相作用和注意力分数的聚合。</p><h3 id="一步步理解self-attention">一步步理解Self-Attention</h3><p>理解分为以下几步：</p><ol type="1"><li>准备输入；</li><li>初始化权重；</li><li>获取<code>key</code>，<code>query</code>和<code>value</code>；</li><li>为第1个输入计算注意力分数；</li><li>计算softmax;</li><li>将分数乘以values；</li><li>对权重化后的values求和，得到输出1；</li><li>对其余的输入，重复第4-7步。</li></ol><blockquote><p>注意：实际上，这些数学运算都是向量化的，也就是说，所有的输入都会一起经历这些数学运算。我们将会在后面的代码部分看到。</p></blockquote><h4 id="第一步准备输入">第一步：准备输入</h4><figure><img src="/img/nlp29_1.png" alt="准备数据" /><figcaption aria-hidden="true">准备数据</figcaption></figure><p>在这个教程中，我们从3个输入开始，每个输入的维数为4。</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">Input</span> <span class="hljs-number">1</span>: <span class="hljs-selector-attr">[1, 0, 1, 0]</span> <br><span class="hljs-selector-tag">Input</span> <span class="hljs-number">2</span>: <span class="hljs-selector-attr">[0, 2, 0, 2]</span><br><span class="hljs-selector-tag">Input</span> <span class="hljs-number">3</span>: <span class="hljs-selector-attr">[1, 1, 1, 1]</span><br></code></pre></td></tr></table></figure><h4 id="第二步初始化权重">第二步：初始化权重</h4><p>每个输入必须由三个表示（看下图）。这些输入被称作<code>key</code>（橙色），<code>query</code>（红色）<code>value</code>（紫色）。在这个例子中，我们假设我们想要的表示维数为3。因为每个输入的维数为4，这就意味着每个权重的形状为4×3。</p><blockquote><p>注意：我们稍后会看到<code>value</code>的维数也是output的维数。</p></blockquote><figure><img src="/img/nlp29_2.gif"alt="从每个输入中获取key，value，query的表示" /><figcaptionaria-hidden="true">从每个输入中获取key，value，query的表示</figcaption></figure><p>为了获取这些表示，每个输入（绿色）会乘以一个权重的集合得到<code>keys</code>，乘以一个权重的集合得到<code>queries</code>，乘以一个权重的集合得到<code>values</code>。在我们的例子中，我们初始化三个权重的集合如下。</p><p><code>key</code>的权重：</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs inform7"><span class="hljs-comment">[<span class="hljs-comment">[0, 0, 1]</span>,</span><br><span class="hljs-comment"> <span class="hljs-comment">[1, 1, 0]</span>,</span><br><span class="hljs-comment"> <span class="hljs-comment">[0, 1, 0]</span>,</span><br><span class="hljs-comment"> <span class="hljs-comment">[1, 1, 0]</span>]</span><br></code></pre></td></tr></table></figure><p><code>query</code>的权重：</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs inform7"><span class="hljs-comment">[<span class="hljs-comment">[1, 0, 1]</span>,</span><br><span class="hljs-comment"> <span class="hljs-comment">[1, 0, 0]</span>,</span><br><span class="hljs-comment"> <span class="hljs-comment">[0, 0, 1]</span>,</span><br><span class="hljs-comment"> <span class="hljs-comment">[0, 1, 1]</span>]</span><br></code></pre></td></tr></table></figure><p><code>value</code>的权重：</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs inform7"><span class="hljs-comment">[<span class="hljs-comment">[0, 2, 0]</span>,</span><br><span class="hljs-comment"> <span class="hljs-comment">[0, 3, 0]</span>,</span><br><span class="hljs-comment"> <span class="hljs-comment">[1, 0, 3]</span>,</span><br><span class="hljs-comment"> <span class="hljs-comment">[1, 1, 0]</span>]</span><br></code></pre></td></tr></table></figure><blockquote><p>注意：在神经网络设置中，这些权重通常都是一些小的数字，利用随机分布，比如Gaussian,Xavier and Kaiming分布，随机初始化。在训练开始前已经完成初始化。</p></blockquote><h3id="第三步获取keyquery和value">第三步：获取<code>key</code>，<code>query</code>和<code>value</code>；</h3><p>现在我们有了3个权重的集合，让我们来给每个输入获取<code>key</code>，<code>query</code>和<code>value</code>。</p><p>第1个输入的<code>key</code>表示：</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs inform7">               <span class="hljs-comment">[0, 0, 1]</span><br><span class="hljs-comment">[1, 0, 1, 0]</span> x <span class="hljs-comment">[1, 1, 0]</span> = <span class="hljs-comment">[0, 1, 1]</span><br>               <span class="hljs-comment">[0, 1, 0]</span><br>               <span class="hljs-comment">[1, 1, 0]</span><br></code></pre></td></tr></table></figure><p>利用相同的权重集合获取第2个输入的<code>key</code>表示：</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs inform7">               <span class="hljs-comment">[0, 0, 1]</span><br><span class="hljs-comment">[0, 2, 0, 2]</span> x <span class="hljs-comment">[1, 1, 0]</span> = <span class="hljs-comment">[4, 4, 0]</span><br>               <span class="hljs-comment">[0, 1, 0]</span><br>               <span class="hljs-comment">[1, 1, 0]</span><br></code></pre></td></tr></table></figure><p>利用相同的权重集合获取第3个输入的<code>key</code>表示：</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs inform7">               <span class="hljs-comment">[0, 0, 1]</span><br><span class="hljs-comment">[1, 1, 1, 1]</span> x <span class="hljs-comment">[1, 1, 0]</span> = <span class="hljs-comment">[2, 3, 1]</span><br>               <span class="hljs-comment">[0, 1, 0]</span><br>               <span class="hljs-comment">[1, 1, 0]</span><br></code></pre></td></tr></table></figure><p>更快的方式是将这些运算用向量来描述：</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs inform7">               <span class="hljs-comment">[0, 0, 1]</span><br><span class="hljs-comment">[1, 0, 1, 0]</span>   <span class="hljs-comment">[1, 1, 0]</span>   <span class="hljs-comment">[0, 1, 1]</span><br><span class="hljs-comment">[0, 2, 0, 2]</span> x <span class="hljs-comment">[0, 1, 0]</span> = <span class="hljs-comment">[4, 4, 0]</span><br><span class="hljs-comment">[1, 1, 1, 1]</span>   <span class="hljs-comment">[1, 1, 0]</span>   <span class="hljs-comment">[2, 3, 1]</span><br></code></pre></td></tr></table></figure><figure><img src="/img/nlp29_3.gif" alt="获取key表示" /><figcaption aria-hidden="true">获取key表示</figcaption></figure><p>让我们用相同的操作来获取每个输入的<code>value</code>表示：</p><figure><img src="/img/nlp29_4.gif" alt="获取value" /><figcaption aria-hidden="true">获取value</figcaption></figure><p>最后是<code>query</code>的表示：</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs inform7">               <span class="hljs-comment">[1, 0, 1]</span><br><span class="hljs-comment">[1, 0, 1, 0]</span>   <span class="hljs-comment">[1, 0, 0]</span>   <span class="hljs-comment">[1, 0, 2]</span><br><span class="hljs-comment">[0, 2, 0, 2]</span> x <span class="hljs-comment">[0, 0, 1]</span> = <span class="hljs-comment">[2, 2, 2]</span><br><span class="hljs-comment">[1, 1, 1, 1]</span>   <span class="hljs-comment">[0, 1, 1]</span>   <span class="hljs-comment">[2, 1, 3]</span><br></code></pre></td></tr></table></figure><figure><img src="/img/nlp29_5.gif" alt="获取query" /><figcaption aria-hidden="true">获取query</figcaption></figure><blockquote><p>注意：实际上，一个偏重向量也许会加到矩阵相乘后的结果。</p></blockquote><h4id="第四步为第1个输入计算注意力分数">第四步：为第1个输入计算注意力分数</h4><figure><img src="/img/nlp29_6.gif" alt="为第1个输入计算注意力分数（蓝色）" /><figcaptionaria-hidden="true">为第1个输入计算注意力分数（蓝色）</figcaption></figure><p>为了获取注意力分数，我们从输入1的<code>query</code>（红色）和所有<code>keys</code>（橙色）的点积开始。因为有3个<code>key</code>表示（这是由于我们有3个输入），我们得到3个注意力分数（蓝色）。</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs inform7">            <span class="hljs-comment">[0, 4, 2]</span><br><span class="hljs-comment">[1, 0, 2]</span> x <span class="hljs-comment">[1, 4, 3]</span> = <span class="hljs-comment">[2, 4, 4]</span><br>            <span class="hljs-comment">[1, 0, 1]</span><br></code></pre></td></tr></table></figure><p>注意到我们只用了输入的<code>query</code>。后面我们会为其他的<code>queries</code>重复这些步骤。</p><h4 id="第五步计算softmax">第五步：计算softmax</h4><figure><img src="/img/nlp29_7.gif" alt="对注意力分数进行softmax运算" /><figcaption aria-hidden="true">对注意力分数进行softmax运算</figcaption></figure><p>对这些注意力分数进行softmax函数运算（蓝色部分）。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">softmax</span>([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>]) =<span class="hljs-meta"> [0.0, 0.5, 0.5]</span><br></code></pre></td></tr></table></figure><h4 id="第六步-将分数乘以values">第六步： 将分数乘以values</h4><figure><img src="/img/nlp29_8.gif"alt="将value（紫色）和score（蓝色）相乘得到权重化value的表示" /><figcaptionaria-hidden="true">将value（紫色）和score（蓝色）相乘得到权重化value的表示</figcaption></figure><p>将每个输入（绿色）的softmax作用后的注意力分数乘以各自对应的<code>value</code>（紫色）。这会产生3个向量（黄色）。在这个教程中，我们把它们称作<code>权重化value</code>。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">1</span>: <span class="hljs-number">0</span>.<span class="hljs-number">0</span> *<span class="hljs-meta"> [1, 2, 3] = [0.0, 0.0, 0.0]</span><br><span class="hljs-attribute">2</span>: <span class="hljs-number">0</span>.<span class="hljs-number">5</span> *<span class="hljs-meta"> [2, 8, 0] = [1.0, 4.0, 0.0]</span><br><span class="hljs-attribute">3</span>: <span class="hljs-number">0</span>.<span class="hljs-number">5</span> *<span class="hljs-meta"> [2, 6, 3] = [1.0, 3.0, 1.5]</span><br></code></pre></td></tr></table></figure><h4id="第七步对权重化后的values求和得到输出1">第七步：对权重化后的values求和，得到输出1</h4><figure><img src="/img/nlp29_9.gif" alt="将权重后value（黄色）相加得到输出1" /><figcaptionaria-hidden="true">将权重后value（黄色）相加得到输出1</figcaption></figure><p>将<code>权重后value</code>按元素相加得到输出1：</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs excel">  [<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>]<br>+ [<span class="hljs-number">1.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">0.0</span>]<br>+ [<span class="hljs-number">1.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">1.5</span>]<br>-----------------<br>= [<span class="hljs-number">2.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">1.5</span>]<br></code></pre></td></tr></table></figure><p>产生的向量[2.0, 7.0,1.5]（暗绿色）就是输出1，这是基于输入1的<code>query</code>表示与其它的<code>keys</code>，包括它自身的<code>key</code>互相作用的结果。</p><h4 id="第八步对输入23重复第4-7步">第八步：对输入2、3，重复第4-7步</h4><p>既然我们已经完成了输入1，我们重复步骤4-7能得到输出2和3。这个可以留给读者自己尝试，相信聪明的你可以做出来。</p><figure><img src="/img/nlp29_10.gif" alt="重复之前的步骤，得到输出2和3" /><figcaption aria-hidden="true">重复之前的步骤，得到输出2和3</figcaption></figure><h3 id="代码">代码</h3><p>这里有PyTorch的实现代码，PyTorch是一个主流的Python深度学习框架。为了能够很好地使用代码片段中的<code>@</code>运算符,<code>.T</code> and <code>None</code>操作，请确保Python≥3.6，PyTorch≥1.3.1。</p><h4 id="准备输入">1. 准备输入</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>x = [<br>  [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>], <span class="hljs-comment"># Input 1</span><br>  [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>], <span class="hljs-comment"># Input 2</span><br>  [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]  <span class="hljs-comment"># Input 3</span><br> ]<br>x = torch.tensor(x, dtype=torch.float32)<br></code></pre></td></tr></table></figure><h4 id="初始化权重">2. 初始化权重</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python">w_key = [<br>  [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>  [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>  [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>  [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]<br>]<br>w_query = [<br>  [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>  [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>  [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>  [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]<br>]<br>w_value = [<br>  [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>],<br>  [<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>],<br>  [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>],<br>  [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]<br>]<br>w_key = torch.tensor(w_key, dtype=torch.float32)<br>w_query = torch.tensor(w_query, dtype=torch.float32)<br>w_value = torch.tensor(w_value, dtype=torch.float32)<br></code></pre></td></tr></table></figure><h4 id="获取keyquery和value">3.获取<code>key</code>，<code>query</code>和<code>value</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>keys = x @ w_key<br>querys = x @ w_query<br>values = x @ w_value<br><br><span class="hljs-built_in">print</span>(keys)<br><span class="hljs-comment"># tensor([[0., 1., 1.],</span><br><span class="hljs-comment">#         [4., 4., 0.],</span><br><span class="hljs-comment">#         [2., 3., 1.]])</span><br><br><span class="hljs-built_in">print</span>(querys)<br><span class="hljs-comment"># tensor([[1., 0., 2.],</span><br><span class="hljs-comment">#         [2., 2., 2.],</span><br><span class="hljs-comment">#         [2., 1., 3.]])</span><br><br><span class="hljs-built_in">print</span>(values)<br><span class="hljs-comment"># tensor([[1., 2., 3.],</span><br><span class="hljs-comment">#         [2., 8., 0.],</span><br><span class="hljs-comment">#         [2., 6., 3.]])</span><br></code></pre></td></tr></table></figure><h4 id="为第1个输入计算注意力分数">4. 为第1个输入计算注意力分数</h4><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs clean">attn_scores = querys @ keys.T<br><br># tensor([[ <span class="hljs-number">2.</span>,  <span class="hljs-number">4.</span>,  <span class="hljs-number">4.</span>],  # attention scores <span class="hljs-keyword">from</span> Query <span class="hljs-number">1</span><br>#         [ <span class="hljs-number">4.</span>, <span class="hljs-number">16.</span>, <span class="hljs-number">12.</span>],  # attention scores <span class="hljs-keyword">from</span> Query <span class="hljs-number">2</span><br>#         [ <span class="hljs-number">4.</span>, <span class="hljs-number">12.</span>, <span class="hljs-number">10.</span>]]) # attention scores <span class="hljs-keyword">from</span> Query <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><h4 id="计算softmax">5. 计算softmax</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.nn.functional <span class="hljs-keyword">import</span> softmax<br><br>attn_scores_softmax = softmax(attn_scores, dim=-<span class="hljs-number">1</span>)<br><span class="hljs-comment"># tensor([[6.3379e-02, 4.6831e-01, 4.6831e-01],</span><br><span class="hljs-comment">#         [6.0337e-06, 9.8201e-01, 1.7986e-02],</span><br><span class="hljs-comment">#         [2.9539e-04, 8.8054e-01, 1.1917e-01]])</span><br><br><span class="hljs-comment"># For readability, approximate the above as follows</span><br>attn_scores_softmax = [<br>  [<span class="hljs-number">0.0</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>],<br>  [<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>],<br>  [<span class="hljs-number">0.0</span>, <span class="hljs-number">0.9</span>, <span class="hljs-number">0.1</span>]<br>]<br>attn_scores_softmax = torch.tensor(attn_scores_softmax)<br></code></pre></td></tr></table></figure><h4 id="将分数乘以values">6. 将分数乘以values</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">weighted_values = values[:,<span class="hljs-literal">None</span>] * attn_scores_softmax.T[:,:,<span class="hljs-literal">None</span>]<br><br><span class="hljs-comment"># tensor([[[0.0000, 0.0000, 0.0000],</span><br><span class="hljs-comment">#          [0.0000, 0.0000, 0.0000],</span><br><span class="hljs-comment">#          [0.0000, 0.0000, 0.0000]],</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment">#         [[1.0000, 4.0000, 0.0000],</span><br><span class="hljs-comment">#          [2.0000, 8.0000, 0.0000],</span><br><span class="hljs-comment">#          [1.8000, 7.2000, 0.0000]],</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment">#         [[1.0000, 3.0000, 1.5000],</span><br><span class="hljs-comment">#          [0.0000, 0.0000, 0.0000],</span><br><span class="hljs-comment">#          [0.2000, 0.6000, 0.3000]]])</span><br></code></pre></td></tr></table></figure><h4 id="对权重化后的values求和得到输出">7.对权重化后的values求和，得到输出</h4><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs gcode">outputs = weighted_values.sum<span class="hljs-comment">(dim=0)</span><br><br><span class="hljs-attr"># tensor([[2</span><span class="hljs-number">.0000</span>, <span class="hljs-number">7.0000</span>, <span class="hljs-number">1.5000</span>],  <span class="hljs-attr"># Output 1</span><br><span class="hljs-attr">#         [2</span><span class="hljs-number">.0000</span>, <span class="hljs-number">8.0000</span>, <span class="hljs-number">0.0000</span>],  <span class="hljs-attr"># Output 2</span><br><span class="hljs-attr">#         [2</span><span class="hljs-number">.0000</span>, <span class="hljs-number">7.8000</span>, <span class="hljs-number">0.3000</span>]]) <span class="hljs-attr"># Output 3</span><br></code></pre></td></tr></table></figure><blockquote><p>注意：PyTorch已经提供了这个API，名字为<code>nn.MultiheadAttention</code>。但是，这个API需要你提供PyTorch的Tensor形式的key，value，query。还有，这个模块的输出会经历一个线性变换。</p></blockquote><h3 id="自己实现">自己实现？</h3><p>以下是笔者自己写的部分。</p><p>对于不熟悉PyTorch的读者来说，上述的向量操作理解起来有点困难，因此，笔者自己用简单的Python代码实现了一遍上述Self-Attention的过程。</p><p>完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><br>x = [[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>], <span class="hljs-comment"># Input 1</span><br>     [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>], <span class="hljs-comment"># Input 2</span><br>     [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]  <span class="hljs-comment"># Input 3</span><br>    ]<br><br>w_key = [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>        [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]<br>        ]<br><br>w_query = [[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>            [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>            [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>            [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]<br>          ]<br><br>w_value = [[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>],<br>            [<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>],<br>            [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>],<br>            [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]<br>          ]<br><br><br><span class="hljs-comment"># vector dot of two vectors</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">vector_dot</span>(<span class="hljs-params">list1: <span class="hljs-type">List</span>[<span class="hljs-built_in">float</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">int</span>], list2: <span class="hljs-type">List</span>[<span class="hljs-built_in">float</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">float</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">int</span>:<br>    dot_sum = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> element_i, element_j <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(list1, list2):<br>        dot_sum += element_i * element_j<br><br>    <span class="hljs-keyword">return</span> dot_sum<br><br><br><span class="hljs-comment"># get weights matrix by x, using matrix multiplication</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_weights_matrix_by_x</span>(<span class="hljs-params">x, weight_matrix</span>):<br>    x_matrix = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x)):<br>        x_row = []<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(weight_matrix[<span class="hljs-number">0</span>])):<br>            x_row.append(vector_dot(x[i], [_[j] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> weight_matrix]))<br><br>        x_matrix.append(x_row)<br><br>    <span class="hljs-keyword">return</span> x_matrix<br><br><br><span class="hljs-comment"># softmax function</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">x: <span class="hljs-type">List</span>[<span class="hljs-built_in">float</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">float</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">int</span>]:<br>    x_sum = <span class="hljs-built_in">sum</span>([math.exp(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> x])<br>    <span class="hljs-keyword">return</span> [math.exp(_)/x_sum <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> x]<br><br><br>x_key = get_weights_matrix_by_x(x, w_key)<br>x_value = get_weights_matrix_by_x(x, w_value)<br>x_query = get_weights_matrix_by_x(x, w_query)<br><span class="hljs-comment"># print(x_key)</span><br><span class="hljs-comment"># print(x_value)</span><br><span class="hljs-comment"># print(x_query)</span><br><br>outputs = []<br><span class="hljs-keyword">for</span> query <span class="hljs-keyword">in</span> x_query:<br>    score_list = [vector_dot(query, key) <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> x_key]<br>    softmax_score_list = softmax(score_list)<br><br>    weights_list = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(softmax_score_list)):<br>        weights = [softmax_score_list[i] * _ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> x_value[i]]<br>        weights_list.append(weights)<br><br>    output = []<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(weights_list[<span class="hljs-number">0</span>])):<br>        output.append(<span class="hljs-built_in">sum</span>([_[j] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> weights_list]))<br><br>    outputs.append(output)<br><br>pprint(outputs)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-string">[[1.9366210616669624, 6.683105308334811, 1.5950684074995565],</span><br><span class="hljs-string"> [1.9999939663351456, 7.9639915951322156, 0.0539764053125496],</span><br><span class="hljs-string"> [1.9997046127769653, 7.759892254657784, 0.3583892946751152]]</span><br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本文主要讲述了如何一步一步来实现Self-Attention机制，对于想要自己实现算法的读者来说，值得一读。</p><p>本文分享到此结束，感谢大家的阅读~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>Self-Attention</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（二十八）多标签文本分类</title>
    <link href="/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%85%AB%EF%BC%89%E5%A4%9A%E6%A0%87%E7%AD%BE%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    <url>/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%85%AB%EF%BC%89%E5%A4%9A%E6%A0%87%E7%AD%BE%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会讲述如何实现多标签文本分类。</p><h3 id="什么是多标签分类">什么是多标签分类？</h3><p>在分类问题中，我们已经接触过二分类和多分类问题了。所谓二（多）分类问题，指的是y值一共有两（多）个类别，每个样本的y值只能属于其中的一个类别。对于多标签问题而言，每个样本的y值可能不仅仅属于一个类别。</p><p>举个简单的例子，我们平时在给新闻贴标签的时候，就有可能把一篇文章分为经济和文化两个类别。因此，多标签问题在我们的日常生活中也是很常见的。</p><p>对于多标签问题，业界还没有很成熟的解决方法，主要是因为标签之间可能会存在复杂的依赖关系，这种依赖关系现阶段还没有成熟的模型来解决。我们在解决多标签问题的时候，一种办法是认为标签之间互相独立，然后把该问题转化为我们熟悉的二（多）分类问题。</p><p>本文以 <ahref="https://aistudio.baidu.com/aistudio/competition/detail/32?isFromCcf=true">2020语言与智能技术竞赛：事件抽取任务</a>中的数据作为多分类标签的样例数据，借助多标签分类模型来解决。</p><p>整个项目的结构如下图所示：</p><figure><img src="/img/nlp28_1.png" alt="项目结构图" /><figcaption aria-hidden="true">项目结构图</figcaption></figure><p>首先，让我们来看一下样例数据。</p><h3 id="数据分析">数据分析</h3><p>首先，让我们来看一下样例数据的几个例子：</p><blockquote><p>司法行为-起诉|组织关系-裁员最近，一位前便利蜂员工就因公司违规裁员，将便利蜂所在的公司虫极科技（北京）有限公司告上法庭。组织关系-裁员 思科上海大规模裁员人均可获赔100万官方澄清事实组织关系-裁员 日本巨头面临危机，已裁员1000多人，苹果也救不了它！组织关系-裁员|组织关系-解散在硅谷镀金失败的造车新势力们：蔚来裁员、奇点被偷窃、拜腾解散</p></blockquote><p>从上面的例子中我们可以看出，同样的描述文本，有可能会属于多个事件类型。比如上面的<code>在硅谷镀金失败的造车新势力们：蔚来裁员、奇点被偷窃、拜腾解散</code>，该句话中包含了<code>组织关系-裁员</code>和<code>组织关系-解散</code>两个事件类型。</p><p>该数据集中的训练集一共有11958个样本，65个事件类型，我们对该训练集进行简单的数据分析，来看看多事件类型的个数和占比，以及每个事件类型的数量。数据分析的脚本如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-04-09 21:31</span><br><br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./data/multi-classification-train.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br><span class="hljs-comment"># 每个事件类型的数量统计</span><br>event_type_count_dict = defaultdict(<span class="hljs-built_in">int</span>)<br><br><span class="hljs-comment"># 多事件类型数量</span><br>multi_event_type_cnt = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> content:<br>    <span class="hljs-comment"># 事件类型</span><br>    event_types = line.split(<span class="hljs-string">&quot; &quot;</span>, maxsplit=<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]<br><br>    <span class="hljs-comment"># 如果|在事件类型中，则为多事件类型</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;|&quot;</span> <span class="hljs-keyword">in</span> event_types:<br>        multi_event_type_cnt += <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># 对应的每个事件类型数量加1</span><br>    <span class="hljs-keyword">for</span> event_type <span class="hljs-keyword">in</span> event_types.split(<span class="hljs-string">&quot;|&quot;</span>):<br>        event_type_count_dict[event_type] += <span class="hljs-number">1</span><br><br><br><span class="hljs-comment"># 输出结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;多事件类型的样本共有%d个，占比为%.4f。&quot;</span> %(multi_event_type_cnt, multi_event_type_cnt/<span class="hljs-built_in">len</span>(content)))<br><br>pprint(event_type_count_dict)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs actionscript">多事件类型的样本共有<span class="hljs-number">1121</span>个，占比为<span class="hljs-number">0.0937</span>。<br>defaultdict(&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;int&#x27;</span>&gt;,<br>            &#123;<span class="hljs-string">&#x27;交往-会见&#x27;</span>: <span class="hljs-number">98</span>,<br>             <span class="hljs-string">&#x27;交往-感谢&#x27;</span>: <span class="hljs-number">63</span>,<br>             <span class="hljs-string">&#x27;交往-探班&#x27;</span>: <span class="hljs-number">69</span>,<br>             <span class="hljs-string">&#x27;交往-点赞&#x27;</span>: <span class="hljs-number">95</span>,<br>             <span class="hljs-string">&#x27;交往-道歉&#x27;</span>: <span class="hljs-number">149</span>,<br>             <span class="hljs-string">&#x27;产品行为-上映&#x27;</span>: <span class="hljs-number">286</span>,<br>             <span class="hljs-string">&#x27;产品行为-下架&#x27;</span>: <span class="hljs-number">188</span>,<br>             <span class="hljs-string">&#x27;产品行为-发布&#x27;</span>: <span class="hljs-number">1196</span>,<br>             <span class="hljs-string">&#x27;产品行为-召回&#x27;</span>: <span class="hljs-number">287</span>,<br>             <span class="hljs-string">&#x27;产品行为-获奖&#x27;</span>: <span class="hljs-number">139</span>,<br>             <span class="hljs-string">&#x27;人生-产子/女&#x27;</span>: <span class="hljs-number">106</span>,<br>             <span class="hljs-string">&#x27;人生-出轨&#x27;</span>: <span class="hljs-number">32</span>,<br>             <span class="hljs-string">&#x27;人生-分手&#x27;</span>: <span class="hljs-number">118</span>,<br>             <span class="hljs-string">&#x27;人生-失联&#x27;</span>: <span class="hljs-number">105</span>,<br>             <span class="hljs-string">&#x27;人生-婚礼&#x27;</span>: <span class="hljs-number">59</span>,<br>             <span class="hljs-string">&#x27;人生-庆生&#x27;</span>: <span class="hljs-number">133</span>,<br>             <span class="hljs-string">&#x27;人生-怀孕&#x27;</span>: <span class="hljs-number">65</span>,<br>             <span class="hljs-string">&#x27;人生-死亡&#x27;</span>: <span class="hljs-number">811</span>,<br>             <span class="hljs-string">&#x27;人生-求婚&#x27;</span>: <span class="hljs-number">76</span>,<br>             <span class="hljs-string">&#x27;人生-离婚&#x27;</span>: <span class="hljs-number">268</span>,<br>             <span class="hljs-string">&#x27;人生-结婚&#x27;</span>: <span class="hljs-number">294</span>,<br>             <span class="hljs-string">&#x27;人生-订婚&#x27;</span>: <span class="hljs-number">62</span>,<br>             <span class="hljs-string">&#x27;司法行为-举报&#x27;</span>: <span class="hljs-number">98</span>,<br>             <span class="hljs-string">&#x27;司法行为-入狱&#x27;</span>: <span class="hljs-number">155</span>,<br>             <span class="hljs-string">&#x27;司法行为-开庭&#x27;</span>: <span class="hljs-number">105</span>,<br>             <span class="hljs-string">&#x27;司法行为-拘捕&#x27;</span>: <span class="hljs-number">712</span>,<br>             <span class="hljs-string">&#x27;司法行为-立案&#x27;</span>: <span class="hljs-number">82</span>,<br>             <span class="hljs-string">&#x27;司法行为-约谈&#x27;</span>: <span class="hljs-number">266</span>,<br>             <span class="hljs-string">&#x27;司法行为-罚款&#x27;</span>: <span class="hljs-number">224</span>,<br>             <span class="hljs-string">&#x27;司法行为-起诉&#x27;</span>: <span class="hljs-number">174</span>,<br>             <span class="hljs-string">&#x27;灾害/意外-地震&#x27;</span>: <span class="hljs-number">119</span>,<br>             <span class="hljs-string">&#x27;灾害/意外-坍/垮塌&#x27;</span>: <span class="hljs-number">80</span>,<br>             <span class="hljs-string">&#x27;灾害/意外-坠机&#x27;</span>: <span class="hljs-number">104</span>,<br>             <span class="hljs-string">&#x27;灾害/意外-洪灾&#x27;</span>: <span class="hljs-number">48</span>,<br>             <span class="hljs-string">&#x27;灾害/意外-爆炸&#x27;</span>: <span class="hljs-number">73</span>,<br>             <span class="hljs-string">&#x27;灾害/意外-袭击&#x27;</span>: <span class="hljs-number">117</span>,<br>             <span class="hljs-string">&#x27;灾害/意外-起火&#x27;</span>: <span class="hljs-number">204</span>,<br>             <span class="hljs-string">&#x27;灾害/意外-车祸&#x27;</span>: <span class="hljs-number">286</span>,<br>             <span class="hljs-string">&#x27;竞赛行为-夺冠&#x27;</span>: <span class="hljs-number">430</span>,<br>             <span class="hljs-string">&#x27;竞赛行为-晋级&#x27;</span>: <span class="hljs-number">302</span>,<br>             <span class="hljs-string">&#x27;竞赛行为-禁赛&#x27;</span>: <span class="hljs-number">135</span>,<br>             <span class="hljs-string">&#x27;竞赛行为-胜负&#x27;</span>: <span class="hljs-number">1663</span>,<br>             <span class="hljs-string">&#x27;竞赛行为-退役&#x27;</span>: <span class="hljs-number">95</span>,<br>             <span class="hljs-string">&#x27;竞赛行为-退赛&#x27;</span>: <span class="hljs-number">141</span>,<br>             <span class="hljs-string">&#x27;组织关系-停职&#x27;</span>: <span class="hljs-number">87</span>,<br>             <span class="hljs-string">&#x27;组织关系-加盟&#x27;</span>: <span class="hljs-number">335</span>,<br>             <span class="hljs-string">&#x27;组织关系-裁员&#x27;</span>: <span class="hljs-number">142</span>,<br>             <span class="hljs-string">&#x27;组织关系-解散&#x27;</span>: <span class="hljs-number">81</span>,<br>             <span class="hljs-string">&#x27;组织关系-解约&#x27;</span>: <span class="hljs-number">45</span>,<br>             <span class="hljs-string">&#x27;组织关系-解雇&#x27;</span>: <span class="hljs-number">93</span>,<br>             <span class="hljs-string">&#x27;组织关系-辞/离职&#x27;</span>: <span class="hljs-number">580</span>,<br>             <span class="hljs-string">&#x27;组织关系-退出&#x27;</span>: <span class="hljs-number">183</span>,<br>             <span class="hljs-string">&#x27;组织行为-开幕&#x27;</span>: <span class="hljs-number">251</span>,<br>             <span class="hljs-string">&#x27;组织行为-游行&#x27;</span>: <span class="hljs-number">73</span>,<br>             <span class="hljs-string">&#x27;组织行为-罢工&#x27;</span>: <span class="hljs-number">63</span>,<br>             <span class="hljs-string">&#x27;组织行为-闭幕&#x27;</span>: <span class="hljs-number">59</span>,<br>             <span class="hljs-string">&#x27;财经/交易-上市&#x27;</span>: <span class="hljs-number">51</span>,<br>             <span class="hljs-string">&#x27;财经/交易-出售/收购&#x27;</span>: <span class="hljs-number">181</span>,<br>             <span class="hljs-string">&#x27;财经/交易-加息&#x27;</span>: <span class="hljs-number">24</span>,<br>             <span class="hljs-string">&#x27;财经/交易-涨价&#x27;</span>: <span class="hljs-number">58</span>,<br>             <span class="hljs-string">&#x27;财经/交易-涨停&#x27;</span>: <span class="hljs-number">219</span>,<br>             <span class="hljs-string">&#x27;财经/交易-融资&#x27;</span>: <span class="hljs-number">116</span>,<br>             <span class="hljs-string">&#x27;财经/交易-跌停&#x27;</span>: <span class="hljs-number">102</span>,<br>             <span class="hljs-string">&#x27;财经/交易-降价&#x27;</span>: <span class="hljs-number">78</span>,<br>             <span class="hljs-string">&#x27;财经/交易-降息&#x27;</span>: <span class="hljs-number">28</span>&#125;)<br></code></pre></td></tr></table></figure><h3 id="模型训练">模型训练</h3><p>我们利用sklearn模块中的MultiLabelBinarizer进行多标签编码，如果文本所对应的事件类型存在，则将该位置的元素置为1，否则为0。因此，y值为65维的向量，其中1个或多个为1，是该文本（x值）对应一个或多个事件类型。</p><p>我们采用ALBERT对文本进行特征提取，最大文本长度为200，采用的深度学习模型如下：</p><figure><img src="/img/nlp28_2.png" alt="深度学习模型" /><figcaption aria-hidden="true">深度学习模型</figcaption></figure><p>模型训练的脚本（model_trian.py）的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-04-03 18:12</span><br><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MultiLabelBinarizer<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model<br><span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> Adam<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Input, Dense<br><span class="hljs-keyword">from</span> att <span class="hljs-keyword">import</span> Attention<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> GRU, Bidirectional<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">from</span> albert_zh.extract_feature <span class="hljs-keyword">import</span> BertVector<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./data/multi-classification-train.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    train_content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./data/multi-classification-test.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    test_content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br><span class="hljs-comment"># 获取训练集合、测试集的事件类型</span><br>movie_genres = []<br><br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> train_content+test_content:<br>    genres = line.split(<span class="hljs-string">&quot; &quot;</span>, maxsplit=<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>].split(<span class="hljs-string">&quot;|&quot;</span>)<br>    movie_genres.append(genres)<br><br><span class="hljs-comment"># 利用sklearn中的MultiLabelBinarizer进行多标签编码</span><br>mlb = MultiLabelBinarizer()<br>mlb.fit(movie_genres)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;一共有%d种事件类型。&quot;</span> % <span class="hljs-built_in">len</span>(mlb.classes_))<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;event_type.json&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> h:<br>    h.write(json.dumps(mlb.classes_.tolist(), ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br><br><span class="hljs-comment"># 对训练集和测试集的数据进行多标签编码</span><br>y_train = []<br>y_test = []<br><br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> train_content:<br>    genres = line.split(<span class="hljs-string">&quot; &quot;</span>, maxsplit=<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>].split(<span class="hljs-string">&quot;|&quot;</span>)<br>    y_train.append(mlb.transform([genres])[<span class="hljs-number">0</span>])<br><br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> test_content:<br>    genres = line.split(<span class="hljs-string">&quot; &quot;</span>, maxsplit=<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>].split(<span class="hljs-string">&quot;|&quot;</span>)<br>    y_test.append(mlb.transform([genres])[<span class="hljs-number">0</span>])<br><br>y_train = np.array(y_train)<br>y_test = np.array(y_test)<br><br><span class="hljs-built_in">print</span>(y_train.shape)<br><span class="hljs-built_in">print</span>(y_test.shape)<br><br><span class="hljs-comment"># 利用ALBERT对x值（文本）进行编码</span><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;NONE&quot;</span>, max_seq_len=<span class="hljs-number">200</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;begin encoding&#x27;</span>)<br>f = <span class="hljs-keyword">lambda</span> text: bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br><br>x_train = []<br>x_test = []<br><br>process_bar = tqdm(train_content)<br><br><span class="hljs-keyword">for</span> ch, line <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(process_bar, train_content):<br>    movie_intro = line.split(<span class="hljs-string">&quot; &quot;</span>, maxsplit=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]<br>    x_train.append(f(movie_intro))<br><br>process_bar = tqdm(test_content)<br><br><span class="hljs-keyword">for</span> ch, line <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(process_bar, test_content):<br>    movie_intro = line.split(<span class="hljs-string">&quot; &quot;</span>, maxsplit=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]<br>    x_test.append(f(movie_intro))<br><br>x_train = np.array(x_train)<br>x_test = np.array(x_test)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;end encoding&quot;</span>)<br><span class="hljs-built_in">print</span>(x_train.shape)<br><br><br><span class="hljs-comment"># 深度学习模型</span><br><span class="hljs-comment"># 模型结构：ALBERT + 双向GRU + Attention + FC</span><br>inputs = Input(shape=(<span class="hljs-number">200</span>, <span class="hljs-number">312</span>, ), name=<span class="hljs-string">&quot;input&quot;</span>)<br>gru = Bidirectional(GRU(<span class="hljs-number">128</span>, dropout=<span class="hljs-number">0.2</span>, return_sequences=<span class="hljs-literal">True</span>), name=<span class="hljs-string">&quot;bi-gru&quot;</span>)(inputs)<br>attention = Attention(<span class="hljs-number">32</span>, name=<span class="hljs-string">&quot;attention&quot;</span>)(gru)<br>num_class = <span class="hljs-built_in">len</span>(mlb.classes_)<br>output = Dense(num_class, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>, name=<span class="hljs-string">&quot;dense&quot;</span>)(attention)<br>model = Model(inputs, output)<br><br><span class="hljs-comment"># 模型可视化</span><br><span class="hljs-comment"># from keras.utils import plot_model</span><br><span class="hljs-comment"># plot_model(model, to_file=&#x27;multi-label-model.png&#x27;, show_shapes=True)</span><br><br>model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;binary_crossentropy&#x27;</span>,<br>              optimizer=Adam(),<br>              metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br>history = model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=<span class="hljs-number">128</span>, epochs=<span class="hljs-number">10</span>)<br>model.save(<span class="hljs-string">&#x27;event_type.h5&#x27;</span>)<br><br><br><span class="hljs-comment"># 训练结果可视化</span><br><span class="hljs-comment"># 绘制loss和acc图像</span><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>epochs = <span class="hljs-built_in">len</span>(history.history[<span class="hljs-string">&#x27;loss&#x27;</span>])<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;loss&#x27;</span>], label=<span class="hljs-string">&#x27;loss&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;val_loss&#x27;</span>], label=<span class="hljs-string">&#x27;val_loss&#x27;</span>)<br>plt.legend()<br><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>epochs = <span class="hljs-built_in">len</span>(history.history[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;accuracy&#x27;</span>], label=<span class="hljs-string">&#x27;acc&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;val_accuracy&#x27;</span>], label=<span class="hljs-string">&#x27;val_acc&#x27;</span>)<br>plt.legend()<br>plt.savefig(<span class="hljs-string">&quot;loss_acc.png&quot;</span>)<br></code></pre></td></tr></table></figure><p>训练过程输出内容如下：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs less">一共有<span class="hljs-number">65</span>种事件类型。<br>(<span class="hljs-number">11958</span>, <span class="hljs-number">65</span>)<br>(<span class="hljs-number">1498</span>, <span class="hljs-number">65</span>)<br><span class="hljs-selector-tag">I</span>:<span class="hljs-selector-tag">BERT_VEC</span>:<span class="hljs-selector-attr">[graph:opt:128]</span>:<span class="hljs-selector-tag">load</span> <span class="hljs-selector-tag">parameters</span> <span class="hljs-selector-tag">from</span> <span class="hljs-selector-tag">checkpoint</span>...<br><span class="hljs-selector-tag">I</span>:<span class="hljs-selector-tag">BERT_VEC</span>:<span class="hljs-selector-attr">[graph:opt:130]</span>:<span class="hljs-selector-tag">freeze</span>...<br><span class="hljs-selector-tag">I</span>:<span class="hljs-selector-tag">BERT_VEC</span>:<span class="hljs-selector-attr">[graph:opt:133]</span>:<span class="hljs-selector-tag">optimize</span>...<br><span class="hljs-selector-tag">I</span>:<span class="hljs-selector-tag">BERT_VEC</span>:<span class="hljs-selector-attr">[graph:opt:144]</span>:<span class="hljs-selector-tag">write</span> <span class="hljs-selector-tag">graph</span> <span class="hljs-selector-tag">to</span> <span class="hljs-selector-tag">a</span> <span class="hljs-selector-tag">tmp</span> <span class="hljs-selector-tag">file</span>: ./<span class="hljs-selector-tag">tmp_graph11</span><br><span class="hljs-number">100%</span>|██████████| <span class="hljs-number">11958</span>/<span class="hljs-number">11958</span> <span class="hljs-selector-attr">[02:47&lt;00:00, 71.39it/s]</span><br><span class="hljs-number">100%</span>|██████████| <span class="hljs-number">1498</span>/<span class="hljs-number">1498</span> <span class="hljs-selector-attr">[00:20&lt;00:00, 72.54it/s]</span><br><span class="hljs-selector-tag">end</span> <span class="hljs-selector-tag">encoding</span><br>(<span class="hljs-number">11958</span>, <span class="hljs-number">200</span>, <span class="hljs-number">312</span>)<br><span class="hljs-selector-tag">Train</span> <span class="hljs-selector-tag">on</span> <span class="hljs-number">11958</span> <span class="hljs-selector-tag">samples</span>, <span class="hljs-selector-tag">validate</span> <span class="hljs-selector-tag">on</span> <span class="hljs-number">1498</span> <span class="hljs-selector-tag">samples</span><br></code></pre></td></tr></table></figure><p>在最终的epoch上，训练集上的acuuracy为0.9966，测试集上的acuuracy为0.9964。训练结果的loss和acc曲线如下：</p><figure><img src="/img/nlp28_3.png" alt="模型的训练效果" /><figcaption aria-hidden="true">模型的训练效果</figcaption></figure><p>从上述结果看，多标签分类的模型效果还是相当不错的。</p><h3 id="模型预测">模型预测</h3><p>我们利用下面的模型预测脚本（model_predict.py）对新的测试集数据进行验证，脚本代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-04-03 21:50</span><br><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><br><span class="hljs-keyword">from</span> att <span class="hljs-keyword">import</span> Attention<br><span class="hljs-keyword">from</span> albert_zh.extract_feature <span class="hljs-keyword">import</span> BertVector<br>load_model = load_model(<span class="hljs-string">&quot;event_type.h5&quot;</span>, custom_objects=&#123;<span class="hljs-string">&quot;Attention&quot;</span>: Attention&#125;)<br><br><span class="hljs-comment"># 预测语句</span><br>text = <span class="hljs-string">&quot;北京时间6月7日，中国男足在广州天河体育场与菲律宾进行了一场热身赛，最终国足以2-0击败了对手，里皮也赢得了再度执教国足后的首场比赛胜利！&quot;</span><br>text = text.replace(<span class="hljs-string">&quot;\n&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&quot;\r&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&quot;\t&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)<br><br>labels = []<br><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;NONE&quot;</span>, max_seq_len=<span class="hljs-number">200</span>)<br><br><span class="hljs-comment"># 将句子转换成向量</span><br>vec = bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br>x_train = np.array([vec])<br><br><span class="hljs-comment"># 模型预测</span><br>predicted = load_model.predict(x_train)[<span class="hljs-number">0</span>]<br><br>indices = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(predicted)) <span class="hljs-keyword">if</span> predicted[i] &gt; <span class="hljs-number">0.5</span>]<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;event_type.json&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> g:<br>    movie_genres = json.loads(g.read())<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;预测语句: %s&quot;</span> % text)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;预测事件类型: %s&quot;</span> % <span class="hljs-string">&quot;|&quot;</span>.join([movie_genres[index] <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> indices]))<br></code></pre></td></tr></table></figure><p>其中的几个样本的预测结果如下：</p><blockquote><p>预测语句:北京时间6月7日，中国男足在广州天河体育场与菲律宾进行了一场热身赛，最终国足以2-0击败了对手，里皮也赢得了再度执教国足后的首场比赛胜利！预测事件类型: 竞赛行为-胜负</p></blockquote><blockquote><p>预测语句: 巴西亚马孙雨林大火持续多日，引发全球关注。 预测事件类型:灾害/意外-起火</p></blockquote><blockquote><p>预测语句: 19里加大师赛资格赛前两天战报中国选手8人晋级6人遭淘汰2人弃赛 预测事件类型: 竞赛行为-晋级</p></blockquote><blockquote><p>预测语句: 日本电车卡车相撞，车头部分脱轨并倾斜，现场起火浓烟滚滚预测事件类型: 灾害/意外-车祸</p></blockquote><blockquote><p>预测语句: 截止到11日13：30，因台风致浙江32人死亡，16人失联。具体如下：永嘉县岩坦镇山早村23死9失联，乐清6死，临安区岛石镇银坑村3死4失联，临海市东塍镇王加山村3失联。预测事件类型: 人生-失联|人生-死亡</p></blockquote><blockquote><p>预测语句: 定位B端应用，BeBop发布Quest专属版柔性VR手套 预测事件类型:产品行为-发布</p></blockquote><blockquote><p>预测语句:8月17日。凌晨3点20分左右，济南消防支队领秀城中队接到指挥中心调度命令，济南市中区中海环宇城往南方向发生车祸，有人员被困。预测事件类型: 灾害/意外-车祸</p></blockquote><blockquote><p>预测语句:注意！济南可能有雷电事故｜英才学院14.9亿被收购｜八里桥蔬菜市场今日拆除，未来将建新的商业综合体预测事件类型: 财经/交易-出售/收购</p></blockquote><blockquote><p>预测语句:昨天18：30，陕西宁强县胡家坝镇向家沟村三组发生山体坍塌，5人被埋。当晚，3人被救出，其中1人在医院抢救无效死亡，2人在送医途中死亡。今天凌晨，另外2人被发现，已无生命迹象。预测事件类型: 人生-死亡|灾害/意外-坍/垮塌</p></blockquote><h3 id="总结">总结</h3><p>本项目已经上传至Github项目，网址为：<ahref="https://github.com/percent4/multi-label-classification-4-event-type">https://github.com/percent4/multi-label-classification-4-event-type</a>。</p><p>后续有机会再给大家介绍更多多标签分类相关的问题，欢迎大家关注~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>文本分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（二十七）开放领域的三元组抽取的一次尝试</title>
    <link href="/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%83%EF%BC%89%E5%BC%80%E6%94%BE%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%89%E5%85%83%E7%BB%84%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/"/>
    <url>/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%83%EF%BC%89%E5%BC%80%E6%94%BE%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%89%E5%85%83%E7%BB%84%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>当我写下这篇文章的时候，我的内心是激动的，这是因为，自从去年6月份写了文章<ahref="https://percent4.github.io/%E5%88%A9%E7%94%A8%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E6%9E%84%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/">利用关系抽取构建知识图谱的一次尝试</a>后，我就一直在试图寻找一种在开放领域能够进行三元组抽取的办法，也有很多读者问过我这方面的问题，今天，笔者将给出答复，虽然不是正确答案（现在也没有正确答案），但至少，我写下了自己的答案。</p><p>离我想出这个抽取系统虽然才过去不久，但我的心情，已经由开始的激动狂喜，转化为后来的平淡，直到现在的不满。事实证明，开放领域的三元组抽取实在太难，以笔者个人的努力和智商，实在没法给出完美的答案，所以，文章的题目是尝试，仅仅作为尝试，并不能解决好这个问题。但，我还是想写些什么，希望能够对笔者有一点点启发，同时，也是对自己近半年的探寻做一个总结。</p><p>关于三元组抽取的基本介绍和常用办法，笔者之前已经在不少文章中描述过，这里不再过多介绍，有兴趣的读者可以参考文章<ahref="https://percent4.github.io/%E5%88%A9%E7%94%A8%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E6%9E%84%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/">利用关系抽取构建知识图谱的一次尝试</a>和 <ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%85%AD%EF%BC%89%E9%99%90%E5%AE%9A%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%89%E5%85%83%E7%BB%84%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/">NLP（二十六）限定领域的三元组抽取的一次尝试</a>。本文将会介绍笔者在开放领域做三元组抽取的一次尝试。</p><p>本项目已经开源至Github，文章最后会给出相应的网址。本项目的项目结构如下：</p><figure><img src="/img/nlp27_1.png" alt="项目结构" /><figcaption aria-hidden="true">项目结构</figcaption></figure><p>本项目一共分为四部分，主要模块介绍如下：</p><ul><li><p>extract_example:利用训练好的模型对基本小说和新闻进行三元组抽取，形成知识图谱例子；</p></li><li><p>sequence_labeling：训练标注，对标注的实体数据进行序列标注算法训练；</p></li><li><p>spo_tagging_platform：标注平台，标注subject，predicate和object以及三元组是否有效；</p></li><li><p>text_classification：文本分类，用于判别抽取的三元组是否有效。</p><p>本项目的抽取系统流程图如下：</p></li></ul><figure><img src="/img/nlp27_2.png" alt="抽取系统流程图" /><figcaption aria-hidden="true">抽取系统流程图</figcaption></figure><p>接下来笔者将逐一介绍。</p><h3 id="标注平台">标注平台</h3><p>笔者用tornado搭建了简易的标注平台，在标注页面中，标注人员需要输入标注的句子（句子级别的抽取）以及subject，predicate，object，点击“显示SPO”，将有效的三元组标注为1，无效的三元组标注为0。之所以采取这种标注方法，是因为我们可以在句子中标注subject，predicate，object，这些标注的实体就会形成可能的三元组组合，再利用0，1来标注这种三元组是否有效，这样就能做到在开放领域进行三元组抽取。</p><p>一个简单的标注例子如下：</p><figure><img src="/img/nlp27_3.png" alt="标注例子" /><figcaption aria-hidden="true">标注例子</figcaption></figure><p>再对以上的标注结果做一些说明，我们的标注是以句子为单位，进行句子级别的标注，不同要素在标注的时候加#区分，标注了两个subject，1个predicate（共用）和2个object，其中predidate是这些subject和object公用的，所以只需要标注一次。这样，点击“显示SPO”，一共会显示4个三元组，s，p，o用#隔开，0，1表示是否是有效三元组，默认为0。</p><p>笔者利用空余时间，一共标注了3200多个样本，对于序列标注来说，就是3200多个样本，对于文本分类来说，就是9000多个样本了。</p><h3 id="序列标注">序列标注</h3><p>对于上述的标注例子，会形成如下的标注序列：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs bash">美B-SUBJ<br>国I-SUBJ<br>疾I-SUBJ<br>控I-SUBJ<br>中I-SUBJ<br>心I-SUBJ<br>主B-PRED<br>任I-PRED<br>雷B-OBJ<br>德I-OBJ<br>菲I-OBJ<br>尔I-OBJ<br>德I-OBJ<br>（O<br>左O<br>圈O<br>）O<br>和O<br>美B-SUBJ<br>国I-SUBJ<br>国I-SUBJ<br>立I-SUBJ<br>卫I-SUBJ<br>生I-SUBJ<br>研I-SUBJ<br>究I-SUBJ<br>院I-SUBJ<br>过I-SUBJ<br>敏I-SUBJ<br>和I-SUBJ<br>传I-SUBJ<br>染I-SUBJ<br>病I-SUBJ<br>研I-SUBJ<br>究I-SUBJ<br>所I-SUBJ<br>主B-PRED<br>任I-PRED<br>福B-OBJ<br>西I-OBJ<br>（O<br>右O<br>圈O<br>）O<br></code></pre></td></tr></table></figure><p>将数据集分为训练集和测试集，比例为8：2.采用经典的深度学习模型ALBERT+Bi-LSTM+CRF进行实体识别，设置最大文本长度为128，训练100个epoch。关于该模型的介绍，可以参考文章<ahref="https://blog.csdn.net/jclian91/article/details/104826655">NLP（二十五）实现ALBERT+Bi-LSTM+CRF模型</a>。</p><p>在测试集上的训练结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">accuracy</span>:  <span class="hljs-number">93</span>.<span class="hljs-number">69</span>%; precision:  <span class="hljs-number">76</span>.<span class="hljs-number">26</span>%; recall:  <span class="hljs-number">82</span>.<span class="hljs-number">33</span>%; FB1:  <span class="hljs-number">79</span>.<span class="hljs-number">18</span><br><span class="hljs-attribute">OBJ</span>: precision:  <span class="hljs-number">80</span>.<span class="hljs-number">47</span>%; recall:  <span class="hljs-number">88</span>.<span class="hljs-number">81</span>%; FB1:  <span class="hljs-number">84</span>.<span class="hljs-number">44</span>  <span class="hljs-number">927</span><br><span class="hljs-attribute">PRED</span>: precision:  <span class="hljs-number">76</span>.<span class="hljs-number">89</span>%; recall:  <span class="hljs-number">83</span>.<span class="hljs-number">69</span>%; FB1:  <span class="hljs-number">80</span>.<span class="hljs-number">14</span>  <span class="hljs-number">1021</span><br><span class="hljs-attribute">SUBJ</span>: precision:  <span class="hljs-number">71</span>.<span class="hljs-number">72</span>%; recall:  <span class="hljs-number">75</span>.<span class="hljs-number">32</span>%; FB1:  <span class="hljs-number">73</span>.<span class="hljs-number">48</span>  <span class="hljs-number">983</span><br></code></pre></td></tr></table></figure><p>在测试集上的总体F1值接近80%。</p><h3 id="文本分类">文本分类</h3><p>关于文本分类，需要多做一些说明。</p><p>虽然本文的题目是关于在开发领域的三元组抽取的尝试，但实际我在标注的时候，还是更多地标注人物头衔，人物关系，公司与人的关系，影视剧主演、导演信息等。形成的有效的文本分类的样本为9000多个，一共有关系1365个，数量最多的前20个关系如下图：</p><figure><img src="/img/nlp27_4.png" alt="数量最多的20个关系" /><figcaption aria-hidden="true">数量最多的20个关系</figcaption></figure><p>以上述的标注数据为例，形成的标注数据如下：</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs clean">美国疾控中心#主任#雷德菲尔德#<span class="hljs-number">1</span>#美国疾控中心主任雷德菲尔德（左圈）和美国国立卫生研究院过敏和传染病研究所主任福西（右圈）<br>美国疾控中心#主任#福西#<span class="hljs-number">0</span>#美国疾控中心主任雷德菲尔德（左圈）和美国国立卫生研究院过敏和传染病研究所主任福西（右圈）<br>美国国立卫生研究院过敏和传染病研究所#主任#雷德菲尔德#<span class="hljs-number">0</span>#美国疾控中心主任雷德菲尔德（左圈）和美国国立卫生研究院过敏和传染病研究所主任福西（右圈）<br>美国国立卫生研究院过敏和传染病研究所#主任#福西#<span class="hljs-number">1</span>#美国疾控中心主任雷德菲尔德（左圈）和美国国立卫生研究院过敏和传染病研究所主任福西（右圈）<br></code></pre></td></tr></table></figure><p>在实际模型训练的时候，会将原文中的subject用S*len(subject)代替，predicate用P，object用O。</p><p>将数据集分为训练集和测试集，比例为8：2。采用经典的深度学习模型ALBERT+Bi-GRU+ATT+FC，设置文本的最大长度为为128，训练30个epoch，采用earlystopping机制，训练过程的loss和acc图像如下：</p><figure><img src="/img/nlp27_5.png" alt="训练过程的loss和acc图像" /><figcaption aria-hidden="true">训练过程的loss和acc图像</figcaption></figure><p>最终在测试集上的accuracy约为96%。</p><h3 id="新数据进行三元组抽取">新数据进行三元组抽取</h3><p>上述的模型训练完毕后，我们就可以将其封装成HTTP服务。对于新输入的句子，我们先利用序列标注模型预测出其中的subject，predicate和object，组合成三元组与句子的拼接，输入到文本分类模型，判别该三元组是否有效，0为无效，1为有效。</p><p>从网上找几个例子，预测的结果如下：</p><figure><img src="/img/nlp27_6.png" alt="例子1" /><figcaption aria-hidden="true">例子1</figcaption></figure><figure><img src="/img/nlp27_7.png" alt="例子2" /><figcaption aria-hidden="true">例子2</figcaption></figure><figure><img src="/img/nlp27_8.png" alt="例子3" /><figcaption aria-hidden="true">例子3</figcaption></figure><p><code>extract_example</code>目录中为抽取的效果，包括几本小说和一些新闻上的效果，关于这方面的演示，可以参考另一个项目：<ahref="https://github.com/percent4/knowledge_graph_demo">https://github.com/percent4/knowledge_graph_demo</a>。也可以参考文章<ahref="https://percent4.github.io/2023/07/09/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA%E4%B8%BE%E4%BE%8B/">知识图谱构建举例</a>中给出的几个知识图谱的建构的例子。</p><h3 id="总结">总结</h3><p>本文写的过程较为简单，也没有代码，这是因为笔者在之前的文章中做了大量的铺垫，主要是集中在模型方面。况且，这个项目比较大，也不适合在这里详细讲述，笔者只在这里给出思路和大概的处理流程，具体的实现代码可以参考下方的Github地址。</p><p>在实际的抽取过程中，一些句子也存在抽取出大量无用的三元组的情况，导致召回率高，这是因为本项目针对的是开放领域的三元组抽取，因此效果比不会有想象中的那么好，提升抽取效果的办法如下：</p><ul><li><p>增加数据标注量，目前序列标注算法的样本仅3200多个；</p></li><li><p>模型方面：现在是pipeline形式，各自的效果还行，但总体上不如Joint形式好；</p></li><li><p>对于自己想抽的其他三元组的情形，建议增加这方面的标注；</p></li><li><p>文本预测耗时长（该问题已经解决）。</p><p>本项目作为笔者在开放领域的三元组抽取的一次尝试，在此之前关于这方面的文章或者项目还很少，因此可以说是探索阶段。</p><p>源码和数据已经在Github项目中给出，网址为 <ahref="https://github.com/percent4/spo_extract_platform">https://github.com/percent4/spo_extract_platform</a>。</p><p>本人的微信公众号为<code>NLP奇幻之旅</code>，欢迎关注~</p></li></ul><h3 id="参考文献">参考文献</h3><ol type="1"><li>利用关系抽取构建知识图谱的一次尝试：https://www.cnblogs.com/jclian91/p/11107323.html</li><li>NLP（二十六）限定领域的三元组抽取的一次尝试：https://blog.csdn.net/jclian91/article/details/104874488</li><li>NLP（二十五）实现ALBERT+Bi-LSTM+CRF模型：https://blog.csdn.net/jclian91/article/details/104826655</li><li>知识图谱构建举例：https://blog.csdn.net/jclian91/article/details/104685424</li><li>NLP（二十一）人物关系抽取的一次实战：https://blog.csdn.net/jclian91/article/details/104380371</li><li>《知识图谱 方法、实践与应用》王昊奋、漆桂林、陈华钧著，中国工信出版集团、电子工业出版社出版。</li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>关系抽取</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（二十六）限定领域的三元组抽取的一次尝试</title>
    <link href="/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%85%AD%EF%BC%89%E9%99%90%E5%AE%9A%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%89%E5%85%83%E7%BB%84%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/"/>
    <url>/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%85%AD%EF%BC%89%E9%99%90%E5%AE%9A%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%89%E5%85%83%E7%BB%84%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会介绍笔者在2019语言与智能技术竞赛的三元组抽取比赛方面的一次尝试。由于该比赛早已结束，笔者当时也没有参加这个比赛，因此没有测评成绩，我们也只能拿到训练集和验证集。但是，这并不耽误我们在这方面做实验。</p><h3 id="比赛介绍">比赛介绍</h3><p>该比赛的网址为：<ahref="http://lic2019.ccf.org.cn/kg">http://lic2019.ccf.org.cn/kg</a>，该比赛主要是从给定的句子中提取三元组，给定schema约束集合及句子sent，其中schema定义了关系P以及其对应的主体S和客体O的类别，例如（S_TYPE:人物，P:妻子，O_TYPE:人物）、（S_TYPE:公司，P:创始人，O_TYPE:人物）等。比如下面的例子：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;九玄珠是在纵横中文网连载的一部小说，作者是龙马&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;spo_list&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;九玄珠&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;连载网站&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;纵横中文网&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;九玄珠&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;作者&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;龙马&quot;</span><span class="hljs-punctuation">]</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>该比赛一共提供了20多万标注质量很高的三元组，其中17万训练集，2万验证集和2万测试集，实体关系（schema）50个。</p><p>在具体介绍笔者的思路和实战前，先介绍下本次任务的处理思路：</p><figure><img src="/img/nlp26_1.png" alt="任务的处理思路" /><figcaption aria-hidden="true">任务的处理思路</figcaption></figure><p>首先是对拿到的数据进行数据分析，包括统计每个句子的长度及三元组数量，每种关系的数量分布情况。接着，对数据单独走序列标注模型和关系分析模型。最后在提取三元组的时候，用Pipeline模型，先用序列标注模型预测句子中的实体，再对实体（加上句子）走关系分类模型，预测实体的关系，最后形成有效的三元组。</p><p>接下来笔者将逐一介绍，项目结构图如下：</p><figure><img src="/img/nlp26_2.png" alt="项目结构图" /><figcaption aria-hidden="true">项目结构图</figcaption></figure><h3 id="数据分析">数据分析</h3><p>我们能拿到的只有训练集和验证集，没有测试集。我们对训练集做数据分析，训练集数据文件为train_data.json。</p><p>数据分析会统计训练集中每个句子的长度及三元组数量，还有关系的分布图，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-03-12 21:52</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>plt.figure(figsize=(<span class="hljs-number">18</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">100</span>)   <span class="hljs-comment"># 输出图片大小为1800*800</span><br><span class="hljs-comment"># Mac系统设置中文字体支持</span><br>plt.rcParams[<span class="hljs-string">&quot;font.family&quot;</span>] = <span class="hljs-string">&#x27;Arial Unicode MS&#x27;</span><br><br><br><span class="hljs-comment"># 加载数据集</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">filename</span>):<br>    D = []<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        content = f.readlines()<br><br>    content = [_.replace(<span class="hljs-string">&#x27; &#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>).replace(<span class="hljs-string">&#x27;\u3000&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>).replace(<span class="hljs-string">&#x27;\xa0&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>).replace(<span class="hljs-string">&#x27;\u2003&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> content]<br><br>    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> content:<br>        l = json.loads(l)<br>        D.append(&#123;<br>            <span class="hljs-string">&#x27;text&#x27;</span>: l[<span class="hljs-string">&#x27;text&#x27;</span>],<br>            <span class="hljs-string">&#x27;spo_list&#x27;</span>: [<br>                (spo[<span class="hljs-string">&#x27;subject&#x27;</span>], spo[<span class="hljs-string">&#x27;predicate&#x27;</span>], spo[<span class="hljs-string">&#x27;object&#x27;</span>])<br>                <span class="hljs-keyword">for</span> spo <span class="hljs-keyword">in</span> l[<span class="hljs-string">&#x27;spo_list&#x27;</span>]<br>            ]<br>        &#125;)<br>    <span class="hljs-keyword">return</span> D<br><br>filename = <span class="hljs-string">&#x27;../data/train_data.json&#x27;</span><br><br>D = load_data(filename=filename)<br>pprint(D)<br><br><span class="hljs-comment"># 创建text, text_length, spo_num的DataFrame</span><br>text_list = [_[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> D]<br>spo_num = [<span class="hljs-built_in">len</span>(_[<span class="hljs-string">&quot;spo_list&quot;</span>])<span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> D]<br><br>df = pd.DataFrame(&#123;<span class="hljs-string">&quot;text&quot;</span>: text_list, <span class="hljs-string">&quot;spo_num&quot;</span>: spo_num&#125; )<br>df[<span class="hljs-string">&quot;text_length&quot;</span>] = df[<span class="hljs-string">&quot;text&quot;</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x))<br><span class="hljs-built_in">print</span>(df.head())<br><span class="hljs-built_in">print</span>(df.describe())<br><br><span class="hljs-comment"># 绘制spo_num的条形统计图</span><br>pprint(df[<span class="hljs-string">&#x27;spo_num&#x27;</span>].value_counts())<br>label_list = <span class="hljs-built_in">list</span>(df[<span class="hljs-string">&#x27;spo_num&#x27;</span>].value_counts().index)<br>num_list = df[<span class="hljs-string">&#x27;spo_num&#x27;</span>].value_counts().tolist()<br><br><span class="hljs-comment"># 利用Matplotlib模块绘制条形图</span><br>x = <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(num_list))<br>rects = plt.bar(x=x, height=num_list, width=<span class="hljs-number">0.6</span>, color=<span class="hljs-string">&#x27;blue&#x27;</span>, label=<span class="hljs-string">&quot;频数&quot;</span>)<br>plt.ylim(<span class="hljs-number">0</span>, <span class="hljs-number">80000</span>) <span class="hljs-comment"># y轴范围</span><br>plt.ylabel(<span class="hljs-string">&quot;数量&quot;</span>)<br>plt.xticks([index + <span class="hljs-number">0.1</span> <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> x], label_list)<br>plt.xlabel(<span class="hljs-string">&quot;三元组数量&quot;</span>)<br>plt.title(<span class="hljs-string">&quot;三元组频数统计图&quot;</span>)<br><br><span class="hljs-comment"># 条形图的文字说明</span><br><span class="hljs-keyword">for</span> rect <span class="hljs-keyword">in</span> rects:<br>    height = rect.get_height()<br>    plt.text(rect.get_x() + rect.get_width() / <span class="hljs-number">2</span>, height+<span class="hljs-number">1</span>, <span class="hljs-built_in">str</span>(height), ha=<span class="hljs-string">&quot;center&quot;</span>, va=<span class="hljs-string">&quot;bottom&quot;</span>)<br><br><span class="hljs-comment"># plt.show()</span><br>plt.savefig(<span class="hljs-string">&#x27;./spo_num_bar_chart.png&#x27;</span>)<br><br>plt.close()<br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>plt.figure(figsize=(<span class="hljs-number">18</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">100</span>)   <span class="hljs-comment"># 输出图片大小为1800*800</span><br><span class="hljs-comment"># Mac系统设置中文字体支持</span><br>plt.rcParams[<span class="hljs-string">&quot;font.family&quot;</span>] = <span class="hljs-string">&#x27;Arial Unicode MS&#x27;</span><br><br><br><span class="hljs-comment"># 关系统计图</span><br>relation_dict = defaultdict(<span class="hljs-built_in">int</span>)<br><br><span class="hljs-keyword">for</span> spo_dict <span class="hljs-keyword">in</span> D:<br>    <span class="hljs-comment"># print(spo_dict[&quot;spo_list&quot;])</span><br>    <span class="hljs-keyword">for</span> spo <span class="hljs-keyword">in</span> spo_dict[<span class="hljs-string">&quot;spo_list&quot;</span>]:<br>        relation_dict[spo[<span class="hljs-number">1</span>]] += <span class="hljs-number">1</span><br><br>label_list = <span class="hljs-built_in">list</span>(relation_dict.keys())<br>num_list = <span class="hljs-built_in">list</span>(relation_dict.values())<br><br><span class="hljs-comment"># 利用Matplotlib模块绘制条形图</span><br>x = <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(num_list))<br>rects = plt.bar(x=x, height=num_list, width=<span class="hljs-number">0.6</span>, color=<span class="hljs-string">&#x27;blue&#x27;</span>, label=<span class="hljs-string">&quot;频数&quot;</span>)<br>plt.ylim(<span class="hljs-number">0</span>, <span class="hljs-number">80000</span>) <span class="hljs-comment"># y轴范围</span><br>plt.ylabel(<span class="hljs-string">&quot;数量&quot;</span>)<br>plt.xticks([index + <span class="hljs-number">0.1</span> <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> x], label_list)<br>plt.xticks(rotation=<span class="hljs-number">45</span>) <span class="hljs-comment"># x轴的标签旋转45度</span><br>plt.xlabel(<span class="hljs-string">&quot;三元组关系&quot;</span>)<br>plt.title(<span class="hljs-string">&quot;三元组关系频数统计图&quot;</span>)<br><br><span class="hljs-comment"># 条形图的文字说明</span><br><span class="hljs-keyword">for</span> rect <span class="hljs-keyword">in</span> rects:<br>    height = rect.get_height()<br>    plt.text(rect.get_x() + rect.get_width() / <span class="hljs-number">2</span>, height+<span class="hljs-number">1</span>, <span class="hljs-built_in">str</span>(height), ha=<span class="hljs-string">&quot;center&quot;</span>, va=<span class="hljs-string">&quot;bottom&quot;</span>)<br><br><br>plt.savefig(<span class="hljs-string">&#x27;./relation_bar_chart.png&#x27;</span>)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache">             <span class="hljs-attribute">spo_num</span>    text_length<br><span class="hljs-attribute">count</span>  <span class="hljs-number">173108</span>.<span class="hljs-number">000000</span>  <span class="hljs-number">173108</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">mean</span>        <span class="hljs-number">2</span>.<span class="hljs-number">103993</span>      <span class="hljs-number">54</span>.<span class="hljs-number">057190</span><br><span class="hljs-attribute">std</span>         <span class="hljs-number">1</span>.<span class="hljs-number">569331</span>      <span class="hljs-number">31</span>.<span class="hljs-number">498245</span><br><span class="hljs-attribute">min</span>         <span class="hljs-number">0</span>.<span class="hljs-number">000000</span>       <span class="hljs-number">5</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">25</span>%         <span class="hljs-number">1</span>.<span class="hljs-number">000000</span>      <span class="hljs-number">32</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">50</span>%         <span class="hljs-number">2</span>.<span class="hljs-number">000000</span>      <span class="hljs-number">45</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">75</span>%         <span class="hljs-number">2</span>.<span class="hljs-number">000000</span>      <span class="hljs-number">68</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">max</span>        <span class="hljs-number">25</span>.<span class="hljs-number">000000</span>     <span class="hljs-number">300</span>.<span class="hljs-number">000000</span><br></code></pre></td></tr></table></figure><p>句子的平均长度为54，最大长度为300；每句话中的三元组数量的平均值为2.1，最大值为25。</p><p>每句话中的三元组数量的分布图如下：</p><figure><img src="/img/nlp26_3.png" alt="每句话中的三元组数量分布图" /><figcaption aria-hidden="true">每句话中的三元组数量分布图</figcaption></figure><p>关系数量的分布图如下：</p><figure><img src="/img/nlp26_4.png" alt="关系数量分布图" /><figcaption aria-hidden="true">关系数量分布图</figcaption></figure><h3 id="序列标注模型">序列标注模型</h3><p>我们将句子中的主体和客体作为实体，分别标注为SUBJ和OBJ，标注体系采用BIO。一个简单的标注例子如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs bash">如 O<br>何 O<br>演 O<br>好 O<br>自 O<br>己 O<br>的 O<br>角 O<br>色 O<br>， O<br>请 O<br>读 O<br>《 O<br>演 O<br>员 O<br>自 O<br>我 O<br>修 O<br>养 O<br>》 O<br>《 O<br>喜 B-SUBJ<br>剧 I-SUBJ<br>之 I-SUBJ<br>王 I-SUBJ<br>》 O<br>周 B-OBJ<br>星 I-OBJ<br>驰 I-OBJ<br>崛 O<br>起 O<br>于 O<br>穷 O<br>困 O<br>潦 O<br>倒 O<br>之 O<br>中 O<br>的 O<br>独 O<br>门 O<br>秘 O<br>笈 O<br></code></pre></td></tr></table></figure><p>序列标注的模型采用ALBERT+Bi-LSTM+CRF，结构图如下：</p><figure><img src="/img/nlp26_5.png" alt="序列标注模型结构图" /><figcaption aria-hidden="true">序列标注模型结构图</figcaption></figure><p>模型方面的代码不再具体给出，有兴趣的同学可以参考文章<ahref="https://percent4.github.io/2023/07/09/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%94%EF%BC%89%E5%AE%9E%E7%8E%B0ALBERT-Bi-LSTM-CRF%E6%A8%A1%E5%9E%8B/">NLP（二十五）实现ALBERT+Bi-LSTM+CRF模型</a>，也可以参考文章最后给出的Github项目网址。</p><p>模型设置文本最大长度为128，利用ALBERT做特征提取，在自己的电脑上用CPU训练5个epoch，结果如下：</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs gradle">_________________________________________________________________<br>Train on <span class="hljs-number">173109</span> samples, validate on <span class="hljs-number">21639</span> samples<br>Epoch <span class="hljs-number">1</span>/<span class="hljs-number">10</span><br><span class="hljs-number">173109</span><span class="hljs-regexp">/173109 [==============================] - 422s 2ms/</span><span class="hljs-keyword">step</span> - loss: <span class="hljs-number">0.4460</span> - crf_viterbi_accuracy: <span class="hljs-number">0.8710</span> - val_loss: <span class="hljs-number">0.1613</span> - val_crf_viterbi_accuracy: <span class="hljs-number">0.9235</span><br>Epoch <span class="hljs-number">2</span>/<span class="hljs-number">10</span><br><span class="hljs-number">173109</span><span class="hljs-regexp">/173109 [==============================] - 417s 2ms/</span><span class="hljs-keyword">step</span> - loss: <span class="hljs-number">0.1170</span> - crf_viterbi_accuracy: <span class="hljs-number">0.9496</span> - val_loss: <span class="hljs-number">0.0885</span> - val_crf_viterbi_accuracy: <span class="hljs-number">0.9592</span><br>Epoch <span class="hljs-number">3</span>/<span class="hljs-number">10</span><br><span class="hljs-number">173109</span><span class="hljs-regexp">/173109 [==============================] - 417s 2ms/</span><span class="hljs-keyword">step</span> - loss: <span class="hljs-number">0.0758</span> - crf_viterbi_accuracy: <span class="hljs-number">0.9602</span> - val_loss: <span class="hljs-number">0.0653</span> - val_crf_viterbi_accuracy: <span class="hljs-number">0.9638</span><br>Epoch <span class="hljs-number">4</span>/<span class="hljs-number">10</span><br><span class="hljs-number">173109</span><span class="hljs-regexp">/173109 [==============================] - 415s 2ms/</span><span class="hljs-keyword">step</span> - loss: <span class="hljs-number">0.0586</span> - crf_viterbi_accuracy: <span class="hljs-number">0.9645</span> - val_loss: <span class="hljs-number">0.0544</span> - val_crf_viterbi_accuracy: <span class="hljs-number">0.9651</span><br>Epoch <span class="hljs-number">5</span>/<span class="hljs-number">10</span><br><span class="hljs-number">173109</span><span class="hljs-regexp">/173109 [==============================] - 422s 2ms/</span><span class="hljs-keyword">step</span> - loss: <span class="hljs-number">0.0488</span> - crf_viterbi_accuracy: <span class="hljs-number">0.9663</span> - val_loss: <span class="hljs-number">0.0464</span> - val_crf_viterbi_accuracy: <span class="hljs-number">0.9654</span><br>Epoch <span class="hljs-number">6</span>/<span class="hljs-number">10</span><br><span class="hljs-number">173109</span><span class="hljs-regexp">/173109 [==============================] - 423s 2ms/</span><span class="hljs-keyword">step</span> - loss: <span class="hljs-number">0.0399</span> - crf_viterbi_accuracy: <span class="hljs-number">0.9677</span> - val_loss: <span class="hljs-number">0.0375</span> - val_crf_viterbi_accuracy: <span class="hljs-number">0.9660</span><br>Epoch <span class="hljs-number">7</span>/<span class="hljs-number">10</span><br><span class="hljs-number">173109</span><span class="hljs-regexp">/173109 [==============================] - 415s 2ms/</span><span class="hljs-keyword">step</span> - loss: <span class="hljs-number">0.0293</span> - crf_viterbi_accuracy: <span class="hljs-number">0.9687</span> - val_loss: <span class="hljs-number">0.0265</span> - val_crf_viterbi_accuracy: <span class="hljs-number">0.9664</span><br>Epoch <span class="hljs-number">8</span>/<span class="hljs-number">10</span><br><span class="hljs-number">173109</span><span class="hljs-regexp">/173109 [==============================] - 414s 2ms/</span><span class="hljs-keyword">step</span> - loss: <span class="hljs-number">0.0174</span> - crf_viterbi_accuracy: <span class="hljs-number">0.9695</span> - val_loss: <span class="hljs-number">0.0149</span> - val_crf_viterbi_accuracy: <span class="hljs-number">0.9671</span><br>Epoch <span class="hljs-number">9</span>/<span class="hljs-number">10</span><br><span class="hljs-number">173109</span><span class="hljs-regexp">/173109 [==============================] - 422s 2ms/</span><span class="hljs-keyword">step</span> - loss: <span class="hljs-number">0.0049</span> - crf_viterbi_accuracy: <span class="hljs-number">0.9703</span> - val_loss: <span class="hljs-number">0.0036</span> - val_crf_viterbi_accuracy: <span class="hljs-number">0.9670</span><br>Epoch <span class="hljs-number">10</span>/<span class="hljs-number">10</span><br><span class="hljs-number">173109</span><span class="hljs-regexp">/173109 [==============================] - 429s 2ms/</span><span class="hljs-keyword">step</span> - loss: -<span class="hljs-number">0.0072</span> - crf_viterbi_accuracy: <span class="hljs-number">0.9709</span> - val_loss: -<span class="hljs-number">0.0078</span> - val_crf_viterbi_accuracy: <span class="hljs-number">0.9674</span><br>           precision    recall  f1-score   support<br><br>      OBJ     <span class="hljs-number">0.9593</span>    <span class="hljs-number">0.9026</span>    <span class="hljs-number">0.9301</span>     <span class="hljs-number">44598</span><br>     SUBJ     <span class="hljs-number">0.9670</span>    <span class="hljs-number">0.9238</span>    <span class="hljs-number">0.9449</span>     <span class="hljs-number">25521</span><br><br>micro avg     <span class="hljs-number">0.9621</span>    <span class="hljs-number">0.9104</span>    <span class="hljs-number">0.9355</span>     <span class="hljs-number">70119</span><br>macro avg     <span class="hljs-number">0.9621</span>    <span class="hljs-number">0.9104</span>    <span class="hljs-number">0.9355</span>     <span class="hljs-number">70119</span><br></code></pre></td></tr></table></figure><p>利用seqeval模块做评估，在验证集上的F1值约为93.55%。</p><h3 id="关系分类模型">关系分类模型</h3><p>需要对关系做一下说明，因为笔者会对句子（sent）中的主体（S）和客体（O）组合起来，加上句子，形成训练数据。举个例子，在句子<code>历史评价李氏朝鲜的创立并非太祖大王李成桂一人之功﹐其五子李芳远功不可没</code>，三元组为<code>[&#123;"predicate": "父亲", "object_type": "人物", "subject_type": "人物", "object": "李成桂", "subject": "李芳远"&#125;, &#123;"predicate": "国籍", "object_type": "国家", "subject_type": "人物", "object": "朝鲜", "subject": "李成桂"&#125;]&#125;</code>，在这句话中主体有李成桂，李芳远，客体有李成桂和朝鲜，关系有父亲（关系类型：2）和国籍（关系类型：22）。按照笔者的思路，这句话应组成4个关系分类样本，如下：</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">2 </span>李芳远$李成桂$历史评价李氏朝鲜的创立并非太祖大王###一人之功﹐其五子###功不可没<br><span class="hljs-symbol">0 </span>李芳远$朝鲜$历史评价李氏##的创立并非太祖大王李成桂一人之功﹐其五子###功不可没<br><span class="hljs-symbol">0 </span>李成桂$李成桂$历史评价李氏朝鲜的创立并非太祖大王###一人之功﹐其五子李芳远功不可没<br><span class="hljs-symbol">22 </span>李成桂$朝鲜$历史评价李氏##的创立并非太祖大王###一人之功﹐其五子李芳远功不可没<br></code></pre></td></tr></table></figure><p>因此，就会出现关系0（表示“未知”），这样我们在提取三元组的时候就可以略过这条关系，形成真正有用的三元组。</p><p>因此，关系一共为51个（加上未知关系：0）。关系分类模型采用ALBERT+Bi-GRU+ATT，结构图如下：</p><figure><img src="/img/nlp26_6.png" alt="关系分类模型图" /><figcaption aria-hidden="true">关系分类模型图</figcaption></figure><p>模型方面的代码不再具体给出，有兴趣的同学可以参考文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%80%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%AE%9E%E6%88%98/">NLP（二十一）人物关系抽取的一次实战</a>，也可以参考文章最后给出的Github项目网址。</p><p>模型设置文本最大长度为128，利用ALBERT做特征提取，在自己的电脑上用CPU训练30个epoch（实际上，由于有earlystopping机制，训练不到30个eopch），在验证集上的评估结果如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">Epoch</span> <span class="hljs-number">23</span><span class="hljs-string">/30</span><br><span class="hljs-number">396766</span><span class="hljs-string">/396766</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">776s 2ms/step - loss: 0.1770 - accuracy: 0.9402 - val_loss: 0.2170 - val_accuracy:</span> <span class="hljs-number">0.9308</span><br><br><span class="hljs-attr">Epoch 00023:</span> <span class="hljs-string">val_accuracy</span> <span class="hljs-string">did</span> <span class="hljs-string">not</span> <span class="hljs-string">improve</span> <span class="hljs-string">from</span> <span class="hljs-number">0.93292</span><br><span class="hljs-number">49506</span><span class="hljs-string">/49506</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-string">151s</span> <span class="hljs-string">3ms/step</span><br><span class="hljs-string">在测试集上的效果：</span> [<span class="hljs-number">0.21701653493155634</span>, <span class="hljs-number">0.930776059627533</span>]<br>    <span class="hljs-string">precision</span>    <span class="hljs-string">recall</span>  <span class="hljs-string">f1-score</span>   <span class="hljs-string">support</span><br><br>          <span class="hljs-string">未知</span>       <span class="hljs-number">0.87</span>      <span class="hljs-number">0.76</span>      <span class="hljs-number">0.81</span>      <span class="hljs-number">5057</span><br>          <span class="hljs-string">祖籍</span>       <span class="hljs-number">0.92</span>      <span class="hljs-number">0.73</span>      <span class="hljs-number">0.82</span>       <span class="hljs-number">181</span><br>          <span class="hljs-string">父亲</span>       <span class="hljs-number">0.79</span>      <span class="hljs-number">0.88</span>      <span class="hljs-number">0.83</span>       <span class="hljs-number">609</span><br>        <span class="hljs-string">总部地点</span>       <span class="hljs-number">0.95</span>      <span class="hljs-number">0.95</span>      <span class="hljs-number">0.95</span>       <span class="hljs-number">310</span><br>         <span class="hljs-string">出生地</span>       <span class="hljs-number">0.94</span>      <span class="hljs-number">0.95</span>      <span class="hljs-number">0.94</span>      <span class="hljs-number">2330</span><br>           <span class="hljs-string">目</span>       <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">1271</span><br>          <span class="hljs-string">面积</span>       <span class="hljs-number">0.90</span>      <span class="hljs-number">0.92</span>      <span class="hljs-number">0.91</span>        <span class="hljs-number">79</span><br>          <span class="hljs-string">简称</span>       <span class="hljs-number">0.97</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">0.98</span>       <span class="hljs-number">138</span><br>        <span class="hljs-string">上映时间</span>       <span class="hljs-number">0.94</span>      <span class="hljs-number">0.98</span>      <span class="hljs-number">0.96</span>       <span class="hljs-number">463</span><br>          <span class="hljs-string">妻子</span>       <span class="hljs-number">0.91</span>      <span class="hljs-number">0.83</span>      <span class="hljs-number">0.87</span>       <span class="hljs-number">680</span><br>        <span class="hljs-string">所属专辑</span>       <span class="hljs-number">0.97</span>      <span class="hljs-number">0.97</span>      <span class="hljs-number">0.97</span>      <span class="hljs-number">1282</span><br>        <span class="hljs-string">注册资本</span>       <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>        <span class="hljs-number">63</span><br>          <span class="hljs-string">首都</span>       <span class="hljs-number">0.92</span>      <span class="hljs-number">0.96</span>      <span class="hljs-number">0.94</span>        <span class="hljs-number">47</span><br>          <span class="hljs-string">导演</span>       <span class="hljs-number">0.92</span>      <span class="hljs-number">0.94</span>      <span class="hljs-number">0.93</span>      <span class="hljs-number">2603</span><br>           <span class="hljs-string">字</span>       <span class="hljs-number">0.96</span>      <span class="hljs-number">0.97</span>      <span class="hljs-number">0.97</span>       <span class="hljs-number">339</span><br>          <span class="hljs-string">身高</span>       <span class="hljs-number">0.98</span>      <span class="hljs-number">0.98</span>      <span class="hljs-number">0.98</span>       <span class="hljs-number">393</span><br>        <span class="hljs-string">出品公司</span>       <span class="hljs-number">0.96</span>      <span class="hljs-number">0.96</span>      <span class="hljs-number">0.96</span>       <span class="hljs-number">851</span><br>        <span class="hljs-string">修业年限</span>       <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>         <span class="hljs-number">2</span><br>        <span class="hljs-string">出生日期</span>       <span class="hljs-number">0.99</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">2892</span><br>         <span class="hljs-string">制片人</span>       <span class="hljs-number">0.69</span>      <span class="hljs-number">0.88</span>      <span class="hljs-number">0.77</span>       <span class="hljs-number">127</span><br>          <span class="hljs-string">母亲</span>       <span class="hljs-number">0.75</span>      <span class="hljs-number">0.88</span>      <span class="hljs-number">0.81</span>       <span class="hljs-number">425</span><br>          <span class="hljs-string">编剧</span>       <span class="hljs-number">0.82</span>      <span class="hljs-number">0.80</span>      <span class="hljs-number">0.81</span>       <span class="hljs-number">771</span><br>          <span class="hljs-string">国籍</span>       <span class="hljs-number">0.92</span>      <span class="hljs-number">0.92</span>      <span class="hljs-number">0.92</span>      <span class="hljs-number">1621</span><br>          <span class="hljs-string">海拔</span>       <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>        <span class="hljs-number">43</span><br>        <span class="hljs-string">连载网站</span>       <span class="hljs-number">0.98</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">1658</span><br>          <span class="hljs-string">丈夫</span>       <span class="hljs-number">0.84</span>      <span class="hljs-number">0.91</span>      <span class="hljs-number">0.87</span>       <span class="hljs-number">678</span><br>          <span class="hljs-string">朝代</span>       <span class="hljs-number">0.85</span>      <span class="hljs-number">0.92</span>      <span class="hljs-number">0.88</span>       <span class="hljs-number">419</span><br>          <span class="hljs-string">民族</span>       <span class="hljs-number">0.98</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">1434</span><br>           <span class="hljs-string">号</span>       <span class="hljs-number">0.95</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">0.97</span>       <span class="hljs-number">197</span><br>         <span class="hljs-string">出版社</span>       <span class="hljs-number">0.98</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">2272</span><br>         <span class="hljs-string">主持人</span>       <span class="hljs-number">0.82</span>      <span class="hljs-number">0.86</span>      <span class="hljs-number">0.84</span>       <span class="hljs-number">200</span><br>        <span class="hljs-string">专业代码</span>       <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>         <span class="hljs-number">3</span><br>          <span class="hljs-string">歌手</span>       <span class="hljs-number">0.89</span>      <span class="hljs-number">0.94</span>      <span class="hljs-number">0.91</span>      <span class="hljs-number">2857</span><br>          <span class="hljs-string">作词</span>       <span class="hljs-number">0.85</span>      <span class="hljs-number">0.81</span>      <span class="hljs-number">0.83</span>       <span class="hljs-number">884</span><br>          <span class="hljs-string">主角</span>       <span class="hljs-number">0.86</span>      <span class="hljs-number">0.77</span>      <span class="hljs-number">0.81</span>        <span class="hljs-number">39</span><br>         <span class="hljs-string">董事长</span>       <span class="hljs-number">0.81</span>      <span class="hljs-number">0.74</span>      <span class="hljs-number">0.78</span>        <span class="hljs-number">47</span><br>        <span class="hljs-string">毕业院校</span>       <span class="hljs-number">0.99</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">1433</span><br>        <span class="hljs-string">占地面积</span>       <span class="hljs-number">0.89</span>      <span class="hljs-number">0.89</span>      <span class="hljs-number">0.89</span>        <span class="hljs-number">61</span><br>        <span class="hljs-string">官方语言</span>       <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>        <span class="hljs-number">15</span><br>        <span class="hljs-string">邮政编码</span>       <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>         <span class="hljs-number">4</span><br>        <span class="hljs-string">人口数量</span>       <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>        <span class="hljs-number">45</span><br>        <span class="hljs-string">所在城市</span>       <span class="hljs-number">0.90</span>      <span class="hljs-number">0.94</span>      <span class="hljs-number">0.92</span>        <span class="hljs-number">77</span><br>          <span class="hljs-string">作者</span>       <span class="hljs-number">0.97</span>      <span class="hljs-number">0.97</span>      <span class="hljs-number">0.97</span>      <span class="hljs-number">4359</span><br>        <span class="hljs-string">成立日期</span>       <span class="hljs-number">0.99</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">1608</span><br>          <span class="hljs-string">作曲</span>       <span class="hljs-number">0.78</span>      <span class="hljs-number">0.77</span>      <span class="hljs-number">0.78</span>       <span class="hljs-number">849</span><br>          <span class="hljs-string">气候</span>       <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">1.00</span>       <span class="hljs-number">103</span><br>          <span class="hljs-string">嘉宾</span>       <span class="hljs-number">0.76</span>      <span class="hljs-number">0.72</span>      <span class="hljs-number">0.74</span>       <span class="hljs-number">158</span><br>          <span class="hljs-string">主演</span>       <span class="hljs-number">0.94</span>      <span class="hljs-number">0.97</span>      <span class="hljs-number">0.95</span>      <span class="hljs-number">7383</span><br>         <span class="hljs-string">改编自</span>       <span class="hljs-number">0.95</span>      <span class="hljs-number">0.82</span>      <span class="hljs-number">0.88</span>        <span class="hljs-number">71</span><br>         <span class="hljs-string">创始人</span>       <span class="hljs-number">0.86</span>      <span class="hljs-number">0.87</span>      <span class="hljs-number">0.86</span>        <span class="hljs-number">75</span><br><br>    <span class="hljs-string">accuracy</span>                           <span class="hljs-number">0.93</span>     <span class="hljs-number">49506</span><br>   <span class="hljs-string">macro</span> <span class="hljs-string">avg</span>       <span class="hljs-number">0.92</span>      <span class="hljs-number">0.92</span>      <span class="hljs-number">0.92</span>     <span class="hljs-number">49506</span><br><span class="hljs-string">weighted</span> <span class="hljs-string">avg</span>       <span class="hljs-number">0.93</span>      <span class="hljs-number">0.93</span>      <span class="hljs-number">0.93</span>     <span class="hljs-number">49506</span><br></code></pre></td></tr></table></figure><h3 id="三元组提取">三元组提取</h3><p>最后一部分，也是本次比赛的最终目标，就是三元组提取。</p><p>三元组提取采用Pipeline模式，先用序列标注模型预测句子中的实体，然后再用关系分类模型判断实体关系的类别，过滤掉关系为未知的情形，就是我们想要提取的三元组了。</p><p>三元组提取的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-03-14 20:41</span><br><span class="hljs-keyword">import</span> os, re, json, traceback<br><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras_contrib.layers <span class="hljs-keyword">import</span> CRF<br><span class="hljs-keyword">from</span> keras_contrib.losses <span class="hljs-keyword">import</span> crf_loss<br><span class="hljs-keyword">from</span> keras_contrib.metrics <span class="hljs-keyword">import</span> crf_accuracy, crf_viterbi_accuracy<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><span class="hljs-keyword">from</span> text_classification.att <span class="hljs-keyword">import</span> Attention<br><br><span class="hljs-keyword">from</span> albert_zh.extract_feature <span class="hljs-keyword">import</span> BertVector<br><br><span class="hljs-comment"># 读取label2id字典</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../sequence_labeling/ccks2019_label2id.json&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> h:<br>    label_id_dict = json.loads(h.read())<br><br>id_label_dict = &#123;v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> label_id_dict.items()&#125;<br><span class="hljs-comment"># 利用ALBERT提取文本特征</span><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;NONE&quot;</span>, max_seq_len=<span class="hljs-number">128</span>)<br>f = <span class="hljs-keyword">lambda</span> text: bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># 载入NER模型</span><br>custom_objects = &#123;<span class="hljs-string">&#x27;CRF&#x27;</span>: CRF, <span class="hljs-string">&#x27;crf_loss&#x27;</span>: crf_loss, <span class="hljs-string">&#x27;crf_viterbi_accuracy&#x27;</span>: crf_viterbi_accuracy&#125;<br>ner_model = load_model(<span class="hljs-string">&quot;../sequence_labeling/ccks2019_ner.h5&quot;</span>, custom_objects=custom_objects)<br><br><span class="hljs-comment"># 载入分类模型</span><br>best_model_path = <span class="hljs-string">&#x27;../text_classification/models/per-rel-08-0.9234.h5&#x27;</span><br>classification_model = load_model(best_model_path, custom_objects=&#123;<span class="hljs-string">&quot;Attention&quot;</span>: Attention&#125;)<br><br><span class="hljs-comment"># 分类与id的对应关系</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../data/relation2id.json&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> g:<br>    relation_id_dict = json.loads(g.read())<br><br>id_relation_dict = &#123;v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> relation_id_dict.items()&#125;<br><br><br><span class="hljs-comment"># 从预测的标签列表中获取实体</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_entity</span>(<span class="hljs-params">sent, tags_list</span>):<br><br>    entity_dict = defaultdict(<span class="hljs-built_in">list</span>)<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> char, tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(sent, tags_list):<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;B-&#x27;</span> <span class="hljs-keyword">in</span> tag:<br>            entity = char<br>            j = i+<span class="hljs-number">1</span><br>            entity_type = tag.split(<span class="hljs-string">&#x27;-&#x27;</span>)[-<span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">while</span> j &lt; <span class="hljs-built_in">min</span>(<span class="hljs-built_in">len</span>(sent), <span class="hljs-built_in">len</span>(tags_list)) <span class="hljs-keyword">and</span> <span class="hljs-string">&#x27;I-%s&#x27;</span> % entity_type <span class="hljs-keyword">in</span> tags_list[j]:<br>                entity += sent[j]<br>                j += <span class="hljs-number">1</span><br><br>            entity_dict[entity_type].append(entity)<br><br>        i += <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">dict</span>(entity_dict)<br><br><span class="hljs-comment"># 三元组提取类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TripleExtract</span>(<span class="hljs-title class_ inherited__">object</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, text</span>):<br>        self.text = text.replace(<span class="hljs-string">&quot; &quot;</span>, <span class="hljs-string">&quot;&quot;</span>)    <span class="hljs-comment"># 输入句子</span><br><br>    <span class="hljs-comment"># 获取输入句子中的实体（即：主体和客体）</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_entity</span>(<span class="hljs-params">self</span>):<br>        train_x = np.array([f(self. text)])<br>        y = np.argmax(ner_model.predict(train_x), axis=<span class="hljs-number">2</span>)<br>        y = [id_label_dict[_] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> y[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> _]<br><br>        <span class="hljs-comment"># 输出预测结果</span><br>        <span class="hljs-keyword">return</span> get_entity(self.text, y)<br><br>    <span class="hljs-comment"># 对实体做关系判定</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">relation_classify</span>(<span class="hljs-params">self</span>):<br>        entities = self.get_entity()<br>        subjects = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(entities.get(<span class="hljs-string">&quot;SUBJ&quot;</span>, [])))<br>        objs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(entities.get(<span class="hljs-string">&quot;OBJ&quot;</span>, [])))<br><br>        spo_list = []<br><br>        <span class="hljs-keyword">for</span> subj <span class="hljs-keyword">in</span> subjects:<br>            <span class="hljs-keyword">for</span> obj <span class="hljs-keyword">in</span> objs:<br>                sample = <span class="hljs-string">&#x27;$&#x27;</span>.join([subj, obj, self.text.replace(subj, <span class="hljs-string">&#x27;#&#x27;</span>*<span class="hljs-built_in">len</span>(subj)).replace(obj, <span class="hljs-string">&quot;#&quot;</span>*<span class="hljs-built_in">len</span>(obj))])<br>                vec = bert_model.encode([sample])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br>                x_train = np.array([vec])<br><br>                <span class="hljs-comment"># 模型预测并输出预测结果</span><br>                predicted = classification_model.predict(x_train)<br>                y = np.argmax(predicted[<span class="hljs-number">0</span>])<br><br>                relation = id_relation_dict[y]<br>                <span class="hljs-keyword">if</span> relation != <span class="hljs-string">&quot;未知&quot;</span>:<br>                    spo_list.append([subj, relation, obj])<br><br>        <span class="hljs-keyword">return</span> spo_list<br><br>    <span class="hljs-comment"># 提取三元组</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">extractor</span>(<span class="hljs-params">self</span>):<br><br>        <span class="hljs-keyword">return</span> self.relation_classify()<br></code></pre></td></tr></table></figure><p>运行三元组提取脚本，代码如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-03-14 20:53</span><br>import os, re, json, traceback<br><span class="hljs-keyword">from</span> pprint import pprint<br><br><span class="hljs-keyword">from</span> triple_extract.triple_extractor import TripleExtract<br><br><br>text = <span class="hljs-string">&quot;真人版的《花木兰》由新西兰导演妮基·卡罗执导，由刘亦菲、甄子丹、郑佩佩、巩俐、李连杰等加盟，几乎是全亚洲阵容。&quot;</span><br><br>triple_extract = TripleExtract(text)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;原文： %s&quot;</span> % text)<br>entities = triple_extract.get_entity()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;实体： &quot;</span>, <span class="hljs-attribute">end</span>=<span class="hljs-string">&#x27;&#x27;</span>)<br>pprint(entities)<br><br>spo_list = triple_extract.extractor()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;三元组： &quot;</span>, <span class="hljs-attribute">end</span>=<span class="hljs-string">&#x27;&#x27;</span>)<br>pprint(spo_list)<br></code></pre></td></tr></table></figure><p>我们在网上找几条样本进行测试，测试的结果如下：</p><blockquote><p>原文：真人版的《花木兰》由新西兰导演妮基·卡罗执导，由刘亦菲、甄子丹、郑佩佩、巩俐、李连杰等加盟，几乎是全亚洲阵容。实体： {'OBJ': ['妮基·卡罗', '刘亦菲', '甄子丹', '郑佩佩', '巩俐','李连杰'], 'SUBJ': ['花木兰']} 三元组： [['花木兰', '主演', '刘亦菲'],['花木兰', '导演', '妮基·卡罗'], ['花木兰', '主演', '甄子丹'],['花木兰', '主演', '李连杰'], ['花木兰', '主演', '郑佩佩'], ['花木兰','主演', '巩俐']]</p></blockquote><blockquote><p>原文：《冒险小王子》作者周艺文先生，教育、文学领域的专家学者以及来自全国各地的出版业从业者参加了此次沙龙，并围绕儿童文学创作这一话题做了精彩的分享与交流。实体： {'OBJ': ['周艺文'], 'SUBJ': ['冒险小王子']} 三元组：[['冒险小王子', '作者', '周艺文']]</p></blockquote><blockquote><p>原文：宋应星是江西奉新人，公元1587年生，经历过明朝腐败至灭亡的最后时期。实体： {'OBJ': ['江西奉新', '1587年'], 'SUBJ': ['宋应星']} 三元组：[['宋应星', '出生地', '江西奉新'], ['宋应星', '出生日期', '1587年']]</p></blockquote><blockquote><p>原文： 韩愈，字退之，河阳（今河南孟县）人。 实体： {'OBJ': ['退之','河阳'], 'SUBJ': ['韩愈']} 三元组： [['韩愈', '出生地', '河阳'],['韩愈', '字', '退之']]</p></blockquote><blockquote><p>原文：公开资料显示，李强，男，汉族，出生于1971年12月，北京市人，北京市委党校在职研究生学历，教育学学士学位，1996年11月入党，1993年7月参加工作。实体： {'OBJ': ['汉族', '1971年12月', '北京市', '北京市委党校'], 'SUBJ':['李强']} 三元组： [['李强', '民族', '汉族'], ['李强', '出生地','北京市'], ['李强', '毕业院校', '北京市委党校'], ['李强', '出生日期','1971年12月']]</p></blockquote><blockquote><p>原文：杨牧，本名王靖献，早期笔名叶珊，1940年生于台湾花莲，著名诗人、作家。实体： {'OBJ': ['1940年', '台湾花莲'], 'SUBJ': ['杨牧']} 三元组：[['杨牧', '出生地', '台湾花莲'], ['杨牧', '出生日期', '1940年']]</p></blockquote><blockquote><p>原文： 杨广是隋文帝杨坚的第二个儿子。 实体： {'OBJ': ['杨坚'],'SUBJ': ['杨广']} 三元组： [['杨广', '父亲', '杨坚']]</p></blockquote><blockquote><p>原文：此次权益变动后，何金明与妻子宋琦、其子何浩不再拥有对上市公司的控制权。实体： {'OBJ': ['何金明'], 'SUBJ': ['宋琦', '何浩']} 三元组： [['何浩','父亲', '何金明'], ['宋琦', '丈夫', '何金明']]</p></blockquote><blockquote><p>原文：线上直播发布会中，谭维维首次演绎了新歌《章存仙》，这首歌由钱雷作曲、尹约作词，尹约也在直播现场透过手机镜头跟网友互动聊天。实体： {'OBJ': ['谭维维', '钱雷', '尹约', '尹约'], 'SUBJ': ['章存仙']}三元组： [['章存仙', '作曲', '钱雷'], ['章存仙', '作词', '尹约'],['章存仙', '歌手', '谭维维']]</p></blockquote><blockquote><p>原文： “土木之变”后，造就了明代杰出的民族英雄于谦。 实体： {'OBJ':['明代'], 'SUBJ': ['于谦']} 三元组： [['于谦', '朝代', '明代']]</p></blockquote><blockquote><p>原文：另外，哈尔滨历史博物馆也是全国面积最小的国有博物馆，该场馆面积只有50平方米，可称之“微缩博物馆”。实体： {'OBJ': ['50平方米'], 'SUBJ': ['哈尔滨历史博物馆']} 三元组：[['哈尔滨历史博物馆', '占地面积', '50平方米']]</p></blockquote><blockquote><p>原文： 孙杨的妈妈叫杨明，孙杨的名字后面一个字也是来源于她的名字。实体： {'OBJ': ['杨明', '孙杨'], 'SUBJ': ['孙杨']} 三元组： [['孙杨','母亲', '杨明']]</p></blockquote><blockquote><p>原文：企查查显示，达鑫电子成立于1998年6月，法定代表人张高圳，注册资本772.33万美元，股东仅新加坡达鑫控股有限公司一名。实体： {'OBJ': ['1998年6月'], 'SUBJ': ['达鑫电子']} 三元组：[['达鑫电子', '成立日期', '1998年6月']]</p></blockquote><h3 id="总结">总结</h3><p>本文标题为限定领域的三元组抽取的一次尝试，之所以取名为限定领域，是因为该任务的实体关系是确定，一共为50种关系。</p><p>当然，上述方法还存在着诸多不足，参考苏建林的文章<ahref="https://spaces.ac.cn/archives/6671">基于DGCNN和概率图的轻量级信息抽取模型</a>，我们发现不足之处如下：</p><ul><li><p>主体和客体的标注策略有问题，因为句子中有时候主体和客体会重叠在一起；</p></li><li><p>新引入了一类关系：未知，是否有办法避免引入；</p></li><li><p>其他（暂时未想到）</p><p>从比赛的角度将，本文的办法效果未知，应该会比联合模型的效果差一些。但是，这是作为笔者自己的模型，算法是一种尝试，之所以采用这种方法，是因为笔者一开始是从开放领域的三元组抽取入手的，而这种方法方便扩展至开放领域。关于开放领域的三元组抽取，笔者稍后就会写文章介绍，敬请期待。本文的源代码已经公开至Github，网址为： <ahref="https://github.com/percent4/ccks_triple_extract">https://github.com/percent4/ccks_triple_extract</a>。</p></li></ul><h3 id="参考网址">参考网址</h3><ol type="1"><li>NLP（二十五）实现ALBERT+Bi-LSTM+CRF模型：https://blog.csdn.net/jclian91/article/details/104826655</li><li>NLP（二十一）人物关系抽取的一次实战：https://blog.csdn.net/jclian91/article/details/104380371</li><li>基于DGCNN和概率图的轻量级信息抽取模型：https://spaces.ac.cn/archives/6671</li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>关系抽取</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（二十五）实现ALBERT+Bi-LSTM+CRF模型</title>
    <link href="/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%94%EF%BC%89%E5%AE%9E%E7%8E%B0ALBERT-Bi-LSTM-CRF%E6%A8%A1%E5%9E%8B/"/>
    <url>/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%94%EF%BC%89%E5%AE%9E%E7%8E%B0ALBERT-Bi-LSTM-CRF%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%9B%9B%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E5%AE%9E%E7%8E%B0%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/">NLP（二十四）利用ALBERT实现命名实体识别</a>中，笔者介绍了ALBERT+Bi-LSTM模型在命名实体识别方面的应用。</p><p>在本文中，笔者将介绍如何实现ALBERT+Bi-LSTM+CRF模型，以及在人民日报NER数据集和CLUENER数据集上的表现。</p><p>功能项目方面的介绍里面不再多介绍，笔者只介绍模型训练和模型预测部分的代码。项目方面的代码可以参考文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%9B%9B%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E5%AE%9E%E7%8E%B0%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/">NLP（二十四）利用ALBERT实现命名实体识别</a>，模型为ALBERT+Bi-LSTM+CRF，结构图如下：</p><figure><img src="/img/nlp25_1.png" alt="ALBERT+Bi-LSTM+CRF模型结构图" /><figcaption aria-hidden="true">ALBERT+Bi-LSTM+CRF模型结构图</figcaption></figure><p>模型训练的代码（albert_model_train.py）中新增导入keras-contrib模块中的CRF层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> keras_contrib.layers <span class="hljs-keyword">import</span> CRF<br><span class="hljs-keyword">from</span> keras_contrib.losses <span class="hljs-keyword">import</span> crf_loss<br><span class="hljs-keyword">from</span> keras_contrib.metrics <span class="hljs-keyword">import</span> crf_accuracy, crf_viterbi_accuracy<br></code></pre></td></tr></table></figure><p>模型方面的代码如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Build model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_model</span>(<span class="hljs-params">max_para_length, n_tags</span>):<br>    <span class="hljs-comment"># Bert Embeddings</span><br>    bert_output = Input(shape=(max_para_length, <span class="hljs-number">312</span>, ), name=<span class="hljs-string">&quot;bert_output&quot;</span>)<br>    <span class="hljs-comment"># LSTM model</span><br>    lstm = Bidirectional(LSTM(units=<span class="hljs-number">128</span>, return_sequences=<span class="hljs-literal">True</span>), name=<span class="hljs-string">&quot;bi_lstm&quot;</span>)(bert_output)<br>    drop = Dropout(<span class="hljs-number">0.1</span>, name=<span class="hljs-string">&quot;dropout&quot;</span>)(lstm)<br>    dense = TimeDistributed(Dense(n_tags, activation=<span class="hljs-string">&quot;softmax&quot;</span>), name=<span class="hljs-string">&quot;time_distributed&quot;</span>)(drop)<br>    crf = CRF(n_tags)<br>    out = crf(dense)<br>    model = Model(inputs=bert_output, outputs=out)<br>    <span class="hljs-comment"># model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])</span><br>    model.<span class="hljs-built_in">compile</span>(loss=crf.loss_function, optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>, metrics=[crf.accuracy])<br><br>    <span class="hljs-comment"># 模型结构总结</span><br>    model.summary()<br>    plot_model(model, to_file=<span class="hljs-string">&quot;albert_bi_lstm.png&quot;</span>, show_shapes=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></table></figure></p><p>设置文本的最大长度MAX_SEQ_LEN =128，训练10个epoch，在测试集上的F1值（利用seqeval模块评估）输出如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache">           <span class="hljs-attribute">precision</span>    recall  f1-score   support<br><br>      <span class="hljs-attribute">LOC</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9766</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9032</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9385</span>      <span class="hljs-number">3658</span><br>      <span class="hljs-attribute">ORG</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9700</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9465</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9581</span>      <span class="hljs-number">2185</span><br>      <span class="hljs-attribute">PER</span>     <span class="hljs-number">0</span>.<span class="hljs-number">9880</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9721</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9800</span>      <span class="hljs-number">1864</span><br><br><span class="hljs-attribute">micro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9775</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9321</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9543</span>      <span class="hljs-number">7707</span><br><span class="hljs-attribute">macro</span> avg     <span class="hljs-number">0</span>.<span class="hljs-number">9775</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9321</span>    <span class="hljs-number">0</span>.<span class="hljs-number">9541</span>      <span class="hljs-number">7707</span><br></code></pre></td></tr></table></figure><p>之前用ALBERT+Bi-LSTM模型得到的F1值为91.96%，而ALBERT+Bi-LSTM+CRF模型能达到95.43%，提升效果不错。</p><p>模型预测代码（model_predict.py）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-03-11 13:16</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras_contrib.layers <span class="hljs-keyword">import</span> CRF<br><span class="hljs-keyword">from</span> keras_contrib.losses <span class="hljs-keyword">import</span> crf_loss<br><span class="hljs-keyword">from</span> keras_contrib.metrics <span class="hljs-keyword">import</span> crf_accuracy, crf_viterbi_accuracy<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> MAX_SEQ_LEN, event_type<br><span class="hljs-keyword">from</span> albert_zh.extract_feature <span class="hljs-keyword">import</span> BertVector<br><br><span class="hljs-comment"># 读取label2id字典</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;%s_label2id.json&quot;</span> % event_type, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> h:<br>    label_id_dict = json.loads(h.read())<br><br>id_label_dict = &#123;v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> label_id_dict.items()&#125;<br><br><span class="hljs-comment"># 利用ALBERT提取文本特征</span><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;NONE&quot;</span>, max_seq_len=MAX_SEQ_LEN)<br>f = <span class="hljs-keyword">lambda</span> text: bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># 载入模型</span><br>custom_objects = &#123;<span class="hljs-string">&#x27;CRF&#x27;</span>: CRF, <span class="hljs-string">&#x27;crf_loss&#x27;</span>: crf_loss, <span class="hljs-string">&#x27;crf_viterbi_accuracy&#x27;</span>: crf_viterbi_accuracy&#125;<br>ner_model = load_model(<span class="hljs-string">&quot;%s_ner.h5&quot;</span> % event_type, custom_objects=custom_objects)<br><br><br><span class="hljs-comment"># 从预测的标签列表中获取实体</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_entity</span>(<span class="hljs-params">sent, tags_list</span>):<br><br>    entity_dict = defaultdict(<span class="hljs-built_in">list</span>)<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> char, tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(sent, tags_list):<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;B-&#x27;</span> <span class="hljs-keyword">in</span> tag:<br>            entity = char<br>            j = i+<span class="hljs-number">1</span><br>            entity_type = tag.split(<span class="hljs-string">&#x27;-&#x27;</span>)[-<span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">while</span> j &lt; <span class="hljs-built_in">min</span>(<span class="hljs-built_in">len</span>(sent), <span class="hljs-built_in">len</span>(tags_list)) <span class="hljs-keyword">and</span> <span class="hljs-string">&#x27;I-%s&#x27;</span> % entity_type <span class="hljs-keyword">in</span> tags_list[j]:<br>                entity += sent[j]<br>                j += <span class="hljs-number">1</span><br><br>            entity_dict[entity_type].append(entity)<br><br>        i += <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">dict</span>(entity_dict)<br><br><br><span class="hljs-comment"># 输入句子，进行预测</span><br><span class="hljs-keyword">while</span> <span class="hljs-number">1</span>:<br>    <span class="hljs-comment"># 输入句子</span><br>    text = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Please enter an sentence: &quot;</span>).replace(<span class="hljs-string">&#x27; &#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-comment"># 利用训练好的模型进行预测</span><br>    train_x = np.array([f(text)])<br>    y = np.argmax(ner_model.predict(train_x), axis=<span class="hljs-number">2</span>)<br>    y = [id_label_dict[_] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> y[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> _]<br><br>    <span class="hljs-comment"># 输出预测结果</span><br>    pprint(get_entity(text, y))<br></code></pre></td></tr></table></figure><p>在网上找几条新闻，预测结果如下：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs prolog"><span class="hljs-symbol">Please</span> enter an sentence: 驴妈妈旅游网创始人洪清华近日接受媒体采访谈及驴妈妈的发展模式时表示：现在，电商有两种做法——小而美的电商追求盈利，大而全的电商钟情规模。<br>&#123;<span class="hljs-string">&#x27;PER&#x27;</span>: [<span class="hljs-string">&#x27;洪清华&#x27;</span>]&#125;<br><span class="hljs-symbol">Please</span> enter an sentence: <span class="hljs-symbol">EF</span>英孚教育集团是全球最大的私人英语教育机构，主要致力于英语培训、留学旅游以及英语文化交流等方面。<br>&#123;<span class="hljs-string">&#x27;ORG&#x27;</span>: [<span class="hljs-string">&#x27;EF英孚教育集团&#x27;</span>]&#125;<br><span class="hljs-symbol">Please</span> enter an sentence: 宋元时期起，在台湾早期开发的过程中，中华文化传统已随着大陆垦民传入台湾。<br>&#123;<span class="hljs-string">&#x27;LOC&#x27;</span>: [<span class="hljs-string">&#x27;台湾&#x27;</span>, <span class="hljs-string">&#x27;中华&#x27;</span>, <span class="hljs-string">&#x27;台湾&#x27;</span>]&#125;<br><span class="hljs-symbol">Please</span> enter an sentence: 吸引了众多投资者来津发展，康师傅红烧牛肉面就是于<span class="hljs-number">1992</span>年在天津诞生。<br>&#123;<span class="hljs-string">&#x27;LOC&#x27;</span>: [<span class="hljs-string">&#x27;天津&#x27;</span>]&#125;<br><span class="hljs-symbol">Please</span> enter an sentence: 经过激烈角逐，那英战队成功晋级<span class="hljs-number">16</span>强的学员有实力非凡的姚贝娜、挚情感打动观众的朱克、音乐创作能力十分突出的侯磊。<br>&#123;<span class="hljs-string">&#x27;PER&#x27;</span>: [<span class="hljs-string">&#x27;姚贝娜&#x27;</span>, <span class="hljs-string">&#x27;朱克&#x27;</span>, <span class="hljs-string">&#x27;侯磊&#x27;</span>]&#125;<br></code></pre></td></tr></table></figure><p>接下来我们看看该模型在CLUENER数据集上的表现。CLUENER数据集是在清华大学开源的文本分类数据集THUCTC基础上，选出部分数据进行细粒度命名实体标注，原数据来源于SinaNewsRSS，实体有：地址（address），书名（book），公司（company），游戏（game），政府（goverment），电影（movie），姓名（name），组织机构（organization），职位（position），景点（scene），该数据集的介绍网站为：<ahref="https://www.cluebenchmarks.com/introduce.html">https://www.cluebenchmarks.com/introduce.html</a>。</p><p>下载数据集，用脚本将其处理成模型支持的数据格式，因为缺少test数据集，故模型评测的时候用dev数据集代替。设置模型的文本最大长度MAX_SEQ_LEN=128，训练10个epoch，在测试集上的F1值（利用seqeval模块评估）输出如下：</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-keyword">sentences</span> <span class="hljs-built_in">length</span>: <span class="hljs-number">10748</span> <br><span class="hljs-keyword">last</span> <span class="hljs-keyword">sentence</span>:  艺术家也讨厌画廊的老板，内心恨他们，这样的话，你是在这样的状态下，两年都是一次性合作，甚至两年、<br><span class="hljs-built_in">start</span> ALBERT encding<br><span class="hljs-function"><span class="hljs-keyword">end</span> <span class="hljs-title">ALBERT</span> <span class="hljs-title">encoding</span></span><br><span class="hljs-keyword">sentences</span> <span class="hljs-built_in">length</span>: <span class="hljs-number">1343</span> <br><span class="hljs-keyword">last</span> <span class="hljs-keyword">sentence</span>:  另外意大利的PlayGeneration杂志也刚刚给出了<span class="hljs-number">92</span>%的高分。<br><span class="hljs-built_in">start</span> ALBERT encding<br><span class="hljs-function"><span class="hljs-keyword">end</span> <span class="hljs-title">ALBERT</span> <span class="hljs-title">encoding</span></span><br><span class="hljs-keyword">sentences</span> <span class="hljs-built_in">length</span>: <span class="hljs-number">1343</span> <br><span class="hljs-keyword">last</span> <span class="hljs-keyword">sentence</span>:  另外意大利的PlayGeneration杂志也刚刚给出了<span class="hljs-number">92</span>%的高分。<br><span class="hljs-built_in">start</span> ALBERT encding<br><span class="hljs-function"><span class="hljs-keyword">end</span> <span class="hljs-title">ALBERT</span> <span class="hljs-title">encoding</span></span><br>......<br>.......<br>              precision    recall  f1-score   support<br><br>        book     <span class="hljs-number">0.9343</span>    <span class="hljs-number">0.8421</span>    <span class="hljs-number">0.8858</span>       <span class="hljs-number">152</span><br>    position     <span class="hljs-number">0.9549</span>    <span class="hljs-number">0.8965</span>    <span class="hljs-number">0.9248</span>       <span class="hljs-number">425</span><br>  government     <span class="hljs-number">0.9372</span>    <span class="hljs-number">0.9180</span>    <span class="hljs-number">0.9275</span>       <span class="hljs-number">244</span><br>        game     <span class="hljs-number">0.6968</span>    <span class="hljs-number">0.6725</span>    <span class="hljs-number">0.6844</span>       <span class="hljs-number">287</span><br>organization     <span class="hljs-number">0.8836</span>    <span class="hljs-number">0.8605</span>    <span class="hljs-number">0.8719</span>       <span class="hljs-number">344</span><br>     company     <span class="hljs-number">0.8659</span>    <span class="hljs-number">0.7760</span>    <span class="hljs-number">0.8184</span>       <span class="hljs-number">366</span><br>     address     <span class="hljs-number">0.8394</span>    <span class="hljs-number">0.8187</span>    <span class="hljs-number">0.8289</span>       <span class="hljs-number">364</span><br>       movie     <span class="hljs-number">0.9217</span>    <span class="hljs-number">0.7067</span>    <span class="hljs-number">0.8000</span>       <span class="hljs-number">150</span><br>        name     <span class="hljs-number">0.8771</span>    <span class="hljs-number">0.8071</span>    <span class="hljs-number">0.8406</span>       <span class="hljs-number">451</span><br>       scene     <span class="hljs-number">0.9939</span>    <span class="hljs-number">0.8191</span>    <span class="hljs-number">0.8981</span>       <span class="hljs-number">199</span><br><br>   micro <span class="hljs-built_in">avg</span>     <span class="hljs-number">0.8817</span>    <span class="hljs-number">0.8172</span>    <span class="hljs-number">0.8482</span>      <span class="hljs-number">2982</span><br>   macro <span class="hljs-built_in">avg</span>     <span class="hljs-number">0.8835</span>    <span class="hljs-number">0.8172</span>    <span class="hljs-number">0.8482</span>      <span class="hljs-number">2982</span><br></code></pre></td></tr></table></figure><p>在网上找几条新闻，预测结果如下：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs prolog"><span class="hljs-symbol">Please</span> enter an sentence: 据中山外侨局消息，近日，秘鲁国会议员、祖籍中山市开发区的玛利亚·洪大女士在秘鲁国会大厦亲切会见了中山市人民政府副市长冯煜荣一行，对中山市友好代表团的来访表示热烈的欢迎。<br>&#123;<span class="hljs-string">&#x27;address&#x27;</span>: [<span class="hljs-string">&#x27;中山市开发区&#x27;</span>, <span class="hljs-string">&#x27;秘鲁国会大厦&#x27;</span>],<br> <span class="hljs-string">&#x27;government&#x27;</span>: [<span class="hljs-string">&#x27;中山外侨局&#x27;</span>, <span class="hljs-string">&#x27;秘鲁国会&#x27;</span>, <span class="hljs-string">&#x27;中山市人民政府&#x27;</span>],<br> <span class="hljs-string">&#x27;name&#x27;</span>: [<span class="hljs-string">&#x27;玛利亚·洪大&#x27;</span>, <span class="hljs-string">&#x27;冯煜荣&#x27;</span>],<br> <span class="hljs-string">&#x27;position&#x27;</span>: [<span class="hljs-string">&#x27;议员&#x27;</span>, <span class="hljs-string">&#x27;副市长&#x27;</span>]&#125;<br> <span class="hljs-symbol">Please</span> enter an sentence: “隔离结束回来，发现公司不见了”，网上的段子，真发生在了昆山达鑫电子有限公司员工身上。<br>&#123;<span class="hljs-string">&#x27;company&#x27;</span>: [<span class="hljs-string">&#x27;昆山达鑫电子有限公司&#x27;</span>]&#125;<br><span class="hljs-symbol">Please</span> enter an sentence: 由黄子韬、易烊千玺、胡冰卿、王子腾等一众青年演员主演的热血励志剧《热血同行》正在热播中。<br>&#123;<span class="hljs-string">&#x27;game&#x27;</span>: [<span class="hljs-string">&#x27;《热血同行》&#x27;</span>], <span class="hljs-string">&#x27;name&#x27;</span>: [<span class="hljs-string">&#x27;黄子韬&#x27;</span>, <span class="hljs-string">&#x27;易烊千玺&#x27;</span>, <span class="hljs-string">&#x27;胡冰卿&#x27;</span>, <span class="hljs-string">&#x27;王子腾&#x27;</span>], <span class="hljs-string">&#x27;position&#x27;</span>: [<span class="hljs-string">&#x27;演员&#x27;</span>]&#125;<br><span class="hljs-symbol">Please</span> enter an sentence: 近日，由作家出版社主办的韩作荣《天生我才——李白传》新书发布会在京举行<br>&#123;<span class="hljs-string">&#x27;book&#x27;</span>: [<span class="hljs-string">&#x27;《天生我才——李白传》&#x27;</span>], <span class="hljs-string">&#x27;name&#x27;</span>: [<span class="hljs-string">&#x27;韩作荣&#x27;</span>], <span class="hljs-string">&#x27;organization&#x27;</span>: [<span class="hljs-string">&#x27;作家出版社&#x27;</span>]&#125;<br></code></pre></td></tr></table></figure><p>本项目已经开源，Github网址为：<ahref="https://github.com/percent4/ALBERT_NER_KERAS">https://github.com/percent4/ALBERT_NER_KERAS</a>。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>ALBERT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（二十四）利用ALBERT实现命名实体识别</title>
    <link href="/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%9B%9B%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E5%AE%9E%E7%8E%B0%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/"/>
    <url>/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E5%9B%9B%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E5%AE%9E%E7%8E%B0%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会介绍如何利用ALBERT来实现<code>命名实体识别</code>。如果有对<code>命名实体识别</code>不清楚的读者，请参考笔者的文章<ahref="https://percent4.github.io/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%9B%9B%EF%BC%89%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%EF%BC%88NER%EF%BC%89/">NLP入门（四）命名实体识别（NER）</a>。</p><p>本文的项目结构如下：</p><figure><img src="/img/nlp24_1.png" alt="项目结构" /><figcaption aria-hidden="true">项目结构</figcaption></figure><p>其中，<code>albert_zh</code>为ALBERT提取文本特征模块，这方面的代码已经由别人开源，我们只需要拿来使用即可。data目录下为我们本次讲解所需要的数据，图中只有example开头的数据集，这是人民日报的标注语料，实体为人名（PER）、地名（LOC）和组织机构名（ORG）。数据集一行一个字符以及标注符号，标注系统采用<code>BIO</code>系统，我们以example.train的第一句为例，标注信息如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">海 O<br>钓 O<br>比 O<br>赛 O<br>地 O<br>点 O<br>在 O<br>厦 B-LOC<br>门 I-LOC<br>与 O<br>金 B-LOC<br>门 I-LOC<br>之 O<br>间 O<br>的 O<br>海 O<br>域 O<br>。 O<br></code></pre></td></tr></table></figure><p>在<code>utils.py</code>文件中，配置了一些关于文件路径和模型参数方面的信息，其中规定了输入的文本长度最大为128，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-03-11 21:12</span><br><br><span class="hljs-comment"># 数据相关的配置</span><br>event_type = <span class="hljs-string">&quot;example&quot;</span><br><br>train_file_path = <span class="hljs-string">&quot;./data/%s.train&quot;</span> % event_type<br>dev_file_path = <span class="hljs-string">&quot;./data/%s.dev&quot;</span> % event_type<br>test_file_path = <span class="hljs-string">&quot;./data/%s.test&quot;</span> % event_type<br><br><span class="hljs-comment"># 模型相关的配置</span><br>MAX_SEQ_LEN = <span class="hljs-number">128</span>   <span class="hljs-comment"># 输入的文本最大长度</span><br></code></pre></td></tr></table></figure><p>在<code>load_data.py</code>文件中，我们将处理训练集、验证集和测试集数据，并将标签转换为id，形成label2id.json文件，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-03-11 10:04</span><br><span class="hljs-keyword">import</span> json<br><br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> train_file_path, event_type<br><br><br><span class="hljs-comment"># 读取数据集</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_data</span>(<span class="hljs-params">file_path</span>):<br>    <span class="hljs-comment"># 读取数据集</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br>    <span class="hljs-comment"># 添加原文句子以及该句子的标签</span><br><br>    <span class="hljs-comment"># 读取空行所在的行号</span><br>    index = [-<span class="hljs-number">1</span>]<br>    index.extend([i <span class="hljs-keyword">for</span> i, _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(content) <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27; &#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> _])<br>    index.append(<span class="hljs-built_in">len</span>(content))<br><br>    <span class="hljs-comment"># 按空行分割，读取原文句子及标注序列</span><br>    sentences, tags = [], []<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(index)-<span class="hljs-number">1</span>):<br>        sent, tag = [], []<br>        segment = content[index[j]+<span class="hljs-number">1</span>: index[j+<span class="hljs-number">1</span>]]<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> segment:<br>            sent.append(line.split()[<span class="hljs-number">0</span>])<br>            tag.append(line.split()[-<span class="hljs-number">1</span>])<br><br>        sentences.append(<span class="hljs-string">&#x27;&#x27;</span>.join(sent))<br>        tags.append(tag)<br><br>    <span class="hljs-comment"># 去除空的句子及标注序列，一般放在末尾</span><br>    sentences = [_ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> sentences <span class="hljs-keyword">if</span> _]<br>    tags = [_ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> tags <span class="hljs-keyword">if</span> _]<br><br>    <span class="hljs-keyword">return</span> sentences, tags<br><br><br><span class="hljs-comment"># 读取训练集数据</span><br><span class="hljs-comment"># 将标签转换成id</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">label2id</span>():<br><br>    train_sents, train_tags = read_data(train_file_path)<br><br>    <span class="hljs-comment"># 标签转换成id，并保存成文件</span><br>    unique_tags = []<br>    <span class="hljs-keyword">for</span> seq <span class="hljs-keyword">in</span> train_tags:<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> seq:<br>            <span class="hljs-keyword">if</span> _ <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> unique_tags:<br>                unique_tags.append(_)<br><br>    label_id_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(unique_tags, <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(unique_tags) + <span class="hljs-number">1</span>)))<br><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;%s_label2id.json&quot;</span> % event_type, <span class="hljs-string">&quot;w&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> g:<br>        g.write(json.dumps(label_id_dict, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">2</span>))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    label2id()<br></code></pre></td></tr></table></figure><p>运行代码，生成的example_label2id.json文件如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;O&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;B-LOC&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;I-LOC&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;B-PER&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;I-PER&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">5</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;B-ORG&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">6</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;I-ORG&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">7</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>生成该文件是为了方便我们后边的模型训练和预测的时候调用。</p><p>接着就是最重要的模型训练部分了，模型的结构图如下：</p><figure><img src="/img/nlp24_2.png" alt="模型结构图" /><figcaption aria-hidden="true">模型结构图</figcaption></figure><p>我们采用ALBERT作为文本特征提取，后接经典的序列标注算法——Bi-LSTM算法。<code>albert_model_train.py</code>的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model, Input<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Dense, Bidirectional, Dropout, LSTM, TimeDistributed, Masking<br><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> to_categorical, plot_model<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> classification_report<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> event_type<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> MAX_SEQ_LEN, train_file_path, test_file_path, dev_file_path<br><span class="hljs-keyword">from</span> load_data <span class="hljs-keyword">import</span> read_data<br><span class="hljs-keyword">from</span> albert_zh.extract_feature <span class="hljs-keyword">import</span> BertVector<br><br><span class="hljs-comment"># 利用ALBERT提取文本特征</span><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;NONE&quot;</span>, max_seq_len=MAX_SEQ_LEN)<br>f = <span class="hljs-keyword">lambda</span> text: bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># 读取label2id字典</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;%s_label2id.json&quot;</span> % event_type, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> h:<br>    label_id_dict = json.loads(h.read())<br><br>id_label_dict = &#123;v:k <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> label_id_dict.items()&#125;<br><br><br><span class="hljs-comment"># 载入数据</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">input_data</span>(<span class="hljs-params">file_path</span>):<br><br>    sentences, tags = read_data(file_path)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;sentences length: %s &quot;</span> % <span class="hljs-built_in">len</span>(sentences))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;last sentence: &quot;</span>, sentences[-<span class="hljs-number">1</span>])<br><br>    <span class="hljs-comment"># ALBERT ERCODING</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;start ALBERT encding&quot;</span>)<br>    x = np.array([f(sent) <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sentences])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;end ALBERT encoding&quot;</span>)<br><br>    <span class="hljs-comment"># 对y值统一长度为MAX_SEQ_LEN</span><br>    new_y = []<br>    <span class="hljs-keyword">for</span> seq <span class="hljs-keyword">in</span> tags:<br>        num_tag = [label_id_dict[_] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> seq]<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(seq) &lt; MAX_SEQ_LEN:<br>            num_tag = num_tag + [<span class="hljs-number">0</span>] * (MAX_SEQ_LEN-<span class="hljs-built_in">len</span>(seq))<br>        <span class="hljs-keyword">else</span>:<br>            num_tag = num_tag[: MAX_SEQ_LEN]<br><br>        new_y.append(num_tag)<br><br>    <span class="hljs-comment"># 将y中的元素编码成ont-hot encoding</span><br>    y = np.empty(shape=(<span class="hljs-built_in">len</span>(tags), MAX_SEQ_LEN, <span class="hljs-built_in">len</span>(label_id_dict.keys())+<span class="hljs-number">1</span>))<br><br>    <span class="hljs-keyword">for</span> i, seq <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(new_y):<br>        y[i, :, :] = to_categorical(seq, num_classes=<span class="hljs-built_in">len</span>(label_id_dict.keys())+<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">return</span> x, y<br><br><br><span class="hljs-comment"># Build model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_model</span>(<span class="hljs-params">max_para_length, n_tags</span>):<br>    <span class="hljs-comment"># Bert Embeddings</span><br>    bert_output = Input(shape=(max_para_length, <span class="hljs-number">312</span>, ), name=<span class="hljs-string">&quot;bert_output&quot;</span>)<br>    <span class="hljs-comment"># LSTM model</span><br>    lstm = Bidirectional(LSTM(units=<span class="hljs-number">128</span>, return_sequences=<span class="hljs-literal">True</span>), name=<span class="hljs-string">&quot;bi_lstm&quot;</span>)(bert_output)<br>    drop = Dropout(<span class="hljs-number">0.1</span>, name=<span class="hljs-string">&quot;dropout&quot;</span>)(lstm)<br>    out = TimeDistributed(Dense(n_tags, activation=<span class="hljs-string">&quot;softmax&quot;</span>), name=<span class="hljs-string">&quot;time_distributed&quot;</span>)(drop)<br>    model = Model(inputs=bert_output, outputs=out)<br>    model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>, loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br>    <span class="hljs-comment"># 模型结构总结</span><br>    model.summary()<br>    plot_model(model, to_file=<span class="hljs-string">&quot;albert_bi_lstm.png&quot;</span>, show_shapes=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-comment"># 模型训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_model</span>():<br><br>    <span class="hljs-comment"># 读取训练集，验证集和测试集数据</span><br>    train_x, train_y = input_data(train_file_path)<br>    dev_x, dev_y = input_data(dev_file_path)<br>    test_x, test_y = input_data(test_file_path)<br><br>    <span class="hljs-comment"># 模型训练</span><br>    model = build_model(MAX_SEQ_LEN, <span class="hljs-built_in">len</span>(label_id_dict.keys())+<span class="hljs-number">1</span>)<br><br>    history = model.fit(train_x, train_y, validation_data=(dev_x, dev_y), batch_size=<span class="hljs-number">32</span>, epochs=<span class="hljs-number">10</span>)<br><br>    model.save(<span class="hljs-string">&quot;%s_ner.h5&quot;</span> % event_type)<br><br>    <span class="hljs-comment"># 绘制loss和acc图像</span><br>    plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    epochs = <span class="hljs-built_in">len</span>(history.history[<span class="hljs-string">&#x27;loss&#x27;</span>])<br>    plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;loss&#x27;</span>], label=<span class="hljs-string">&#x27;loss&#x27;</span>)<br>    plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;val_loss&#x27;</span>], label=<span class="hljs-string">&#x27;val_loss&#x27;</span>)<br>    plt.legend()<br><br>    plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>    epochs = <span class="hljs-built_in">len</span>(history.history[<span class="hljs-string">&#x27;acc&#x27;</span>])<br>    plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;acc&#x27;</span>], label=<span class="hljs-string">&#x27;acc&#x27;</span>)<br>    plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;val_acc&#x27;</span>], label=<span class="hljs-string">&#x27;val_acc&#x27;</span>)<br>    plt.legend()<br>    plt.savefig(<span class="hljs-string">&quot;%s_loss_acc.png&quot;</span> % event_type)<br><br>    <span class="hljs-comment"># 模型在测试集上的表现</span><br>    <span class="hljs-comment"># 预测标签</span><br>    y = np.argmax(model.predict(test_x), axis=<span class="hljs-number">2</span>)<br>    pred_tags = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(y.shape[<span class="hljs-number">0</span>]):<br>        pred_tags.append([id_label_dict[_] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> y[i] <span class="hljs-keyword">if</span> _])<br><br>    <span class="hljs-comment"># 因为存在预测的标签长度与原来的标注长度不一致的情况，因此需要调整预测的标签</span><br>    test_sents, test_tags = read_data(test_file_path)<br>    final_tags = []<br>    <span class="hljs-keyword">for</span> test_tag, pred_tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(test_tags, pred_tags):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(test_tag) == <span class="hljs-built_in">len</span>(pred_tag):<br>            final_tags.append(pred_tag)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(test_tag) &lt; <span class="hljs-built_in">len</span>(pred_tag):<br>            final_tags.append(pred_tag[:<span class="hljs-built_in">len</span>(test_tag)])<br>        <span class="hljs-keyword">else</span>:<br>            final_tags.append(pred_tag + [<span class="hljs-string">&#x27;O&#x27;</span>] * (<span class="hljs-built_in">len</span>(test_tag) - <span class="hljs-built_in">len</span>(pred_tag)))<br><br>    <span class="hljs-comment"># 利用seqeval对测试集进行验证</span><br>    <span class="hljs-built_in">print</span>(classification_report(test_tags, final_tags, digits=<span class="hljs-number">4</span>))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    train_model()<br></code></pre></td></tr></table></figure><p>模型训练过程中的输出结果如下（部分输出省略）：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs markdown">sentences length: 20864 <br>last sentence:  思想自由是对自我而言，用中国传统的说法是有所为；兼容并包是指对待他人，要有所不为。<br>start ALBERT encding<br>end ALBERT encoding<br>sentences length: 2318 <br>last sentence:  良性肿瘤、恶性肿瘤虽然只是一字之差，但两者有根本性的差别。<br>start ALBERT encding<br>end ALBERT encoding<br>sentences length: 4636 <br>last sentence:  因此，村民进行民主选举的心态是在这样一种背景映衬下加以表现的，这无疑给该片增添了几分厚重的历史文化氛围。<br>start ALBERT encding<br>end ALBERT encoding<br><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_<br><span class="hljs-section">Layer (type)                 Output Shape              Param #   </span><br><span class="hljs-section">=================================================================</span><br>bert<span class="hljs-emphasis">_output (InputLayer)     (None, 128, 312)          0         </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span><br>bi<span class="hljs-emphasis">_lstm (Bidirectional)      (None, 128, 256)          451584    </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span><br>dropout (Dropout)            (None, 128, 256)          0         <br><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_<br><span class="hljs-section">time<span class="hljs-emphasis">_distributed (TimeDistri (None, 128, 8)            2056      </span></span><br><span class="hljs-emphasis"><span class="hljs-section">=================================================================</span></span><br><span class="hljs-emphasis"><span class="hljs-section">Total params: 453,640</span></span><br><span class="hljs-emphasis"><span class="hljs-section">Trainable params: 453,640</span></span><br><span class="hljs-emphasis"><span class="hljs-section">Non-trainable params: 0</span></span><br><span class="hljs-emphasis"><span class="hljs-section"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span></span><br><span class="hljs-section">Train on 20864 samples, validate on 2318 samples</span><br><span class="hljs-section">......</span><br><span class="hljs-section">......</span><br><span class="hljs-section">......</span><br><span class="hljs-section">20864/20864 [==============================] - 97s 5ms/step - loss: 0.0091 - acc: 0.9969 - val<span class="hljs-emphasis">_loss: 0.0397 - val_</span>acc: 0.9900</span><br><span class="hljs-section">           precision    recall  f1-score   support</span><br><span class="hljs-section"></span><br><span class="hljs-section">      ORG     0.9001    0.9112    0.9056      2185</span><br><span class="hljs-section">      LOC     0.9383    0.8898    0.9134      3658</span><br><span class="hljs-section">      PER     0.9543    0.9415    0.9479      1864</span><br><span class="hljs-section"></span><br><span class="hljs-section">micro avg     0.9310    0.9084    0.9196      7707</span><br><span class="hljs-section">macro avg     0.9313    0.9084    0.9195      7707</span><br></code></pre></td></tr></table></figure><p>在测试集上的F1值为91.96%。同时，训练过程中的loss和acc曲线如下图：</p><figure><img src="/img/nlp24_3.png" alt="训练过程中的loss和acc曲线图" /><figcaption aria-hidden="true">训练过程中的loss和acc曲线图</figcaption></figure><p>模型预测部分的代码（脚本为model_predict.py）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-03-11 13:16</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> albert_zh.extract_feature <span class="hljs-keyword">import</span> BertVector<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> MAX_SEQ_LEN, event_type<br><br><span class="hljs-comment"># 读取label2id字典</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;%s_label2id.json&quot;</span> % event_type, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> h:<br>    label_id_dict = json.loads(h.read())<br><br>id_label_dict = &#123;v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> label_id_dict.items()&#125;<br><br><span class="hljs-comment"># 利用ALBERT提取文本特征</span><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;NONE&quot;</span>, max_seq_len=MAX_SEQ_LEN)<br>f = <span class="hljs-keyword">lambda</span> text: bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># 载入模型</span><br>ner_model = load_model(<span class="hljs-string">&quot;%s_ner.h5&quot;</span> % event_type)<br><br><br><span class="hljs-comment"># 从预测的标签列表中获取实体</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_entity</span>(<span class="hljs-params">sent, tags_list</span>):<br><br>    entity_dict = defaultdict(<span class="hljs-built_in">list</span>)<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> char, tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(sent, tags_list):<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;B-&#x27;</span> <span class="hljs-keyword">in</span> tag:<br>            entity = char<br>            j = i+<span class="hljs-number">1</span><br>            entity_type = tag.split(<span class="hljs-string">&#x27;-&#x27;</span>)[-<span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">while</span> j &lt; <span class="hljs-built_in">min</span>(<span class="hljs-built_in">len</span>(sent), <span class="hljs-built_in">len</span>(tags_list)) <span class="hljs-keyword">and</span> <span class="hljs-string">&#x27;I-%s&#x27;</span> % entity_type <span class="hljs-keyword">in</span> tags_list[j]:<br>                entity += sent[j]<br>                j += <span class="hljs-number">1</span><br><br>            entity_dict[entity_type].append(entity)<br><br>        i += <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">dict</span>(entity_dict)<br><br><br><span class="hljs-comment"># 输入句子，进行预测</span><br><span class="hljs-keyword">while</span> <span class="hljs-number">1</span>:<br>    <span class="hljs-comment"># 输入句子</span><br>    text = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Please enter an sentence: &quot;</span>).replace(<span class="hljs-string">&#x27; &#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-comment"># 利用训练好的模型进行预测</span><br>    train_x = np.array([f(text)])<br>    y = np.argmax(ner_model.predict(train_x), axis=<span class="hljs-number">2</span>)<br>    y = [id_label_dict[_] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> y[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> _]<br><br>    <span class="hljs-comment"># 输出预测结果</span><br>    pprint(get_entity(text, y)<br></code></pre></td></tr></table></figure><p>随机在网上找几条新闻测试，结果如下：</p><blockquote><p>Please enter an sentence:昨天进行的女单半决赛中，陈梦4-2击败了队友王曼昱，伊藤美诚则以4-0横扫了中国选手丁宁。{'LOC': ['中国'], 'PER': ['陈梦', '王曼昱', '伊藤美诚', '丁宁']} Pleaseenter an sentence:报道还提到，德国卫生部长延斯·施潘在会上也表示，如果不能率先开发出且使用疫苗，那么60%至70%的人可能会被感染新冠病毒。{'ORG': ['德国卫生部'], 'PER': ['延斯·施潘']} Please enter an sentence:“隔离结束回来，发现公司不见了”，网上的段子，真发生在了昆山达鑫电子有限公司员工身上。{'ORG': ['昆山达鑫电子有限公司']} Please enter an sentence:真人版的《花木兰》由新西兰导演妮基·卡罗执导，由刘亦菲、甄子丹、郑佩佩、巩俐、李连杰等加盟，几乎是全亚洲整容。{'LOC': ['新西兰', '亚洲'], 'PER': ['妮基·卡罗', '刘亦菲', '甄子丹','郑佩佩', '巩俐', '李连杰']}</p></blockquote><p>本项目已经开源，Github网址为：<ahref="https://github.com/percent4/ALBERT_NER_KERAS">https://github.com/percent4/ALBERT_NER_KERAS</a>。</p><p>本文到此结束，感谢大家阅读。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>NER</tag>
      
      <tag>ALBERT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（二十三）序列标注算法评估模块seqeval的使用</title>
    <link href="/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%89%EF%BC%89%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9D%97seqeval%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%89%EF%BC%89%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9D%97seqeval%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在NLP中，序列标注算法是常见的深度学习模型，但是，对于序列标注算法的评估，我们真的熟悉吗？</p><p>在本文中，笔者将会序列标注算法的模型效果评估方法和<code>seqeval</code>的使用。</p><h3 id="序列标注算法的模型效果评估">序列标注算法的模型效果评估</h3><p>在序列标注算法中，一般我们会形成如下的序列列表，如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;B-MISC</span>&#x27;, <span class="hljs-symbol">&#x27;I-MISC</span>&#x27;, <span class="hljs-symbol">&#x27;B-MISC</span>&#x27;, <span class="hljs-symbol">&#x27;I-MISC</span>&#x27;, <span class="hljs-symbol">&#x27;O</span>&#x27;, <span class="hljs-symbol">&#x27;B-PER</span>&#x27;, <span class="hljs-symbol">&#x27;I-PER</span>&#x27;]<br></code></pre></td></tr></table></figure><p>一般序列标注算法的格式有<code>BIO</code>，<code>IOBES</code>，<code>BMES</code>等。其中，<code>实体</code>指的是从B开头标签开始的，同一类型（比如：PER/LOC/ORG）的，非O的连续标签序列。</p><p>常见的序列标注算法的模型效果评估指标有准确率（accuracy）、查准率(percision)、召回率(recall)、F1值等，计算的公式如下：</p><ul><li><p>准确率: accuracy = 预测对的元素个数/总的元素个数</p></li><li><p>查准率：precision = 预测正确的实体个数 /预测的实体总个数</p></li><li><p>召回率：recall = 预测正确的实体个数 / 标注的实体总个数</p></li><li><p>F1值：F1 = 2 <em>准确率 </em> 召回率 / (准确率 + 召回率)</p><p>举个例子，我们有如下的真实序列<code>y_true</code>和预测序列<code>y_pred</code>，如下：</p></li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">y_true</span> = [<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>]<br><span class="hljs-attr">y_pred</span> = [<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>]<br></code></pre></td></tr></table></figure><p>列表中一个有9个元素，其中预测对的元素个数为6个，那么准确率为2/3。标注的实体总个数为2个，预测的实体总个数为3个，预测正确的实体个数为1个，那么precision=1/3,recall=1/2, F1=0.4。</p><h3 id="seqeval的使用">seqeval的使用</h3><p>一般我们的序列标注算法，是用<code>conlleval.pl</code>脚本实现，但这是用perl语言实现的。在Python中，也有相应的序列标注算法的模型效果评估的第三方模块，那就是<code>seqeval</code>，其官网网址为：<ahref="https://pypi.org/project/seqeval/0.0.3/">https://pypi.org/project/seqeval/0.0.3/</a>。</p><p><code>seqeval</code>支持<code>BIO</code>，<code>IOBES</code>标注模式，可用于命名实体识别，词性标注，语义角色标注等任务的评估。</p><p>官网文档中给出了两个例子，笔者修改如下：</p><p>例子1：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> f1_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> precision_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> recall_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> classification_report<br><br>y_true = [<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>]<br>y_pred = [<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>]<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;accuary: &quot;</span>, accuracy_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;p: &quot;</span>, precision_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;r: &quot;</span>, recall_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;f1: &quot;</span>, f1_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;classification report: &quot;</span>)<br><span class="hljs-built_in">print</span>(classification_report(y_true, y_pred))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">accuary</span>:  <span class="hljs-number">0</span>.<span class="hljs-number">6666666666666666</span><br><span class="hljs-attribute">p</span>:  <span class="hljs-number">0</span>.<span class="hljs-number">3333333333333333</span><br><span class="hljs-attribute">r</span>:  <span class="hljs-number">0</span>.<span class="hljs-number">5</span><br><span class="hljs-attribute">f1</span>:  <span class="hljs-number">0</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">classification</span> report: <br>           <span class="hljs-attribute">precision</span>    recall  f1-score   support<br><br>     <span class="hljs-attribute">MISC</span>       <span class="hljs-number">0</span>.<span class="hljs-number">00</span>      <span class="hljs-number">0</span>.<span class="hljs-number">00</span>      <span class="hljs-number">0</span>.<span class="hljs-number">00</span>         <span class="hljs-number">1</span><br>      <span class="hljs-attribute">PER</span>       <span class="hljs-number">1</span>.<span class="hljs-number">00</span>      <span class="hljs-number">1</span>.<span class="hljs-number">00</span>      <span class="hljs-number">1</span>.<span class="hljs-number">00</span>         <span class="hljs-number">1</span><br><br><span class="hljs-attribute">micro</span> avg       <span class="hljs-number">0</span>.<span class="hljs-number">33</span>      <span class="hljs-number">0</span>.<span class="hljs-number">50</span>      <span class="hljs-number">0</span>.<span class="hljs-number">40</span>         <span class="hljs-number">2</span><br><span class="hljs-attribute">macro</span> avg       <span class="hljs-number">0</span>.<span class="hljs-number">50</span>      <span class="hljs-number">0</span>.<span class="hljs-number">50</span>      <span class="hljs-number">0</span>.<span class="hljs-number">50</span>         <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>例子2：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> f1_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> precision_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> recall_score<br><span class="hljs-keyword">from</span> seqeval.metrics <span class="hljs-keyword">import</span> classification_report<br><br>y_true = [[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>], [<span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>]]<br>y_pred =  [[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>], [<span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>]]<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;accuary: &quot;</span>, accuracy_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;p: &quot;</span>, precision_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;r: &quot;</span>, recall_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;f1: &quot;</span>, f1_score(y_true, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;classification report: &quot;</span>)<br><span class="hljs-built_in">print</span>(classification_report(y_true, y_pred))<br></code></pre></td></tr></table></figure><p>输出结果同上。</p><h3 id="在keras中使用seqeval">在Keras中使用seqeval</h3><p>笔者一年多年写过文章：<ahref="https://percent4.github.io/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%94%EF%BC%89%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%8E%B0%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%EF%BC%88NER%EF%BC%89/">用深度学习实现命名实体识别（NER）</a>，我们对模型训练部分的代码加以改造，使之在训练过程中能输出F1值。</p><p>在Github上下载项目<code>DL_4_NER</code>，网址为：<ahref="https://github.com/percent4/DL_4_NER">https://github.com/percent4/DL_4_NER</a>。修改utils.py中的文件夹路径，以及模型训练部分的代码（DL_4_NER/Bi_LSTM_Model_training.py）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> BASE_DIR, CONSTANTS, load_data<br><span class="hljs-keyword">from</span> data_processing <span class="hljs-keyword">import</span> data_processing<br><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> np_utils, plot_model<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential<br><span class="hljs-keyword">from</span> keras.preprocessing.sequence <span class="hljs-keyword">import</span> pad_sequences<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Bidirectional, LSTM, Dense, Embedding, TimeDistributed<br><br><br><span class="hljs-comment"># 模型输入数据</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">input_data_for_model</span>(<span class="hljs-params">input_shape</span>):<br><br>    <span class="hljs-comment"># 数据导入</span><br>    input_data = load_data()<br>    <span class="hljs-comment"># 数据处理</span><br>    data_processing()<br>    <span class="hljs-comment"># 导入字典</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(CONSTANTS[<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        word_dictionary = pickle.load(f)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(CONSTANTS[<span class="hljs-number">2</span>], <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        inverse_word_dictionary = pickle.load(f)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(CONSTANTS[<span class="hljs-number">3</span>], <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        label_dictionary = pickle.load(f)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(CONSTANTS[<span class="hljs-number">4</span>], <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        output_dictionary = pickle.load(f)<br>    vocab_size = <span class="hljs-built_in">len</span>(word_dictionary.keys())<br>    label_size = <span class="hljs-built_in">len</span>(label_dictionary.keys())<br><br>    <span class="hljs-comment"># 处理输入数据</span><br>    aggregate_function = <span class="hljs-keyword">lambda</span> <span class="hljs-built_in">input</span>: [(word, pos, label) <span class="hljs-keyword">for</span> word, pos, label <span class="hljs-keyword">in</span><br>                                            <span class="hljs-built_in">zip</span>(<span class="hljs-built_in">input</span>[<span class="hljs-string">&#x27;word&#x27;</span>].values.tolist(),<br>                                                <span class="hljs-built_in">input</span>[<span class="hljs-string">&#x27;pos&#x27;</span>].values.tolist(),<br>                                                <span class="hljs-built_in">input</span>[<span class="hljs-string">&#x27;tag&#x27;</span>].values.tolist())]<br><br>    grouped_input_data = input_data.groupby(<span class="hljs-string">&#x27;sent_no&#x27;</span>).apply(aggregate_function)<br>    sentences = [sentence <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> grouped_input_data]<br><br>    x = [[word_dictionary[word[<span class="hljs-number">0</span>]] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sent] <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sentences]<br>    x = pad_sequences(maxlen=input_shape, sequences=x, padding=<span class="hljs-string">&#x27;post&#x27;</span>, value=<span class="hljs-number">0</span>)<br>    y = [[label_dictionary[word[<span class="hljs-number">2</span>]] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sent] <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sentences]<br>    y = pad_sequences(maxlen=input_shape, sequences=y, padding=<span class="hljs-string">&#x27;post&#x27;</span>, value=<span class="hljs-number">0</span>)<br>    y = [np_utils.to_categorical(label, num_classes=label_size + <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> y]<br><br>    <span class="hljs-keyword">return</span> x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary<br><br><br><span class="hljs-comment"># 定义深度学习模型：Bi-LSTM</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_Bi_LSTM</span>(<span class="hljs-params">vocab_size, label_size, input_shape, output_dim, n_units, out_act, activation</span>):<br>    model = Sequential()<br>    model.add(Embedding(input_dim=vocab_size + <span class="hljs-number">1</span>, output_dim=output_dim,<br>                        input_length=input_shape, mask_zero=<span class="hljs-literal">True</span>))<br>    model.add(Bidirectional(LSTM(units=n_units, activation=activation,<br>                                 return_sequences=<span class="hljs-literal">True</span>)))<br>    model.add(TimeDistributed(Dense(label_size + <span class="hljs-number">1</span>, activation=out_act)))<br>    model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>, loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-comment"># 模型训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model_train</span>():<br><br>    <span class="hljs-comment"># 将数据集分为训练集和测试集，占比为9:1</span><br>    input_shape = <span class="hljs-number">60</span><br>    x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary = input_data_for_model(input_shape)<br>    train_end = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(x)*<span class="hljs-number">0.9</span>)<br>    train_x, train_y = x[<span class="hljs-number">0</span>:train_end], np.array(y[<span class="hljs-number">0</span>:train_end])<br>    test_x, test_y = x[train_end:], np.array(y[train_end:])<br><br>    <span class="hljs-comment"># 模型输入参数</span><br>    activation = <span class="hljs-string">&#x27;selu&#x27;</span><br>    out_act = <span class="hljs-string">&#x27;softmax&#x27;</span><br>    n_units = <span class="hljs-number">100</span><br>    batch_size = <span class="hljs-number">32</span><br>    epochs = <span class="hljs-number">10</span><br>    output_dim = <span class="hljs-number">20</span><br><br>    <span class="hljs-comment"># 模型训练</span><br>    lstm_model = create_Bi_LSTM(vocab_size, label_size, input_shape, output_dim, n_units, out_act, activation)<br>    lstm_model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=epochs, batch_size=batch_size, verbose=<span class="hljs-number">1</span>)<br><br><br>model_train()<br></code></pre></td></tr></table></figure><p>模型训练的结果如下（中间过程省略）：</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gradle">......<br><span class="hljs-number">12598</span><span class="hljs-regexp">/12598 [==============================] - 26s 2ms/</span><span class="hljs-keyword">step</span> - loss: <span class="hljs-number">0.0075</span> - acc: <span class="hljs-number">0.9981</span> - val_loss: <span class="hljs-number">0.2131</span> - val_acc: <span class="hljs-number">0.9592</span><br></code></pre></td></tr></table></figure><p>我们修改代码，在lstm_model.fit那一行修改代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">lables = [<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;sO&#x27;</span>]<br>   id2label = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(lables)), lables))<br>   callbacks = [F1Metrics(id2label)]<br>   lstm_model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=epochs,<br>                  batch_size=batch_size, verbose=<span class="hljs-number">1</span>, callbacks=callbacks)<br></code></pre></td></tr></table></figure><p>此时输出结果为：</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs stata">12598/12598 [==============================] - 26s 2ms/step - loss: 0.0089 - acc: 0.9978 - val_loss: 0.2145 - val_acc: 0.9560<br> - f1: 95.40<br>           precision    recall  f1-<span class="hljs-keyword">score</span>   support<br><br>     MISC     0.9707    0.9833    0.9769     15844<br>      PER     0.9080    0.8194    0.8614      1157<br>      <span class="hljs-keyword">LOC</span>     0.7517    0.8095    0.7795       677<br>      ORG     0.8290    0.7289    0.7757       745<br>       <span class="hljs-keyword">sO</span>     0.7757    0.8300    0.8019       100<br><br>micro avg     0.9524    0.9556    0.9540     18523<br><span class="hljs-keyword">macro</span> avg     0.9520    0.9556    0.9535     18523<br></code></pre></td></tr></table></figure><p>这就是seqeval的强大之处。</p><p>关于seqeval在Keras的使用，有不清楚的地方可以参考该项目的Github网址：<ahref="https://github.com/chakki-works/seqeval">https://github.com/chakki-works/seqeval</a>。</p><h3 id="总结">总结</h3><p>感谢大家的阅读，本次分享到此结束。</p><p>欢迎大家关注我的微信公众号：<code>NLP奇幻之旅</code>。</p><h3 id="参考网址">参考网址</h3><ol type="1"><li>序列标注的准确率和召回率计算: <ahref="https://zhuanlan.zhihu.com/p/56582082">https://zhuanlan.zhihu.com/p/56582082</a></li><li>seqeval官方文档： <ahref="https://pypi.org/project/seqeval/0.0.3/">https://pypi.org/project/seqeval/0.0.3/</a></li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>NLP工具</tag>
      
      <tag>序列标注</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>知识图谱构建举例</title>
    <link href="/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA%E4%B8%BE%E4%BE%8B/"/>
    <url>/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA%E4%B8%BE%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>笔者在去年的时候，给出了利用深度学习来构建知识图谱的一次尝试，文章为：<ahref="https://percent4.github.io/%E5%88%A9%E7%94%A8%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E6%9E%84%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/">利用关系抽取构建知识图谱的一次尝试</a>，本文将会更出更多的例子，也是笔者近一个星期的忙碌结果。下面为知识图谱构建的例子，由笔者原创，是从新闻或者小说中直接抽取而来，加上大量时间的人工整理而得到，下面的图片是从Neo4J导出并截图。例子1：《平凡的世界》实体关系图（局部）： <img src="/img/kg2_1.png"alt="《平凡的世界》实体关系图（局部）" />例子2：《白鹿原》实体关系图（局部）： <img src="/img/kg2_2.png"alt="《白鹿原》实体关系图（局部）" />例子3：政治新闻实体关系图（局部）： <img src="/img/kg2_3.png"alt="政治新闻实体关系图（局部）" />例子4：《神雕侠侣》实体关系图（局部）： <img src="/img/kg2_4.png"alt="《神雕侠侣》实体关系图（局部）" />例子5：《明朝那些事儿》实体关系图（局部）： <img src="/img/kg2_5.png"alt="《明朝那些事儿》实体关系图（局部）" />例子6：《曾国藩》实体关系图（局部）： <img src="/img/kg2_6.png"alt="《曾国藩》实体关系图（局部）" /></p><p>以上展示的图以及数据放在Github上，网址为：<ahref="https://github.com/percent4/knowledge_graph_demo">https://github.com/percent4/knowledge_graph_demo</a>。关于这方面的技术和数据将会在不久后公开，代码和数据已经放在Github上，网址为：<ahref="https://github.com/percent4/spo_extract_platform">https://github.com/percent4/spo_extract_platform</a>，笔者将会另写文章来介绍。</p><p>感觉大家的阅读，笔者将会在不久之后公开该技术的源代码和数据，敬请期待~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>知识图谱</category>
      
    </categories>
    
    
    <tags>
      
      <tag>知识图谱</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（二十二）利用ALBERT实现文本二分类</title>
    <link href="/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%8C%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB/"/>
    <url>/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%8C%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%EF%BC%89%E5%88%A9%E7%94%A8BERT%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB/">NLP（二十）利用BERT实现文本二分类</a>中，笔者介绍了如何使用BERT来实现文本二分类功能，以判别是否属于出访类事件为例子。但是呢，利用BERT在做模型预测的时候存在预测时间较长的问题。因此，我们考虑用新出来的预训练模型来加快模型预测速度。</p><p>本文将介绍如何利用ALBERT来实现文本二分类。</p><h3 id="关于albert">关于ALBERT</h3><p>ALBERT的提出时间大约是在2019年10月，其第一作者为谷歌科学家蓝振忠博士。ALBERT的论文地址为：<ahref="https://openreview.net/pdf?id=H1eA7AEtvS">https://openreview.net/pdf?id=H1eA7AEtvS</a>, Github项目地址为： <ahref="https://github.com/brightmart/albert_zh">https://github.com/brightmart/albert_zh</a>。简单说来，ALBERT是BERT的一个精简版，它在BERT模型的基础上进行改造，减少了大量参数，使得其在模型训练和模型预测的速度上有很大提升，而模型的效果只会有微小幅度的下降，具体的效果和速度方面的说明可以参考Github项目。ALBERT相对于BERT的改进如下：</p><ul><li><p>对Embedding因式分解（Factorized embeddingparameterization）；</p></li><li><p>跨层的参数共享（Cross-layer parameter sharing）；</p></li><li><p>句间连贯（Inter-sentence coherence loss）；</p></li><li><p>移除dropout 。</p><p>笔者在北京的时候也写过ALBERT在提升序列标注算法的预测速度方面的一篇文章：<ahref="https://percent4.github.io/NLP%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E9%80%9F%E5%BA%A6%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/">NLP（十八）利用ALBERT提升模型预测速度的一次尝试</a>，该项目的Github地址为：<ahref="https://github.com/percent4/ALBERT_4_Time_Recognition">https://github.com/percent4/ALBERT_4_Time_Recognition</a>。</p></li></ul><h3 id="项目说明">项目说明</h3><p>本项目的数据和代码主要参考笔者的文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%EF%BC%89%E5%88%A9%E7%94%A8BERT%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB/">NLP（二十）利用BERT实现文本二分类</a>，该项目是想判别输入的句子是否属于政治上的出访类事件。笔者一共收集了340条数据，其中280条用作训练集，60条用作测试集。</p><p>项目结构如下图：</p><p><a href="/img/nlp22_1.png">项目结构</a></p><p>在这里我们使用ALBERT已经训练好的文件<code>albert_tiny</code>，借鉴BERT的调用方法，我们在这里给出<code>albert_zh</code>模块，能够让ALBERT提取文本的特征，具体代码不在这里给出，有兴趣的读者可以访问该项目的Github地址：<ahref="https://github.com/percent4/ALBERT_text_classification">https://github.com/percent4/ALBERT_text_classification</a>。</p><p>注意，<code>albert_tiny</code>给出的向量维度为312，我们的模型训练代码（model_train.py）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-03-04 13:37</span><br><br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> load_data <span class="hljs-keyword">import</span> train_df, test_df<br><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> to_categorical<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model<br><span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> Adam<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Input, BatchNormalization, Dense<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">from</span> albert_zh.extract_feature <span class="hljs-keyword">import</span> BertVector<br><br><span class="hljs-comment"># 读取文件并进行转换</span><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;REDUCE_MEAN&quot;</span>, max_seq_len=<span class="hljs-number">100</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;begin encoding&#x27;</span>)<br>f = <span class="hljs-keyword">lambda</span> text: bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br>train_df[<span class="hljs-string">&#x27;x&#x27;</span>] = train_df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(f)<br>test_df[<span class="hljs-string">&#x27;x&#x27;</span>] = test_df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(f)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;end encoding&#x27;</span>)<br><br>x_train = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> train_df[<span class="hljs-string">&#x27;x&#x27;</span>]])<br>x_test = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> test_df[<span class="hljs-string">&#x27;x&#x27;</span>]])<br>y_train = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> train_df[<span class="hljs-string">&#x27;label&#x27;</span>]])<br>y_test = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> test_df[<span class="hljs-string">&#x27;label&#x27;</span>]])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;x_train: &#x27;</span>, x_train.shape)<br><br><span class="hljs-comment"># Convert class vectors to binary class matrices.</span><br>num_classes = <span class="hljs-number">2</span><br>y_train = to_categorical(y_train, num_classes)<br>y_test = to_categorical(y_test, num_classes)<br><br><span class="hljs-comment"># 创建模型</span><br>x_in = Input(shape=(<span class="hljs-number">312</span>, ))<br>x_out = Dense(<span class="hljs-number">32</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>)(x_in)<br>x_out = BatchNormalization()(x_out)<br>x_out = Dense(num_classes, activation=<span class="hljs-string">&quot;softmax&quot;</span>)(x_out)<br>model = Model(inputs=x_in, outputs=x_out)<br><span class="hljs-built_in">print</span>(model.summary())<br><br>model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>,<br>              optimizer=Adam(),<br>              metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br><span class="hljs-comment"># 模型训练以及评估</span><br>history = model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=<span class="hljs-number">8</span>, epochs=<span class="hljs-number">20</span>)<br>model.save(<span class="hljs-string">&#x27;visit_classify.h5&#x27;</span>)<br><span class="hljs-built_in">print</span>(model.evaluate(x_test, y_test))<br><br><span class="hljs-comment"># 绘制loss和acc图像</span><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>epochs = <span class="hljs-built_in">len</span>(history.history[<span class="hljs-string">&#x27;loss&#x27;</span>])<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;loss&#x27;</span>], label=<span class="hljs-string">&#x27;loss&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;val_loss&#x27;</span>], label=<span class="hljs-string">&#x27;val_loss&#x27;</span>)<br>plt.legend()<br><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>epochs = <span class="hljs-built_in">len</span>(history.history[<span class="hljs-string">&#x27;acc&#x27;</span>])<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;acc&#x27;</span>], label=<span class="hljs-string">&#x27;acc&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), history.history[<span class="hljs-string">&#x27;val_acc&#x27;</span>], label=<span class="hljs-string">&#x27;val_acc&#x27;</span>)<br>plt.legend()<br>plt.savefig(<span class="hljs-string">&quot;loss_acc.png&quot;</span>)<br></code></pre></td></tr></table></figure><p>模型训练的效果很不错，在训练集的acc为0.9857,在测试集上的acc为0.9500，具体如下：</p><figure><img src="/img/nlp22_2.png" alt="训练过程中的loss和acc图" /><figcaption aria-hidden="true">训练过程中的loss和acc图</figcaption></figure><h3 id="与bert的预测对比">与BERT的预测对比</h3><p>接下来我们在模型预测上的时间，与BERT的文本二分类模型预测时间做一个对比，这样有助于提升我们对ALBERT的印象。</p><p>BERT的文本二分类模型预测可以参考文章<ahref="https://percent4.github.io/2023/07/08/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%EF%BC%89%E5%88%A9%E7%94%A8BERT%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB/">NLP（二十）利用BERT实现文本二分类</a>，本文给出的代码与BERT实现的模型预测代码基本一致，只不过BERT提取特征改成ALBERT提取特征。</p><p>本文的模型预测代码（model_predict.py）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-03-04 17:33</span><br><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> albert_zh.extract_feature <span class="hljs-keyword">import</span> BertVector<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br>load_model = load_model(<span class="hljs-string">&quot;visit_classify.h5&quot;</span>)<br><br><span class="hljs-comment"># 预测语句</span><br>texts = [<span class="hljs-string">&#x27;在访问限制中，用户可以选择禁用iPhone的功能，包括Siri、iTunes购买功能、安装/删除应用等，甚至还可以让iPhone变成一台功能手机。以下是访问限制具体可以实现的一些功能&#x27;</span>,<br>         <span class="hljs-string">&#x27;IT之家4月23日消息 近日，谷歌在其官方论坛发布消息表示，他们为Android Auto添加了一项新功能：可以访问完整联系人列表。用户现在可以通过在Auto的电话拨号界面中打开左上角的菜单访问完整的联系人列表。值得注意的是，这一功能仅支持在车辆停止时使用。&#x27;</span>,<br>         <span class="hljs-string">&#x27;要通过telnet 访问路由器，需要先通过console 口对路由器进行基本配置，例如：IP地址、密码等。&#x27;</span>,<br>         <span class="hljs-string">&#x27;IT之家3月26日消息 近日反盗版的国际咨询公司MUSO发布了2017年的年度报告，其中的数据显示，去年盗版资源网站访问量达到了3000亿次，比前一年（2016年）提高了1.6%。美国是访问盗版站点次数最多的国家，共有279亿次访问；其后分别是俄罗斯、印度和巴西，中国位列第18。&#x27;</span>,<br>         <span class="hljs-string">&#x27;目前A站已经恢复了访问，可以直接登录，网页加载正常，视频已经可以正常播放。&#x27;</span>,<br>         <span class="hljs-string">&#x27;Win7电脑提示无线适配器或访问点有问题怎么办?很多用户在使用无线网连接上网时，发现无线网显示已连接，但旁边却出现了一个黄色感叹号，无法进行网络操作，通过诊断提示电脑无线适配器或访问点有问题，且处于未修复状态，这该怎么办呢?下面小编就和大家分享下Win7电脑提示无线适配器或访问点有问题的解决方法。&#x27;</span>,<br>         <span class="hljs-string">&#x27;未开发所有安全组之前访问，FTP可以链接上，但是打开会很慢，需要1-2分钟才能链接上&#x27;</span>,<br>         <span class="hljs-string">&#x27;win7系统电脑的用户，在连接WIFI网络网上时，有时候会遇到突然上不了网，查看连接的WIFI出现“有限的访问权限”的文字提示。&#x27;</span>,<br>         <span class="hljs-string">&#x27;2月28日，唐山曹妃甸蓝色海洋科技有限公司董事长赵力军等一行5人到黄海水产研究所交流访问。黄海水产研究所副所长辛福言及相关部门负责人、专家等参加了会议。&#x27;</span>,<br>         <span class="hljs-string">&#x27;与标准Mozy一样，Stash文件夹为用户提供了对其备份文件的基于云的访问，但是它们还使他们可以随时，跨多个设备(包括所有计算机，智能手机和平板电脑)访问它们。换句话说，使用浏览器的任何人都可以同时查看文件(如果需要)。操作系统和设备品牌无关。&#x27;</span>,<br>         <span class="hljs-string">&#x27;研究表明，每个网页的平均预期寿命为44至100天。当用户通过浏览器访问已消失的网页时，就会看到「Page Not Found」的错误信息。对于这种情况，相信大多数人也只能不了了之。不过有责任心的组织——互联网档案馆为了提供更可靠的Web服务，它联手Brave浏览器专门针对此类网页提供了一键加载存档页面的功能。&#x27;</span>,<br>         <span class="hljs-string">&#x27;3日，根据三星电子的消息，李在镕副会长这天访问了位于韩国庆尚北道龟尾市的三星电子工厂。&#x27;</span>] * <span class="hljs-number">10</span><br><br>labels = []<br><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;REDUCE_MEAN&quot;</span>, max_seq_len=<span class="hljs-number">100</span>)<br><br>init_time = time.time()<br><br><span class="hljs-comment"># 对上述句子进行预测</span><br><span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts:<br><br>    <span class="hljs-comment"># 将句子转换成向量</span><br>    vec = bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br>    x_train = np.array([vec])<br><br>    <span class="hljs-comment"># 模型预测</span><br>    predicted = load_model.predict(x_train)<br>    y = np.argmax(predicted[<span class="hljs-number">0</span>])<br>    label = <span class="hljs-string">&#x27;Y&#x27;</span> <span class="hljs-keyword">if</span> y <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;N&#x27;</span><br>    labels.append(label)<br><br>cost_time = time.time() - init_time<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Average cost time: %s.&quot;</span> % (cost_time/<span class="hljs-built_in">len</span>(texts)))<br><br><span class="hljs-keyword">for</span> text, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(texts, labels):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%s\t%s&#x27;</span> % (label, text))<br><br>df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;句子&#x27;</span>:texts, <span class="hljs-string">&quot;是否属于出访类事件&quot;</span>: labels&#125;)<br>df.to_excel(<span class="hljs-string">&#x27;./result.xlsx&#x27;</span>, index=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>输出的平均预测时长为：<code>16.98ms</code>，而BERT版的平均预测时间为：<code>257.31ms</code>。</p><p>我们将模型预测写成HTTP服务，代码（server.py）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-03-04 20:13</span><br><br><span class="hljs-keyword">import</span> tornado.httpserver<br><span class="hljs-keyword">import</span> tornado.ioloop<br><span class="hljs-keyword">import</span> tornado.options<br><span class="hljs-keyword">import</span> tornado.web<br><span class="hljs-keyword">from</span> tornado.options <span class="hljs-keyword">import</span> define, options<br><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> albert_zh.extract_feature <span class="hljs-keyword">import</span> BertVector<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><br><br><span class="hljs-comment"># 定义端口为10008</span><br>define(<span class="hljs-string">&quot;port&quot;</span>, default=<span class="hljs-number">10008</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;run on the given port&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>)<br><br><span class="hljs-comment"># 加载ALBERT</span><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;REDUCE_MEAN&quot;</span>, max_seq_len=<span class="hljs-number">100</span>)<br><span class="hljs-comment"># 加载已经训练好的模型</span><br>load_model = load_model(<span class="hljs-string">&quot;visit_classify.h5&quot;</span>)<br><br><br><span class="hljs-comment"># 对句子进行预测</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PredictHandler</span>(tornado.web.RequestHandler):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">post</span>(<span class="hljs-params">self</span>):<br><br>        text = self.get_argument(<span class="hljs-string">&quot;text&quot;</span>)<br><br>        <span class="hljs-comment"># 将句子转换成向量</span><br>        vec = bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br>        x_train = np.array([vec])<br><br>        <span class="hljs-comment"># 模型预测</span><br>        predicted = load_model.predict(x_train)<br>        y = np.argmax(predicted[<span class="hljs-number">0</span>])<br>        label = <span class="hljs-string">&#x27;是&#x27;</span> <span class="hljs-keyword">if</span> y <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;否&quot;</span><br><br>        <span class="hljs-comment"># 返回结果</span><br>        result = &#123;<span class="hljs-string">&quot;原文&quot;</span>: text, <span class="hljs-string">&quot;是否属于出访类事件？&quot;</span>: label&#125;<br><br>        self.write(json.dumps(result, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">2</span>))<br><br><br><span class="hljs-comment"># 主函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br><br>    <span class="hljs-comment"># 开启tornado服务</span><br>    tornado.options.parse_command_line()<br>    <span class="hljs-comment"># 定义app</span><br>    app = tornado.web.Application(<br>            handlers=[(<span class="hljs-string">r&#x27;/predict&#x27;</span>, PredictHandler)] <span class="hljs-comment">#网页路径控制</span><br>           )<br>    http_server = tornado.httpserver.HTTPServer(app)<br>    http_server.listen(options.port)<br>    tornado.ioloop.IOLoop.instance().start()<br><br><br>main()<br></code></pre></td></tr></table></figure><p>用Postman进行测试，如下图：</p><p><img src="/img/nlp22_3.png" /></p><p>实践证明，用ALBERT做文本特征提取，模型训练的效果基本与BERT差别微小，模型训练速度明显提升，更重要的是，模型预测的速度只有BERT版本的6.6%（不同情况下可能有略微差异），这在生产上是十分有帮助的。</p><h3 id="参考网址">参考网址</h3><ol type="1"><li>中文预训练ALBERT模型来了：小模型登顶GLUE，Base版模型小10倍速度快1倍：<ahref="https://zhuanlan.zhihu.com/p/85037097">https://zhuanlan.zhihu.com/p/85037097</a></li><li>ALBERT一作蓝振忠：预训练模型应用已成熟，ChineseGLUE要对标GLUE基准：<ahref="https://tech.sina.com.cn/roll/2019-11-17/doc-iihnzhfy9804802.shtml">https://tech.sina.com.cn/roll/2019-11-17/doc-iihnzhfy9804802.shtml</a>。</li><li>解读ALBERT：<ahref="https://blog.csdn.net/weixin_37947156/article/details/101529943">https://blog.csdn.net/weixin_37947156/article/details/101529943</a>。</li><li>ALBERT的Github项目地址：<ahref="https://github.com/brightmart/albert_zh">https://github.com/brightmart/albert_zh</a>。</li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>文本分类</tag>
      
      <tag>ALBERT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（二十一）人物关系抽取的一次实战</title>
    <link href="/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%80%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%AE%9E%E6%88%98/"/>
    <url>/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%80%EF%BC%89%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E4%B8%80%E6%AC%A1%E5%AE%9E%E6%88%98/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>去年，笔者写过一篇文章<ahref="https://percent4.github.io/%E5%88%A9%E7%94%A8%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E6%9E%84%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/">利用关系抽取构建知识图谱的一次尝试</a>，试图用现在的深度学习办法去做开放领域的关系抽取，但是遗憾的是，目前在开放领域的关系抽取，还没有成熟的解决方案和模型。当时的文章仅作为笔者的一次尝试，在实际使用过程中，效果有限。</p><p>本文将讲述如何利用深度学习模型来进行人物关系抽取。人物关系抽取可以理解为是关系抽取，这是我们构建知识图谱的重要一步。本文人物关系抽取的主要思想是关系抽取的pipeline（管道）模式，因为人名可以使用现成的NER模型提取，因此本文仅解决从文章中抽取出人名后，如何进行人物关系抽取。</p><p>本文采用的深度学习模型是文本分类模型，结合BERT预训练模型，取得了较为不错的效果。</p><p>本项目已经开源，Github地址为：<ahref="https://github.com/percent4/people_relation_extract">https://github.com/percent4/people_relation_extract</a>。</p><p>本项目的项目结构图如下：</p><figure><img src="/img/nlp21_1.png" alt="人物关系抽取项目结构" /><figcaption aria-hidden="true">人物关系抽取项目结构</figcaption></figure><h3 id="数据集介绍">数据集介绍</h3><p>在进行这方面的尝试之前，我们还不得不面对这样一个难题，那就是中文人物关系抽取语料的缺失。数据是模型的前提，没有数据，一切模型无从谈起。因此，笔者不得不花费大量的时间收集数据。</p><p>笔者利用大量自己业余的时间，收集了大约2900条人物关系样本，整理成Excel（文件名称为<code>人物关系表.xlsx</code>），其中几行如下：</p><figure><img src="/img/nlp21_2.png" alt="笔者自己收集的数据集" /><figcaption aria-hidden="true">笔者自己收集的数据集</figcaption></figure><p>人物关系一共有14类，分别为<code>unknown</code>,<code>夫妻</code>,<code>父母</code>,<code>兄弟姐妹</code>,<code>上下级</code>,<code>师生</code>,<code>好友</code>,<code>同学</code>,<code>合作</code>,<code>同人</code>,<code>情侣</code>,<code>祖孙</code>,<code>同门</code>,<code>亲戚</code>，其中<code>unknown</code>类别表示该人物关系不在其余的13类中（人物之间没有关系或者为其他关系），<code>同人</code>关系指的是两个人物其实是同一个人，比如下面的例子：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dns">邵逸夫(<span class="hljs-number">1907年10月4</span>日—<span class="hljs-number">2014年1月7</span>日)，原名邵仁楞，生于浙江省宁波市镇海镇，祖籍浙江宁波。<br></code></pre></td></tr></table></figure><p>上面的例子中，邵逸夫和邵仁楞就是同一个人。<code>亲戚</code>关系指的是除了<code>夫妻</code>,<code>父母</code>,<code>兄弟姐妹</code>,<code>祖孙</code>之外的亲戚关系，比如叔侄，舅甥关系等。</p><p>为了对该数据集的每个关系类别的数量进行统计，我们可以使用脚本<code>data/relation_bar_chart.py</code>，完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># 绘制人物关系频数统计条形图</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 读取EXCEL数据</span><br>df = pd.read_excel(<span class="hljs-string">&#x27;人物关系表.xlsx&#x27;</span>)<br>label_list = <span class="hljs-built_in">list</span>(df[<span class="hljs-string">&#x27;关系&#x27;</span>].value_counts().index)<br>num_list= df[<span class="hljs-string">&#x27;关系&#x27;</span>].value_counts().tolist()<br><br><span class="hljs-comment"># Mac系统设置中文字体支持</span><br>plt.rcParams[<span class="hljs-string">&quot;font.family&quot;</span>] = <span class="hljs-string">&#x27;Arial Unicode MS&#x27;</span><br><br><span class="hljs-comment"># 利用Matplotlib绘制条形图</span><br>x = <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(num_list))<br>rects = plt.bar(left=x, height=num_list, width=<span class="hljs-number">0.6</span>, color=<span class="hljs-string">&#x27;blue&#x27;</span>, label=<span class="hljs-string">&quot;频数&quot;</span>)<br>plt.ylim(<span class="hljs-number">0</span>, <span class="hljs-number">500</span>) <span class="hljs-comment"># y轴范围</span><br>plt.ylabel(<span class="hljs-string">&quot;数量&quot;</span>)<br>plt.xticks([index + <span class="hljs-number">0.1</span> <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> x], label_list)<br>plt.xticks(rotation=<span class="hljs-number">45</span>) <span class="hljs-comment"># x轴的标签旋转45度</span><br>plt.xlabel(<span class="hljs-string">&quot;人物关系&quot;</span>)<br>plt.title(<span class="hljs-string">&quot;人物关系频数统计&quot;</span>)<br>plt.legend()<br><br><span class="hljs-comment"># 条形图的文字说明</span><br><span class="hljs-keyword">for</span> rect <span class="hljs-keyword">in</span> rects:<br>    height = rect.get_height()<br>    plt.text(rect.get_x() + rect.get_width() / <span class="hljs-number">2</span>, height+<span class="hljs-number">1</span>, <span class="hljs-built_in">str</span>(height), ha=<span class="hljs-string">&quot;center&quot;</span>, va=<span class="hljs-string">&quot;bottom&quot;</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure><p>运行后的结果如下：</p><figure><img src="/img/nlp21_3.png" alt="人物关系条形图" /><figcaption aria-hidden="true">人物关系条形图</figcaption></figure><p><code>unknown</code>类别最多，有791条，其余的如<code>祖孙</code>,<code>亲戚</code>,<code>情侣</code>等较少，只有90多条，这是因为这类人物关系的数据缺失不好收集。因此，语料的收集费时费力，需要消耗大量的精力。</p><h3 id="数据预处理">数据预处理</h3><p>收集好数据后，我们需要对数据进行预处理，预处理主要分两步，一步是将人物关系和原文本整合在一起，第二步简单，将数据集划分为训练集和测试集，比例为8:2。</p><p>我们对第一步进行详细说明，将人物关系和原文本整合在一起。一般我们给定原文本和该文本中的两个人物，比如：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dns">邵逸夫(<span class="hljs-number">1907年10月4</span>日—<span class="hljs-number">2014年1月7</span>日)，原名邵仁楞，生于浙江省宁波市镇海镇，祖籍浙江宁波。<br></code></pre></td></tr></table></figure><p>这句话中有两个人物：邵逸夫，邵仁楞，这个容易在语料中找到。然后我们将原文本的这两个人物中的每个字符分别用'#'号代码，并通过'$'符号拼接在一起，形成的整合文本如下：</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clean">邵逸夫$邵仁楞$###(<span class="hljs-number">1907</span>年<span class="hljs-number">10</span>月<span class="hljs-number">4</span>日—<span class="hljs-number">2014</span>年<span class="hljs-number">1</span>月<span class="hljs-number">7</span>日)，原名###，生于浙江省宁波市镇海镇，祖籍浙江宁波。<br></code></pre></td></tr></table></figure><p>处理成这种格式是为了方便文本分类模型进行调用。</p><p>数据预处理的脚本为<code>data/data_into_train_test.py</code>，完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint<br><br>df = pd.read_excel(<span class="hljs-string">&#x27;人物关系表.xlsx&#x27;</span>)<br>relations = <span class="hljs-built_in">list</span>(df[<span class="hljs-string">&#x27;关系&#x27;</span>].unique())<br>relations.remove(<span class="hljs-string">&#x27;unknown&#x27;</span>)<br>relation_dict = &#123;<span class="hljs-string">&#x27;unknown&#x27;</span>: <span class="hljs-number">0</span>&#125;<br>relation_dict.update(<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(relations, <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(relations)+<span class="hljs-number">1</span>))))<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;rel_dict.json&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> h:<br>    h.write(json.dumps(relation_dict, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">2</span>))<br><br>pprint(df[<span class="hljs-string">&#x27;关系&#x27;</span>].value_counts())<br>df[<span class="hljs-string">&#x27;rel&#x27;</span>] = df[<span class="hljs-string">&#x27;关系&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: relation_dict[x])<br><br>texts = []<br><span class="hljs-keyword">for</span> per1, per2, text <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(df[<span class="hljs-string">&#x27;人物1&#x27;</span>].tolist(), df[<span class="hljs-string">&#x27;人物2&#x27;</span>].tolist(), df[<span class="hljs-string">&#x27;文本&#x27;</span>].tolist()):<br>    text = <span class="hljs-string">&#x27;$&#x27;</span>.join([per1, per2, text.replace(per1, <span class="hljs-built_in">len</span>(per1)*<span class="hljs-string">&#x27;#&#x27;</span>).replace(per2, <span class="hljs-built_in">len</span>(per2)*<span class="hljs-string">&#x27;#&#x27;</span>)])<br>    texts.append(text)<br><br>df[<span class="hljs-string">&#x27;text&#x27;</span>] = texts<br><br>train_df = df.sample(frac=<span class="hljs-number">0.8</span>, random_state=<span class="hljs-number">1024</span>)<br>test_df = df.drop(train_df.index)<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;train.txt&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> text, rel <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(train_df[<span class="hljs-string">&#x27;text&#x27;</span>].tolist(), train_df[<span class="hljs-string">&#x27;rel&#x27;</span>].tolist()):<br>        f.write(<span class="hljs-built_in">str</span>(rel)+<span class="hljs-string">&#x27; &#x27;</span>+text+<span class="hljs-string">&#x27;\n&#x27;</span>)<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;test.txt&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> g:<br>    <span class="hljs-keyword">for</span> text, rel <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(test_df[<span class="hljs-string">&#x27;text&#x27;</span>].tolist(), test_df[<span class="hljs-string">&#x27;rel&#x27;</span>].tolist()):<br>        g.write(<span class="hljs-built_in">str</span>(rel)+<span class="hljs-string">&#x27; &#x27;</span>+text+<span class="hljs-string">&#x27;\n&#x27;</span>)<br></code></pre></td></tr></table></figure><p>运行完该脚本后，会在<code>data</code>目录下生成train.txt,test.txt和rel_dict.json，该json文件中保存的信息如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;unknown&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;夫妻&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;父母&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;兄弟姐妹&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;上下级&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;师生&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">5</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;好友&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">6</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;同学&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">7</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;合作&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">8</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;同人&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">9</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;情侣&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">10</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;祖孙&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">11</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;同门&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">12</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;亲戚&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">13</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>简单来说，是给每种关系一个id，转化成类别型变量。</p><p>以train.txt为例，其前5行的内容如下：</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">4 </span>方琳$李伟康$在生活中，###则把##看作小辈，常常替她解决难题。<br><span class="hljs-symbol">3 </span>佳子$久仁$<span class="hljs-number">12</span>月，##和弟弟##参加了在东京举行的全国初中生演讲比赛。<br><span class="hljs-symbol">2 </span>钱慧安$钱禄新$###，生卒年不详，海上画家###之子。<br><span class="hljs-symbol">0 </span>吴继坤$邓新生$###还曾对媒体说：“我这个小小的投资商，经常得到###等领导的亲自关注和关照，我觉到受宠若惊。”<br><span class="hljs-symbol">2 </span>洪博培$乔恩·M·亨茨曼$###的父亲########是著名企业家、美国最大化学公司亨茨曼公司创始人。<br><span class="hljs-symbol">10 </span>夏乐$陈飞$两小无猜剧情简介:##和##是一对从小一起长大的青梅竹马。<br></code></pre></td></tr></table></figure><p>在每一行中，空格之前的数字所对应的人物关系可以在<code>rel_dict.json</code>中找到。</p><h3 id="模型训练">模型训练</h3><p>在模型训练前，为了将数据的格式更好地适应模型，需要再对trian.txt和test.txt进行处理。处理脚本为<code>load_data.py</code>，完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><br><span class="hljs-comment"># 读取txt文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_txt_file</span>(<span class="hljs-params">file_path</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br>    labels, texts = [], []<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> content:<br>        parts = line.split()<br>        label, text = parts[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;&#x27;</span>.join(parts[<span class="hljs-number">1</span>:])<br>        labels.append(label)<br>        texts.append(text)<br><br>    <span class="hljs-keyword">return</span> labels, texts<br><br><span class="hljs-comment"># 获取训练数据和测试数据，格式为pandas的DataFrame</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_train_test_pd</span>():<br>    file_path = <span class="hljs-string">&#x27;data/train.txt&#x27;</span><br>    labels, texts = read_txt_file(file_path)<br>    train_df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;label&#x27;</span>: labels, <span class="hljs-string">&#x27;text&#x27;</span>: texts&#125;)<br><br>    file_path = <span class="hljs-string">&#x27;data/test.txt&#x27;</span><br>    labels, texts = read_txt_file(file_path)<br>    test_df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;label&#x27;</span>: labels, <span class="hljs-string">&#x27;text&#x27;</span>: texts&#125;)<br><br>    <span class="hljs-keyword">return</span> train_df, test_df<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br><br>    train_df, test_df = get_train_test_pd()<br>    <span class="hljs-built_in">print</span>(train_df.head())<br>    <span class="hljs-built_in">print</span>(test_df.head())<br><br>    train_df[<span class="hljs-string">&#x27;text_len&#x27;</span>] = train_df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x))<br>    <span class="hljs-built_in">print</span>(train_df.describe())<br></code></pre></td></tr></table></figure><p>本项目所采用的模型为：BERT + 双向GRU + Attention +FC，其中BERT用来提取文本的特征，关于这一部分的介绍，已经在文章<ahref="https://percent4.github.io/2023/07/08/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%EF%BC%89%E5%88%A9%E7%94%A8BERT%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB/">NLP（二十）利用BERT实现文本二分类</a>中给出；Attention为注意力机制层，FC为全连接层，模型的结构图如下（利用Keras导出）：</p><figure><img src="/img/nlp21_4.png" alt="模型结构示例图" /><figcaption aria-hidden="true">模型结构示例图</figcaption></figure><p>模型训练的脚本为<code>model_train.py</code>，完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># 模型训练</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> load_data <span class="hljs-keyword">import</span> get_train_test_pd<br><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> to_categorical<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model<br><span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> Adam<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Input, Dense<br><span class="hljs-keyword">from</span> bert.extract_feature <span class="hljs-keyword">import</span> BertVector<br><br><span class="hljs-keyword">from</span> att <span class="hljs-keyword">import</span> Attention<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> GRU, Bidirectional<br><br><br><span class="hljs-comment"># 读取文件并进行转换</span><br>train_df, test_df = get_train_test_pd()<br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;NONE&quot;</span>, max_seq_len=<span class="hljs-number">80</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;begin encoding&#x27;</span>)<br>f = <span class="hljs-keyword">lambda</span> text: bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br><br>train_df[<span class="hljs-string">&#x27;x&#x27;</span>] = train_df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(f)<br>test_df[<span class="hljs-string">&#x27;x&#x27;</span>] = test_df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(f)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;end encoding&#x27;</span>)<br><br><span class="hljs-comment"># 训练集和测试集</span><br>x_train = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> train_df[<span class="hljs-string">&#x27;x&#x27;</span>]])<br>x_test = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> test_df[<span class="hljs-string">&#x27;x&#x27;</span>]])<br>y_train = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> train_df[<span class="hljs-string">&#x27;label&#x27;</span>]])<br>y_test = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> test_df[<span class="hljs-string">&#x27;label&#x27;</span>]])<br><span class="hljs-comment"># print(&#x27;x_train: &#x27;, x_train.shape)</span><br><br><span class="hljs-comment"># 将类型y值转化为ont-hot向量</span><br>num_classes = <span class="hljs-number">14</span><br>y_train = to_categorical(y_train, num_classes)<br>y_test = to_categorical(y_test, num_classes)<br><br><span class="hljs-comment"># 模型结构：BERT + 双向GRU + Attention + FC</span><br>inputs = Input(shape=(<span class="hljs-number">80</span>, <span class="hljs-number">768</span>,))<br>gru = Bidirectional(GRU(<span class="hljs-number">128</span>, dropout=<span class="hljs-number">0.2</span>, return_sequences=<span class="hljs-literal">True</span>))(inputs)<br>attention = Attention(<span class="hljs-number">32</span>)(gru)<br>output = Dense(<span class="hljs-number">14</span>, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>)(attention)<br>model = Model(inputs, output)<br><br><span class="hljs-comment"># 模型可视化</span><br><span class="hljs-comment"># from keras.utils import plot_model</span><br><span class="hljs-comment"># plot_model(model, to_file=&#x27;model.png&#x27;)</span><br><br>model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>,<br>              optimizer=Adam(),<br>              metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br><span class="hljs-comment"># 模型训练以及评估</span><br>model.fit(x_train, y_train, batch_size=<span class="hljs-number">8</span>, epochs=<span class="hljs-number">30</span>)<br>model.save(<span class="hljs-string">&#x27;people_relation.h5&#x27;</span>)<br><span class="hljs-built_in">print</span>(model.evaluate(x_test, y_test))<br></code></pre></td></tr></table></figure><p>利用该模型对数据集进行训练，输出的结果如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs markdown">begin encoding<br>end encoding<br>Epoch 1/30<br>1433/1433 [==============================] - 15s 10ms/step - loss: 1.5558 - acc: 0.4962<br><span class="hljs-strong">****</span><span class="hljs-strong">****</span><span class="hljs-strong">**(中间部分省略输出)**</span><span class="hljs-strong">****</span><span class="hljs-strong">****</span><span class="hljs-strong">****</span><br>Epoch 30/30<br>1433/1433 [==============================] - 12s 8ms/step - loss: 0.0210 - acc: 0.9951<br>[1.1099, 0.7709]<br></code></pre></td></tr></table></figure><p>整个训练过程持续十来分钟，经过30个epoch的训练，最终在测试集上的loss为1.1099，acc为0.7709，在小数据量下的效果还是不错的。训练过程（加入了earlystopping机制）生成的loss和acc图形如下：</p><figure><img src="/img/nlp21_5.png" alt="加入early stopping后的训练结果" /><figcaption aria-hidden="true">加入earlystopping后的训练结果</figcaption></figure><h3 id="模型预测">模型预测</h3><p>上述模型训练完后，利用保存好的模型文件，对新的数据进行预测。模型预测的脚本为<code>model_predict.py</code>，完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># 模型预测</span><br><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> bert.extract_feature <span class="hljs-keyword">import</span> BertVector<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> att <span class="hljs-keyword">import</span> Attention<br><br><span class="hljs-comment"># 加载模型</span><br>model = load_model(<span class="hljs-string">&#x27;people_relation.h5&#x27;</span>, custom_objects=&#123;<span class="hljs-string">&quot;Attention&quot;</span>: Attention&#125;)<br><br><span class="hljs-comment"># 示例语句及预处理</span><br>text = <span class="hljs-string">&#x27;赵金闪#罗玉兄#在这里，赵金闪和罗玉兄夫妇已经生活了大半辈子。他们夫妇都是哈密市伊州区林业和草原局的护林员，扎根东天山脚下，守护着这片绿。&#x27;</span><br>per1, per2, doc = text.split(<span class="hljs-string">&#x27;#&#x27;</span>)<br>text = <span class="hljs-string">&#x27;$&#x27;</span>.join([per1, per2, doc.replace(per1, <span class="hljs-built_in">len</span>(per1)*<span class="hljs-string">&#x27;#&#x27;</span>).replace(per2, <span class="hljs-built_in">len</span>(per2)*<span class="hljs-string">&#x27;#&#x27;</span>)])<br><span class="hljs-built_in">print</span>(text)<br><br><br><span class="hljs-comment"># 利用BERT提取句子特征</span><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;NONE&quot;</span>, max_seq_len=<span class="hljs-number">80</span>)<br>vec = bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br>x_train = np.array([vec])<br><br><span class="hljs-comment"># 模型预测并输出预测结果</span><br>predicted = model.predict(x_train)<br>y = np.argmax(predicted[<span class="hljs-number">0</span>])<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;data/rel_dict.json&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    rel_dict = json.load(f)<br><br>id_rel_dict = &#123;v:k <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> rel_dict.items()&#125;<br><span class="hljs-built_in">print</span>(id_rel_dict[y])<br></code></pre></td></tr></table></figure><p>该人物关系输出的结果为<code>夫妻</code>。</p><p>接着，我们对更好的数据进行预测，输出的结果如下：</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs clean">原文: 润生#润叶#不过，他对润生的姐姐润叶倒怀有一种亲切的感情。<br>预测人物关系: 兄弟姐妹<br>原文: 孙玉厚#兰花#脑子里把前后村庄未嫁的女子一个个想过去，最后选定了双水村孙玉厚的大女子兰花。<br>预测人物关系: 父母<br>原文: 金波#田福堂#每天来回二十里路，与他一块上学的金波和大队书记田福堂的儿子润生都有自行车，只有他是两条腿走路。<br>预测人物关系: unknown<br>原文: 润生#田福堂#每天来回二十里路，与他一块上学的金波和大队书记田福堂的儿子润生都有自行车，只有他是两条腿走路。<br>预测人物关系: 父母<br>原文: 周山#李自成#周山原是李自成亲手提拔的将领，闯王对他十分信任，叫他担任中军。<br>预测人物关系: 上下级<br>原文: 高桂英#李自成#高桂英是李自成的结发妻子，今年才三十岁。<br>预测人物关系: 夫妻<br>原文: 罗斯福#特德#果然，此后罗斯福的政治旅程与长他<span class="hljs-number">24</span>岁的特德叔叔如出一辙——纽约州议员、助理海军部长、纽约州州长以至美国总统。<br>预测人物关系: 亲戚<br>原文: 詹姆斯#克利夫兰#詹姆斯担任了该公司的经理，作为一名民主党人，他曾资助过克利夫兰的再度竞选，两人私交不错。<br>预测人物关系: 上下级（预测出错，应该是好友关系）<br>原文: 高剑父#关山月#高剑父是关山月在艺术道路上非常重要的导师，同时关山月也是最能够贯彻高剑父“折中中西”理念的得意门生。<br>预测人物关系: 师生<br>原文: 唐怡莹#唐石霞#唐怡莹，姓他他拉氏，名为他他拉·怡莹，又名唐石霞，隶属于满洲镶红旗。<br>预测人物关系: 同人<br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本文采用的深度学习模型是文本分类模型，结合BERT预训练模型，在小标注数据量下对人物关系抽取这个任务取得了还不错的效果。同时模型的识别准确率和使用范围还有待于提升，提升点笔者认为如下：</p><ul><li><p>标注的数据量需要加大，现在的数据才2900条左右，如果数据量上去了，那么模型的准确率还有使用范围也会提升；</p></li><li><p>其他更多的模型有待于尝试；</p></li><li><p>在预测时，模型的预测时间较长，原因在于用BERT提取特征时耗时较长，可以考虑缩短模型预测的时间（比如使用ALBERT就能大大缩短预测时间）；</p></li><li><p>其他问题欢迎补充。</p><p>感谢大家阅读~</p></li></ul>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>关系抽取</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（二十）利用BERT实现文本二分类</title>
    <link href="/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%EF%BC%89%E5%88%A9%E7%94%A8BERT%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB/"/>
    <url>/NLP%EF%BC%88%E4%BA%8C%E5%8D%81%EF%BC%89%E5%88%A9%E7%94%A8BERT%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在我们进行事件抽取的时候，我们需要触发词来确定是否属于某个特定的事件类型，比如我们以政治上的出访类事件为例，这类事件往往会出现“访问”这个词语，但是仅仅通过“访问”这个触发词来判断是否属于出访类事件是不可靠的，比如我们会碰到以下情况：</p><p><img src="/img/nlp20_1.png" /></p><p>通过上面的例子，我们知道，像访问速度，访问量这种文档虽然出现了访问，但却不属于政治上的出访类事件。因此，这时候我们需要借助<code>文本分类</code>模型来判断，显然，这是一个二分类模型。</p><p>本文将会讲述如何利用BERT+DNN模型来判断文档是否属于政治上的出访类事件。</p><h3 id="数据集">数据集</h3><p>笔者找了300个文档，里面的文档都含有“出访”这个词语，标签1表示属于政治上的出访类事件，标签0则不是。将数据集分为训练集（250个样本）和测试集（50个样本），比例为5:1，样本不是很多，但借助BERT，我们可以在小样本上取得不错的效果。</p><p>训练集（部分）的样本如下：</p><figure><img src="/img/nlp20_2.png" alt="训练集部分数据" /><figcaption aria-hidden="true">训练集部分数据</figcaption></figure><h3 id="代码">代码</h3><p>本项目的结构如下：</p><figure><img src="/img/nlp20_3.png" alt="项目结构" /><figcaption aria-hidden="true">项目结构</figcaption></figure><p>因为我们这边是小样本量，所以需要用到BERT。又因为是中文，所以需要下载BERT的中文训练文件<code>chinese_L-12_H-768_A-12</code>，这是已经训练好的模型文件。</p><p>根据我们在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E5%8D%81%E4%B9%9D%EF%BC%89%E9%A6%96%E6%AC%A1%E4%BD%BF%E7%94%A8BERT%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%AF%BC/">NLP（十九）首次使用BERT的可视化指导</a>中的经验，我们需要写代码来调用BERT模型文件，比如tokenizer，padding,masking以及BERT模型产生输出向量等，幸运的是，有人已经帮助我们做好了这件事，我们只需要调用其代码就行了。这部分的代码位于bert文件夹下，读者可以在文章最后的Github地址上找到。因为本文的模型为文本分类模型，所以需要取[CLS]这个token所对应的768维的向量。</p><p>接下来，我们先读取数据集，处理成训练集和测试集，脚本为load_data.py，完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-02-12 12:57</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><br><span class="hljs-comment"># 读取txt文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_txt_file</span>(<span class="hljs-params">file_path</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br>    labels, texts = [], []<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> content:<br>        parts = line.split()<br>        label, text = parts[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;&#x27;</span>.join(parts[<span class="hljs-number">1</span>:])<br>        labels.append(label)<br>        texts.append(text)<br><br>    <span class="hljs-keyword">return</span> labels, texts<br><br><br>file_path = <span class="hljs-string">&#x27;data/train.txt&#x27;</span><br>labels, texts = read_txt_file(file_path)<br>train_df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;label&#x27;</span>: labels, <span class="hljs-string">&#x27;text&#x27;</span>: texts&#125;)<br><br>file_path = <span class="hljs-string">&#x27;data/test.txt&#x27;</span><br>labels, texts = read_txt_file(file_path)<br>test_df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;label&#x27;</span>: labels, <span class="hljs-string">&#x27;text&#x27;</span>: texts&#125;)<br><br><span class="hljs-built_in">print</span>(train_df.head())<br><span class="hljs-built_in">print</span>(test_df.head())<br><br>train_df[<span class="hljs-string">&#x27;text_len&#x27;</span>] = train_df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x))<br><span class="hljs-built_in">print</span>(train_df.describe())<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs bash">  label                                               text<br>0     1  当地时间2月10日，白宫发表声明称，美国总统特朗普及夫人梅拉尼娅将于2月24日至25日访问印...<br>1     0  俄罗斯卫星通讯社11日最新消息，菲律宾总统杜特尔特已下令终止与美国间的《访问部队协定》(VFA)。<br>2     1  据俄罗斯卫星网6日报道，土耳其总统发言人卡林表示，俄罗斯军事代表团将于近日访问安卡拉，讨论叙...<br>3     0  先来说说什么是LPDDR5：要知道，手机中有两种内存颗粒，一种就是DRAM也就是大家常说的“...<br>4     1  在疫情的关键时刻，出现了一件令人感动的事情，让我们明白这才是真正的好朋友，不惧疫情访问我国，...<br>  label                                               text<br>0     1  应巴基斯坦总理伊姆兰·汗、荷兰王国首相吕特、德国联邦政府邀请，国家副主席王岐山将于5月26日...<br>1     1  联邦德国总理默克尔抵达印度进行访问，在雾霾笼罩下的新德里受到军人仪仗队的欢迎。默克尔赞扬了德...<br>2     1  5月6日至12日，省委副书记乌兰率代表团访问韩国、泰国，与韩国国际交流联盟、新村运动中央会等...<br>3     1  国台办发言人马晓光今天（5月22日）表示，新党主席、新中华儿女学会荣誉理事长郁慕明将率台湾各...<br>4     1  6月13日至15日，联合国反恐事务副秘书长沃伦科夫应邀访问北京和新疆，并与中国外交部副部长乐...<br>         text_len<br>count  250.000000<br>mean    77.540000<br>std     36.804493<br>min     11.000000<br>25%     47.500000<br>50%     73.000000<br>75%    100.750000<br>max    192.000000<br></code></pre></td></tr></table></figure><p>可以发现，训练数据集的文本长度的75%分位点为100.75，所以我们在模型训练的时候，padding过程中的统一长度取100。</p><p>数据预处理之后，我们利用BERT提取文档的特征，每个文档的填充长度为100，对应1个768维的向量，然后用Keras创建DNN来进行模型训练，训练完模型后对测试集进行验证，并保存该模型文件，便于后续的模型预测使用。模型训练的脚本为model_train.py，完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-02-12 13:37</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-comment"># 是否使用GPU训练</span><br><span class="hljs-comment"># os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;4,5,6,7,8&quot;</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> load_data <span class="hljs-keyword">import</span> train_df, test_df<br><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> to_categorical<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model<br><span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> Adam<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Input, BatchNormalization, Dense<br><span class="hljs-keyword">from</span> bert.extract_feature <span class="hljs-keyword">import</span> BertVector<br><br><span class="hljs-comment"># 读取文件并进行转换</span><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;REDUCE_MEAN&quot;</span>, max_seq_len=<span class="hljs-number">100</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;begin encoding&#x27;</span>)<br>f = <span class="hljs-keyword">lambda</span> text: bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br>train_df[<span class="hljs-string">&#x27;x&#x27;</span>] = train_df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(f)<br>test_df[<span class="hljs-string">&#x27;x&#x27;</span>] = test_df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(f)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;end encoding&#x27;</span>)<br><br>x_train = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> train_df[<span class="hljs-string">&#x27;x&#x27;</span>]])<br>x_test = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> test_df[<span class="hljs-string">&#x27;x&#x27;</span>]])<br>y_train = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> train_df[<span class="hljs-string">&#x27;label&#x27;</span>]])<br>y_test = np.array([vec <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> test_df[<span class="hljs-string">&#x27;label&#x27;</span>]])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;x_train: &#x27;</span>, x_train.shape)<br><br><span class="hljs-comment"># Convert class vectors to binary class matrices.</span><br>num_classes = <span class="hljs-number">2</span><br>y_train = to_categorical(y_train, num_classes)<br>y_test = to_categorical(y_test, num_classes)<br><br><span class="hljs-comment"># 创建DNN模型</span><br>x_in = Input(shape=(<span class="hljs-number">768</span>, ))<br>x_out = Dense(<span class="hljs-number">32</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>)(x_in)<br>x_out = BatchNormalization()(x_out)<br>x_out = Dense(num_classes, activation=<span class="hljs-string">&quot;softmax&quot;</span>)(x_out)<br>model = Model(inputs=x_in, outputs=x_out)<br><span class="hljs-built_in">print</span>(model.summary())<br><br>model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>,<br>              optimizer=Adam(),<br>              metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br><span class="hljs-comment"># 模型训练、评估以及保存</span><br>model.fit(x_train, y_train, batch_size=<span class="hljs-number">8</span>, epochs=<span class="hljs-number">20</span>)<br>model.save(<span class="hljs-string">&#x27;visit_classify.h5&#x27;</span>)<br><span class="hljs-built_in">print</span>(model.evaluate(x_test, y_test))<br></code></pre></td></tr></table></figure><h3 id="模型训练">模型训练</h3><p>在模型训练中，我们创建的DNN模型结构如下： <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_<br><span class="hljs-section">Layer (type)                 Output Shape              Param #   </span><br><span class="hljs-section">=================================================================</span><br>input<span class="hljs-emphasis">_1 (InputLayer)         (None, 768)               0         </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span><br>dense<span class="hljs-emphasis">_1 (Dense)              (None, 32)                24608     </span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span><br>batch<span class="hljs-emphasis">_normalization_</span>1 (Batch (None, 32)                128       <br><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_<br><span class="hljs-section">dense<span class="hljs-emphasis">_2 (Dense)              (None, 2)                 66        </span></span><br><span class="hljs-emphasis"><span class="hljs-section">=================================================================</span></span><br><span class="hljs-emphasis"><span class="hljs-section">Total params: 24,802</span></span><br><span class="hljs-emphasis"><span class="hljs-section">Trainable params: 24,738</span></span><br><span class="hljs-emphasis"><span class="hljs-section">Non-trainable params: 64</span></span><br><span class="hljs-emphasis"><span class="hljs-section"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span></span><br></code></pre></td></tr></table></figure>模型训练过程中的输出如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs bash">Epoch 1/20<br><br>  8/250 [..............................] - ETA: 43s - loss: 1.0427 - acc: 0.3750<br>250/250 [==============================] - 1s 6ms/step - loss: 0.3345 - acc: 0.8640<br>Epoch 2/20<br><br>  8/250 [..............................] - ETA: 0s - loss: 0.2664 - acc: 0.8750<br>250/250 [==============================] - 0s 133us/step - loss: 0.2147 - acc: 0.9320<br><br>.........(省略部分输出结果)............<br><br>Epoch 19/20<br><br>  8/250 [..............................] - ETA: 0s - loss: 0.2481 - acc: 0.8750<br>250/250 [==============================] - 0s 136us/step - loss: 0.0716 - acc: 0.9760<br>Epoch 20/20<br><br>  8/250 [..............................] - ETA: 0s - loss: 0.0149 - acc: 1.0000<br>250/250 [==============================] - 0s 140us/step - loss: 0.0560 - acc: 0.9800<br><br>32/50 [==================&gt;...........] - ETA: 0s<br>50/50 [==============================] - 0s 4ms/step<br>[0.3687818288803101, 0.9199999928474426]<br></code></pre></td></tr></table></figure><p>经过20个epoch的训练，模型在训练集上的准确率为0.9800，在测试集上的准确率约为0.9200，BERT的效果如此惊人，后接简单的DNN模型就能取得如此不错的效果。</p><h3 id="模型预测">模型预测</h3><p>为了再次验证模型的预测效果，笔者从网站上又重新找了20个文档，对其进行预测。预测的脚本为model_predict.py，完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># author: Jclian91</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><span class="hljs-comment"># time: 2020-02-12 17:33</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> bert.extract_feature <span class="hljs-keyword">import</span> BertVector<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br>load_model = load_model(<span class="hljs-string">&quot;visit_classify.h5&quot;</span>)<br><br><span class="hljs-comment"># 预测语句</span><br>texts = [<span class="hljs-string">&#x27;在访问限制中，用户可以选择禁用iPhone的功能，包括Siri、iTunes购买功能、安装/删除应用等，甚至还可以让iPhone变成一台功能手机。以下是访问限制具体可以实现的一些功能&#x27;</span>,<br>         <span class="hljs-string">&#x27;IT之家4月23日消息 近日，谷歌在其官方论坛发布消息表示，他们为Android Auto添加了一项新功能：可以访问完整联系人列表。用户现在可以通过在Auto的电话拨号界面中打开左上角的菜单访问完整的联系人列表。值得注意的是，这一功能仅支持在车辆停止时使用。&#x27;</span>,<br>         <span class="hljs-string">&#x27;要通过telnet 访问路由器，需要先通过console 口对路由器进行基本配置，例如：IP地址、密码等。&#x27;</span>,<br>         <span class="hljs-string">&#x27;IT之家3月26日消息 近日反盗版的国际咨询公司MUSO发布了2017年的年度报告，其中的数据显示，去年盗版资源网站访问量达到了3000亿次，比前一年（2016年）提高了1.6%。美国是访问盗版站点次数最多的国家，共有279亿次访问；其后分别是俄罗斯、印度和巴西，中国位列第18。&#x27;</span>,<br>         <span class="hljs-string">&#x27;应葡萄牙议会邀请，全国人大常委会副委员长吉炳轩率团于12月14日至16日访问葡萄牙，会见副议长费利佩、社会党副总书记卡内罗。&#x27;</span>,<br>         <span class="hljs-string">&#x27;2月26日至3月2日，应香港特区政府“内地贵宾访港计划”邀请，省委常委、常务副省长陈向群赴港考察访问，重点围绕“香港所长、湖南所需”，与特区政府相关部门和机构深入交流，推动湖南与香港交流合作取得新进展。&#x27;</span>,<br>         <span class="hljs-string">&#x27;目前A站已经恢复了访问，可以直接登录，网页加载正常，视频已经可以正常播放。&#x27;</span>,<br>         <span class="hljs-string">&#x27;难民署特使安吉丽娜·朱莉6月8日结束了对哥伦比亚和委内瑞拉边境地区的难民营地为期两天的访问，她对哥伦比亚人民展现的人道主义和勇气表示赞扬。&#x27;</span>,<br>         <span class="hljs-string">&#x27;据《南德意志报》报道，德国总理默克尔计划明年1月就前往安卡拉，和土耳其总统埃尔多安进行会谈。&#x27;</span>,<br>         <span class="hljs-string">&#x27;自9月14日至18日，由越共中央政治局委员、中央书记处书记、中央经济部部长阮文平率领工作代表团对希腊进行工作访问。&#x27;</span>,<br>         <span class="hljs-string">&#x27;Win7电脑提示无线适配器或访问点有问题怎么办?很多用户在使用无线网连接上网时，发现无线网显示已连接，但旁边却出现了一个黄色感叹号，无法进行网络操作，通过诊断提示电脑无线适配器或访问点有问题，且处于未修复状态，这该怎么办呢?下面小编就和大家分享下Win7电脑提示无线适配器或访问点有问题的解决方法。&#x27;</span>,<br>         <span class="hljs-string">&#x27;2019年10月13日至14日，外交部副部长马朝旭访问智利，会见智利外长里韦拉，同智利总统外事顾问萨拉斯举行会谈，就智利举办亚太经合组织（APEC）第二十七次领导人非正式会议等深入交换意见。&#x27;</span>,<br>         <span class="hljs-string">&#x27;未开发所有安全组之前访问，FTP可以链接上，但是打开会很慢，需要1-2分钟才能链接上&#x27;</span>,<br>         <span class="hljs-string">&#x27;win7系统电脑的用户，在连接WIFI网络网上时，有时候会遇到突然上不了网，查看连接的WIFI出现“有限的访问权限”的文字提示。&#x27;</span>,<br>         <span class="hljs-string">&#x27;联合国秘书长潘基文８日访问了日本福岛县，与当地灾民交流并访问了一所高中。&#x27;</span>,<br>         <span class="hljs-string">&#x27;国务院总理温家宝当地时间23日下午乘专机抵达布宜诺斯艾利斯，开始对阿根廷进行正式访问。&#x27;</span>,<br>         <span class="hljs-string">&#x27;正在中国访问的巴巴多斯总理斯图尔特１５日在陕西西安参观访问。&#x27;</span>,<br>         <span class="hljs-string">&#x27;据外媒报道,当地时间10日,美国白宫发声明称,美国总统特朗普将于2月底访问印度,与印度总理莫迪进行战略对话。&#x27;</span>,<br>         <span class="hljs-string">&#x27;2月28日，唐山曹妃甸蓝色海洋科技有限公司董事长赵力军等一行5人到黄海水产研究所交流访问。黄海水产研究所副所长辛福言及相关部门负责人、专家等参加了会议。&#x27;</span>,<br>         <span class="hljs-string">&#x27;2018年7月2日，莫斯科孔子文化促进会会长姜彦彬，常务副会长陈国建，在中国著名留俄油画大师牟克教授的陪同下，访问了莫斯科国立苏里科夫美术学院，受到第一副校长伊戈尔·戈尔巴秋克先生接待。&#x27;</span><br>         ]<br><br>labels = []<br><br>bert_model = BertVector(pooling_strategy=<span class="hljs-string">&quot;REDUCE_MEAN&quot;</span>, max_seq_len=<span class="hljs-number">100</span>)<br><br><span class="hljs-comment"># 对上述句子进行预测</span><br><span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts:<br><br>    <span class="hljs-comment"># 将句子转换成向量</span><br>    vec = bert_model.encode([text])[<span class="hljs-string">&quot;encodes&quot;</span>][<span class="hljs-number">0</span>]<br>    x_train = np.array([vec])<br><br>    <span class="hljs-comment"># 模型预测</span><br>    predicted = load_model.predict(x_train)<br>    y = np.argmax(predicted[<span class="hljs-number">0</span>])<br>    label = <span class="hljs-string">&#x27;Y&#x27;</span> <span class="hljs-keyword">if</span> y <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;N&#x27;</span><br>    labels.append(label)<br><br><span class="hljs-keyword">for</span> text,label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(texts, labels):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%s\t%s&#x27;</span>%(label, text))<br><br><span class="hljs-comment"># 将结果保存为xlsx文件</span><br>df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;句子&#x27;</span>:texts, <span class="hljs-string">&quot;是否属于出访类事件&quot;</span>: labels&#125;)<br>df.to_excel(<span class="hljs-string">&#x27;./result.xlsx&#x27;</span>, index=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>模型预测的结果会输出，同时也会保存至Excel，文件的内容如下：</p><figure><img src="/img/nlp20_4.png" alt="excel文件中的内容" /><figcaption aria-hidden="true">excel文件中的内容</figcaption></figure><p>所有预测的文档完全正确！</p><h3 id="预测">预测</h3><p>本项目已开源，Github地址为：<ahref="https://github.com/percent4/bert_doc_binary_classification">https://github.com/percent4/bert_doc_binary_classification</a>。</p><p>通过笔者自己的试验，BERT在小标注样本量的效果确实很不错，后续我们还将继续接触BERT！</p><p>感谢大家的阅读~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BERT</tag>
      
      <tag>NLP</tag>
      
      <tag>文本分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（十九）首次使用BERT的可视化指导</title>
    <link href="/NLP%EF%BC%88%E5%8D%81%E4%B9%9D%EF%BC%89%E9%A6%96%E6%AC%A1%E4%BD%BF%E7%94%A8BERT%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%AF%BC/"/>
    <url>/NLP%EF%BC%88%E5%8D%81%E4%B9%9D%EF%BC%89%E9%A6%96%E6%AC%A1%E4%BD%BF%E7%94%A8BERT%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%AF%BC/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文（部分内容）翻译自文章<ahref="http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/">AVisual Guide to Using BERT for the First Time</a>，其作者为JayAlammar，访问网址为：<ahref="http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/">http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/</a>，可以作为那些不熟悉BERT的读者首次阅读。文章中如有翻译不当之处，还请批评指正。</p><p><img src="/img/nlp19_1.png" /></p><p>本文是关于如何使用BERT的变异版本来进行句子分类的简单教程。该例子足够简单，因此可以作为首次使用BERT的介绍，当然，它也包含了一些关键性的概念。</p><h3 id="数据集sst2">数据集：SST2</h3><p>本文中使用的数据集为<ahref="https://nlp.stanford.edu/sentiment/index.html">SST2</a>，它包含了电影评论的句子，每一句带有一个标签，或者标注为<code>正面情感</code>（取值为1），或者标注为<code>负面情感</code>（取值为0）。</p><p><img src="/img/nlp19_2.png" /></p><h3 id="模型句子情感分类">模型：句子情感分类</h3><p>我们的目标是创建一个模型，它能够处理一个句子（就行我们数据集中的句子那样）并且输出1（表明该句子具有正面情感）或者0（表明该句子具有负面情感）。我们设想它长这样：</p><figure><img src="/img/nlp19_3.png" alt="模型描述" /><figcaption aria-hidden="true">模型描述</figcaption></figure><p>事实上，该模型包含两个模型：</p><ul><li><code>DistillBERT</code>会处理句子并把它提取后的信息传递给下一个模型。<code>DistillBERT</code>是<code>BERT</code>的变异版本，由<code>HuggingFace</code>小组开发和开源。它是<code>BERT</code>的更轻量、更快速的版本，同时它的表现基本与<code>BERT</code>相近。</li><li>下一个模型，从scikitlearn中导入的一个基本的<code>逻辑回归模型</code>（Logistic Regressionmodel），它会利用<code>DistillBERT</code>的处理结果，然后将句子进行分类成<code>正面情感</code>或者<code>负面情感</code>（分别为1或者0）。</li></ul><p>在两个模型之间传递的数据为1个768维的向量。我们可以把这个向量理解为这个句子的嵌入向量（EmbeddingVector），用于分类。</p><p><img src="/img/nlp19_4.png" /></p><h3 id="模型训练">模型训练</h3><p>尽管我们用了两个模型，但是我们只会训练<code>逻辑回归模型</code>。对于<code>DistillBERT</code>，我们会使用已经预训练好的英语模型。该模型，既不会被训练也不会做<code>微调（fine-tuned）</code>，直接进行句子分类。这是因为，我们可以从<code>BERT</code>中获得句子分类的能力。这尤其适合<code>BERT</code>输出的第一个位置（跟[CLS]标志相关）。我相信这是由于<code>BERT</code>的第二个训练模型——<code>下一句分类（Next sentence classification）</code>。该模型的目标在于封装句子级别的语料进行训练，并输出第一个位置。<code>transformers</code>库已经提供了<code>DistillBERT</code>的操作，作为其预训练模型版本。</p><figure><img src="/img/nlp19_5.png" alt="模型训练" /><figcaption aria-hidden="true">模型训练</figcaption></figure><h3 id="教程总览">教程总览</h3><p>以下是该教程的计划安排。首先我们会使用<code>DistillBERT</code>来产生2000个句子的句子向量。</p><figure><img src="/img/nlp19_6.png" alt="利用DistillBERT产生句子向量" /><figcaption aria-hidden="true">利用DistillBERT产生句子向量</figcaption></figure><p>这一步之后我们不会接触<code>DistillBERT</code>。接下去只是ScikitLearn的操作。我们将数据集分为训练集和测试集。</p><figure><img src="/img/nlp19_7.png"alt="将数据集经过Distilll处理后划分为训练集和测试集，注意sklearn的划分是将数据集打乱(shuffle)后再进行划分，所以不是取数据集的前75%作为训练集。" /><figcaptionaria-hidden="true">将数据集经过Distilll处理后划分为训练集和测试集，注意sklearn的划分是将数据集打乱(shuffle)后再进行划分，所以不是取数据集的前75%作为训练集。</figcaption></figure><p>接下来我们在训练集上使用<code>逻辑回归模型</code>进行训练。</p><p><img src="/img/nlp19_8.png" /></p><h3 id="单次预测如何计算">单次预测如何计算</h3><p>在我们讲解代码和解释如何训练模型之前，让我们看一下已预训练好的模型如何进行预测。我们尝试着预测句子“a visually stunning rumination onlove”。第一步是使用BERT tokenizer将句子划分成tokens。然后加上句子分类的特殊tokens（[CLS]在开始位置，[SEP]在句子结尾）。</p><p><img src="/img/nlp19_9.png" /></p><p>第三步是通过已预训练好的模型的嵌入表（embeddingtable）将每一个tokens映射成各自的id。这一步可以参考<code>word embedding</code>，参考阅读文章<ahref="http://jalammar.github.io/illustrated-word2vec/">The IllustratedWord2vec</a>。</p><p><img src="/img/nlp19_10.png" /></p><p>我们注意到，tokenizer仅需要一行代码就能完成以上步骤。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer.encode(<span class="hljs-string">&quot;a visually stunning rumination on love&quot;</span>, add_special_tokens=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>我们的输入句子现在已经处理成<code>DistilBERT</code>可以处理的格式了。如果你已经读过<ahref="http://jalammar.github.io/illustrated-bert/">IllustratedBERT</a>，那么这一步的可视化如下：</p><p><img src="/img/nlp19_11.png" /></p><h3 id="distilbert处理流程">DistilBERT处理流程</h3><p><code>DistilBERT</code>处理输入向量的流程类似于<code>BERT</code>。输出是每一个token对应一个向量。每个向量由768个浮点型数字组成。</p><p><img src="/img/nlp19_12.png" /></p><p>因为这是一个句子分类任务，故我们忽略其他向量而只取第一个向量（跟[CLS]相关的那个）。这个向量我们会作为<code>逻辑回归模型</code>的输入。</p><p><img src="/img/nlp19_13.png" /></p><p>从这里开始，就是<code>逻辑回归模型</code>的事儿了，它负责将输入的向量进行分类。我们设想一个预测的流程长这样：</p><p><img src="/img/nlp19_14.png" /></p><h3 id="代码">代码</h3><p>文章中用到的数据集下载网址为：<ahref="https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv">https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv</a>。下载<code>DistillBERT</code>模型文件，网址为：<ahref="https://www.kaggle.com/abhishek/distilbertbaseuncased">https://www.kaggle.com/abhishek/distilbertbaseuncased</a>。</p><p>原文中这部分的代码讲解比较多，我这边忽略过去了，笔者想按自己的思路来处理，因此这部分内容会有调整。完整的思路如下：</p><p>下载数据集和模型文件，与代码放在同一目录下。建立jupyter脚本，先载入必要的模块：</p><p><img src="/img/nlp19_15.png" /></p><p>接着我们利用pandas读取训练集数据，并统计标签值的频数：</p><p><img src="/img/nlp19_16.png" /></p><p>读取<code>DistillBERT</code>模型文件并创建tokenizer：</p><p><img src="/img/nlp19_17.png" /></p><p>通过tokenizer完成句子切分成tokens，并映射到id:</p><p><img src="/img/nlp19_18.png" /></p><p>由于每个句子的长度可能会不同，因此需要对句子进行填充（Padding），保持每个句子的输入维度一致，句子填充的长度为该数据集中句子长度的最大值。</p><p><img src="/img/nlp19_19.png" /></p><p>对句子进行填充后，然后再进行Masking。这是因为如果我们直接将padded传入<code>BERT</code>，这会造成一定的困扰。我们需要创建另一个变量，来告诉模型去mask之前的填充结果。这就是attention_mask的作用：</p><p><img src="/img/nlp19_20.png" /></p><p>我们的输入已经准备完毕，接下来我们尝试着用<code>DistillBERT</code>来获取向量，也就是之前说的第一步。这一步的处理结果会返回<code>last_hidden_states</code>，而我们的分类模型只需要获取<code>[CLS]</code>这个token对应的输出向量。</p><p><img src="/img/nlp19_21.png" /></p><p>可视化的操作说明如下图：</p><p><img src="/img/nlp19_22.png" /></p><p>这样，我们就把之前的每一个句子映射成了1个768维的句子向量，然后就利用<code>逻辑回归模型</code>直接进行训练就可以了。</p><p><img src="/img/nlp19_23.png" /></p><p>最后，我们来看一下这个模型在测试集上的效果：</p><p><img src="/img/nlp19_24.png" /></p><h3 id="总结">总结</h3><p>本文主要介绍了如何利用<code>DistillBERT</code>和已经封装好的<code>transformers</code>模块，结合<code>逻辑回归模型</code>对英文句子进行文本二分类。后续笔者还会研究在中文上的文本分类以及如何进行微调（Fine_tuning）。</p><p>本项目的Gitlab地址为：<ahref="https://gitlab.com/jclian91/sentence_classify_using_distillBERT_LR">https://gitlab.com/jclian91/sentence_classify_using_distillBERT_LR</a>，原文章作者的Github地址为<ahref="https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb">https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb</a>。</p><p>感谢大家阅读~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>利用关系抽取构建知识图谱的一次尝试</title>
    <link href="/%E5%88%A9%E7%94%A8%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E6%9E%84%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/"/>
    <url>/%E5%88%A9%E7%94%A8%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E6%9E%84%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="关系抽取">关系抽取</h3><p>信息抽取（Information Extraction,IE）旨在从大规模非结构或半结构的自然语言文本中抽取结构化信息。关系抽取（RelationExtraction,RE）是其中的重要子任务之一，主要目的是从文本中识别实体并抽取实体之间的语义关系，是自然语言处理（NLP）中的一项基本任务。比如，我们可以从下面的一段话中，</p><blockquote><p>鸿海集团董事长郭台铭25日表示，阿里巴巴集团董事局主席马云提的新零售、新制造中的「新制造」，是他给加上的。网易科技报导，郭台铭在2018深圳IT领袖峰会谈到工业互联网时表示，眼睛看的、脑筋想的、嘴巴吃的、耳朵听的，都在随着互联网的发展而蓬勃发展，当然互联网不是万能的，比如说刚才李小加要水喝，在手机上一按就能出一瓶水吗？当然做不到，还是得有实体经济。</p></blockquote><p>可以抽取出如下三元组，用来表示实体之间的关系：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-symbol">&#x27;鸿海集团</span>&#x27;, <span class="hljs-symbol">&#x27;董事长</span>&#x27;, <span class="hljs-symbol">&#x27;郭台铭</span>&#x27;]<br>[<span class="hljs-symbol">&#x27;阿里巴巴集团</span>&#x27;, <span class="hljs-symbol">&#x27;主席</span>&#x27;, <span class="hljs-symbol">&#x27;马云</span>&#x27;]<br></code></pre></td></tr></table></figure><p>并且能够形成如下的简单的知识图谱（Knowledge Graph）。</p><p><img src="/img/kg1_1.png" /></p><p>关于知识图谱，笔者已经在文章<ahref="https://www.jianshu.com/p/286eeef0e0c3">SPARQL入门（一）SPARQL简介与简单使用</a>中给出了一些介绍，而利用关系抽取，我们可以从一些非结构化数据中，提取出实体之间的关系，形成知识图谱，这在很大程度上可以帮助我们减轻构建知识图谱的成本。非结构化数据越多，关系抽取效果越好，我们构建的知识图谱就会越庞大，实体之间的关系也会越丰富。</p><h3 id="如何做好关系抽取">如何做好关系抽取？</h3><p>目前，网络上有许多与关系抽取相关的公开比赛，比如：</p><ul><li><p>CCKS 2019 人物关系抽取，网址为：<ahref="https://biendata.com/competition/ccks_2019_ipre/">https://biendata.com/competition/ccks_2019_ipre/</a>；</p></li><li><p>2019语言与智能技术竞赛信息抽取：<ahref="http://lic2019.ccf.org.cn/kg">http://lic2019.ccf.org.cn/kg</a>。</p><p>常用的关系抽取语料如下：</p></li><li><p>MUC关系抽取任务数据集；</p></li><li><p>ACE关系抽取任务数据集；</p></li><li><p>TAC-KBP数据集。</p><p>现阶段，关系抽取的办法主要如下：</p></li><li><p>基于规则的模式匹配；</p></li><li><p>基于监督学习的方法；</p></li><li><p>半监督和无监督学习方法；</p></li><li><p>远程监督的方法；</p></li><li><p>深度学习模型。</p><p>接着，笔者想说下，为什么最近会研究关系抽取。在一个偶然的机会，笔者看到了这个网站：<ahref="https://www.wisers.ai/zh-cn/browse/relation-extraction/demo/">https://www.wisers.ai/zh-cn/browse/relation-extraction/demo/</a>，截图如下：</p></li></ul><p><img src="/img/kg1_2.png" /></p><p>这个图给人以一种非常炫酷的感觉，因此，笔者就被它所吸引了。但笔者在这个demo网站上尝试了几篇新的语料，有些效果好，有些效果不尽如人意，因此，笔者决定自己动手实现一个关系抽取的模型！</p><p>虽然网上已经有许多现成的很好的关系抽取的模型，但笔者还是希望能够按照自己的意愿和想法来实现一下，当然，仅仅是作为一次尝试。笔者的思路如下：</p><ul><li>以句子级别进行标注，标注出句子中的主语，谓语，宾语，形成标注序列；</li><li>利用标注好的语料，采用bert+dl的方法进行训练；</li><li>对新的语料，预测主语，谓语，宾语，然后利用一定的策略，形成实体关系；</li><li>对新语料的实体关系进行可视化展示。</li></ul><p>如果你对笔者的尝试感兴趣，请尝试这阅读下去。</p><h3 id="如何标注">如何标注？</h3><p>按照笔者的惯例，还是自己进行标注。那么，对于关系抽取，该如何进行标注呢？比如，下面这句话：</p><blockquote><p>应日本国首相安倍晋三邀请，出席二十国集团领导人第十四次峰会。</p></blockquote><p>我们需要的实体关系应该是：日本国--&gt;首相--&gt;安倍晋三，那么我们可以选择主语为日本，谓语为首相，宾语为安倍晋三，形成的标注序列如下：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs mathematica">应<span class="hljs-built_in">O</span><br>日<span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>本<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>国<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>首<span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">PRED</span><br>相<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">PRED</span><br>安<span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">OBJ</span><br>倍<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">OBJ</span><br>晋<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">OBJ</span><br>三<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">OBJ</span><br>邀<span class="hljs-built_in">O</span><br>请<span class="hljs-built_in">O</span><br>，<span class="hljs-built_in">O</span><br>出<span class="hljs-built_in">O</span><br>席<span class="hljs-built_in">O</span><br>二<span class="hljs-built_in">O</span><br>十<span class="hljs-built_in">O</span><br>国<span class="hljs-built_in">O</span><br>集<span class="hljs-built_in">O</span><br>团<span class="hljs-built_in">O</span><br>领<span class="hljs-built_in">O</span><br>导<span class="hljs-built_in">O</span><br>人<span class="hljs-built_in">O</span><br>第<span class="hljs-built_in">O</span><br>十<span class="hljs-built_in">O</span><br>四<span class="hljs-built_in">O</span><br>次<span class="hljs-built_in">O</span><br>峰<span class="hljs-built_in">O</span><br>会<span class="hljs-built_in">O</span><br>。<span class="hljs-built_in">O</span><br></code></pre></td></tr></table></figure><p>对于句子中出现多主语，多谓语，多宾语的情况，也可以照此进行标注，比如下面这句：</p><blockquote><p>齐鹏飞同志任中共中国人民大学委员会常委、副书记。</p></blockquote><p>形成的标注序列如下：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs mathematica">齐<span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">OBJ</span><br>鹏<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">OBJ</span><br>飞<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">OBJ</span><br>同<span class="hljs-built_in">O</span><br>志<span class="hljs-built_in">O</span><br>任<span class="hljs-built_in">O</span><br>中<span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>共<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>中<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>国<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>人<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>民<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>大<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>学<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>委<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>员<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>会<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">SUBJ</span><br>常<span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">PRED</span><br>委<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">PRED</span><br>、<span class="hljs-built_in">O</span><br>副<span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">PRED</span><br>书<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">PRED</span><br>记<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">PRED</span><br>。<span class="hljs-built_in">O</span><br></code></pre></td></tr></table></figure><p>对此，我们希望形成两个三元组，分别为：中共中国人民大学委员会--&gt;常委--&gt;齐鹏飞,中共中国人民大学委员会--&gt;副书记--&gt;齐鹏飞。</p><p>笔者利用自己的标注平台（后续会在Github开源），一共标注了950分语料，其中80%作为训练集，10%作为验证集，另外10%作为测试集。当然，标注的过程是很痛苦的，这些标注量也还远远不够，后续会持续不断地更新。</p><h3 id="模型训练">模型训练</h3><p>由于是小样本量的标注数量，因此，在模型的选择上，需要预训练模型，笔者的预训练模型选择BERT。在预训练的基础上，选择BiLSTM+CRF深度学习模型，对上述语料进行训练，共训练100次，在验证集和测试集上的效果如下：</p><p>验证集：</p><table><thead><tr class="header"><th>项目</th><th>precision</th><th>recall</th><th>f1</th></tr></thead><tbody><tr class="odd"><td>全部</td><td>71.08%</td><td>78.27%</td><td>74.50%</td></tr><tr class="even"><td>宾语</td><td>78.95%</td><td>88.24%</td><td>83.33%</td></tr><tr class="odd"><td>谓语</td><td>68.00%</td><td>74.56%</td><td>71.13%</td></tr><tr class="even"><td>主语</td><td>67.18%</td><td>73.33%</td><td>70.12%</td></tr></tbody></table><p>测试集</p><table><thead><tr class="header"><th>项目</th><th>precision</th><th>recall</th><th>f1</th></tr></thead><tbody><tr class="odd"><td>全部</td><td>75.07%</td><td>82.18%</td><td>78.46%</td></tr><tr class="even"><td>宾语</td><td>78.33%</td><td>85.45%</td><td>81.74%</td></tr><tr class="odd"><td>谓语</td><td>73.23%</td><td>82.30%</td><td>77.50%</td></tr><tr class="even"><td>主语</td><td>73.88%</td><td>79.20%</td><td>76.45%</td></tr></tbody></table><p>效果并没有达到很好，一方面是标注策略的问题，另一方面是标注的数量问题（因为这是一个通用模型），后续我们可以看看，当标注数量提上去后，模型训练的效果是否会有提升。</p><h3 id="模型预测">模型预测</h3><p>接着，我们利用刚才训练好的模型，对新的句子进行预测，记住，预测的级别为句子。当然，预测的结果，只是序列标注模型识别出的结果，我们还要采用一定的策略，将其形成三元组。比如以下的句子：</p><blockquote><p>英媒称，美国农业部长桑尼·珀杜在6月25日播出的一个访谈节目中承认，美国农民是特朗普总统对华贸易战的“受害者”。</p></blockquote><p>预测的结果如下：</p><blockquote><p>[{'word': '美国', 'start': 4, 'end': 6, 'type': 'SUBJ'}, {'word':'农业部长', 'start': 6, 'end': 10, 'type': 'PRED'}, {'word':'桑尼·珀杜', 'start': 10, 'end': 15, 'type': 'OBJ'}, {'word': '美国','start': 34, 'end': 36, 'type': 'SUBJ'}]</p></blockquote><p>可以看到，模型识别出主语为美国，谓语为农业部长，宾语为桑尼·珀杜，这是一个完美的三元组。</p><p>我们再来对下面的语句进行预测：</p><blockquote><p>6月25日，华为常务董事、运营商事业部总裁丁耘表示，华为已在全球范围内获得50个5G商用合同，其中2/3是由华为协助其构建的。</p></blockquote><p>预测结果为：</p><blockquote><p>[{'word': '华为', 'start': 6, 'end': 8, 'type': 'SUBJ'}, {'word':'常务董事', 'start': 8, 'end': 12, 'type': 'PRED'}, {'word':'运营商事业部', 'start': 13, 'end': 19, 'type': 'SUBJ'}, {'word':'总裁', 'start': 19, 'end': 21, 'type': 'PRED'}, {'word': '丁耘','start': 21, 'end': 23, 'type': 'OBJ'}, {'word': '华为', 'start': 26,'end': 28, 'type': 'SUBJ'}, {'word': '华为', 'start': 54, 'end': 56,'type': 'SUBJ'}]</p></blockquote><p>这就需要一定的策略，才能识别出具体的三元组了。笔者采用的策略如下：</p><ul><li>按主语，谓语，宾语进行归类，形成主体集合<code>&#123;华为, 运营商事业部&#125;</code>，谓语集合<code>&#123;常务董事, 总裁&#125;</code>以及宾语集合<code>&#123;丁耘&#125;</code>；</li><li>接着，按照各个元素在句子出现的位置进行组合，比如<code>华为</code>的位置，离<code>常务董事</code>挨得近，那么形成一个三元组['华为','常务董事', '丁耘']，同理，形成另一个三元组['运营商事业部', '总裁','丁耘'];</li><li>将句子按照逗号进行分割，形成<code>小句子集合</code>，看三元组的三个元素是否都在一个小句子中，如果是，则提取该三元组，如果不是，则放弃该三元组。</li></ul><h3 id="关系抽取可视化">关系抽取可视化</h3><p>对于关系抽取后的节后，我们将三元组导入至Neo4J中，查看可视化的效果。我们一共选择三篇文章进行测试，为了取得较好的效果，我们选择了程序处理+人工check（过滤）的过程，稍微有点工作量。</p><p>第一篇文章来自微信公众号，标题为：<code>哈工大社会计算与信息检索研究中心（HIT-SCIR）拟于7月20日在哈工大举办首届事理图谱研讨会</code>,访问网址为：https://mp.weixin.qq.com/s/9H7rxsPdo5S5trwz_CASZw，我们抽取出来的实体关系（带原文）如下：</p><blockquote><p>原文,s,p,o2017年10月，研究中心主任刘挺教授在中国计算机大会（CNCC）上正式提出事理图谱的概念，2018年9月，在研究中心丁效老师的主持下，研制出中文金融事理图谱1.0版本。,研究中心,老师,丁效<br />2017年10月，研究中心主任刘挺教授在中国计算机大会（CNCC）上正式提出事理图谱的概念，2018年9月，在研究中心丁效老师的主持下，研制出中文金融事理图谱1.0版本。,研究中心,教授,刘挺<br />2017年10月，研究中心主任刘挺教授在中国计算机大会（CNCC）上正式提出事理图谱的概念，2018年9月，在研究中心丁效老师的主持下，研制出中文金融事理图谱1.0版本。,研究中心,主任,刘挺<br />白硕（上海证券交易所前任总工程师，中科院计算所博导）,上海证券交易所,前任总工程师,白硕<br />荀恩东（北京语言大学信息学院院长）,北京语言大学信息学院,院长,荀恩东<br />赵军（中科院自动化所研究员）,中科院自动化所,研究员,赵军<br />吴华（百度技术委员会主席）,百度技术,主席,吴华<br />吴华（百度技术委员会主席）,百度技术,委员,吴华<br />宋阳秋（香港科技大学助理教授）,香港科技大学,助理教授,宋阳秋<br />李金龙（招商银行人工智能实验室负责人）,招商银行人工智能实验室,负责人,李金龙<br />李世奇（北京西亚财信人工智能科技有限责任公司CEO）,北京西亚财信人工智能科技有限责任公司,CEO,李世奇</p></blockquote><p>对于这篇文章，我们没有抽取出<code>李斌阳（国际关系学院副教授）</code>中的实体关系，并且<code>吴华（百度技术委员会主席</code>这句为抽取有误，正确的应为：百度技术委员会,主席,吴华。</p><p>将上述关系修改下，导入至Neo4J中，得到的实体关系图如下：</p><p><img src="/img/kg1_3.png" /></p><p>第二篇文章为凤凰网的新闻，标题为<code>南阳“水氢车”风波：一个中部城市的招商突围战</code>，访问网址为：<ahref="https://news.ifeng.com/c/7ntawxhCDvj">https://news.ifeng.com/c/7ntawxhCDvj</a>，我们抽取出来的实体关系（带原文）如下表：</p><blockquote><p>原文,s,p,o2017年，因巴铁所属企业北京华赢凯来资产管理有限公司涉嫌非法集资活动，北京警方将“巴铁之父”白丹青依法刑拘。,巴铁,之父,白丹青<br />南阳“神车”下线之后，界面新闻约访南阳市委书记张文深，被告知张文深与市长双双出差，工作人员并不确定张文深何时回到南阳，他的手机则处于忙线状态。,南阳,市委书记,张文深<br />南阳洛特斯新能源汽车有限公司实际控制人庞青年说，水氢汽车并未下线，媒体的报道使他措手不及。,南阳洛特斯新能源汽车有限公司,实际控制人,庞青年<br />从2006年开始，前湖北工业大学学者董仕节带领的团队开始研发一项车载铝合金水解制氢技术，并获得国家973前期研究项目和国家自然基金的支持。,湖北工业大学,学者,董仕节<br />南阳市高新区投资公司负责人尹召翼在接受央视采访时表示，庞青年经常拿“水氢”来混淆“水解制氢”的概念。,南阳市高新区投资公司,负责人,尹召翼<br />南阳市招商局招商二科科长赵怿接受界面新闻采访时表示，他只知道这个项目不是招商科引进的。,南阳市招商局招商二科,科长,赵怿<br />庞青年告诉界面新闻，南阳市高新区投资有限公司已经为他提供了9600万元，用途是南阳高新区投资有限公司给南阳市洛特斯新能源汽车有限公司的注册资金，占股49%。,南阳高新区投资有限公司,南阳市,洛特斯新能<br />曾先后在南阳市委党校、南阳市发改委任职的退休干部张一江（化名）说，“走工业突围道路的冲动在南阳早已有之，所以这几年的巴铁神车项目、加水就能跑的神车项目能被引进南阳，我觉得算不上奇怪。”,南阳市发改委,退休干部,张一江<br />以此次南阳神车项目为例，南阳市科技局局长张梅明确告诉界面新闻，庞青年的企业进入南阳时未有任何部门邀请科技局鉴别其“新能源技术”。,南阳市科技局,局长,张梅<br />官方报道显示，2012年6月18日，一位时任南阳市委主要领导在南阳宾馆会见了青年汽车董事局主席庞青年一行，双方就如何发挥自身优势，谋求合作共赢进行了交流，“南阳的发展需要大项目的带动和支撑，我们欢迎中国青年汽车集团这样有实力、有影响的大企业来南阳投资兴业。,青年汽车,董事局主席,庞青年<br />早在当年5月，在第十九届中国北京国际科技博览会上，时任南阳市副市长郑茂杰与巴铁科技发展有限公司总工程师宋有洲签署战略合作协议。,巴铁科技发展有限公司,总工程师,宋有洲<br />早在当年5月，在第十九届中国北京国际科技博览会上，时任南阳市副市长郑茂杰与巴铁科技发展有限公司总工程师宋有洲签署战略合作协议。,南阳市,副市长,郑茂杰</p></blockquote><p>对于这篇文章，我们没有抽取出一些关系，比如<code>南阳市发展和改革委员会主任乔长恩受访时承认，招商引入南阳洛斯特之前“掌握这个情况。”</code>等，并且<code>庞青年告诉界面新闻，南阳市高新区投资有限公司已经为他提供了9600万元，用途是南阳高新区投资有限公司给南阳市洛特斯新能源汽车有限公司的注册资金，占股49%。</code>这句为抽取有误，应当删除。</p><p>将上述关系修改下，导入至Neo4J中，得到的实体关系图如下：</p><p><img src="/img/kg1_4.png" /></p><p>最后一篇为长篇小说——著名作家路遥的《平凡的世界》第一部。利用我们的关系抽取模型，一共在该小说中抽取了169对实体关系，其中有效实体关系100对。由于我们在该小说中抽取的实体关系过多，因此只展示前10条原文及抽取的实体关系：</p><blockquote><p>原文,s,p,o每天来回二十里路，与他一块上学的金波和大队书记田福堂的儿子润生都有自行车，只有他是两条腿走路。,田福堂,儿子,润生<br />不过，他对润生的姐姐润叶倒怀有一种亲切的感情。,润生,姐姐,润叶<br />“金波是金俊海的小子。”,金俊海,小子,“金波<br />脑子里把前后村庄未嫁的女子一个个想过去，最后选定了双水村孙玉厚的大女子兰花。,双水村孙玉厚,大女子,兰花<br />玉亭是大队党支部委员、农田基建队队长、贫下中农管理学校委员会主任，一身三职，在村里也是一个人物。,贫下中农管理学校,主任,玉亭<br />玉亭是大队党支部委员、农田基建队队长、贫下中农管理学校委员会主任，一身三职，在村里也是一个人物。,农田基建队,队长,玉亭<br />玉亭是大队党支部委员、农田基建队队长、贫下中农管理学校委员会主任，一身三职，在村里也是一个人物。,大队,党支部委员,玉亭<br />会战总指挥是公社副主任徐治功，副总指挥是公社武装专干杨高虎。,公社,武装,杨高虎<br />会战总指挥是公社副主任徐治功，副总指挥是公社武装专干杨高虎。,公社,副主任,徐治功<br />这时候，双水村妇女主任贺凤英，正领着本村和外村的一些“铁姑娘”，忙碌地布置会场。,双水村,妇女主任,贺凤英<br />……</p></blockquote><p>将上述关系修改下，导入至Neo4J中，得到的实体关系图如下：</p><p><img src="/img/kg1_5.png" /></p><p><img src="/img/kg1_6.png" /></p><p><img src="/img/kg1_7.png" /></p><h3 id="总结">总结</h3><p>本次关系抽取仅仅作为笔者的一次尝试，在实际的应用中还存在着许多的不足之处，比如：</p><ul><li><p>对语料的标注，是否可以采用其他更好的办法；</p></li><li><p>作为通用模型，标注的数量还远远不够；</p></li><li><p>模型的选择方面，是否可以其他更好的模型；</p></li><li><p>对预测的结果，如何能更好地提取出三元组；</p></li><li><p>将三元组扫入至图数据库中，能否做到实体对齐，且能做一些实体关系的分析与推理。</p><p>本文用到的语料以及模型会在后续的文章中公开，希望大家能继续关注～</p></li></ul>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>知识图谱</category>
      
    </categories>
    
    
    <tags>
      
      <tag>关系抽取</tag>
      
      <tag>知识图谱</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（十八）利用ALBERT提升模型预测速度的一次尝试</title>
    <link href="/NLP%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E9%80%9F%E5%BA%A6%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/"/>
    <url>/NLP%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%E5%88%A9%E7%94%A8ALBERT%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E9%80%9F%E5%BA%A6%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="前沿">前沿</h3><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E5%8D%81%E4%B8%83%EF%BC%89%E5%88%A9%E7%94%A8tensorflow-serving%E9%83%A8%E7%BD%B2kashgari%E6%A8%A1%E5%9E%8B/">NLP（十七）利用tensorflow-serving部署kashgari模型</a>中，笔者介绍了如何利用tensorflow-serving部署来部署深度模型模型，在那篇文章中，笔者利用kashgari模块实现了经典的BERT+Bi-LSTM+CRF模型结构，在标注了时间的文本语料（大约2000多个训练句子）中也达到了很好的识别效果，但是也存在着不足之处，那就是模型的预测时间过长，平均预测一个句子中的时间耗时约400毫秒，这种预测速度在生产环境或实际应用中是不能忍受的。</p><p>查看该模型的耗时原因，很大一部分原因在于BERT的调用。BERT是当下最火，知名度最高的预训练模型，虽然会使得模型的训练、预测耗时增加，但也是小样本语料下的最佳模型工具之一，因此，BERT在模型的架构上是不可缺少的。那么，该如何避免使用预训练模型带来的模型预测耗时过长的问题呢？</p><p>本文决定尝试使用ALBERT，来验证ALBERT在提升模型预测速度方面的应用，同时，也算是本人对于使用ALBERT的一次实战吧~</p><h3 id="albert简介">ALBERT简介</h3><p>我们不妨花一些时间来简单地了解一下ALBERT。ALBERT是最近一周才开源的预训练模型，其Github的网址为：https://github.com/brightmart/albert_zh，其论文可以参考网址：https://arxiv.org/pdf/1909.11942.pdf 。</p><p>根据ALBERT的Github介绍，ALBERT在海量中文语料上进行了预训练，模型的参数更少，效果更好。以albert_tiny_zh为例，其文件大小16M、参数为1.8M，模型大小仅为BERT的1/25，效果仅比BERT略差或者在某些NLP任务上更好。在本文的预训练模型中，将采用albert_tiny_zh。</p><h3 id="利用albert训练时间识别模型">利用ALBERT训练时间识别模型</h3><p>我们以Github中的bertNER为本次项目的代码模板，在该项目中，实现的模型为BERT+Bi-LSTM+CRF，我们将BERT替换为ALBERT，也就是说笔者的项目中模型为ALBERT+Bi-LSTM+CRF，同时替换bert文件夹的代码为alert_zh，替换预训练模型文件夹chinese_L-12_H-768_A-12（BERT中文预训练模型文件）为albert_tiny。当然，也需要修改一部分的项目源代码，来适应ALBERT的模型训练。</p><p>数据集采用笔者自己标注的时间语料，即标注了时间的句子，大概2000+句子，其中75%作为训练集（time.train文件），10%作为验证集（time.dev文件），15%作为测试集（time.test文件）。在这里笔者不打算给出具体的Python代码，因为工程比较复杂，有兴趣的额读者可以去查看该项目的Github地址：<ahref="https://github.com/percent4/ALBERT_4_Time_Recognition">https://github.com/percent4/ALBERT_4_Time_Recognition</a>。</p><p>一些模型的参数可以如下：</p><ul><li><p>预训练模型：ALBERT（tiny）</p></li><li><p>训练样本的最大字符长度： 128</p></li><li><p>batch_size: 8</p></li><li><p>epoch: 100</p></li><li><p>双向LSTM的个数：100</p><p>ALBERT的模型训练时间也会显著提高，我们耐心地等待模型训练完毕。在time.dev和time.test数据集上的表现如下表：</p></li></ul><table><thead><tr class="header"><th>数据集</th><th>precision</th><th>recall</th><th>f1</th></tr></thead><tbody><tr class="odd"><td>time.dev</td><td>81.41%</td><td>84.95%</td><td>83.14%</td></tr><tr class="even"><td>time.test</td><td>83.03%</td><td>86.38%</td><td>84.67%</td></tr></tbody></table><p>接着笔者利用训练好的模型，用tornado封装了一个模型预测的HTTP服务，具体的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> traceback<br><br><span class="hljs-keyword">import</span> tornado.httpserver<br><span class="hljs-keyword">import</span> tornado.ioloop<br><span class="hljs-keyword">import</span> tornado.options<br><span class="hljs-keyword">import</span> tornado.web<br><span class="hljs-keyword">from</span> tornado.options <span class="hljs-keyword">import</span> define, options<br><br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> create_model, get_logger<br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> Model<br><span class="hljs-keyword">from</span> loader <span class="hljs-keyword">import</span> input_from_line<br><span class="hljs-keyword">from</span> train <span class="hljs-keyword">import</span> FLAGS, load_config, train<br><br><span class="hljs-comment"># 定义端口为12306</span><br>define(<span class="hljs-string">&quot;port&quot;</span>, default=<span class="hljs-number">12306</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;run on the given port&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>)<br><span class="hljs-comment"># 导入模型</span><br>config = load_config(FLAGS.config_file)<br>logger = get_logger(FLAGS.log_file)<br><span class="hljs-comment"># limit GPU memory</span><br>tf_config = tf.ConfigProto()<br>tf_config.gpu_options.allow_growth = <span class="hljs-literal">False</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(FLAGS.map_file, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    tag_to_id, id_to_tag = pickle.load(f)<br><br>sess = tf.Session(config=tf_config)<br>model = create_model(sess, Model, FLAGS.ckpt_path, config, logger)<br><br><span class="hljs-comment"># 模型预测的HTTP接口</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResultHandler</span>(tornado.web.RequestHandler):<br>    <span class="hljs-comment"># post函数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">post</span>(<span class="hljs-params">self</span>):<br>        event = self.get_argument(<span class="hljs-string">&#x27;event&#x27;</span>)<br>        result = model.evaluate_line(sess, input_from_line(event, FLAGS.max_seq_len, tag_to_id), id_to_tag)<br>        self.write(json.dumps(result, ensure_ascii=<span class="hljs-literal">False</span>))<br><br><span class="hljs-comment"># 主函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-comment"># 开启tornado服务</span><br>    tornado.options.parse_command_line()<br>    <span class="hljs-comment"># 定义app</span><br>    app = tornado.web.Application(<br>            handlers=[<br>                      (<span class="hljs-string">r&#x27;/subj_extract&#x27;</span>, ResultHandler)<br>                     ], <span class="hljs-comment">#网页路径控制</span><br>           )<br>    http_server = tornado.httpserver.HTTPServer(app)<br>    http_server.listen(options.port)<br>    tornado.ioloop.IOLoop.instance().start()<br><br>main()<br></code></pre></td></tr></table></figure><h3 id="模型预测提速了吗">模型预测提速了吗？</h3><p>将模型预测封装成HTTP服务后，我们利用Postman来测试模型预测的效果和时间，如下图所示：</p><p><img src="/img/nlp18_1.png" /></p><p>可以看到，模型预测的结果正确，且耗时仅为38ms。</p><p>接着我们尝试多测试几个句子的测试，测试代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Daxing, Beijing</span><br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> time<br><br>url = <span class="hljs-string">&#x27;http://localhost:12306/subj_extract&#x27;</span><br><br>texts = [<span class="hljs-string">&#x27;记者从国家发展改革委、商务部相关方面获悉，日前美方已决定对拟于10月1日实施的中国输美商品加征关税措施做出调整，中方支持相关企业从即日起按照市场化原则和WTO规则，自美采购一定数量大豆、猪肉等农产品，国务院关税税则委员会将对上述采购予以加征关税排除。&#x27;</span>,<br>         <span class="hljs-string">&#x27;据印度Zee新闻网站12日报道，亚洲新闻国际通讯社援引印度军方消息人士的话说，9月11日的对峙事件发生在靠近班公错北岸的实际控制线一带。&#x27;</span>,<br>         <span class="hljs-string">&#x27;儋州市决定，从9月开始，对城市低保、农村低保、特困供养人员、优抚对象、领取失业保险金人员、建档立卡未脱贫人口等低收入群体共3万多人，发放猪肉价格补贴，每人每月发放不低于100元补贴，以后发放标准，将根据猪肉价波动情况进行动态调整。&#x27;</span>,<br>         <span class="hljs-string">&#x27;9月11日，华为心声社区发布美国经济学家托马斯.弗里德曼在《纽约时报》上的专栏内容，弗里德曼透露，在与华为创始人任正非最近一次采访中，任正非表示华为愿意与美国司法部展开话题不设限的讨论。&#x27;</span>,<br>         <span class="hljs-string">&#x27;造血干细胞移植治疗白血病技术已日益成熟，然而，通过该方法同时治愈艾滋病目前还是一道全球尚在攻克的难题。&#x27;</span>,<br>         <span class="hljs-string">&#x27;英国航空事故调查局（AAIB）近日披露，今年2月6日一趟由德国法兰克福飞往墨西哥坎昆的航班上，因飞行员打翻咖啡使操作面板冒烟，导致飞机折返迫降爱尔兰。&#x27;</span>,<br>         <span class="hljs-string">&#x27;当地时间周四（9月12日），印度尼西亚财政部长英卓华（Sri Mulyani Indrawati）明确表示：特朗普的推特是风险之一。&#x27;</span>,<br>         <span class="hljs-string">&#x27;华中科技大学9月12日通过其官方网站发布通报称，9月2日，我校一硕士研究生不幸坠楼身亡。&#x27;</span>,<br>         <span class="hljs-string">&#x27;微博用户@ooooviki 9月12日下午公布发生在自己身上的惊悚遭遇：一个自称网警、名叫郑洋的人利用职务之便，查到她的完备的个人信息，包括但不限于身份证号、家庭地址、电话号码、户籍变动情况等，要求她做他女朋友。&#x27;</span>,<br>         <span class="hljs-string">&#x27;今天，贵阳取消了汽车限购，成为目前全国实行限购政策的9个省市中，首个取消限购的城市。&#x27;</span>,<br>         <span class="hljs-string">&#x27;据悉，与全球同步，中国区此次将于9月13日于iPhone官方渠道和京东正式开启预售，京东成Apple中国区唯一官方授权预售渠道。&#x27;</span>,<br>         <span class="hljs-string">&#x27;根据央行公布的数据，截至2019年6月末，存款类金融机构住户部门短期消费贷款规模为9.11万亿元，2019年上半年该项净增3293.19亿元，上半年增量看起来并不乐观。&#x27;</span>,<br>         <span class="hljs-string">&#x27;9月11日，一段拍摄浙江万里学院学生食堂的视频走红网络，视频显示该学校食堂不仅在用餐区域设置了可以看电影、比赛的大屏幕，还推出了“一人食”餐位。&#x27;</span>,<br>         <span class="hljs-string">&#x27;当日，在北京举行的2019年国际篮联篮球世界杯半决赛中，西班牙队对阵澳大利亚队。&#x27;</span>,<br>         ]<br><br>t1 = time.time()<br><span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts:<br>    data = &#123;<span class="hljs-string">&#x27;event&#x27;</span>: text.replace(<span class="hljs-string">&#x27; &#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)&#125;<br>    req = requests.post(url, data)<br>    <span class="hljs-keyword">if</span> req.status_code == <span class="hljs-number">200</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;原文：%s&#x27;</span> % text)<br>        res = json.loads(req.content)[<span class="hljs-string">&#x27;entities&#x27;</span>]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;抽取结果：%s&#x27;</span> % <span class="hljs-built_in">str</span>([_[<span class="hljs-string">&#x27;word&#x27;</span>] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> res]))<br><br><br>t2 = time.time()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;一共耗时：%ss.&#x27;</span> % <span class="hljs-built_in">str</span>(<span class="hljs-built_in">round</span>(t2-t1, <span class="hljs-number">4</span>)))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs prolog">原文：记者从国家发展改革委、商务部相关方面获悉，日前美方已决定对拟于<span class="hljs-number">10</span>月<span class="hljs-number">1</span>日实施的中国输美商品加征关税措施做出调整，中方支持相关企业从即日起按照市场化原则和<span class="hljs-symbol">WTO</span>规则，自美采购一定数量大豆、猪肉等农产品，国务院关税税则委员会将对上述采购予以加征关税排除。<br>抽取结果：[<span class="hljs-string">&#x27;日前&#x27;</span>, <span class="hljs-string">&#x27;10月1日&#x27;</span>]<br>原文：据印度<span class="hljs-symbol">Zee</span>新闻网站<span class="hljs-number">12</span>日报道，亚洲新闻国际通讯社援引印度军方消息人士的话说，<span class="hljs-number">9</span>月<span class="hljs-number">11</span>日的对峙事件发生在靠近班公错北岸的实际控制线一带。<br>抽取结果：[<span class="hljs-string">&#x27;12日&#x27;</span>, <span class="hljs-string">&#x27;9月11日&#x27;</span>]<br>原文：儋州市决定，从<span class="hljs-number">9</span>月开始，对城市低保、农村低保、特困供养人员、优抚对象、领取失业保险金人员、建档立卡未脱贫人口等低收入群体共<span class="hljs-number">3</span>万多人，发放猪肉价格补贴，每人每月发放不低于<span class="hljs-number">100</span>元补贴，以后发放标准，将根据猪肉价波动情况进行动态调整。<br>抽取结果：[<span class="hljs-string">&#x27;9月&#x27;</span>]<br>原文：<span class="hljs-number">9</span>月<span class="hljs-number">11</span>日，华为心声社区发布美国经济学家托马斯.弗里德曼在《纽约时报》上的专栏内容，弗里德曼透露，在与华为创始人任正非最近一次采访中，任正非表示华为愿意与美国司法部展开话题不设限的讨论。<br>抽取结果：[<span class="hljs-string">&#x27;9月11日&#x27;</span>]<br>原文：造血干细胞移植治疗白血病技术已日益成熟，然而，通过该方法同时治愈艾滋病目前还是一道全球尚在攻克的难题。<br>抽取结果：[]<br>原文：英国航空事故调查局（<span class="hljs-symbol">AAIB</span>）近日披露，今年<span class="hljs-number">2</span>月<span class="hljs-number">6</span>日一趟由德国法兰克福飞往墨西哥坎昆的航班上，因飞行员打翻咖啡使操作面板冒烟，导致飞机折返迫降爱尔兰。<br>抽取结果：[<span class="hljs-string">&#x27;近日&#x27;</span>, <span class="hljs-string">&#x27;今年2月6日&#x27;</span>]<br>原文：当地时间周四（<span class="hljs-number">9</span>月<span class="hljs-number">12</span>日），印度尼西亚财政部长英卓华（<span class="hljs-symbol">Sri</span> <span class="hljs-symbol">Mulyani</span> <span class="hljs-symbol">Indrawati</span>）明确表示：特朗普的推特是风险之一。<br>抽取结果：[<span class="hljs-string">&#x27;当地时间周四（9月12日）&#x27;</span>]<br>原文：华中科技大学<span class="hljs-number">9</span>月<span class="hljs-number">12</span>日通过其官方网站发布通报称，<span class="hljs-number">9</span>月<span class="hljs-number">2</span>日，我校一硕士研究生不幸坠楼身亡。<br>抽取结果：[<span class="hljs-string">&#x27;9月12日&#x27;</span>, <span class="hljs-string">&#x27;9月2日&#x27;</span>]<br>原文：微博用户@ooooviki <span class="hljs-number">9</span>月<span class="hljs-number">12</span>日下午公布发生在自己身上的惊悚遭遇：一个自称网警、名叫郑洋的人利用职务之便，查到她的完备的个人信息，包括但不限于身份证号、家庭地址、电话号码、户籍变动情况等，要求她做他女朋友。<br>抽取结果：[<span class="hljs-string">&#x27;9月12日下午&#x27;</span>]<br>原文：今天，贵阳取消了汽车限购，成为目前全国实行限购政策的<span class="hljs-number">9</span>个省市中，首个取消限购的城市。<br>抽取结果：[<span class="hljs-string">&#x27;今天&#x27;</span>, <span class="hljs-string">&#x27;目前&#x27;</span>]<br>原文：据悉，与全球同步，中国区此次将于<span class="hljs-number">9</span>月<span class="hljs-number">13</span>日于iPhone官方渠道和京东正式开启预售，京东成<span class="hljs-symbol">Apple</span>中国区唯一官方授权预售渠道。<br>抽取结果：[<span class="hljs-string">&#x27;9月13日&#x27;</span>]<br>原文：根据央行公布的数据，截至<span class="hljs-number">2019</span>年<span class="hljs-number">6</span>月末，存款类金融机构住户部门短期消费贷款规模为<span class="hljs-number">9.11</span>万亿元，<span class="hljs-number">2019</span>年上半年该项净增<span class="hljs-number">3293.19</span>亿元，上半年增量看起来并不乐观。<br>抽取结果：[<span class="hljs-string">&#x27;2019年6月末&#x27;</span>, <span class="hljs-string">&#x27;2019年上半年&#x27;</span>, <span class="hljs-string">&#x27;上半年&#x27;</span>]<br>原文：<span class="hljs-number">9</span>月<span class="hljs-number">11</span>日，一段拍摄浙江万里学院学生食堂的视频走红网络，视频显示该学校食堂不仅在用餐区域设置了可以看电影、比赛的大屏幕，还推出了“一人食”餐位。<br>抽取结果：[<span class="hljs-string">&#x27;9月11日&#x27;</span>]<br>原文：当日，在北京举行的<span class="hljs-number">2019</span>年国际篮联篮球世界杯半决赛中，西班牙队对阵澳大利亚队。<br>抽取结果：[<span class="hljs-string">&#x27;当日&#x27;</span>, <span class="hljs-string">&#x27;2019年&#x27;</span>]<br>一共耗时：<span class="hljs-number">0.5314</span>s.<br></code></pre></td></tr></table></figure><p>可以看到，对于测试的14个句子，识别的准确率很高，且预测耗时为531ms，平均每个话的预测时间不超过40ms。相比较而言，文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E5%8D%81%E4%B8%83%EF%BC%89%E5%88%A9%E7%94%A8tensorflow-serving%E9%83%A8%E7%BD%B2kashgari%E6%A8%A1%E5%9E%8B/">NLP（十七）利用tensorflow-serving部署kashgari模型</a>中的模型，该模型的预测时间为每句话1秒多，模型预测的速度为带ALBERT模型的25倍多。</p><p>因此，ALBERT模型确实提升了模型预测的时间，而且效果非常显著。</p><h3 id="总结">总结</h3><p>由于ALBERT开源不到一周，而且笔者的学识、才能有限，因此，在代码方面可能会存在不足。但是，作为一次使用ALBERT的历经，希望能够与大家分享。</p><p>本文绝不是上述项目代码的抄袭和堆砌，该项目融入了笔者自己的思考，希望不要被误解为是抄袭。笔者使用上述的bertNER和ALBERT，只是为了验证ALBERT在模型预测耗时方面的提速效果，而事实是，ALBERT确实给我带来了很大惊喜，感受源代码作者们～</p><p>最后，附上本文中笔者项目的Github地址：<ahref="https://github.com/percent4/ALBERT_4_Time_Recognition">https://github.com/percent4/ALBERT_4_Time_Recognition</a>。</p><p>众里寻他千百度。蓦然回首，那人却在，灯火阑珊处。</p><h3 id="参考文献">参考文献</h3><ol type="1"><li>超小型BERT中文版横空出世！模型只有16M，训练速度提升10倍：https://mp.weixin.qq.com/s/eVlNpejrxdE4ctDTBM-fiA</li><li>ALBERT的Github地址：https://github.com/brightmart/albert_zh</li><li>bertNER项目的Github地址：https://github.com/yumath/bertNER</li><li>NLP（十七）利用tensorflow-serving部署kashgari模型：https://www.cnblogs.com/jclian91/p/11526547.html</li></ol>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>ALBERT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（十七）利用tensorflow-serving部署kashgari模型</title>
    <link href="/NLP%EF%BC%88%E5%8D%81%E4%B8%83%EF%BC%89%E5%88%A9%E7%94%A8tensorflow-serving%E9%83%A8%E7%BD%B2kashgari%E6%A8%A1%E5%9E%8B/"/>
    <url>/NLP%EF%BC%88%E5%8D%81%E4%B8%83%EF%BC%89%E5%88%A9%E7%94%A8tensorflow-serving%E9%83%A8%E7%BD%B2kashgari%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E5%8D%81%E4%BA%94%EF%BC%89%E8%AE%A9%E6%A8%A1%E5%9E%8B%E6%9D%A5%E5%91%8A%E8%AF%89%E4%BD%A0%E6%96%87%E6%9C%AC%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4/">NLP（十五）让模型来告诉你文本中的时间</a>中，我们已经学会了如何利用kashgari模块来完成序列标注模型的训练与预测，在本文中，我们将会了解如何tensorflow-serving来部署模型。</p><p>在kashgari的官方文档中，已经有如何利用tensorflow-serving来部署模型的说明了，网址为：<ahref="https://kashgari.bmio.net/advance-use/tensorflow-serving/">https://kashgari.bmio.net/advance-use/tensorflow-serving/</a>。</p><p>下面，本文将介绍tensorflow-serving以及如何利用tensorflow-serving来部署kashgari的模型。</p><h3 id="tensorflow-serving">tensorflow-serving</h3><p>TensorFlow Serving 是一个用于机器学习模型 serving的高性能开源库。它可以将训练好的机器学习模型部署到线上，使用 gRPC作为接口接受外部调用。更加让人眼前一亮的是，它支持模型热更新与自动模型版本管理。这意味着一旦部署TensorFlow Serving后，你再也不需要为线上服务操心，只需要关心你的线下模型训练。</p><p>TensorFlowServing可以方便我们部署TensorFlow模型，本文将使用TensorFlowServing的Docker镜像来使用TensorFlow Serving，安装的命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull tensorflow/serving<br></code></pre></td></tr></table></figure><h3 id="工程实践">工程实践</h3><p>本项目将演示如何利用tensorflow/serving来部署kashgari中的模型，项目结构如下：</p><p><img src="/img/nlp17_1.png" /></p><p>本项目的data来自之前笔者标注的时间数据集，即标注出文本中的时间，采用BIO标注系统。chinese_wwm_ext文件夹为哈工大的预训练模型文件。</p><p>model_train.py为模型训练的代码，主要功能是完成时间序列标注模型的训练，完整的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># time: 2019-09-12</span><br><span class="hljs-comment"># place: Huangcun Beijing</span><br><br><span class="hljs-keyword">import</span> kashgari<br><span class="hljs-keyword">from</span> kashgari <span class="hljs-keyword">import</span> utils<br><span class="hljs-keyword">from</span> kashgari.corpus <span class="hljs-keyword">import</span> DataReader<br><span class="hljs-keyword">from</span> kashgari.embeddings <span class="hljs-keyword">import</span> BERTEmbedding<br><span class="hljs-keyword">from</span> kashgari.tasks.labeling <span class="hljs-keyword">import</span> BiLSTM_CRF_Model<br><br><span class="hljs-comment"># 模型训练</span><br><br>train_x, train_y = DataReader().read_conll_format_file(<span class="hljs-string">&#x27;./data/time.train&#x27;</span>)<br>valid_x, valid_y = DataReader().read_conll_format_file(<span class="hljs-string">&#x27;./data/time.dev&#x27;</span>)<br>test_x, test_y = DataReader().read_conll_format_file(<span class="hljs-string">&#x27;./data/time.test&#x27;</span>)<br><br>bert_embedding = BERTEmbedding(<span class="hljs-string">&#x27;chinese_wwm_ext_L-12_H-768_A-12&#x27;</span>,<br>                               task=kashgari.LABELING,<br>                               sequence_length=<span class="hljs-number">128</span>)<br><br>model = BiLSTM_CRF_Model(bert_embedding)<br><br>model.fit(train_x, train_y, valid_x, valid_y, batch_size=<span class="hljs-number">16</span>, epochs=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># Save model</span><br>utils.convert_to_saved_model(model,<br>                             model_path=<span class="hljs-string">&#x27;saved_model/time_entity&#x27;</span>,<br>                             version=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>运行该代码，模型训练完后会生成saved_model文件夹，里面含有模型训练好后的文件，方便我们利用tensorflow/serving进行部署。接着我们利用tensorflow/serving来完成模型的部署，命令如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">docker <span class="hljs-built_in">run</span> -t --rm -p 8501:8501 -v <span class="hljs-string">&quot;/Users/jclian/PycharmProjects/kashgari_tf_serving/saved_model:/models/&quot;</span> -e <span class="hljs-attribute">MODEL_NAME</span>=time_entity tensorflow/serving<br></code></pre></td></tr></table></figure><p>其中需要注意该模型所在的路径，路径需要写完整路径，以及模型的名称（MODEL_NAME），这在训练代码（train.py）中已经给出（saved_model/time_entity）。</p><p>接着我们使用tornado来搭建HTTP服务，帮助我们方便地进行模型预测，runServer.py的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> kashgari <span class="hljs-keyword">import</span> utils<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> model_predict <span class="hljs-keyword">import</span> get_predict<br><br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> tornado.httpserver<br><span class="hljs-keyword">import</span> tornado.ioloop<br><span class="hljs-keyword">import</span> tornado.options<br><span class="hljs-keyword">import</span> tornado.web<br><span class="hljs-keyword">from</span> tornado.options <span class="hljs-keyword">import</span> define, options<br><span class="hljs-keyword">import</span> traceback<br><br><span class="hljs-comment"># tornado高并发</span><br><span class="hljs-keyword">import</span> tornado.web<br><span class="hljs-keyword">import</span> tornado.gen<br><span class="hljs-keyword">import</span> tornado.concurrent<br><span class="hljs-keyword">from</span> concurrent.futures <span class="hljs-keyword">import</span> ThreadPoolExecutor<br><br><span class="hljs-comment"># 定义端口为12333</span><br>define(<span class="hljs-string">&quot;port&quot;</span>, default=<span class="hljs-number">16016</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;run on the given port&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>)<br><br><span class="hljs-comment"># 模型预测</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ModelPredictHandler</span>(tornado.web.RequestHandler):<br>    executor = ThreadPoolExecutor(max_workers=<span class="hljs-number">5</span>)<br><br>    <span class="hljs-comment"># get 函数</span><br><span class="hljs-meta">    @tornado.gen.coroutine</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get</span>(<span class="hljs-params">self</span>):<br>        origin_text = self.get_argument(<span class="hljs-string">&#x27;text&#x27;</span>)<br>        result = <span class="hljs-keyword">yield</span> self.function(origin_text)<br>        self.write(json.dumps(result, ensure_ascii=<span class="hljs-literal">False</span>))<br><br><span class="hljs-meta">    @tornado.concurrent.run_on_executor</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">function</span>(<span class="hljs-params">self, text</span>):<br>        <span class="hljs-keyword">try</span>:<br>            text = text.replace(<span class="hljs-string">&#x27; &#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br>            x = [_ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> text]<br><br>            <span class="hljs-comment"># Pre-processor data</span><br>            processor = utils.load_processor(model_path=<span class="hljs-string">&#x27;saved_model/time_entity/1&#x27;</span>)<br>            tensor = processor.process_x_dataset([x])<br><br>            <span class="hljs-comment"># only for bert Embedding</span><br>            tensor = [&#123;<br>                <span class="hljs-string">&quot;Input-Token:0&quot;</span>: i.tolist(),<br>                <span class="hljs-string">&quot;Input-Segment:0&quot;</span>: np.zeros(i.shape).tolist()<br>            &#125; <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tensor]<br><br>            <span class="hljs-comment"># predict</span><br>            r = requests.post(<span class="hljs-string">&quot;http://localhost:8501/v1/models/time_entity:predict&quot;</span>, json=&#123;<span class="hljs-string">&quot;instances&quot;</span>: tensor&#125;)<br>            preds = r.json()[<span class="hljs-string">&#x27;predictions&#x27;</span>]<br><br>            <span class="hljs-comment"># Convert result back to labels</span><br>            labels = processor.reverse_numerize_label_sequences(np.array(preds).argmax(-<span class="hljs-number">1</span>))<br><br>            entities = get_predict(<span class="hljs-string">&#x27;TIME&#x27;</span>, text, labels[<span class="hljs-number">0</span>])<br><br>            <span class="hljs-keyword">return</span> entities<br><br>        <span class="hljs-keyword">except</span> Exception:<br>            self.write(traceback.format_exc().replace(<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27;&lt;br&gt;&#x27;</span>))<br><br><br><span class="hljs-comment"># get请求</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">HelloHandler</span>(tornado.web.RequestHandler):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get</span>(<span class="hljs-params">self</span>):<br>        self.write(<span class="hljs-string">&#x27;Hello from lmj from Daxing Beijing!&#x27;</span>)<br><br><br><span class="hljs-comment"># 主函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-comment"># 开启tornado服务</span><br>    tornado.options.parse_command_line()<br>    <span class="hljs-comment"># 定义app</span><br>    app = tornado.web.Application(<br>            handlers=[(<span class="hljs-string">r&#x27;/model_predict&#x27;</span>, ModelPredictHandler),<br>                      (<span class="hljs-string">r&#x27;/hello&#x27;</span>, HelloHandler),<br>                      ], <span class="hljs-comment">#网页路径控制</span><br>          )<br>    http_server = tornado.httpserver.HTTPServer(app)<br>    http_server.listen(options.port)<br>    tornado.ioloop.IOLoop.instance().start()<br><br>main()<br></code></pre></td></tr></table></figure><p>我们定义了tornado封装HTTP服务来进行模型预测，运行该脚本，启动模型预测的HTTP服务。接着我们再使用Python脚本才测试下模型的预测效果以及预测时间，预测的代码脚本的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> requests<br><br>t1 = time.time()<br>texts = [<span class="hljs-string">&#x27;记者从国家发展改革委、商务部相关方面获悉，日前美方已决定对拟于10月1日实施的中国输美商品加征关税措施做出调整，中方支持相关企业从即日起按照市场化原则和WTO规则，自美采购一定数量大豆、猪肉等农产品，国务院关税税则委员会将对上述采购予以加征关税排除。&#x27;</span>,<br>         <span class="hljs-string">&#x27;据印度Zee新闻网站12日报道，亚洲新闻国际通讯社援引印度军方消息人士的话说，9月11日的对峙事件发生在靠近班公错北岸的实际控制线一带。&#x27;</span>,<br>         <span class="hljs-string">&#x27;儋州市决定，从9月开始，对城市低保、农村低保、特困供养人员、优抚对象、领取失业保险金人员、建档立卡未脱贫人口等低收入群体共3万多人，发放猪肉价格补贴，每人每月发放不低于100元补贴，以后发放标准，将根据猪肉价波动情况进行动态调整。&#x27;</span>,<br>         <span class="hljs-string">&#x27;9月11日，华为心声社区发布美国经济学家托马斯.弗里德曼在《纽约时报》上的专栏内容，弗里德曼透露，在与华为创始人任正非最近一次采访中，任正非表示华为愿意与美国司法部展开话题不设限的讨论。&#x27;</span>,<br>         <span class="hljs-string">&#x27;造血干细胞移植治疗白血病技术已日益成熟，然而，通过该方法同时治愈艾滋病目前还是一道全球尚在攻克的难题。&#x27;</span>,<br>         <span class="hljs-string">&#x27;英国航空事故调查局（AAIB）近日披露，今年2月6日一趟由德国法兰克福飞往墨西哥坎昆的航班上，因飞行员打翻咖啡使操作面板冒烟，导致飞机折返迫降爱尔兰。&#x27;</span>,<br>         <span class="hljs-string">&#x27;当地时间周四（9月12日），印度尼西亚财政部长英卓华（Sri Mulyani Indrawati）明确表示：特朗普的推特是风险之一。&#x27;</span>,<br>         <span class="hljs-string">&#x27;华中科技大学9月12日通过其官方网站发布通报称，9月2日，我校一硕士研究生不幸坠楼身亡。&#x27;</span>,<br>         <span class="hljs-string">&#x27;微博用户@ooooviki 9月12日下午公布发生在自己身上的惊悚遭遇：一个自称网警、名叫郑洋的人利用职务之便，查到她的完备的个人信息，包括但不限于身份证号、家庭地址、电话号码、户籍变动情况等，要求她做他女朋友。&#x27;</span>,<br>         <span class="hljs-string">&#x27;今天，贵阳取消了汽车限购，成为目前全国实行限购政策的9个省市中，首个取消限购的城市。&#x27;</span>,<br>         <span class="hljs-string">&#x27;据悉，与全球同步，中国区此次将于9月13日于iPhone官方渠道和京东正式开启预售，京东成Apple中国区唯一官方授权预售渠道。&#x27;</span>,<br>         <span class="hljs-string">&#x27;根据央行公布的数据，截至2019年6月末，存款类金融机构住户部门短期消费贷款规模为9.11万亿元，2019年上半年该项净增3293.19亿元，上半年增量看起来并不乐观。&#x27;</span>,<br>         <span class="hljs-string">&#x27;9月11日，一段拍摄浙江万里学院学生食堂的视频走红网络，视频显示该学校食堂不仅在用餐区域设置了可以看电影、比赛的大屏幕，还推出了“一人食”餐位。&#x27;</span>,<br>         <span class="hljs-string">&#x27;当日，在北京举行的2019年国际篮联篮球世界杯半决赛中，西班牙队对阵澳大利亚队。&#x27;</span>,<br>         ]<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(texts))<br><br><span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts:<br>    url = <span class="hljs-string">&#x27;http://localhost:16016/model_predict?text=%s&#x27;</span> % text<br>    req = requests.get(url)<br>    <span class="hljs-built_in">print</span>(json.loads(req.content))<br><br>t2 = time.time()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">round</span>(t2-t1, <span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><p>运行该代码，输出的结果如下：（预测文本中的时间）</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs prolog">一共预测<span class="hljs-number">14</span>个句子。<br>[<span class="hljs-string">&#x27;日前&#x27;</span>, <span class="hljs-string">&#x27;10月1日&#x27;</span>, <span class="hljs-string">&#x27;即日&#x27;</span>]<br>[<span class="hljs-string">&#x27;12日&#x27;</span>, <span class="hljs-string">&#x27;9月11日&#x27;</span>]<br>[<span class="hljs-string">&#x27;9月&#x27;</span>]<br>[<span class="hljs-string">&#x27;9月11日&#x27;</span>]<br>[]<br>[<span class="hljs-string">&#x27;近日&#x27;</span>, <span class="hljs-string">&#x27;今年2月6日&#x27;</span>]<br>[<span class="hljs-string">&#x27;当地时间周四（9月12日）&#x27;</span>]<br>[<span class="hljs-string">&#x27;9月12日&#x27;</span>, <span class="hljs-string">&#x27;9月2日&#x27;</span>]<br>[<span class="hljs-string">&#x27;9月12日下午&#x27;</span>]<br>[<span class="hljs-string">&#x27;今天&#x27;</span>, <span class="hljs-string">&#x27;目前&#x27;</span>]<br>[<span class="hljs-string">&#x27;9月13日&#x27;</span>]<br>[<span class="hljs-string">&#x27;2019年6月末&#x27;</span>, <span class="hljs-string">&#x27;2019年上半年&#x27;</span>, <span class="hljs-string">&#x27;上半年&#x27;</span>]<br>[<span class="hljs-string">&#x27;9月11日&#x27;</span>]<br>[<span class="hljs-string">&#x27;当日&#x27;</span>, <span class="hljs-string">&#x27;2019年&#x27;</span>]<br>预测耗时: <span class="hljs-number">15.1085</span>s.<br></code></pre></td></tr></table></figure><p>模型预测的效果还是不错的，但平均每句话的预测时间为1秒多，模型预测时间还是稍微偏长，后续笔者将会研究如何缩短模型预测的时间。</p><h3 id="总结">总结</h3><p>本项目主要是介绍了如何利用tensorflow-serving部署kashgari模型，该项目已经上传至github，地址为：<ahref="https://github.com/percent4/tensorflow-serving_4_kashgari">https://github.com/percent4/tensorflow-serving_4_kashgari</a>。</p><p>至于如何缩短模型预测的时间，笔者还需要再继续研究，欢迎大家关注～</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（十六）轻松上手文本分类</title>
    <link href="/NLP%EF%BC%88%E5%8D%81%E5%85%AD%EF%BC%89%E8%BD%BB%E6%9D%BE%E4%B8%8A%E6%89%8B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    <url>/NLP%EF%BC%88%E5%8D%81%E5%85%AD%EF%BC%89%E8%BD%BB%E6%9D%BE%E4%B8%8A%E6%89%8B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="背景介绍">背景介绍</h3><p>文本分类是NLP中的常见的重要任务之一，它的主要功能就是将输入的文本以及文本的类别训练出一个模型，使之具有一定的泛化能力，能够对新文本进行较好地预测。它的应用很广泛，在很多领域发挥着重要作用，例如垃圾邮件过滤、舆情分析以及新闻分类等。</p><p>现阶段的文本分类模型频出，种类繁多，花样百变，既有机器学习中的朴素贝叶斯模型、SVM等，也有深度学习中的各种模型，比如经典的CNN,RNN，以及它们的变形，如CNN-LSTM，还有各种高大上的Attention模型。</p><p>无疑，文本分类是一个相对比较成熟的任务，我们尽可以选择自己喜欢的模型来完成该任务。本文以kashgari-tf为例，它能够支持各种文本分类模型，比如BiLSTM，CNN_LSTM，AVCNN等，且对预训练模型，比如BERT的支持较好，它能让我们轻松地完成文本分类任务。</p><p>下面，让我们一起走进文本分类的世界，分分钟搞定textclassification！</p><h3 id="项目">项目</h3><p>首先，我们需要找一份数据作为例子。我们选择THUCNews，THUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19GB），均为UTF-8纯文本格式。我们在原始新浪新闻分类体系的基础上，从中选择10个候选分类类别：体育、娱乐、家居、房产、教育、时尚、时政、游戏、科技、财经。</p><p>数据总量一共为6.5万条，其中训练集数据5万条，每个类别5000条，验证集数据0.5万条，每个类别500条，测试集数据1万条，每个类别1000条。笔者已将数据放在Github上，读者可以在最后的总结中找到。</p><p>项目结构，如下图：</p><p><img src="/img/nlp16_1.png" /></p><p>接着，我们尝试着利用kashgari-tf来训练一个文本分类模型，其中模型我们采用CNN-LSTM，完整的Python代码（text_classification_model_train.py）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># time: 2019-08-13 11:16</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><br><span class="hljs-keyword">from</span> kashgari.tasks.classification <span class="hljs-keyword">import</span> CNN_LSTM_Model<br><br><span class="hljs-comment"># 获取数据集</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">data_type</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./data/cnews.%s.txt&#x27;</span> % data_type, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        content = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines() <span class="hljs-keyword">if</span> _.strip()]<br><br>    x, y = [], []<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> content:<br>        label, text = line.split(maxsplit=<span class="hljs-number">1</span>)<br>        y.append(label)<br>        x.append([_ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> text])<br><br>    <span class="hljs-keyword">return</span> x, y<br><br><span class="hljs-comment"># 获取数据</span><br>train_x, train_y = load_data(<span class="hljs-string">&#x27;train&#x27;</span>)<br>valid_x, valid_y = load_data(<span class="hljs-string">&#x27;val&#x27;</span>)<br>test_x, test_y = load_data(<span class="hljs-string">&#x27;test&#x27;</span>)<br><br><span class="hljs-comment"># 训练模型</span><br>model = CNN_LSTM_Model()<br>model.fit(train_x, train_y, valid_x, valid_y, batch_size=<span class="hljs-number">16</span>, epochs=<span class="hljs-number">5</span>)<br><br><span class="hljs-comment"># 评估模型</span><br>model.evaluate(test_x, test_y)<br><br><span class="hljs-comment"># 保存模型</span><br>model.save(<span class="hljs-string">&#x27;text_classification_model&#x27;</span>)<br></code></pre></td></tr></table></figure><p>输出的模型结果如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_<br><span class="hljs-section">Layer (type)                 Output Shape              Param #</span><br><span class="hljs-section">=================================================================</span><br>input (InputLayer)           (None, 2544)              0<br><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_<br>layer<span class="hljs-emphasis">_embedding (Embedding)  (None, 2544, 100)         553200</span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span><br>conv1d (Conv1D)              (None, 2544, 32)          9632<br><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_<br>max<span class="hljs-emphasis">_pooling1d (MaxPooling1D) (None, 1272, 32)          0</span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span><br>cu<span class="hljs-emphasis">_dnnlstm (CuDNNLSTM)       (None, 100)               53600</span><br><span class="hljs-emphasis"><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span><span class="hljs-strong">____</span>_</span><br><span class="hljs-section">dense (Dense)                (None, 10)                1010</span><br><span class="hljs-section">=================================================================</span><br>Total params: 617,442<br>Trainable params: 617,442<br>Non-trainable params: 0<br></code></pre></td></tr></table></figure><p>设定模型训练次数为5个epoch，batch_size为16。模型训练完后，在训练集、验证集上的结果如下：</p><table><thead><tr class="header"><th>数据集</th><th>accuracy</th><th>loss</th></tr></thead><tbody><tr class="odd"><td>训练集</td><td>0.9661</td><td>0.1184</td></tr><tr class="even"><td>验证集</td><td>0.9204</td><td>0.2567</td></tr></tbody></table><p>在测试集上的结果如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs yaml">             <span class="hljs-string">precision</span>    <span class="hljs-string">recall</span>  <span class="hljs-string">f1-score</span>   <span class="hljs-string">support</span><br><br>          <span class="hljs-string">体育</span>     <span class="hljs-number">0.9852</span>    <span class="hljs-number">0.9970</span>    <span class="hljs-number">0.9911</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">娱乐</span>     <span class="hljs-number">0.9938</span>    <span class="hljs-number">0.9690</span>    <span class="hljs-number">0.9813</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">家居</span>     <span class="hljs-number">0.9384</span>    <span class="hljs-number">0.8830</span>    <span class="hljs-number">0.9098</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">房产</span>     <span class="hljs-number">0.9490</span>    <span class="hljs-number">0.9680</span>    <span class="hljs-number">0.9584</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">教育</span>     <span class="hljs-number">0.9650</span>    <span class="hljs-number">0.8820</span>    <span class="hljs-number">0.9216</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">时尚</span>     <span class="hljs-number">0.9418</span>    <span class="hljs-number">0.9710</span>    <span class="hljs-number">0.9562</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">时政</span>     <span class="hljs-number">0.9732</span>    <span class="hljs-number">0.9450</span>    <span class="hljs-number">0.9589</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">游戏</span>     <span class="hljs-number">0.9454</span>    <span class="hljs-number">0.9700</span>    <span class="hljs-number">0.9576</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">科技</span>     <span class="hljs-number">0.8910</span>    <span class="hljs-number">0.9560</span>    <span class="hljs-number">0.9223</span>      <span class="hljs-number">1000</span><br>          <span class="hljs-string">财经</span>     <span class="hljs-number">0.9566</span>    <span class="hljs-number">0.9920</span>    <span class="hljs-number">0.9740</span>      <span class="hljs-number">1000</span><br><br>    <span class="hljs-string">accuracy</span>                         <span class="hljs-number">0.9533</span>     <span class="hljs-number">10000</span><br>   <span class="hljs-string">macro</span> <span class="hljs-string">avg</span>     <span class="hljs-number">0.9539</span>    <span class="hljs-number">0.9533</span>    <span class="hljs-number">0.9531</span>     <span class="hljs-number">10000</span><br><span class="hljs-string">weighted</span> <span class="hljs-string">avg</span>     <span class="hljs-number">0.9539</span>    <span class="hljs-number">0.9533</span>    <span class="hljs-number">0.9531</span>     <span class="hljs-number">10000</span><br></code></pre></td></tr></table></figure><p>总的来说，上述模型训练的效果还是很不错的。接下来，是考验模型的预测能力的时刻了，看看它是否具体文本分类的泛化能力。</p><h3 id="测试">测试</h3><p>我们已经有了训练好的模型<code>text_classification_model</code>，接着让我们利用该模型来对新的数据进行预测，预测的代码（model_predict.py）如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># time: 2019-08-14 00:21</span><br><span class="hljs-comment"># place: Pudong Shanghai</span><br><br><span class="hljs-keyword">import</span> kashgari<br><br><span class="hljs-comment"># 加载模型</span><br>loaded_model = kashgari.utils.load_model(<span class="hljs-string">&#x27;text_classification_model&#x27;</span>)<br><br>text = <span class="hljs-string">&#x27;华夏幸福成立于 1998 年，前身为廊坊市华夏房地产开发有限公司，初始注册资本 200 万元，其中王文学出资 160 万元，廊坊市融通物资贸易有限公司出资 40 万元，后经多次股权转让和增资，公司于 2007 年整体改制为股份制公司，2011 年完成借壳上市。&#x27;</span><br><br>x = [[_ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> text]]<br><br>label = loaded_model.predict(x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;预测分类:%s&#x27;</span> % label)<br></code></pre></td></tr></table></figure><p>以下是测试结果：</p><blockquote><p>原文1: 华夏幸福成立于 1998年，前身为廊坊市华夏房地产开发有限公司，初始注册资本 200万元，其中王文学出资 160 万元，廊坊市融通物资贸易有限公司出资 40万元，后经多次股权转让和增资，公司于 2007 年整体改制为股份制公司，2011年完成借壳上市。 分类结果：预测分类:['财经']</p></blockquote><blockquote><p>原文2:现今常见的短袖衬衫大致上可以分为：夏威夷衬衫、古巴衬衫、保龄球衫，三者之间虽有些微分别，但其实有些时候，一件衬衫也可能包含了多种款式的特色。而‘古巴（领）衬衫’最显而易见的特点在于‘领口’，通常会设计为V领，且呈现微微的外翻，也因此缺少衬衫领口常见的‘第一颗钮扣’，衣服到领子的剪裁为一体成形，整体较宽松舒适。分类结果：预测分类:['时尚']</p></blockquote><blockquote><p>原文3:周琦2014年加盟新疆广汇篮球俱乐部，当年就代表俱乐部青年队接连拿下全国篮球青年联赛冠军和全国俱乐部青年联赛冠军。升入一队后，周琦2016年随队出战第25届亚冠杯，获得冠军。2016-2017赛季，周琦为新疆广汇队夺得队史首座总冠军奖杯立下汗马功劳，他在总决赛中带伤出战，更是传为佳话。分类结果：预测分类:['体育']</p></blockquote><blockquote><p>原文4:周杰伦[微博]监制赛车电影《叱咤风云》13日释出花絮导演篇，不仅真实赛车竞速画面大量曝光，几十辆百万赛车在国际专业赛道、山路飙速，场面浩大震撼，更揭开不少现场拍摄的幕后画面。监制周杰伦在现场与导演讨论剧本、范逸臣[微博]与高英轩大打出手、甚至有眼尖网友发现在花絮中闪过“男神”李玉玺[微博]的画面。分类结果：预测分类:['娱乐']</p></blockquote><blockquote><p>原文5:北京时间8月13日上午消息，据《韩国先驱报》网站报道，近日美国知识产权所有者协会（Intellectual Property Owners Association）发布的一份报告显示，在获得的美国专利数量方面，IBM、微软和通用电气等美国企业名列前茅，排在后面的韩国科技巨头三星、LG与之竞争激烈。分类结果：预测分类:['科技']</p></blockquote><h3 id="总结">总结</h3><p>虽然我们上述测试的文本分类效果还不错，但也存在着一些分类错误的情况。</p><p>本文讲述了如何利用kashgari-tf模块来快速地搭建文本分类任务，其实，也没那么难！</p><p>本文代码和数据及已上传至Github, 网址为： <ahref="https://github.com/percent4/cnews_text_classification">https://github.com/percent4/cnews_text_classification</a></p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>Kashgari</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（十五）让模型来告诉你文本中的时间</title>
    <link href="/NLP%EF%BC%88%E5%8D%81%E4%BA%94%EF%BC%89%E8%AE%A9%E6%A8%A1%E5%9E%8B%E6%9D%A5%E5%91%8A%E8%AF%89%E4%BD%A0%E6%96%87%E6%9C%AC%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4/"/>
    <url>/NLP%EF%BC%88%E5%8D%81%E4%BA%94%EF%BC%89%E8%AE%A9%E6%A8%A1%E5%9E%8B%E6%9D%A5%E5%91%8A%E8%AF%89%E4%BD%A0%E6%96%87%E6%9C%AC%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="背景介绍">背景介绍</h3><p>在文章<ahref="https://percent4.github.io/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89%E4%BB%8E%E6%96%87%E6%9C%AC%E4%B8%AD%E6%8F%90%E5%8F%96%E6%97%B6%E9%97%B4/">NLP入门（十一）从文本中提取时间</a>中，笔者演示了如何利用分词、词性标注的方法从文本中获取时间。当时的想法比较简单快捷，只是利用了词性标注这个功能而已，因此，在某些地方，时间的识别效果并不太好。比如以下的两个例子：</p><p>原文1:</p><blockquote><p>苏北大量农村住房建于上世纪80年代之前。去年9月，江苏省决定全面改善苏北农民住房条件，计划3年内改善30万户，作为决胜全面建成小康社会补短板的重要举措。</p></blockquote><p>用笔者之前的代码，提取的时间结果为：</p><blockquote><p>提取时间： ['去年9月']</p></blockquote><p>但实际上，我们提取的时间应该是：</p><blockquote><p>上世纪80年代之前， 去年9月，3年内</p></blockquote><p>原文2:</p><blockquote><p>南宋绍兴十年，金分兵两路向陕西和河南大举进攻，在很快夺回了河南、陕西之后，又率大军向淮南大举进攻。</p></blockquote><p>用笔者之前的代码，提取的时间结果为：</p><blockquote><p>提取时间： ['南宋']</p></blockquote><p>但实际上，我们提取的时间应该是：</p><blockquote><p>南宋绍兴十年</p></blockquote><p>因此，利用简单的词性标注功能来提取文本中的时间会存在漏提、错提的情况，鉴于此，笔者想到能否用深度学习模型来实现文本中的时间提取呢？</p><p>该功能类似于命名实体识别（NER）功能，只不过NER是识别文本中的人名、地名、组织机构名，而我们这次需要识别文本中的时间。但是，它们背后的算法原理都是一样的，即采用序列标注模型来解决。</p><h3 id="项目">项目</h3><p>在文章<ahref="https://percent4.github.io/NLP%EF%BC%88%E5%8D%81%E5%9B%9B%EF%BC%89%E8%87%AA%E5%88%B6%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E5%B9%B3%E5%8F%B0/">NLP（十四）自制序列标注平台</a>中，笔者提出了一种自制的序列标注平台，利用该标注平台，笔者从新闻网站中标注了大约2000份语料，标注出文本中的时间，其中75%作为训练集（time.train文件），10%作为验证集（time.dev文件），15%作为测试集（time.test文件）。</p><p>虽然我们现在已经有了深度学习框架方便我们来训练模型，比如TensorFlow,Keras,PyTorch等，但目前已有某大神开源了一个序列标注和文本分类的模块，名称为kashgari-tf，它能够方便快速地用几行命令就可以训练一个序列标注或文本分类的模型，容易上手，而且集中了多种模型（BiGRU，CNN，BiLSTM，CRF）以及多种预训练模型（BERT，ERNIE，wwm-ext），对于用户来说算是十分友好了。该模块的参考网址为：<ahref="https://kashgari.bmio.net/">https://kashgari.bmio.net/</a> 。</p><p>笔者自己花了几天的时间来标注数据，目前已累计标注2000+数据，后续将放到Github供大家参考。我们训练的数据，比如time.train的前几行如下：（每一行中间用空格隔开）</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs mathematica"><span class="hljs-number">1</span> <span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br><span class="hljs-number">6</span> <span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br><span class="hljs-number">0</span> <span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br><span class="hljs-number">9</span> <span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br>年 <span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br>， <span class="hljs-built_in">O</span><br>日 <span class="hljs-built_in">O</span><br>本 <span class="hljs-built_in">O</span><br>萨 <span class="hljs-built_in">O</span><br>摩 <span class="hljs-built_in">O</span><br>藩 <span class="hljs-built_in">O</span><br>入 <span class="hljs-built_in">O</span><br>侵 <span class="hljs-built_in">O</span><br>琉 <span class="hljs-built_in">O</span><br>球 <span class="hljs-built_in">O</span><br>国 <span class="hljs-built_in">O</span><br>， <span class="hljs-built_in">O</span><br>并 <span class="hljs-built_in">O</span><br>在 <span class="hljs-built_in">O</span><br>一 <span class="hljs-built_in">O</span><br>个 <span class="hljs-built_in">O</span><br>时 <span class="hljs-built_in">O</span><br>期 <span class="hljs-built_in">O</span><br>内 <span class="hljs-built_in">O</span><br>控 <span class="hljs-built_in">O</span><br>制 <span class="hljs-built_in">O</span><br>琉 <span class="hljs-built_in">O</span><br>球 <span class="hljs-built_in">O</span><br>国 <span class="hljs-built_in">O</span><br><span class="hljs-operator">...</span><br></code></pre></td></tr></table></figure><p>接着是模型这块，我们采用经典的BERT+Bi-LSTM+CRF模型，训练1个epoch，batch_size为16，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># time: 2019-08-09 16:47</span><br><span class="hljs-comment"># place: Zhichunlu Beijing</span><br><br><span class="hljs-keyword">import</span> kashgari<br><span class="hljs-keyword">from</span> kashgari.corpus <span class="hljs-keyword">import</span> DataReader<br><span class="hljs-keyword">from</span> kashgari.embeddings <span class="hljs-keyword">import</span> BERTEmbedding<br><span class="hljs-keyword">from</span> kashgari.tasks.labeling <span class="hljs-keyword">import</span> BiLSTM_CRF_Model<br><br>train_x, train_y = DataReader().read_conll_format_file(<span class="hljs-string">&#x27;./data/time.train&#x27;</span>)<br>valid_x, valid_y = DataReader().read_conll_format_file(<span class="hljs-string">&#x27;./data/time.dev&#x27;</span>)<br>test_x, test_y = DataReader().read_conll_format_file(<span class="hljs-string">&#x27;./data/time.test&#x27;</span>)<br><br>bert_embedding = BERTEmbedding(<span class="hljs-string">&#x27;chinese_L-12_H-768_A-12&#x27;</span>,<br>                               task=kashgari.LABELING,<br>                               sequence_length=<span class="hljs-number">128</span>)<br><br>model = BiLSTM_CRF_Model(bert_embedding)<br>model.fit(train_x, train_y, valid_x, valid_y, batch_size=<span class="hljs-number">16</span>, epochs=<span class="hljs-number">1</span>)<br><br>model.save(<span class="hljs-string">&#x27;time_ner.h5&#x27;</span>)<br><br>model.evaluate(test_x, test_y)<br></code></pre></td></tr></table></figure><p>模型训练完后，得到的效果如下：</p><table><thead><tr class="header"><th>数据集</th><th>accuracy</th><th>loss</th></tr></thead><tbody><tr class="odd"><td>训练集</td><td>0.9814</td><td>6.7295</td></tr><tr class="even"><td>验证集</td><td>0.6868</td><td>150.8513</td></tr></tbody></table><p>在测试集上的结果如下：</p><table><thead><tr class="header"><th>数据集</th><th>precision</th><th>recall</th><th>f1</th></tr></thead><tbody><tr class="odd"><td>测试集</td><td>0.8547</td><td>0.8934</td><td>0.8736</td></tr></tbody></table><p>由于是小标注量，因此我们选择了用BERT预训练模型。如果不采用BERT预训练模型，在同样的数据集上，即使训练100个epoch，虽然在训练集上的准确率超过95%，但是在测试集上却只有大约50%的准确率，效果不行，因此，需要采用预训练模型。</p><h3 id="测试效果">测试效果</h3><p>在训练完模型后，会在当前目录下生成time_ner.h5模型文件，接着我们需要该模型文件来对新的文件进行预测，提取出文本中的时间。模型预测的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Load saved model</span><br><span class="hljs-keyword">import</span> kashgari<br><br>loaded_model = kashgari.utils.load_model(<span class="hljs-string">&#x27;time_ner.h5&#x27;</span>)<br><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    text = <span class="hljs-built_in">input</span>(<span class="hljs-string">&#x27;sentence: &#x27;</span>)<br>    t = loaded_model.predict([[char <span class="hljs-keyword">for</span> char <span class="hljs-keyword">in</span> text]])<br>    <span class="hljs-built_in">print</span>(t)<br></code></pre></td></tr></table></figure><p>接着我们在几条新的数据上进行预测，看看该模型的表现效果：</p><blockquote><p>"原文":"绿地控股2018年年度年报显示，截至2018年12月31日，万科金域中央项目的经营状态为“住宅、办公、商业”，项目用地面积18.90万平方米，规划计容建筑面积79.38万平方米，总建筑面积为105.78万平方米，已竣工面积32.90万平方米，总投资额95亿元，报告期实际投资额为10.18亿元。","预测时间": [ "2018年年度", "2018年12月31日"]</p></blockquote><blockquote><p>"原文":"经过工作人员两天的反复验证、严密测算，记者昨天从上海中心大厦得到确认：被誉为上海中心大厦“定楼神器”的阻尼器，在8月10日出现自2016年正式启用以来的最大摆幅。","预测时间": [ "两天", "昨天", "8月10日", "2016年"]</p></blockquote><blockquote><p>"原文": "不幸的是，在升任内史的同年九月，狄仁杰就在洛阳私宅离世。","预测时间": [ "同年九月"]</p></blockquote><blockquote><p>"原文":"早上9点25分到达北京火车站，火车站在北京市区哦，地铁很方便到达酒店，我们定了王府井大街的锦江之星，409元一晚，有点小贵。下午去了天坛公园，傍晚去了天安门广场。","预测时间": [ "早上9点25分", "下午", "傍晚"],</p></blockquote><h3 id="总结">总结</h3><p>利用深度学习模型，在小标注量数据上，我们对时间识别取得了不错的效果。后续如果我们想要提高时间识别的准确率，可以再多增加标注数据，目前还只有2000+数据～</p><p>本项目已经开源，Github的地址为：<ahref="https://github.com/percent4/Chinese_Time_Recogniztion">https://github.com/percent4/Chinese_Time_Recogniztion</a>。</p><p>另外，强烈推荐kashgari-tf模块，它能够让你在几分钟内搭建一个序列标注模型，而且方便加载各种预训练模型。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（十四）自制序列标注平台</title>
    <link href="/NLP%EF%BC%88%E5%8D%81%E5%9B%9B%EF%BC%89%E8%87%AA%E5%88%B6%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E5%B9%B3%E5%8F%B0/"/>
    <url>/NLP%EF%BC%88%E5%8D%81%E5%9B%9B%EF%BC%89%E8%87%AA%E5%88%B6%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E5%B9%B3%E5%8F%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="背景介绍">背景介绍</h3><p>在平时的NLP任务中，我们经常用到命名实体识别（NER），常用的识别实体类型为人名、地名、组织机构名，但是我们往往也会有识别其它实体的需求，比如时间、品牌名等。在利用算法做实体识别的时候，我们一般采用序列标注算法，这就对标注的文本格式有一定的要求，因此，一个好的序列标注的平台必不可少，将会大大减少我们标注的工作量，有效提升算法的更新迭代速度。</p><p>本文将介绍笔者的一个工作：自制的序列标注平台。我们以时间识别为例。比如，在下面的文章中：</p><blockquote><p>按计划，2019年8月10日，荣耀智慧屏将在华为开发者大会上正式亮相，在8月6日，荣耀官微表示该产品的预约量已破十万台，8月7日下午，荣耀总裁赵明又在微博上造势率先打出差异化牌，智慧屏没有开关机广告，并表态以后也不会有，消费者体验至上，营销一波接一波，可谓来势汹汹。</p></blockquote><p>我们需要从该文章中标注出三个时间：<code>2019年8月10日</code>，<code>8月6日</code>，<code>8月7日下午</code>，并形成标注序列。</p><p>下面将详细介绍笔者的工作。</p><h3 id="序列标注平台">序列标注平台</h3><p>由于开发时间仓促以及笔者能力有限，因此，序列标注平台的功能还没有很完善，希望笔者的工作能抛砖引玉。</p><p>项目的结构图如下：</p><p><img src="/img/nlp14_1.png" /></p><p>templates中存放静态资源，time_index.html为平台的操作界面，time_output为平台标注完实体后的文件保存路径，time_server.py是用tornado写的服务端路径控制代码，utils.py中是获取某个路径下的txt文件的最大数值的函数。</p><p>其中，utils.py的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># time: 2019-03-14</span><br><span class="hljs-comment"># place: Xinbeiqiao, Beijing</span><br><br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># 获取当前所在目录的txt文本的最大数值</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_max_num</span>(<span class="hljs-params">path</span>):<br>    files = os.listdir(path)<br>    <span class="hljs-keyword">if</span> files:<br>        numbers = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x.replace(<span class="hljs-string">&#x27;.txt&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)), files))<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(numbers)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>time_server.py的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># time: 2019-08-08</span><br><span class="hljs-comment"># place: Xinbeiqiao, Beijing</span><br><br><span class="hljs-keyword">import</span> os.path<br><span class="hljs-keyword">import</span> tornado.httpserver<br><span class="hljs-keyword">import</span> tornado.ioloop<br><span class="hljs-keyword">import</span> tornado.options<br><span class="hljs-keyword">import</span> tornado.web<br><span class="hljs-keyword">from</span> tornado.options <span class="hljs-keyword">import</span> define, options<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> get_max_num<br><br><span class="hljs-comment">#定义端口为9005</span><br>define(<span class="hljs-string">&quot;port&quot;</span>, default=<span class="hljs-number">9005</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;run on the given port&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>)<br><br><span class="hljs-comment"># GET请求</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">QueryHandler</span>(tornado.web.RequestHandler):<br>    <span class="hljs-comment"># get函数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get</span>(<span class="hljs-params">self</span>):<br>        self.render(<span class="hljs-string">&#x27;time_index.html&#x27;</span>, data = [<span class="hljs-string">&#x27;&#x27;</span>, []])<br><br><span class="hljs-comment"># POST请求</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PostHandler</span>(tornado.web.RequestHandler):<br>    <span class="hljs-comment"># post函数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">post</span>(<span class="hljs-params">self</span>):<br><br>        <span class="hljs-comment"># 获取前端参数, event, time, index</span><br>        event = self.get_argument(<span class="hljs-string">&#x27;event&#x27;</span>)<br>        times = self.get_arguments(<span class="hljs-string">&#x27;time&#x27;</span>)<br>        indices = self.get_arguments(<span class="hljs-string">&#x27;index&#x27;</span>)<br>        <span class="hljs-built_in">print</span>(event)<br>        <span class="hljs-built_in">print</span>(times)<br>        <span class="hljs-built_in">print</span>(indices)<br><br>        <span class="hljs-comment"># 前端显示序列标注信息</span><br>        tags = [<span class="hljs-string">&#x27;O&#x27;</span>] * <span class="hljs-built_in">len</span>(event)<br><br>        <span class="hljs-keyword">for</span> time, index <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(times, indices):<br>            index = <span class="hljs-built_in">int</span>(index)<br>            tags[index] = <span class="hljs-string">&#x27;B-TIME&#x27;</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(time)):<br>                tags[index+i] = <span class="hljs-string">&#x27;I-TIME&#x27;</span><br><br>        data = [event, tags]<br><br>        self.render(<span class="hljs-string">&#x27;time_index.html&#x27;</span>, data=data)<br><br>        <span class="hljs-comment"># 保存为txt文件</span><br>        dir_path = <span class="hljs-string">&#x27;./time_output&#x27;</span><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./%s/%s.txt&#x27;</span> % (dir_path, get_max_num(dir_path)+<span class="hljs-number">1</span>), <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">for</span> char, tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(event, tags):<br>                f.write(char+<span class="hljs-string">&#x27;\t&#x27;</span>+tag+<span class="hljs-string">&#x27;\n&#x27;</span>)<br><br><br><span class="hljs-comment"># 主函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-comment"># 开启tornado服务</span><br>    tornado.options.parse_command_line()<br>    <span class="hljs-comment"># 定义app</span><br>    app = tornado.web.Application(<br>            handlers=[(<span class="hljs-string">r&#x27;/query&#x27;</span>, QueryHandler),<br>                      (<span class="hljs-string">r&#x27;/result&#x27;</span>, PostHandler)<br>                      ], <span class="hljs-comment">#网页路径控制</span><br>            template_path=os.path.join(os.path.dirname(__file__), <span class="hljs-string">&quot;templates&quot;</span>) <span class="hljs-comment"># 模板路径</span><br>          )<br>    http_server = tornado.httpserver.HTTPServer(app)<br>    http_server.listen(options.port)<br>    tornado.ioloop.IOLoop.instance().start()<br><br>main()<br></code></pre></td></tr></table></figure><p>time_index.html文件如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-keyword">html</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">html</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">charset</span>=<span class="hljs-string">&quot;utf-8&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>时间抽取标注平台<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">&quot;stylesheet&quot;</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://cdn.staticfile.org/twitter-bootstrap/3.3.7/js/bootstrap.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">style</span>&gt;</span><span class="language-css"></span><br><span class="language-css">        <span class="hljs-selector-tag">mark</span> &#123;</span><br><span class="language-css">            <span class="hljs-attribute">background-color</span>:<span class="hljs-number">#00ff90</span>; <span class="hljs-attribute">font-weight</span>:bold;</span><br><span class="language-css">        &#125;</span><br><span class="language-css"><span class="hljs-selector-tag">p</span>&#123;<span class="hljs-attribute">text-indent</span>:<span class="hljs-number">2em</span>;&#125;</span><br><span class="language-css">    </span><span class="hljs-tag">&lt;/<span class="hljs-name">style</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="language-javascript"></span><br><span class="language-javascript">        <span class="hljs-keyword">var</span> click_cnt = <span class="hljs-number">0</span>;</span><br><span class="language-javascript"></span><br><span class="language-javascript">        <span class="hljs-comment">// 双击第i个select, 添加文字的index</span></span><br><span class="language-javascript">        <span class="hljs-keyword">function</span> <span class="hljs-title function_">select_click</span>(<span class="hljs-params">i</span>)&#123;</span><br><span class="language-javascript">        <span class="hljs-keyword">var</span> content = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;event&#x27;</span>).<span class="hljs-property">value</span>;</span><br><span class="language-javascript">        <span class="hljs-keyword">var</span> time = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;time_&#x27;</span>+i.<span class="hljs-title function_">toString</span>()).<span class="hljs-property">value</span>;</span><br><span class="language-javascript"></span><br><span class="language-javascript">        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> j=<span class="hljs-number">0</span>; j&lt;=content.<span class="hljs-property">length</span>-time.<span class="hljs-property">length</span>; j++)&#123;</span><br><span class="language-javascript">        <span class="hljs-keyword">if</span>(content.<span class="hljs-title function_">substr</span>(j, time.<span class="hljs-property">length</span>) == time)&#123;</span><br><span class="language-javascript">        <span class="hljs-keyword">var</span> select = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;index_&#x27;</span>+i.<span class="hljs-title function_">toString</span>());</span><br><span class="language-javascript">        <span class="hljs-keyword">var</span> option = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">createElement</span>(<span class="hljs-string">&quot;option&quot;</span>);</span><br><span class="language-javascript">        option.<span class="hljs-property">value</span> = j;</span><br><span class="language-javascript">        option.<span class="hljs-property">innerHTML</span> = j;</span><br><span class="language-javascript">        select.<span class="hljs-title function_">appendChild</span>(option);</span><br><span class="language-javascript">        &#125;</span><br><span class="language-javascript">        &#125;</span><br><span class="language-javascript">        &#125;</span><br><span class="language-javascript"></span><br><span class="language-javascript"><span class="hljs-comment">// 添加输入框和select框</span></span><br><span class="language-javascript">        $(<span class="hljs-variable language_">document</span>).<span class="hljs-title function_">ready</span>(<span class="hljs-keyword">function</span>(<span class="hljs-params"></span>)&#123;</span><br><span class="language-javascript"></span><br><span class="language-javascript">            $(<span class="hljs-string">&quot;#add_time&quot;</span>).<span class="hljs-title function_">click</span>(<span class="hljs-keyword">function</span>(<span class="hljs-params"></span>)&#123;</span><br><span class="language-javascript">                 click_cnt = click_cnt + <span class="hljs-number">1</span>;</span><br><span class="language-javascript">                 <span class="hljs-keyword">var</span> input_id = <span class="hljs-keyword">new</span> <span class="hljs-title class_">String</span>(<span class="hljs-string">&#x27;time_&#x27;</span>+click_cnt.<span class="hljs-title function_">toString</span>());</span><br><span class="language-javascript">                 <span class="hljs-keyword">var</span> index_id = <span class="hljs-keyword">new</span> <span class="hljs-title class_">String</span>(<span class="hljs-string">&#x27;index_&#x27;</span>+click_cnt.<span class="hljs-title function_">toString</span>());</span><br><span class="language-javascript">                 <span class="hljs-keyword">var</span> content = <span class="hljs-string">&quot;&lt;input type=&#x27;text&#x27; id=&quot;</span> + input_id + <span class="hljs-string">&quot; class=&#x27;form-control&#x27; style=&#x27;width:306px;&#x27; name=&#x27;time&#x27; /&gt; \</span></span><br><span class="hljs-string"><span class="language-javascript">                     &lt;select class=&#x27;form-control&#x27; name=&#x27;index&#x27; id=&quot;</span>+ index_id + <span class="hljs-string">&quot; style=&#x27;width:120px;&#x27; \</span></span><br><span class="hljs-string"><span class="language-javascript">                 ondblclick=&#x27;select_click(&quot;</span>+click_cnt.<span class="hljs-title function_">toString</span>()+<span class="hljs-string">&quot;)&#x27;&gt;&lt;/select&gt;&quot;</span>;</span><br><span class="language-javascript">                 $(content).<span class="hljs-title function_">appendTo</span>($(<span class="hljs-string">&quot;#time_column&quot;</span>));</span><br><span class="language-javascript">            &#125;);</span><br><span class="language-javascript"></span><br><span class="language-javascript">        &#125;);</span><br><span class="language-javascript"></span><br><span class="language-javascript"></span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">center</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">br</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">br</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">br</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">form</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-horizontal&quot;</span> <span class="hljs-attr">role</span>=<span class="hljs-string">&quot;form&quot;</span> <span class="hljs-attr">method</span>=<span class="hljs-string">&quot;post&quot;</span> <span class="hljs-attr">action</span>=<span class="hljs-string">&quot;/result&quot;</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;width:600px&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">label</span> <span class="hljs-attr">for</span>=<span class="hljs-string">&quot;event&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;col-sm-2 control-label&quot;</span>&gt;</span>输入语料<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;col-sm-10&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">textarea</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;text&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;event&quot;</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;width:490px; height:200px&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;event&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">textarea</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-inline&quot;</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;text-align:left;&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">label</span> <span class="hljs-attr">for</span>=<span class="hljs-string">&quot;time_0&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;col-sm-2 control-label&quot;</span>&gt;</span>时间<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;col-sm-10&quot;</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;time_column&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;text&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;time_0&quot;</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;width:306px;&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;time&quot;</span> /&gt;</span><br>               <br>            <span class="hljs-tag">&lt;<span class="hljs-name">select</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;index_0&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;index&quot;</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;width:120px;&quot;</span> <span class="hljs-attr">ondblclick</span>=<span class="hljs-string">&quot;select_click(0)&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">select</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;col-sm-offset-2 col-sm-10&quot;</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">br</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">button</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;button&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-default&quot;</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;add_time&quot;</span>&gt;</span>添加时间<span class="hljs-tag">&lt;/<span class="hljs-name">button</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">button</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;submit&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-success&quot;</span>&gt;</span>显示标签<span class="hljs-tag">&lt;/<span class="hljs-name">button</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;/query&quot;</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">button</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;button&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-danger&quot;</span>&gt;</span>返回<span class="hljs-tag">&lt;/<span class="hljs-name">button</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">button</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;reset&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-warning&quot;</span>&gt;</span>重置<span class="hljs-tag">&lt;/<span class="hljs-name">button</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br><br><span class="hljs-tag">&lt;/<span class="hljs-name">form</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">br</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;width:600px&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span> 原文：&#123;&#123;data[0]&#125;&#125; <span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">table</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;table table-striped&quot;</span>&gt;</span><br>&#123;% for char, tag in zip(data[0], data[1]) %&#125;<br><span class="hljs-tag">&lt;<span class="hljs-name">tr</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">td</span>&gt;</span>&#123;&#123;char&#125;&#125; <span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">td</span>&gt;</span>&#123;&#123;tag&#125;&#125; <span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">tr</span>&gt;</span><br>&#123;%end%&#125;<br><span class="hljs-tag">&lt;/<span class="hljs-name">table</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">center</span>&gt;</span><br><br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="平台使用">平台使用</h3><p>运行上述time_server.py后，在浏览器端输入网址: <ahref="http://localhost:9005/query">http://localhost:9005/query</a> ,则会显示如下界面：</p><p><img src="/img/nlp14_2.png" /></p><p>在<code>输入语料框</code>中，我们输入语料：</p><blockquote><p>8月8日是“全民健身日”，推出重磅微视频《我们要赢的，是自己》。</p></blockquote><p>在时间这个输入框中，可以标注语料中的时间，同时双击同一行中的下拉列表，就能显示该标注时间在语料中的起始位置，有时候同样的标注时间会在语料中出现多次，那么我们在下拉列表中选择我们需要的标注的起始位置即可。</p><p>点击<code>添加时间</code>按钮，它会增加一行标注，允许我们在同一份预料中标注多个时间。我们的一个简单的标注例子如下：</p><p><img src="/img/nlp14_3.png" /></p><p>点击<code>显示标注</code>，则会显示我们标注完后形成的序列标注信息，同时将该序列信息保存为txt文件，该txt文件位于time_output目录下。在网页上的序列标注信息如下：</p><p><img src="/img/nlp14_4.png" /></p><p>同时，我们也可以查看保存的txt文档信息，如下：</p><p><img src="/img/nlp14_5.png" /></p><p>点击<code>返回</code>按钮，它会允许我们进行下一次的标注。刚才展示的只是一个简单例子，稍微复杂的标注如下图：</p><p><img src="/img/nlp14_6.png" /></p><p>它形成的标注序列(部分)如下：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs mathematica">按<span class="hljs-built_in">O</span><br>计<span class="hljs-built_in">O</span><br>划<span class="hljs-built_in">O</span><br>，<span class="hljs-built_in">O</span><br><span class="hljs-number">2</span><span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br><span class="hljs-number">0</span><span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br><span class="hljs-number">1</span><span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br><span class="hljs-number">9</span><span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br>年<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br><span class="hljs-number">8</span><span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br>月<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br><span class="hljs-number">1</span><span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br><span class="hljs-number">0</span><span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br>日<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br>，<span class="hljs-built_in">O</span><br>荣<span class="hljs-built_in">O</span><br>耀<span class="hljs-built_in">O</span><br>智<span class="hljs-built_in">O</span><br>慧<span class="hljs-built_in">O</span><br>屏<span class="hljs-built_in">O</span><br>将<span class="hljs-built_in">O</span><br>在<span class="hljs-built_in">O</span><br>华<span class="hljs-built_in">O</span><br>为<span class="hljs-built_in">O</span><br>开<span class="hljs-built_in">O</span><br>发<span class="hljs-built_in">O</span><br>者<span class="hljs-built_in">O</span><br>大<span class="hljs-built_in">O</span><br>会<span class="hljs-built_in">O</span><br>上<span class="hljs-built_in">O</span><br>正<span class="hljs-built_in">O</span><br>式<span class="hljs-built_in">O</span><br>亮<span class="hljs-built_in">O</span><br>相<span class="hljs-built_in">O</span><br>，<span class="hljs-built_in">O</span><br>在<span class="hljs-built_in">O</span><br><span class="hljs-number">8</span><span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br>月<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br><span class="hljs-number">6</span><span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br>日<span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">TIME</span><br>，<span class="hljs-built_in">O</span><br>荣<span class="hljs-built_in">O</span><br>耀<span class="hljs-built_in">O</span><br>官<span class="hljs-built_in">O</span><br>微<span class="hljs-built_in">O</span><br>表<span class="hljs-built_in">O</span><br>示<span class="hljs-built_in">O</span><br>该<span class="hljs-built_in">O</span><br>产<span class="hljs-built_in">O</span><br>品<span class="hljs-built_in">O</span><br><span class="hljs-operator">......</span><br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本平台仅作为序列标注算法的前期标注工具使用，并不涉及具体的算法。另外，后续该平台也会陆续开放出来，如果大家有好的建议，也可以留言～</p><p>本项目已上传只Github, 网址为： <ahref="https://github.com/percent4/entity_tagging_platform">https://github.com/percent4/entity_tagging_platform</a></p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>标注平台</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（十三）中文分词工具的使用尝试</title>
    <link href="/NLP%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8%E5%B0%9D%E8%AF%95/"/>
    <url>/NLP%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8%E5%B0%9D%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将对三种中文分词工具进行使用尝试，这三种工具分别为哈工大的LTP，结巴分词以及北大的pkuseg。</p><p>首先我们先准备好环境，即需要安装三个模块：pyltp, jieba,pkuseg以及LTP的分词模型文件<code>cws.model</code>。在用户字典中添加以下5个词语：</p><blockquote><p>经 少安 贺凤英 F-35战斗机 埃达尔·阿勒坎</p></blockquote><p>测试的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> jieba<br><span class="hljs-keyword">import</span> pkuseg<br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> Segmentor<br><br>lexicon = [<span class="hljs-string">&#x27;经&#x27;</span>, <span class="hljs-string">&#x27;少安&#x27;</span>, <span class="hljs-string">&#x27;贺凤英&#x27;</span>, <span class="hljs-string">&#x27;F-35战斗机&#x27;</span>, <span class="hljs-string">&#x27;埃达尔·阿勒坎&#x27;</span>] <span class="hljs-comment"># 自定义词典</span><br><br><span class="hljs-comment"># 哈工大LTP分词</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ltp_segment</span>(<span class="hljs-params">sent</span>):<br>    <span class="hljs-comment"># 加载文件</span><br>    cws_model_path = os.path.join(<span class="hljs-string">&#x27;data/cws.model&#x27;</span>) <span class="hljs-comment"># 分词模型路径，模型名称为`cws.model`</span><br>    lexicon_path = os.path.join(<span class="hljs-string">&#x27;data/lexicon.txt&#x27;</span>) <span class="hljs-comment"># 参数lexicon是自定义词典的文件路径</span><br>    segmentor = Segmentor()<br>    segmentor.load_with_lexicon(cws_model_path, lexicon_path)<br>    words = <span class="hljs-built_in">list</span>(segmentor.segment(sent))<br>    segmentor.release()<br><br>    <span class="hljs-keyword">return</span> words<br><br><span class="hljs-comment"># 结巴分词</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">jieba_cut</span>(<span class="hljs-params">sent</span>):<br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> lexicon:<br>        jieba.add_word(word)<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">list</span>(jieba.cut(sent))<br><br><span class="hljs-comment"># pkuseg分词</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pkuseg_cut</span>(<span class="hljs-params">sent</span>):<br>    seg = pkuseg.pkuseg(user_dict=lexicon)<br>    words = seg.cut(sent)<br>    <span class="hljs-keyword">return</span> words<br><br>sent = <span class="hljs-string">&#x27;尽管玉亭成家以后，他老婆贺凤英那些年把少安妈欺负上一回又一回，怕老婆的玉亭连一声也不敢吭，但少安他妈不计较他。&#x27;</span><br><span class="hljs-comment">#sent = &#x27;据此前报道，以色列于去年5月成为世界上第一个在实战中使用F-35战斗机的国家。&#x27;</span><br><span class="hljs-comment">#sent = &#x27;小船4月8日经长江前往小鸟岛。&#x27;</span><br><span class="hljs-comment">#sent = &#x27;1958年，埃达尔·阿勒坎出生在土耳其首都安卡拉，但他的求学生涯多在美国度过。&#x27;</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;ltp:&#x27;</span>, ltp_segment(sent))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;jieba:&#x27;</span>, jieba_cut(sent))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;pkuseg:&#x27;</span>, pkuseg_cut(sent))<br></code></pre></td></tr></table></figure><p>&amp;emsp 对于第一句话，输出结果如下：</p><blockquote><p>原文:尽管玉亭成家以后，他老婆贺凤英那些年把少安妈欺负上一回又一回，怕老婆的玉亭连一声也不敢吭，但少安他妈不计较他。</p></blockquote><blockquote><p>ltp: ['尽管', '玉亭', '成家', '以后', '，', '他', '老婆', '贺凤英','那些', '年', '把', '少安', '妈', '欺负', '上', '一', '回', '又', '一','回', '，', '怕', '老婆', '的', '玉亭', '连', '一', '声', '也', '不','敢', '吭', '，', '但', '少安', '他妈', '不', '计较', '他', '。']</p></blockquote><blockquote><p>jieba: ['尽管', '玉亭', '成家', '以后', '，', '他', '老婆', '贺凤英','那些', '年', '把', '少安', '妈', '欺负', '上', '一回', '又', '一回','，', '怕老婆', '的', '玉亭', '连', '一声', '也', '不敢', '吭', '，','但少安', '他妈', '不', '计较', '他', '。']</p></blockquote><blockquote><p>pkuseg: ['尽管', '玉亭', '成家', '以后', '，', '他', '老婆','贺凤英', '那些', '年', '把', '少安', '妈', '欺负', '上', '一', '回','又', '一', '回', '，', '怕', '老婆', '的', '玉亭', '连', '一', '声','也', '不', '敢', '吭', '，', '但', '少安', '他妈', '不', '计较', '他','。']</p></blockquote><p>对于第二句话，输出结果如下：</p><blockquote><p>原文:据此前报道，以色列于去年5月成为世界上第一个在实战中使用F-35战斗机的国家。</p></blockquote><blockquote><p>ltp: ['据', '此前', '报道', '，', '以色列', '于', '去年', '5月','成为', '世界', '上', '第一', '个', '在', '实战', '中', '使用', 'F-35','战斗机', '的', '国家', '。']</p></blockquote><blockquote><p>jieba: ['据此', '前', '报道', '，', '以色列', '于', '去年', '5','月', '成为', '世界', '上', '第一个', '在', '实战', '中', '使用', 'F','-', '35', '战斗机', '的', '国家', '。']</p></blockquote><blockquote><p>pkuseg: ['据', '此前', '报道', '，', '以色列', '于', '去年', '5月','成为', '世界', '上', '第一', '个', '在', '实战', '中', '使用','F-35战斗机', '的', '国家', '。']</p></blockquote><p>对于第三句话，输出结果如下：</p><blockquote><p>原文: 小船4月8日经长江前往小鸟岛。</p></blockquote><blockquote><p>ltp: ['小船', '4月', '8日', '经长江', '前往', '小鸟岛', '。']</p></blockquote><blockquote><p>jieba: ['小船', '4', '月', '8', '日经', '长江', '前往', '小', '鸟岛','。']</p></blockquote><blockquote><p>pkuseg: ['小船', '4月', '8日', '经', '长江', '前往', '小鸟', '岛','。']</p></blockquote><p>对于第四句话，输出结果如下：</p><blockquote><p>原文:1958年，埃达尔·阿勒坎出生在土耳其首都安卡拉，但他的求学生涯多在美国度过。</p></blockquote><blockquote><p>ltp: ['1958年', '，', '埃达尔·阿勒坎', '出生', '在', '土耳其','首都', '安卡拉', '，', '但', '他', '的', '求学', '生涯', '多', '在','美国', '度过', '。']</p></blockquote><blockquote><p>jieba: ['1958', '年', '，', '埃', '达尔', '·', '阿勒', '坎', '出生','在', '土耳其', '首都', '安卡拉', '，', '但', '他', '的', '求学','生涯', '多', '在', '美国', '度过', '。']</p></blockquote><blockquote><p>pkuseg: ['1958年', '，', '埃达尔·阿勒坎', '出生', '在', '土耳其','首都', '安卡拉', '，', '但', '他', '的', '求学', '生涯', '多', '在','美国', '度过', '。']</p></blockquote><p>接着，对以上的测试情况做一个简单的总结：</p><ol type="1"><li><p>用户词典方面：LTP和pkuseg的效果都很好，jieba的表现不尽如人意，这主要是因为自定义的字典的词语里面含有标点符号，关于该问题的解决办法，可以参考网址：<ahref="https://blog.csdn.net/weixin_42471956/article/details/80795534">https://blog.csdn.net/weixin_42471956/article/details/80795534</a></p></li><li><p>从第二句话的效果来看，pkuseg的分词效果应该是最好的，‘经’应该作为单个的词语切分出来，而LTP和jieba即使加了自定义词典，也没有效果，同理，‘F-35战斗机’也是类似的情形。</p></li></ol><p>总的来说，三者的分词效果都很优秀，差距不是很大，但在自定义词典这块，无疑pkuseg的效果更加稳定些。笔者也会在以后的分词使用中多多考虑pkuseg～有关pkuseg的介绍与使用，可以参考网址：<ahref="https://github.com/lancopku/PKUSeg-python">https://github.com/lancopku/PKUSeg-python</a></p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>分词</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP（十二）依存句法分析的可视化及图分析</title>
    <link href="/NLP%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E5%8F%8A%E5%9B%BE%E5%88%86%E6%9E%90/"/>
    <url>/NLP%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E5%8F%8A%E5%9B%BE%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>依存句法分析的效果虽然没有像分词、NER的效果来的好，但也有其使用价值，在日常的工作中，我们免不了要和其打交道。笔者这几天一直在想如何分析依存句法分析的结果，一个重要的方面便是其可视化和它的图分析。</p><p>我们使用的NLP工具为jieba和LTP，其中jieba用于分词，LTP用于词性标注和句法分析，需要事件下载<code>pos.model</code>和<code>parser.model</code>文件。</p><p>本文使用的示例句子为：</p><blockquote><p>2018年7月26日，华为创始人任正非向5G极化码（Polar码）之父埃尔达尔教授举行颁奖仪式，表彰其对于通信领域做出的贡献。</p></blockquote><p>首先，让我们来看一下没有可视化效果之前的句法分析结果。Python代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> jieba<br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span>  Postagger, Parser<br><br>sent = <span class="hljs-string">&#x27;2018年7月26日，华为创始人任正非向5G极化码（Polar码）之父埃尔达尔教授举行颁奖仪式，表彰其对于通信领域做出的贡献。&#x27;</span><br><br>jieba.add_word(<span class="hljs-string">&#x27;Polar码&#x27;</span>)<br>jieba.add_word(<span class="hljs-string">&#x27;5G极化码&#x27;</span>)<br>jieba.add_word(<span class="hljs-string">&#x27;埃尔达尔&#x27;</span>)<br>jieba.add_word(<span class="hljs-string">&#x27;之父&#x27;</span>)<br>words = <span class="hljs-built_in">list</span>(jieba.cut(sent))<br><br><span class="hljs-built_in">print</span>(words)<br><br><span class="hljs-comment"># 词性标注</span><br>pos_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/pos.model&#x27;</span>)<br>postagger = Postagger()<br>postagger.load(pos_model_path)<br>postags = postagger.postag(words)<br><br><span class="hljs-comment"># 依存句法分析</span><br>par_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/parser.model&#x27;</span>)<br>parser = Parser()<br>parser.load(par_model_path)<br>arcs = parser.parse(words, postags)<br><br>rely_id = [arc.head <span class="hljs-keyword">for</span> arc <span class="hljs-keyword">in</span> arcs]  <span class="hljs-comment"># 提取依存父节点id</span><br>relation = [arc.relation <span class="hljs-keyword">for</span> arc <span class="hljs-keyword">in</span> arcs]  <span class="hljs-comment"># 提取依存关系</span><br>heads = [<span class="hljs-string">&#x27;Root&#x27;</span> <span class="hljs-keyword">if</span> <span class="hljs-built_in">id</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> words[<span class="hljs-built_in">id</span>-<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> <span class="hljs-built_in">id</span> <span class="hljs-keyword">in</span> rely_id]  <span class="hljs-comment"># 匹配依存父节点词语</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(words)):<br>    <span class="hljs-built_in">print</span>(relation[i] + <span class="hljs-string">&#x27;(&#x27;</span> + words[i] + <span class="hljs-string">&#x27;, &#x27;</span> + heads[i] + <span class="hljs-string">&#x27;)&#x27;</span>)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;2018&#x27;</span>, <span class="hljs-string">&#x27;年&#x27;</span>, <span class="hljs-string">&#x27;7&#x27;</span>, <span class="hljs-string">&#x27;月&#x27;</span>, <span class="hljs-string">&#x27;26&#x27;</span>, <span class="hljs-string">&#x27;日&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;华为&#x27;</span>, <span class="hljs-string">&#x27;创始人&#x27;</span>, <span class="hljs-string">&#x27;任正非&#x27;</span>, <span class="hljs-string">&#x27;向&#x27;</span>, <span class="hljs-string">&#x27;5G极化码&#x27;</span>, <span class="hljs-string">&#x27;（&#x27;</span>, <span class="hljs-string">&#x27;Polar码&#x27;</span>, <span class="hljs-string">&#x27;）&#x27;</span>, <span class="hljs-string">&#x27;之父&#x27;</span>, <span class="hljs-string">&#x27;埃尔达尔&#x27;</span>, <span class="hljs-string">&#x27;教授&#x27;</span>, <span class="hljs-string">&#x27;举行&#x27;</span>, <span class="hljs-string">&#x27;颁奖仪式&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;表彰&#x27;</span>, <span class="hljs-string">&#x27;其&#x27;</span>, <span class="hljs-string">&#x27;对于&#x27;</span>, <span class="hljs-string">&#x27;通信&#x27;</span>, <span class="hljs-string">&#x27;领域&#x27;</span>, <span class="hljs-string">&#x27;做出&#x27;</span>, <span class="hljs-string">&#x27;的&#x27;</span>, <span class="hljs-string">&#x27;贡献&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>]</span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(<span class="hljs-number">2018</span>, 年)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(年, 日)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(<span class="hljs-number">7</span>, 月)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(月, 日)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(<span class="hljs-number">26</span>, 日)</span></span><br><span class="hljs-function"><span class="hljs-title">ADV</span><span class="hljs-params">(日, 举行)</span></span><br><span class="hljs-function"><span class="hljs-title">WP</span><span class="hljs-params">(，, 日)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(华为, 创始人)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(创始人, 任正非)</span></span><br><span class="hljs-function"><span class="hljs-title">SBV</span><span class="hljs-params">(任正非, 举行)</span></span><br><span class="hljs-function"><span class="hljs-title">ADV</span><span class="hljs-params">(向, 举行)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(<span class="hljs-number">5</span>G极化码, 之父)</span></span><br><span class="hljs-function"><span class="hljs-title">WP</span><span class="hljs-params">(（, Polar码)</span></span><br><span class="hljs-function"><span class="hljs-title">COO</span><span class="hljs-params">(Polar码, <span class="hljs-number">5</span>G极化码)</span></span><br><span class="hljs-function"><span class="hljs-title">WP</span><span class="hljs-params">(）, Polar码)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(之父, 埃尔达尔)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(埃尔达尔, 教授)</span></span><br><span class="hljs-function"><span class="hljs-title">POB</span><span class="hljs-params">(教授, 向)</span></span><br><span class="hljs-function"><span class="hljs-title">HED</span><span class="hljs-params">(举行, Root)</span></span><br><span class="hljs-function"><span class="hljs-title">VOB</span><span class="hljs-params">(颁奖仪式, 举行)</span></span><br><span class="hljs-function"><span class="hljs-title">WP</span><span class="hljs-params">(，, 举行)</span></span><br><span class="hljs-function"><span class="hljs-title">COO</span><span class="hljs-params">(表彰, 举行)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(其, 贡献)</span></span><br><span class="hljs-function"><span class="hljs-title">ADV</span><span class="hljs-params">(对于, 做出)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(通信, 领域)</span></span><br><span class="hljs-function"><span class="hljs-title">POB</span><span class="hljs-params">(领域, 对于)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(做出, 贡献)</span></span><br><span class="hljs-function"><span class="hljs-title">RAD</span><span class="hljs-params">(的, 做出)</span></span><br><span class="hljs-function"><span class="hljs-title">VOB</span><span class="hljs-params">(贡献, 表彰)</span></span><br><span class="hljs-function"><span class="hljs-title">WP</span><span class="hljs-params">(。, 举行)</span></span><br></code></pre></td></tr></table></figure><p>我们得到了该句子的依存句法分析的结果，但是其可视化效果却不好。</p><p>我们使用Graphviz工具来得到上述依存句法分析的可视化结果，代码（接上述代码）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> graphviz <span class="hljs-keyword">import</span> Digraph<br><br>g = Digraph(<span class="hljs-string">&#x27;测试图片&#x27;</span>)<br><br>g.node(name=<span class="hljs-string">&#x27;Root&#x27;</span>)<br><span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>    g.node(name=word)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(words)):<br>    <span class="hljs-keyword">if</span> relation[i] <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;HED&#x27;</span>]:<br>        g.edge(words[i], heads[i], label=relation[i])<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">if</span> heads[i] == <span class="hljs-string">&#x27;Root&#x27;</span>:<br>            g.edge(words[i], <span class="hljs-string">&#x27;Root&#x27;</span>, label=relation[i])<br>        <span class="hljs-keyword">else</span>:<br>            g.edge(heads[i], <span class="hljs-string">&#x27;Root&#x27;</span>, label=relation[i])<br><br>g.view()<br></code></pre></td></tr></table></figure><p>得到的依存句法分析的可视化图片如下：</p><p><img src="/img/nlp12_1.png" /></p><p>在这张图片中，我们有了对依存句法分析结果的直观感觉，效果也非常好，但是遗憾的是，我们并不能对上述可视化结果形成的图（Graph）进行图分析，因为Graphviz仅仅只是一个可视化工具。那么，我们该用什么样的工具来进行图分析呢？</p><p>答案就是NetworkX。以下是笔者对于NetworkX应用于依存句法分析的可视化和图分析的展示，其中图分析展示了两个节点之间的最短路径。示例的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 利用networkx绘制句法分析结果</span><br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> pylab <span class="hljs-keyword">import</span> mpl<br><br>mpl.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;Arial Unicode MS&#x27;</span>]  <span class="hljs-comment"># 指定默认字体</span><br><br><br>G = nx.Graph()  <span class="hljs-comment"># 建立无向图G</span><br><br><span class="hljs-comment"># 添加节点</span><br><span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>    G.add_node(word)<br><br>G.add_node(<span class="hljs-string">&#x27;Root&#x27;</span>)<br><br><span class="hljs-comment"># 添加边</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(words)):<br>    G.add_edge(words[i], heads[i])<br><br>source = <span class="hljs-string">&#x27;5G极化码&#x27;</span><br>target1 = <span class="hljs-string">&#x27;任正非&#x27;</span><br>distance1 = nx.shortest_path_length(G, source=source, target=target1)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#x27;%s&#x27;与&#x27;%s&#x27;在依存句法分析图中的最短距离为:  %s&quot;</span> % (source, target1, distance1))<br><br>target2 = <span class="hljs-string">&#x27;埃尔达尔&#x27;</span><br>distance2 = nx.shortest_path_length(G, source=source, target=target2)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#x27;%s&#x27;与&#x27;%s&#x27;在依存句法分析图中的最短距离为:  %s&quot;</span> % (source, target2, distance2))<br><br>nx.draw(G, with_labels=<span class="hljs-literal">True</span>)<br>plt.savefig(<span class="hljs-string">&quot;undirected_graph.png&quot;</span>)<br></code></pre></td></tr></table></figure><p>得到的可视化图片如下：</p><p><img src="/img/nlp12_2.png" /></p><p>输出的结果如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scheme"><span class="hljs-symbol">&#x27;5G极化码</span><span class="hljs-symbol">&#x27;与</span><span class="hljs-symbol">&#x27;任正非</span><span class="hljs-symbol">&#x27;在依存句法分析图中的最短距离为:</span>  <span class="hljs-number">6</span><br><span class="hljs-symbol">&#x27;5G极化码</span><span class="hljs-symbol">&#x27;与</span><span class="hljs-symbol">&#x27;埃尔达尔</span><span class="hljs-symbol">&#x27;在依存句法分析图中的最短距离为:</span>  <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>本次到此结束，希望这篇简短的文章能够给读者带来一些启发～</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>依存句法分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP入门（十一）从文本中提取时间</title>
    <link href="/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89%E4%BB%8E%E6%96%87%E6%9C%AC%E4%B8%AD%E6%8F%90%E5%8F%96%E6%97%B6%E9%97%B4/"/>
    <url>/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89%E4%BB%8E%E6%96%87%E6%9C%AC%E4%B8%AD%E6%8F%90%E5%8F%96%E6%97%B6%E9%97%B4/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在我们的日常生活和工作中，从文本中提取时间是一项非常基础却重要的工作，因此，本文将介绍如何从文本中有效地提取时间。</p><p>举个简单的例子，我们需要从下面的文本中提取时间：</p><blockquote><p>6月28日，杭州市统计局权威公布《2019年5月月报》，杭州市医保参保人数达到1006万，相比于2月份的989万，三个月暴涨16万人参保，傲视新一线城市。</p></blockquote><p>我们可以从文本有提取<code>6月28日</code>，<code>2019年5月</code>，<code>2月份</code>这三个有效时间。</p><p>通常情况下，较好的解决思路是利用深度学习模型来识别文本中的时间，通过一定数量的标记文本和合适的模型。本文尝试利用现有的NLP工具来解决如何从文本中提取时间。</p><p>本文使用的工具为哈工大的pyltp，可以在Python的第三方模块中找到，实现下载好分词模型<code>cws.model</code>和词性标注<code>pos.model</code>这两个模型文件。</p><p>话不多说，我们直接上Python代码，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> Segmentor<br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> Postagger<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LTP</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        cws_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;cws.model&#x27;</span>)  <span class="hljs-comment"># 分词模型路径，模型名称为`cws.model`</span><br>        pos_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;pos.model&#x27;</span>)  <span class="hljs-comment"># 词性标注模型路径，模型名称为`pos.model`</span><br>        self.segmentor = Segmentor()  <span class="hljs-comment"># 初始化实例</span><br>        self.segmentor.load(cws_model_path) <span class="hljs-comment"># 加载模型</span><br>        self.postagger = Postagger()  <span class="hljs-comment"># 初始化实例</span><br>        self.postagger.load(pos_model_path)  <span class="hljs-comment"># 加载模型</span><br><br>    <span class="hljs-comment"># 分词</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">segment</span>(<span class="hljs-params">self, text</span>):<br>        words = <span class="hljs-built_in">list</span>(self.segmentor.segment(text))<br>        <span class="hljs-keyword">return</span> words<br><br>    <span class="hljs-comment"># 词性标注</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">postag</span>(<span class="hljs-params">self, words</span>):<br>        postags = <span class="hljs-built_in">list</span>(self.postagger.postag(words))<br>        <span class="hljs-keyword">return</span> postags<br><br>    <span class="hljs-comment"># 获取文本中的时间</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_time</span>(<span class="hljs-params">self, text</span>):<br><br>        <span class="hljs-comment"># 开始分词及词性标注</span><br>        words = self.segment(text)<br>        postags = self.postag(words)<br><br>        time_lst = []<br><br>        i = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> tag, word <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(postags, words):<br>            <span class="hljs-keyword">if</span> tag == <span class="hljs-string">&#x27;nt&#x27;</span>:<br>                j = i<br>                <span class="hljs-keyword">while</span> postags[j] == <span class="hljs-string">&#x27;nt&#x27;</span> <span class="hljs-keyword">or</span> words[j] <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;至&#x27;</span>, <span class="hljs-string">&#x27;到&#x27;</span>]:<br>                    j += <span class="hljs-number">1</span><br>                time_lst.append(<span class="hljs-string">&#x27;&#x27;</span>.join(words[i:j]))<br>            i += <span class="hljs-number">1</span><br><br>        <span class="hljs-comment"># 去重子字符串的情形</span><br>        remove_lst = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> time_lst:<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> time_lst:<br>                <span class="hljs-keyword">if</span> i != j <span class="hljs-keyword">and</span> i <span class="hljs-keyword">in</span> j:<br>                    remove_lst.append(i)<br><br>        text_time_lst = []<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> time_lst:<br>            <span class="hljs-keyword">if</span> item <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> remove_lst:<br>                text_time_lst.append(item)<br><br>        <span class="hljs-comment"># print(text_time_lst)</span><br>        <span class="hljs-keyword">return</span> text_time_lst<br><br>    <span class="hljs-comment"># 释放模型</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">free_ltp</span>(<span class="hljs-params">self</span>):<br>        self.segmentor.release()<br>        self.postagger.release()<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    ltp = LTP()<br><br>    <span class="hljs-comment"># 输入文本</span><br>    sent = <span class="hljs-string">&#x27;6月28日，杭州市统计局权威公布《2019年5月月报》，杭州市医保参保人数达到1006万，相比于2月份的989万，三个月暴涨16万人参保，傲视新一线城市。&#x27;</span><br>    time_lst = ltp.get_time(sent)<br>    ltp.free_ltp()<br><br>    <span class="hljs-comment"># 输出文本中提取的时间</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;提取时间： %s&#x27;</span> % <span class="hljs-built_in">str</span>(time_lst))<br></code></pre></td></tr></table></figure><p>接着，我们测试几个例子。</p><p>输入文本为：</p><blockquote><p>今天，央行举行了2019年6月份金融统计数据解读吹风会，发布了2019年6月份金融统计数据并就当前的一些热点问题进行了解读和回应。</p></blockquote><p>文本中提取的时间为：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c">提取时间： [&#x27;今天&#x27;, &#x27;<span class="hljs-number">2019</span>年6月份&#x27;, &#x27;<span class="hljs-number">2019</span>年6月份&#x27;, &#x27;当前&#x27;]<br></code></pre></td></tr></table></figure><p>输入文本为：</p><blockquote><p>2006年，上海的国内生产总值达到10296.97亿元，是中国内地第一个GDP突破万亿元的城市。2008年，北京GDP破万亿。两年后，广州GDP超过万亿。2011年，深圳、天津、苏州、重庆4城的GDP也进入了万亿行列。武汉、成都在2014年跻身“万亿俱乐部”，杭州、南京和青岛、无锡和长沙的GDP依次在2015年、2016年和2017年过万亿。宁波和郑州则成为2018年万亿俱乐部的新成员。</p></blockquote><p>文本中提取的时间为：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c">提取时间： [&#x27;<span class="hljs-number">2006</span>年&#x27;, &#x27;<span class="hljs-number">2008</span>年&#x27;, &#x27;<span class="hljs-number">2011</span>年&#x27;, &#x27;<span class="hljs-number">2014</span>年&#x27;, &#x27;<span class="hljs-number">2015</span>年&#x27;, &#x27;<span class="hljs-number">2016</span>年&#x27;, &#x27;<span class="hljs-number">2018</span>年&#x27;]<br></code></pre></td></tr></table></figure><p>输入文本为：</p><blockquote><p>此后，6月28日、7月9日和7月11日下午，武威市政协、市人大、市政府分别召开坚决全面彻底肃清火荣贵流毒和影响专题民主生活会。</p></blockquote><p>文本中提取的时间为：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">提取时间： <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;此后&#x27;</span>, <span class="hljs-string">&#x27;6月28日&#x27;</span>, <span class="hljs-string">&#x27;7月9日&#x27;</span>, <span class="hljs-string">&#x27;7月11日下午&#x27;</span>]</span><br></code></pre></td></tr></table></figure><p>输入文本为：</p><blockquote><p>姜保红出生于1974年4月，她于2016年11月至2018年9月任武威市副市长，履新时，武威市的一把手正是火荣贵。</p></blockquote><p>文本中提取的时间为：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c">提取时间： [&#x27;<span class="hljs-number">1974</span>年4月&#x27;, &#x27;<span class="hljs-number">2016</span>年11月至<span class="hljs-number">2018</span>年9月&#x27;]<br></code></pre></td></tr></table></figure><p>本次分享到此结束，欢迎大家批评指正。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BERT的几个可能的应用</title>
    <link href="/BERT%E7%9A%84%E5%87%A0%E4%B8%AA%E5%8F%AF%E8%83%BD%E7%9A%84%E5%BA%94%E7%94%A8/"/>
    <url>/BERT%E7%9A%84%E5%87%A0%E4%B8%AA%E5%8F%AF%E8%83%BD%E7%9A%84%E5%BA%94%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>BERT是谷歌公司于2018年11月发布的一款新模型，它一种预训练语言表示的方法，在大量文本语料（维基百科）上训练了一个通用的“语言理解”模型，然后用这个模型去执行想做的NLP任务。一经公布，它便引爆了整个NLP界，其在11个主流NLP任务中都取得优异的结果，因此成为NLP领域最吸引人的一个模型。简单来说，BERT就是在训练了大量的文本语料（无监督）之后，能够在对英语中的单词（或中文的汉字）给出一个向量表示，使得该单词（或汉字）具有一定的语义表示能力，因此，BERT具有一定的先验知识，在NLP任务中表现十分抢眼。</p><p>在文章<ahref="https://blog.csdn.net/Vancl_Wang/article/details/90349047">利用bert-serving-server搭建bert词向量服务(一)</a>中，作者简洁明了地介绍了如何利用bert-serving-server来获取中文汉字的词向量，这大大降低了一般从业者使用BERT的门槛。</p><p>结合笔者这段时间的工作体会以及思考，笔者尝试着给出BERT的几个可能的应用，如下：</p><ul><li>NLP基本任务</li><li>查找相似词语</li><li>提取文本中的实体</li><li>问答中的实体对齐</li></ul><p>由于笔者才疏学浅且撰写文章时间仓促，文章中有不足之处，请读者多多批评指正！</p><h3 id="nlp基本任务">NLP基本任务</h3><p>BERT公布已经半年多了，现在已经成为NLP中的深度学习模型中必不可少的工具，一般会加载在模型中的Embedding层。由于篇幅原因，笔者不再介绍自己的BERT项目，而是介绍几个BERT在基本任务中的Github项目：</p><ul><li>英语文本分类： <strong><ahref="https://github.com/Socialbird-AILab/BERT-Classification-Tutorial">BERT-Classification-Tutorial</a></strong></li><li>中文情感分类： <strong><ahref="https://github.com/renxingkai/BERT_Chinese_Classification">BERT_Chinese_Classification</a></strong></li><li>中文命名实体识别（NER）: <strong><ahref="https://github.com/yumath/bertNER">bertNER</a></strong></li></ul><p>可以看到，BERT已经广泛应用于NLP基本任务中，在开源项目中导出可以见到它的身影，并且这些项目的作者也写了非常细致的代码工程，便于上手。</p><p>在具体讲述下面的三个应用前，我们先了解下BERT应用的项目结构，如下：</p><p><imgsrc="https://img-blog.csdnimg.cn/20190607111211990.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2pjbGlhbjkx,size_16,color_FFFFFF,t_70" /></p><p>其中，bert_client_lmj.py为调用BERT词向量服务，具体可参考文章<ahref="https://blog.csdn.net/Vancl_Wang/article/details/90349047">利用bert-serving-server搭建bert词向量服务(一)</a>，完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding:utf-8 -*-</span><br><span class="hljs-keyword">from</span> bert_serving.client <span class="hljs-keyword">import</span> BertClient<br><span class="hljs-keyword">from</span> sklearn.metrics.pairwise <span class="hljs-keyword">import</span> cosine_similarity<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Encoding</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.server_ip = <span class="hljs-string">&quot;127.0.0.1&quot;</span><br>        self.bert_client = BertClient(ip=self.server_ip)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, query</span>):<br>        tensor = self.bert_client.encode([query])<br>        <span class="hljs-keyword">return</span> tensor<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">query_similarity</span>(<span class="hljs-params">self, query_list</span>):<br>        tensors = self.bert_client.encode(query_list)<br>        <span class="hljs-keyword">return</span> cosine_similarity(tensors)[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    ec = Encoding()<br>    <span class="hljs-built_in">print</span>(ec.encode(<span class="hljs-string">&quot;中国&quot;</span>).shape)<br>    <span class="hljs-built_in">print</span>(ec.encode(<span class="hljs-string">&quot;美国&quot;</span>).shape)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;中国和美国的向量相似度:&quot;</span>, ec.query_similarity([<span class="hljs-string">&quot;中国&quot;</span>, <span class="hljs-string">&quot;美国&quot;</span>]))<br></code></pre></td></tr></table></figure><h3 id="查找相似词语">查找相似词语</h3><p>利用词向量可以查找文章中与指定词语最相近的几个词语。具体的做法为：现将文章分词，对分词后的每个词，查询其与指定词语的相似度，最后按相似度输出词语即可。我们的示例文章为老舍的《养花》，内容如下：</p><blockquote><p>我爱花，所以也爱养花。我可还没成为养花专家，因为没有工夫去研究和试验。我只把养花当做生活中的一种乐趣，花开得大小好坏都不计较，只要开花，我就高兴。在我的小院子里，一到夏天满是花草，小猫只好上房去玩，地上没有它们的运动场。花虽然多，但是没有奇花异草。珍贵的花草不易养活，看着一棵好花生病要死，是件难过的事。北京的气候，对养花来说不算很好，冬天冷，春天多风，夏天不是干旱就是大雨倾盆，秋天最好，可是会忽然闹霜冻。在这种气候里，想把南方的好花养活，我还没有那么大的本事。因此，我只养些好种易活、自己会奋斗的花草。不过，尽管花草自己会奋斗，我若是置之不理，任其自生自灭，大半还是会死的。我得天天照管它们，像好朋友似的关心它们。一来二去，我摸着一些门道：有的喜阴，就别放在太阳地里；有的喜干，就别多浇水。摸着门道，花草养活了，而且三年五载老活着、开花，多么有意思啊！不是乱吹，这就是知识呀！多得些知识决不是坏事。我不是有腿病吗，不但不利于行，也不利于久坐。我不知道花草们受我的照顾，感谢我不感谢；我可得感谢它们。我工作的时候，我总是写一会儿就到院中去看看，浇浇这棵，搬搬那盆，然后回到屋里再写一会儿，然后再出去。如此循环，让脑力劳动和体力劳动得到适当的调节，有益身心，胜于吃药。要是赶上狂风暴雨或天气突变，就得全家动员，抢救花草，十分紧张。几百盆花，都要很快地抢到屋里去，使人腰酸腿疼，热汗直流。第二天，天气好了，又得把花都搬出去，就又一次腰酸腿疼，热汗直流。可是，这多么有意思呀！不劳动，连棵花也养不活，这难道不是真理吗？送牛奶的同志进门就夸“好香”，这使我们全家都感到骄傲。赶到昙花开放的时候，约几位朋友来看看，更有秉烛夜游的味道——昙花总在夜里开放。花分根了，一棵分为几棵，就赠给朋友们一些。看着友人拿走自己的劳动果实，心里自然特别欢喜。当然，也有伤心的时候，今年夏天就有这么一回。三百棵菊秧还在地上（没到移入盆中的时候），下了暴雨，邻家的墙倒了，菊秧被砸死三十多种，一百多棵。全家人几天都没有笑容。有喜有忧，有笑有泪，有花有果，有香有色，既须劳动，又长见识，这就是养花的乐趣。</p></blockquote><p>指定词语为“开心”，查询《养花》一文中与“开心”最为接近的5个词语，完整的Python代码如下：（find_similar_words.py）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding:utf-8 -*-</span><br><span class="hljs-keyword">import</span> jieba<br><span class="hljs-keyword">from</span> bert_client_lmj <span class="hljs-keyword">import</span> Encoding<br><span class="hljs-keyword">from</span> operator <span class="hljs-keyword">import</span> itemgetter<br><br><span class="hljs-comment"># 读取文章</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./doc.txt&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    content = f.read().replace(<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br><br>ec = Encoding()<br>similar_word_dict = &#123;&#125;<br><br><span class="hljs-comment"># 查找文章中与&#x27;开心&#x27;的最接近的词语</span><br>words = <span class="hljs-built_in">list</span>(jieba.cut(content))<br><span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>    <span class="hljs-built_in">print</span>(word)<br>    <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> similar_word_dict.keys():<br>        similar_word_dict[word] = ec.query_similarity([word, <span class="hljs-string">&#x27;开心&#x27;</span>])<br><br><span class="hljs-comment"># 按相似度从高到低排序</span><br>sorted_dict = <span class="hljs-built_in">sorted</span>(similar_word_dict.items(), key=itemgetter(<span class="hljs-number">1</span>), reverse=<span class="hljs-literal">True</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;与%s最接近的5个词语及相似度如下：&#x27;</span> % <span class="hljs-string">&#x27;开心&#x27;</span>)<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> sorted_dict[:<span class="hljs-number">5</span>]:<br>    <span class="hljs-built_in">print</span>(_)<br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs 1c">与开心最接近的<span class="hljs-number">5</span>个词语及相似度如下：<br>(&#x27;难过&#x27;, <span class="hljs-number">0.9070794</span>)<br>(&#x27;高兴&#x27;, <span class="hljs-number">0.89517105</span>)<br>(&#x27;乐趣&#x27;, <span class="hljs-number">0.89260685</span>)<br>(&#x27;骄傲&#x27;, <span class="hljs-number">0.87363803</span>)<br>(&#x27;我爱花&#x27;, <span class="hljs-number">0.86954254</span>)<br></code></pre></td></tr></table></figure><h3 id="提取文本中的实体">提取文本中的实体</h3><p>在事件抽取中，我们往往需要抽取一些指定的元素，比如在下面的句子中，</p><blockquote><p>巴基斯坦当地时间2014年12月16日早晨，巴基斯坦塔利班运动武装分子袭击了西北部白沙瓦市一所军人子弟学校，打死141人，其中132人为12岁至16岁的学生。</p></blockquote><p>我们需要抽取袭击者，也就是恐怖组织这个元素。</p><p>直接从句法分析，也许可以得到一定的效果，但由于事件描述方式多变，句法分析会显得比较复杂且效果不一定能保证。这时候，我们尝试BERT词向量，它在一定程度上可以作为补充策略，帮助我们定位到事件的元素。具体的想法如下：</p><ul><li>指定事件元素模板</li><li>句子分词，对词语做n-gram</li><li>查询每个n-gram与模板的相似度</li><li>按相似度对n-gram排序，取相似度最高的n-gram</li></ul><p>在这里，我们的事件元素为恐怖组织，指定的模板为“伊斯兰组织”，完整的Python程序如下（find_similar_entity_in_sentence.py）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding:utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> jieba<br><span class="hljs-keyword">from</span> operator <span class="hljs-keyword">import</span> itemgetter<br><span class="hljs-keyword">from</span> bert_client_lmj <span class="hljs-keyword">import</span> Encoding<br><br><span class="hljs-comment"># 创建n-gram</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_ngrams</span>(<span class="hljs-params">sequence, n</span>):<br>    lst = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">zip</span>(*[sequence[index:] <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)]))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(lst)):<br>        lst[i] = <span class="hljs-string">&#x27;&#x27;</span>.join(lst[i])<br>    <span class="hljs-keyword">return</span> lst<br><br><span class="hljs-comment"># 模板</span><br>template = <span class="hljs-string">&#x27;伊斯兰组织&#x27;</span><br><span class="hljs-comment"># 示例句子</span><br>doc = <span class="hljs-string">&quot;巴基斯坦当地时间2014年12月16日早晨，巴基斯坦塔利班运动武装分子袭击了西北部白沙瓦市一所军人子弟学校，打死141人，其中132人为12岁至16岁的学生。&quot;</span><br><br>words = <span class="hljs-built_in">list</span>(jieba.cut(doc))<br>all_lst = []<br><span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">5</span>):<br>    all_lst.extend(compute_ngrams(words, j))<br><br>ec = Encoding()<br>similar_word_dict = &#123;&#125;<br><br><span class="hljs-comment"># 查找文章中与template的最接近的词语</span><br><span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> all_lst:<br>    <span class="hljs-built_in">print</span>(word)<br>    <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> similar_word_dict.keys():<br>        similar_word_dict[word] = ec.query_similarity([word, template])<br><br><span class="hljs-comment"># 按相似度从高到低排序</span><br>sorted_dict = <span class="hljs-built_in">sorted</span>(similar_word_dict.items(), key=itemgetter(<span class="hljs-number">1</span>), reverse=<span class="hljs-literal">True</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;与%s最接近的实体是: %s，相似度为 %s.&#x27;</span> %(template, sorted_dict[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>], sorted_dict[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dns">与伊斯兰组织最接近的实体是: 塔利班运动武装分子，相似度为 <span class="hljs-number">0.8953854</span>.<br></code></pre></td></tr></table></figure><p>可以看到，该算法成功地帮助我们定位到了恐怖组织：塔利班运动武装分子，效果很好，但是由于是无监督产生的词向量，效果不一定可控，而且该算法运行速度较慢，这点可以从工程上加以改进。</p><h3 id="问答中的实体对齐">问答中的实体对齐</h3><p>在智能问答中，我们往往会采用知识图谱或者数据库存储实体，其中一个难点就是实体对齐。举个例子，我们在数据库中储存的实体如下：（entities.txt）</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-number">094</span>型/晋级<br><span class="hljs-number">052</span>C型（旅洋Ⅱ级）<br>辽宁舰<span class="hljs-regexp">/瓦良格/</span>Varyag<br>杰拉尔德·R·福特号航空母舰<br><span class="hljs-number">052</span>D型（旅洋III级）<br><span class="hljs-number">054</span>A型<br>CVN-<span class="hljs-number">72</span><span class="hljs-regexp">/林肯号/</span>Lincoln<br></code></pre></td></tr></table></figure><p>这样的实体名字很复杂，如果用户想查询实体“辽宁舰”，就会碰到困难，但是由于实体以储存在数据库或知识图谱中，实体不好直接修改。一种办法是通过关键字匹配定位实体，在这里，我们可以借助BERT词向量来实现，完整的Python代码如下：（Entity_Alignment.py）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding:utf-8 -*-</span><br><span class="hljs-keyword">from</span> bert_client_lmj <span class="hljs-keyword">import</span> Encoding<br><span class="hljs-keyword">from</span> operator <span class="hljs-keyword">import</span> itemgetter<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;entities.txt&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    entities = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br><br>ec = Encoding()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">entity_alignment</span>(<span class="hljs-params">query</span>):<br><br>    similar_word_dict = &#123;&#125;<br><br>    <span class="hljs-comment"># 查找已有实体中与query最接近的实体</span><br>    <span class="hljs-keyword">for</span> entity <span class="hljs-keyword">in</span> entities:<br>        <span class="hljs-keyword">if</span> entity <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> similar_word_dict.keys():<br>            similar_word_dict[entity] = ec.query_similarity([entity, query])<br><br>    <span class="hljs-comment"># 按相似度从高到低排序</span><br>    sorted_dict = <span class="hljs-built_in">sorted</span>(similar_word_dict.items(), key=itemgetter(<span class="hljs-number">1</span>), reverse=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">return</span> sorted_dict[<span class="hljs-number">0</span>]<br><br>query = <span class="hljs-string">&#x27;辽宁舰&#x27;</span><br>result = entity_alignment(query)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;查询实体：%s，匹配实体：%s 。&#x27;</span> %(query, result))<br><br>query = <span class="hljs-string">&#x27;林肯号&#x27;</span><br>result = entity_alignment(query)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;查询实体：%s，匹配实体：%s 。&#x27;</span> %(query, result))<br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs 1c">查询实体：辽宁舰，匹配实体：(&#x27;辽宁舰/瓦良格/Varyag&#x27;, <span class="hljs-number">0.8534695</span>) 。<br>查询实体：林肯号，匹配实体：(&#x27;CVN-72/林肯号/Lincoln&#x27;, <span class="hljs-number">0.8389378</span>) 。<br></code></pre></td></tr></table></figure><p>在这里，查询的速度应该不是困难，因为我们可以将已储存的实体以离线的方式查询其词向量并储存，这样进来一个查询到实体，只查询一次词向量，并计算其与离线的词向量的相似度。这种方法也存在缺陷，主要是由于词向量的无监督，实体对齐有时候不会很准，但作为一种补充策略，也许可以考虑。</p><h3 id="总结">总结</h3><p>本文介绍了笔者这段时间所思考的BERT词向量的几个应用，由于能力有限，文章中会存在考虑不当的地方，还请读者多多批评指正。</p><p>另外，笔者将会持续调研词向量方面的技术，比如腾讯词向量，百度词向量等，欢迎大家关注～</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BERT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP入门（十）使用LSTM进行文本情感分析</title>
    <link href="/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%8D%81%EF%BC%89%E4%BD%BF%E7%94%A8LSTM%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    <url>/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%8D%81%EF%BC%89%E4%BD%BF%E7%94%A8LSTM%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="情感分析简介">情感分析简介</h4><p>文本情感分析（SentimentAnalysis）是自然语言处理（NLP）方法中常见的应用，也是一个有趣的基本任务，尤其是以提炼文本情绪内容为目的的分类。它是对带有情感色彩的主观性文本进行分析、处理、归纳和推理的过程。</p><p>本文将介绍情感分析中的情感极性（倾向）分析。所谓情感极性分析，指的是对文本进行褒义、贬义、中性的判断。在大多应用场景下，只分为两类。例如对于“喜爱”和“厌恶”这两个词，就属于不同的情感倾向。</p><p>本文将详细介绍如何使用深度学习模型中的LSTM模型来实现文本的情感分析。</p><h3 id="文本介绍及语料分析">文本介绍及语料分析</h3><p>我们以某电商网站中某个商品的评论作为语料（corpus.csv），该数据集的下载网址为：<ahref="https://github.com/renjunxiang/Text-Classification/blob/master/TextClassification/data/data_single.csv">https://github.com/renjunxiang/Text-Classification/blob/master/TextClassification/data/data_single.csv</a>，该数据集一共有4310条评论数据，文本的情感分为两类：“正面”和“反面”，该数据集的前几行如下：</p><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs autohotkey"><span class="hljs-built_in">evaluation,</span>label<br>用了一段时间，感觉还不错，可以,正面<br>电视非常好，已经是家里的第二台了。第一天下单，第二天就到本地了，可是物流的人说车坏了，一直催，客服也帮着催，到第三天下午<span class="hljs-number">5</span>点才送过来。父母年纪大了，买个大电视画面清晰，趁着耳朵还好使，享受几年。,正面<br>电视比想象中的大好多，画面也很清晰，系统很智能，更多功能还在摸索中,正面<br>不错,正面<br>用了这么多天了，感觉还不错。夏普的牌子还是比较可靠。希望以后比较耐用，现在是考量质量的时候。,正面<br>物流速度很快，非常棒，今天就看了电视，非常清晰，非常流畅，一次非常完美的购物体验,正面<br>非常好，客服还特意打电话做回访,正面<br>物流小哥不错，辛苦了，东西还没用,正面<br>送货速度快，质量有保障，活动价格挺好的。希望用的久，不出问题。,正面<br></code></pre></td></tr></table></figure><p>接着我们需要对语料做一个简单的分析：</p><ul><li><p>数据集中的情感分布；</p></li><li><p>数据集中的评论句子长度分布。</p><p>使用以下Python脚本，我们可以统计出数据集中的情感分布以及评论句子长度分布。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> font_manager<br><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> accumulate<br><br><span class="hljs-comment"># 设置matplotlib绘图时的字体</span><br>my_font = font_manager.FontProperties(fname=<span class="hljs-string">&quot;/Library/Fonts/Songti.ttc&quot;</span>)<br><br><span class="hljs-comment"># 统计句子长度及长度出现的频数</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;./corpus.csv&#x27;</span>)<br><span class="hljs-built_in">print</span>(df.groupby(<span class="hljs-string">&#x27;label&#x27;</span>)[<span class="hljs-string">&#x27;label&#x27;</span>].count())<br><br>df[<span class="hljs-string">&#x27;length&#x27;</span>] = df[<span class="hljs-string">&#x27;evaluation&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x))<br>len_df = df.groupby(<span class="hljs-string">&#x27;length&#x27;</span>).count()<br>sent_length = len_df.index.tolist()<br>sent_freq = len_df[<span class="hljs-string">&#x27;evaluation&#x27;</span>].tolist()<br><br><span class="hljs-comment"># 绘制句子长度及出现频数统计图</span><br>plt.bar(sent_length, sent_freq)<br>plt.title(<span class="hljs-string">&quot;句子长度及出现频数统计图&quot;</span>, fontproperties=my_font)<br>plt.xlabel(<span class="hljs-string">&quot;句子长度&quot;</span>, fontproperties=my_font)<br>plt.ylabel(<span class="hljs-string">&quot;句子长度出现的频数&quot;</span>, fontproperties=my_font)<br>plt.savefig(<span class="hljs-string">&quot;./句子长度及出现频数统计图.png&quot;</span>)<br>plt.close()<br><br><span class="hljs-comment"># 绘制句子长度累积分布函数(CDF)</span><br>sent_pentage_list = [(count/<span class="hljs-built_in">sum</span>(sent_freq)) <span class="hljs-keyword">for</span> count <span class="hljs-keyword">in</span> accumulate(sent_freq)]<br><br><span class="hljs-comment"># 绘制CDF</span><br>plt.plot(sent_length, sent_pentage_list)<br><br><span class="hljs-comment"># 寻找分位点为quantile的句子长度</span><br>quantile = <span class="hljs-number">0.91</span><br><span class="hljs-comment">#print(list(sent_pentage_list))</span><br><span class="hljs-keyword">for</span> length, per <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(sent_length, sent_pentage_list):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">round</span>(per, <span class="hljs-number">2</span>) == quantile:<br>        index = length<br>        <span class="hljs-keyword">break</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n分位点为%s的句子长度:%d.&quot;</span> % (quantile, index))<br><br><span class="hljs-comment"># 绘制句子长度累积分布函数图</span><br>plt.plot(sent_length, sent_pentage_list)<br>plt.hlines(quantile, <span class="hljs-number">0</span>, index, colors=<span class="hljs-string">&quot;c&quot;</span>, linestyles=<span class="hljs-string">&quot;dashed&quot;</span>)<br>plt.vlines(index, <span class="hljs-number">0</span>, quantile, colors=<span class="hljs-string">&quot;c&quot;</span>, linestyles=<span class="hljs-string">&quot;dashed&quot;</span>)<br>plt.text(<span class="hljs-number">0</span>, quantile, <span class="hljs-built_in">str</span>(quantile))<br>plt.text(index, <span class="hljs-number">0</span>, <span class="hljs-built_in">str</span>(index))<br>plt.title(<span class="hljs-string">&quot;句子长度累积分布函数图&quot;</span>, fontproperties=my_font)<br>plt.xlabel(<span class="hljs-string">&quot;句子长度&quot;</span>, fontproperties=my_font)<br>plt.ylabel(<span class="hljs-string">&quot;句子长度累积频率&quot;</span>, fontproperties=my_font)<br>plt.savefig(<span class="hljs-string">&quot;./句子长度累积分布函数图.png&quot;</span>)<br>plt.close()<br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">label</span><br><span class="hljs-string">正面</span>    <span class="hljs-number">1908</span><br><span class="hljs-string">负面</span>    <span class="hljs-number">2375</span><br><span class="hljs-attr">Name:</span> <span class="hljs-string">label,</span> <span class="hljs-attr">dtype:</span> <span class="hljs-string">int64</span><br><br><span class="hljs-string">分位点为0.91的句子长度:183.</span><br></code></pre></td></tr></table></figure><p>可以看到，正反面两类情感的比例差不多。句子长度及出现频数统计图如下：</p><p><img src="/img/nlp10_1.png" /></p><p>句子长度累积分布函数图如下：</p><p><img src="/img/nlp10_2.png" /></p><p>可以看到，大多数样本的句子长度集中在1-200之间，句子长度累计频率取0.91分位点，则长度为183左右。</p><h3 id="使用lstm模型">使用LSTM模型</h3><p>接着我们使用深度学习中的LSTM模型来对上述数据集做情感分析，笔者实现的模型框架如下：</p><figure><img src="/img/nlp10_3.png" alt="模型结构图" /><figcaption aria-hidden="true">模型结构图</figcaption></figure><p>完整的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> np_utils, plot_model<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential<br><span class="hljs-keyword">from</span> keras.preprocessing.sequence <span class="hljs-keyword">import</span> pad_sequences<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> LSTM, Dense, Embedding, Dropout<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><br><span class="hljs-comment"># 导入数据</span><br><span class="hljs-comment"># 文件的数据中，特征为evaluation, 类别为label.</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">filepath, input_shape=<span class="hljs-number">20</span></span>):<br>    df = pd.read_csv(filepath)<br><br>    <span class="hljs-comment"># 标签及词汇表</span><br>    labels, vocabulary = <span class="hljs-built_in">list</span>(df[<span class="hljs-string">&#x27;label&#x27;</span>].unique()), <span class="hljs-built_in">list</span>(df[<span class="hljs-string">&#x27;evaluation&#x27;</span>].unique())<br><br>    <span class="hljs-comment"># 构造字符级别的特征</span><br>    string = <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> vocabulary:<br>        string += word<br><br>    vocabulary = <span class="hljs-built_in">set</span>(string)<br><br>    <span class="hljs-comment"># 字典列表</span><br>    word_dictionary = &#123;word: i+<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> i, word <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(vocabulary)&#125;<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;word_dict.pk&#x27;</span>, <span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        pickle.dump(word_dictionary, f)<br>    inverse_word_dictionary = &#123;i+<span class="hljs-number">1</span>: word <span class="hljs-keyword">for</span> i, word <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(vocabulary)&#125;<br>    label_dictionary = &#123;label: i <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels)&#125;<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;label_dict.pk&#x27;</span>, <span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        pickle.dump(label_dictionary, f)<br>    output_dictionary = &#123;i: labels <span class="hljs-keyword">for</span> i, labels <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels)&#125;<br><br>    vocab_size = <span class="hljs-built_in">len</span>(word_dictionary.keys()) <span class="hljs-comment"># 词汇表大小</span><br>    label_size = <span class="hljs-built_in">len</span>(label_dictionary.keys()) <span class="hljs-comment"># 标签类别数量</span><br><br>    <span class="hljs-comment"># 序列填充，按input_shape填充，长度不足的按0补充</span><br>    x = [[word_dictionary[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sent] <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> df[<span class="hljs-string">&#x27;evaluation&#x27;</span>]]<br>    x = pad_sequences(maxlen=input_shape, sequences=x, padding=<span class="hljs-string">&#x27;post&#x27;</span>, value=<span class="hljs-number">0</span>)<br>    y = [[label_dictionary[sent]] <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> df[<span class="hljs-string">&#x27;label&#x27;</span>]]<br>    y = [np_utils.to_categorical(label, num_classes=label_size) <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> y]<br>    y = np.array([<span class="hljs-built_in">list</span>(_[<span class="hljs-number">0</span>]) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> y])<br><br>    <span class="hljs-keyword">return</span> x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary<br><br><span class="hljs-comment"># 创建深度学习模型， Embedding + LSTM + Softmax.</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_LSTM</span>(<span class="hljs-params">n_units, input_shape, output_dim, filepath</span>):<br>    x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary = load_data(filepath)<br>    model = Sequential()<br>    model.add(Embedding(input_dim=vocab_size + <span class="hljs-number">1</span>, output_dim=output_dim,<br>                        input_length=input_shape, mask_zero=<span class="hljs-literal">True</span>))<br>    model.add(LSTM(n_units, input_shape=(x.shape[<span class="hljs-number">0</span>], x.shape[<span class="hljs-number">1</span>])))<br>    model.add(Dropout(<span class="hljs-number">0.2</span>))<br>    model.add(Dense(label_size, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>))<br>    model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br>    plot_model(model, to_file=<span class="hljs-string">&#x27;./model_lstm.png&#x27;</span>, show_shapes=<span class="hljs-literal">True</span>)<br>    model.summary()<br><br>    <span class="hljs-keyword">return</span> model<br><br><span class="hljs-comment"># 模型训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model_train</span>(<span class="hljs-params">input_shape, filepath, model_save_path</span>):<br><br>    <span class="hljs-comment"># 将数据集分为训练集和测试集，占比为9:1</span><br>    <span class="hljs-comment"># input_shape = 100</span><br>    x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary = load_data(filepath, input_shape)<br>    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size = <span class="hljs-number">0.1</span>, random_state = <span class="hljs-number">42</span>)<br><br>    <span class="hljs-comment"># 模型输入参数，需要自己根据需要调整</span><br>    n_units = <span class="hljs-number">100</span><br>    batch_size = <span class="hljs-number">32</span><br>    epochs = <span class="hljs-number">5</span><br>    output_dim = <span class="hljs-number">20</span><br><br>    <span class="hljs-comment"># 模型训练</span><br>    lstm_model = create_LSTM(n_units, input_shape, output_dim, filepath)<br>    lstm_model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 模型保存</span><br>    lstm_model.save(model_save_path)<br><br>    N = test_x.shape[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 测试的条数</span><br>    predict = []<br>    label = []<br>    <span class="hljs-keyword">for</span> start, end <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, N, <span class="hljs-number">1</span>), <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, N+<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)):<br>        sentence = [inverse_word_dictionary[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> test_x[start] <span class="hljs-keyword">if</span> i != <span class="hljs-number">0</span>]<br>        y_predict = lstm_model.predict(test_x[start:end])<br>        label_predict = output_dictionary[np.argmax(y_predict[<span class="hljs-number">0</span>])]<br>        label_true = output_dictionary[np.argmax(test_y[start:end])]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;&#x27;</span>.join(sentence), label_true, label_predict) <span class="hljs-comment"># 输出预测结果</span><br>        predict.append(label_predict)<br>        label.append(label_true)<br><br>    acc = accuracy_score(predict, label) <span class="hljs-comment"># 预测准确率</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;模型在测试集上的准确率为: %s.&#x27;</span> % acc)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    filepath = <span class="hljs-string">&#x27;./corpus.csv&#x27;</span><br>    input_shape = <span class="hljs-number">180</span><br>    model_save_path = <span class="hljs-string">&#x27;./corpus_model.h5&#x27;</span><br>    model_train(input_shape, filepath, model_save_path)<br></code></pre></td></tr></table></figure><p>对上述模型，共训练5次，训练集和测试集比例为9:1，输出的结果为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">......</span><br><span class="hljs-string">Epoch</span> <span class="hljs-number">5</span><span class="hljs-string">/5</span><br><span class="hljs-string">......</span><br><span class="hljs-number">3424</span><span class="hljs-string">/3854</span> [<span class="hljs-string">=========================&gt;....</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 2s - loss: 0.1280 - acc:</span> <span class="hljs-number">0.9565</span><br><span class="hljs-number">3456</span><span class="hljs-string">/3854</span> [<span class="hljs-string">=========================&gt;....</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 1s - loss: 0.1274 - acc:</span> <span class="hljs-number">0.9569</span><br><span class="hljs-number">3488</span><span class="hljs-string">/3854</span> [<span class="hljs-string">==========================&gt;...</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 1s - loss: 0.1274 - acc:</span> <span class="hljs-number">0.9570</span><br><span class="hljs-number">3520</span><span class="hljs-string">/3854</span> [<span class="hljs-string">==========================&gt;...</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 1s - loss: 0.1287 - acc:</span> <span class="hljs-number">0.9568</span><br><span class="hljs-number">3552</span><span class="hljs-string">/3854</span> [<span class="hljs-string">==========================&gt;...</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 1s - loss: 0.1290 - acc:</span> <span class="hljs-number">0.9564</span><br><span class="hljs-number">3584</span><span class="hljs-string">/3854</span> [<span class="hljs-string">==========================&gt;...</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 1s - loss: 0.1284 - acc:</span> <span class="hljs-number">0.9568</span><br><span class="hljs-number">3616</span><span class="hljs-string">/3854</span> [<span class="hljs-string">===========================&gt;..</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 1s - loss: 0.1284 - acc:</span> <span class="hljs-number">0.9569</span><br><span class="hljs-number">3648</span><span class="hljs-string">/3854</span> [<span class="hljs-string">===========================&gt;..</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 0s - loss: 0.1278 - acc:</span> <span class="hljs-number">0.9572</span><br><span class="hljs-number">3680</span><span class="hljs-string">/3854</span> [<span class="hljs-string">===========================&gt;..</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 0s - loss: 0.1271 - acc:</span> <span class="hljs-number">0.9576</span><br><span class="hljs-number">3712</span><span class="hljs-string">/3854</span> [<span class="hljs-string">===========================&gt;..</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 0s - loss: 0.1268 - acc:</span> <span class="hljs-number">0.9580</span><br><span class="hljs-number">3744</span><span class="hljs-string">/3854</span> [<span class="hljs-string">============================&gt;.</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 0s - loss: 0.1279 - acc:</span> <span class="hljs-number">0.9575</span><br><span class="hljs-number">3776</span><span class="hljs-string">/3854</span> [<span class="hljs-string">============================&gt;.</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 0s - loss: 0.1272 - acc:</span> <span class="hljs-number">0.9579</span><br><span class="hljs-number">3808</span><span class="hljs-string">/3854</span> [<span class="hljs-string">============================&gt;.</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 0s - loss: 0.1279 - acc:</span> <span class="hljs-number">0.9580</span><br><span class="hljs-number">3840</span><span class="hljs-string">/3854</span> [<span class="hljs-string">============================&gt;.</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">ETA: 0s - loss: 0.1281 - acc:</span> <span class="hljs-number">0.9581</span><br><span class="hljs-number">3854</span><span class="hljs-string">/3854</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">18s 5ms/step - loss: 0.1298 - acc:</span> <span class="hljs-number">0.9577</span><br><span class="hljs-string">......</span><br><span class="hljs-string">给父母买的，特意用了一段时间再来评价，电视非常好，没有坏点和损坏，界面也很简洁，便于操作，稍微不足就是开机会比普通电视慢一些，这应该是智能电视的通病吧，如果可以希望微鲸大大可以更新系统优化下开机时间~电视真的很棒，性价比爆棚，值得大家考虑购买。</span> <span class="hljs-string">客服很细心，快递小哥很耐心的等我通电验货，态度非常好。</span> <span class="hljs-string">负面</span> <span class="hljs-string">正面</span><br><span class="hljs-string">长须鲸和海狮回答都很及时，虽然物流不够快但是服务不错电视不错，对比了乐视小米和微鲸论性价比还是微鲸好点</span> <span class="hljs-string">负面</span> <span class="hljs-string">负面</span><br><span class="hljs-string">所以看不到4k效果，但是应该可以。</span> <span class="hljs-string">自带音响，中规中矩吧，好像没有别人说的好。而且，到现在没连接上我的漫步者，这个非常不满意，因为看到网上说好像普通3.5mm的连不上或者连上了声音小。希望厂家接下来开发的电视有改进。不知道我要不要换个音响。其他的用用再说。</span> <span class="hljs-string">放在地上的是跟我混了两年的tcl，天气受潮，修了一次，下岗了。</span> <span class="hljs-string">最后，我也觉得底座不算太稳，凑合着用。</span> <span class="hljs-string">负面</span> <span class="hljs-string">负面</span><br><span class="hljs-string">电视机一般，低端机不要求那么高咯。</span> <span class="hljs-string">负面</span> <span class="hljs-string">负面</span><br><span class="hljs-string">很好，两点下单上午就到了，服务很好。</span> <span class="hljs-string">正面</span> <span class="hljs-string">正面</span><br><span class="hljs-string">帮朋友买的，好好好好好好好好</span> <span class="hljs-string">正面</span> <span class="hljs-string">正面</span><br><span class="hljs-string">......</span><br><span class="hljs-string">模型在测试集上的准确率为:</span> <span class="hljs-number">0.9020979020979021</span><span class="hljs-string">.</span><br></code></pre></td></tr></table></figure><p>可以看到，该模型在训练集上的准确率为95%以上，在测试集上的准确率为90%以上，效果还是相当不错的。</p><h3 id="模型预测">模型预测</h3><p>接着，我们利用刚刚训练好的模型，对新的数据进行测试。笔者随机改造上述样本的评论，然后预测其情感倾向。情感预测的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-comment"># Import the necessary modules</span><br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> keras.preprocessing.sequence <span class="hljs-keyword">import</span> pad_sequences<br><br><br><span class="hljs-comment"># 导入字典</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;word_dict.pk&#x27;</span>, <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    word_dictionary = pickle.load(f)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;label_dict.pk&#x27;</span>, <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    output_dictionary = pickle.load(f)<br><br><span class="hljs-keyword">try</span>:<br>    <span class="hljs-comment"># 数据预处理</span><br>    input_shape = <span class="hljs-number">180</span><br>    sent = <span class="hljs-string">&quot;电视刚安装好，说实话，画质不怎么样，很差！&quot;</span><br>    x = [[word_dictionary[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sent]]<br>    x = pad_sequences(maxlen=input_shape, sequences=x, padding=<span class="hljs-string">&#x27;post&#x27;</span>, value=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># 载入模型</span><br>    model_save_path = <span class="hljs-string">&#x27;./sentiment_analysis.h5&#x27;</span><br>    lstm_model = load_model(model_save_path)<br><br>    <span class="hljs-comment"># 模型预测</span><br>    y_predict = lstm_model.predict(x)<br>    label_dict = &#123;v:k <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> output_dictionary.items()&#125;<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;输入语句: %s&#x27;</span> % sent)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;情感预测结果: %s&#x27;</span> % label_dict[np.argmax(y_predict)])<br><br><span class="hljs-keyword">except</span> KeyError <span class="hljs-keyword">as</span> err:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;您输入的句子有汉字不在词汇表中，请重新输入！&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;不在词汇表中的单词为：%s.&quot;</span> % err)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入语句: 电视刚安装好，说实话，画质不怎么样，很差！</span><br><span class="hljs-section">情感预测结果: 负面</span><br></code></pre></td></tr></table></figure><p>让我们再尝试着测试一些其他的评论：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入语句: 物超所值，真心不错</span><br><span class="hljs-section">情感预测结果: 正面</span><br><span class="hljs-section">输入语句: 很大很好，方便安装！</span><br><span class="hljs-section">情感预测结果: 正面</span><br><span class="hljs-section">输入语句: 卡，慢，死机，闪退。</span><br><span class="hljs-section">情感预测结果: 负面</span><br><span class="hljs-section">输入语句: 这种货色就这样吧，别期待怎样。</span><br><span class="hljs-section">情感预测结果: 负面</span><br><span class="hljs-section">输入语句: 啥服务态度码，出了事情一个推一个，送货安装还收我50</span><br><span class="hljs-section">情感预测结果: 负面</span><br><span class="hljs-section">输入语句: 京东服务很好！但我买的这款电视两天后就出现这样的问题，很后悔买了这样的电视</span><br><span class="hljs-section">情感预测结果: 负面</span><br><span class="hljs-section">输入语句: 产品质量不错，就是这位客服的态度十分恶劣，对相关服务不予解释说明，缺乏耐心，</span><br><span class="hljs-section">情感预测结果: 负面</span><br><span class="hljs-section">输入语句: 很满意，电视非常好。护眼模式，很好，也很清晰。</span><br><span class="hljs-section">情感预测结果: 负面</span><br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>当然，该模型并不是对一切该商品的评论都会有好的效果，还是应该针对特定的语料去训练，去预测。</p><p>本文主要介绍了LSTM模型在文本情感分析方面的应用，该项目已上传Github，地址为：<ahref="https://github.com/percent4/Sentiment_Analysis">https://github.com/percent4/Sentiment_Analysis</a>。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center><h3 id="参考文献">参考文献</h3><ol type="1"><li>Python机器学习 -- NLP情感分析：<ahref="https://blog.csdn.net/qq_38328378/article/details/81198322">https://blog.csdn.net/qq_38328378/article/details/81198322</a></li><li>数据集来源：<ahref="https://github.com/renjunxiang/Text-Classification/blob/master/TextClassification/data/data_single.csv">https://github.com/renjunxiang/Text-Classification/blob/master/TextClassification/data/data_single.csv</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>情感分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP入门（九）词义消岐（WSD）的简介与实现</title>
    <link href="/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%B9%9D%EF%BC%89%E8%AF%8D%E4%B9%89%E6%B6%88%E5%B2%90%EF%BC%88WSD%EF%BC%89%E7%9A%84%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
    <url>/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%B9%9D%EF%BC%89%E8%AF%8D%E4%B9%89%E6%B6%88%E5%B2%90%EF%BC%88WSD%EF%BC%89%E7%9A%84%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="词义消岐简介">词义消岐简介</h3><p>词义消岐，英文名称为Word SenseDisambiguation，英语缩写为WSD，是自然语言处理（NLP）中一个非常有趣的基本任务。</p><p>那么，什么是词义消岐呢？通常，在我们的自然语言中，不管是英语，还是中文，都有多义词存在。这些多义词的存在，会让人对句子的意思产生混淆，但人通过学习又是可以正确地区分出来的。</p><p>以<strong>“小米”</strong>这个词为例，如果仅仅只是说“小米”这个词语，你并不知道它实际指的到底是小米科技公司还是谷物。但当我们把词语置于某个特定的语境中，我们能很好地区分出这个词语的意思。比如，</p><blockquote><p>雷军是小米的创始人。</p></blockquote><p>在这个句子中，我们知道这个“小米”指的是小米科技公司。比如</p><blockquote><p>我今天早上喝了一碗小米粥。</p></blockquote><p>在这个句子中，“小米”指的是谷物、农作物。</p><p>所谓词义消岐，指的是在特定的语境中，识别出某个歧义词的正确含义。</p><p>那么，词义消岐有什么作用呢？词义消岐可以很好地服务于语言翻译和智能问答领域，当然，还有许多应用有待开发～</p><h3 id="词义消岐实现">词义消岐实现</h3><p>在目前的词义消岐算法中，有不少原创算法，有些实现起来比较简单，有些想法较为复杂，但实现的效果普遍都不是很好。比较经典的词义消岐的算法为Lesk算法，该算法的想法很简单，通过对某个歧义词构建不同含义的语料及待判别句子中该词语与语料的重合程度来实现，具体的算法原理可参考网址：<ahref="https://en.wikipedia.org/wiki/Lesk_algorithm">https://en.wikipedia.org/wiki/Lesk_algorithm</a>.</p><p>在下面的部分中，笔者将会介绍自己想的一种实现词义消岐的算法，仅仅是一个想法，仅供参考。</p><p>我们以词语“火箭”为例，选取其中的两个<strong>义项</strong>（同一个词语的不同含义）：<ahref="https://baike.baidu.com/item/%E7%81%AB%E7%AE%AD/8794081#viewPageContent"title="NBA球队名">NBA球队名</a> 和 <ahref="https://baike.baidu.com/item/%E7%81%AB%E7%AE%AD/6308#viewPageContent"title="燃气推进装置">燃气推进装置</a> ，如下：</p><p><img src="/img/nlp9_1.png" /></p><h4 id="获取语料">获取语料</h4><p>首先，我们利用爬虫爬取这两个义项的百度百科网页，以句子为单位，只要句子中出现该词语，则把这句话加入到这个义项的预料中。爬虫的完整Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> SentenceSplitter<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">WebScrape</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, word, url</span>):<br>        self.url = url<br>        self.word = word<br><br>    <span class="hljs-comment"># 爬取百度百科页面</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">web_parse</span>(<span class="hljs-params">self</span>):<br>        headers = &#123;<span class="hljs-string">&#x27;User-Agent&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 \</span><br><span class="hljs-string">                                             (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36&#x27;</span>&#125;<br>        req = requests.get(url=self.url, headers=headers)<br><br>        <span class="hljs-comment"># 解析网页，定位到main-content部分</span><br>        <span class="hljs-keyword">if</span> req.status_code == <span class="hljs-number">200</span>:<br>            soup = BeautifulSoup(req.text.encode(req.encoding), <span class="hljs-string">&#x27;lxml&#x27;</span>)<br>            <span class="hljs-keyword">return</span> soup<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br>    <span class="hljs-comment"># 获取该词语的义项</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_gloss</span>(<span class="hljs-params">self</span>):<br>        soup = self.web_parse()<br>        <span class="hljs-keyword">if</span> soup:<br>            lis = soup.find(<span class="hljs-string">&#x27;ul&#x27;</span>, class_=<span class="hljs-string">&quot;polysemantList-wrapper cmn-clearfix&quot;</span>)<br>            <span class="hljs-keyword">if</span> lis:<br>                <span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> lis(<span class="hljs-string">&#x27;li&#x27;</span>):<br>                    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;&lt;a&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">str</span>(li):<br>                        gloss = li.text.replace(<span class="hljs-string">&#x27;▪&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br>                        <span class="hljs-keyword">return</span> gloss<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br>    <span class="hljs-comment"># 获取该义项的语料，以句子为单位</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_content</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># 发送HTTP请求</span><br>        result = []<br>        soup = self.web_parse()<br>        <span class="hljs-keyword">if</span> soup:<br>            paras = soup.find(<span class="hljs-string">&#x27;div&#x27;</span>, class_=<span class="hljs-string">&#x27;main-content&#x27;</span>).text.split(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>            <span class="hljs-keyword">for</span> para <span class="hljs-keyword">in</span> paras:<br>                <span class="hljs-keyword">if</span> self.word <span class="hljs-keyword">in</span> para:<br>                    sents = <span class="hljs-built_in">list</span>(SentenceSplitter.split(para))<br>                    <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents:<br>                        <span class="hljs-keyword">if</span> self.word <span class="hljs-keyword">in</span> sent:<br>                            sent = sent.replace(<span class="hljs-string">&#x27;\xa0&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>).replace(<span class="hljs-string">&#x27;\u3000&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br>                            result.append(sent)<br><br>        result = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(result))<br><br>        <span class="hljs-keyword">return</span> result<br><br>    <span class="hljs-comment"># 将该义项的语料写入到txt</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">write_2_file</span>(<span class="hljs-params">self</span>):<br>        gloss = self.get_gloss()<br>        result = self.get_content()<br>        <span class="hljs-built_in">print</span>(gloss)<br>        <span class="hljs-built_in">print</span>(result)<br>        <span class="hljs-keyword">if</span> result <span class="hljs-keyword">and</span> gloss:<br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./%s_%s.txt&#x27;</span>% (self.word, gloss), <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                f.writelines([_+<span class="hljs-string">&#x27;\n&#x27;</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> result])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">self</span>):<br>        self.write_2_file()<br><br><span class="hljs-comment"># NBA球队名</span><br><span class="hljs-comment">#url = &#x27;https://baike.baidu.com/item/%E4%BC%91%E6%96%AF%E6%95%A6%E7%81%AB%E7%AE%AD%E9%98%9F/370758?fromtitle=%E7%81%AB%E7%AE%AD&amp;fromid=8794081#viewPageContent&#x27;</span><br><span class="hljs-comment"># 燃气推进装置</span><br>url = <span class="hljs-string">&#x27;https://baike.baidu.com/item/%E7%81%AB%E7%AE%AD/6308#viewPageContent&#x27;</span><br>WebScrape(<span class="hljs-string">&#x27;火箭&#x27;</span>, url).run()<br></code></pre></td></tr></table></figure><p>利用这个爬虫，我们爬取了“火箭”这个词语的两个义项的语料，生成了火箭_燃气推进装置.txt文件和火箭_NBA球队名.txt文件，这两个文件分别含有361和171个句子。以火箭_燃气推进装置.txt文件为例，前10个句子如下：</p><blockquote><p>火箭技术的飞速发展，不仅可提供更加完善的各类导弹和推动相关科学的发展，还将使开发空间资源、建立空间产业、空间基地及星际航行等成为可能。火箭技术是一项十分复杂的综合性技术，主要包括火箭推进技术、总体设计技术、火箭结构技术、控制和制导技术、计划管理技术、可靠性和质量控制技术、试验技术，对导弹来说还有弹头制导和控制、1903年，俄国的К.E.齐奥尔科夫斯基提出了制造大型液体火箭的设想和设计原理。火箭有很多种，原始的火箭是用引火物附在弓箭头上，然后射到敌人身上引起焚烧的一种箭矢。“长征三号丙”火箭是在 “长征三号乙”火箭的基础上，减少了两个助推器并取消了助推器上的尾翼。 火箭与导弹有什么区别为了能够在未来大规模的将人类送入太空，不可能依赖传统的火箭和飞船。火箭V2火箭探测高层大气的物理特征（如气压、温度、湿度等）和现象的探空火箭。可一次发射一发至数十发火箭弹。</p></blockquote><h4 id="实现算法">实现算法</h4><p>我们以句子为单位进行词义消岐，即输入一句话，识别出该句子中某个歧义词的含义。笔者使用的算法比较简单，是以TF-IDF为权重的频数判别。以句子</p><blockquote><p>赛季初的时候，火箭是众望所归的西部决赛球队。</p></blockquote><p>为例，对该句子分词后，去掉停用词（stopwords），然后分别统计除了“火箭”这个词以外的TF-IDF值，累加起来,比较在两个义项下这个值的大小即可。</p><p>实现这个算法的完整Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> jieba<br><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> log2<br><br><span class="hljs-comment"># 读取每个义项的语料</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_file</span>(<span class="hljs-params">path</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        lines = [_.strip() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> f.readlines()]<br>        <span class="hljs-keyword">return</span> lines<br><br><span class="hljs-comment"># 对示例句子分词</span><br>sent = <span class="hljs-string">&#x27;赛季初的时候，火箭是众望所归的西部决赛球队。&#x27;</span><br>wsd_word = <span class="hljs-string">&#x27;火箭&#x27;</span><br><br>jieba.add_word(wsd_word)<br>sent_words = <span class="hljs-built_in">list</span>(jieba.cut(sent, cut_all=<span class="hljs-literal">False</span>))<br><br><span class="hljs-comment"># 去掉停用词</span><br>stopwords = [wsd_word, <span class="hljs-string">&#x27;我&#x27;</span>, <span class="hljs-string">&#x27;你&#x27;</span>, <span class="hljs-string">&#x27;它&#x27;</span>, <span class="hljs-string">&#x27;他&#x27;</span>, <span class="hljs-string">&#x27;她&#x27;</span>, <span class="hljs-string">&#x27;了&#x27;</span>, <span class="hljs-string">&#x27;是&#x27;</span>, <span class="hljs-string">&#x27;的&#x27;</span>, <span class="hljs-string">&#x27;啊&#x27;</span>, <span class="hljs-string">&#x27;谁&#x27;</span>, <span class="hljs-string">&#x27;什么&#x27;</span>,<span class="hljs-string">&#x27;都&#x27;</span>,\<br>             <span class="hljs-string">&#x27;很&#x27;</span>, <span class="hljs-string">&#x27;个&#x27;</span>, <span class="hljs-string">&#x27;之&#x27;</span>, <span class="hljs-string">&#x27;人&#x27;</span>, <span class="hljs-string">&#x27;在&#x27;</span>, <span class="hljs-string">&#x27;上&#x27;</span>, <span class="hljs-string">&#x27;下&#x27;</span>, <span class="hljs-string">&#x27;左&#x27;</span>, <span class="hljs-string">&#x27;右&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;！&#x27;</span>, <span class="hljs-string">&#x27;？&#x27;</span>]<br><br>sent_cut = []<br><span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sent_words:<br>    <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stopwords:<br>        sent_cut.append(word)<br><br><span class="hljs-built_in">print</span>(sent_cut)<br><br><br><span class="hljs-comment"># 计算其他词的TF-IDF以及频数</span><br>wsd_dict = &#123;&#125;<br><span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> os.listdir(<span class="hljs-string">&#x27;.&#x27;</span>):<br>    <span class="hljs-keyword">if</span> wsd_word <span class="hljs-keyword">in</span> file:<br>        wsd_dict[file.replace(<span class="hljs-string">&#x27;.txt&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)] = read_file(file)<br><br><span class="hljs-comment"># 统计每个词语在语料中出现的次数</span><br>tf_dict = &#123;&#125;<br><span class="hljs-keyword">for</span> meaning, sents <span class="hljs-keyword">in</span> wsd_dict.items():<br>    tf_dict[meaning] = []<br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sent_cut:<br>        word_count = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents:<br>            example = <span class="hljs-built_in">list</span>(jieba.cut(sent, cut_all=<span class="hljs-literal">False</span>))<br>            word_count += example.count(word)<br><br>        <span class="hljs-keyword">if</span> word_count:<br>            tf_dict[meaning].append((word, word_count))<br><br>idf_dict = &#123;&#125;<br><span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sent_cut:<br>    document_count = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> meaning, sents <span class="hljs-keyword">in</span> wsd_dict.items():<br>        <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents:<br>            <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> sent:<br>                document_count += <span class="hljs-number">1</span><br><br>    idf_dict[word] = document_count<br><br><span class="hljs-comment"># 输出值</span><br>total_document = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> meaning, sents <span class="hljs-keyword">in</span> wsd_dict.items():<br>    total_document += <span class="hljs-built_in">len</span>(sents)<br><br><span class="hljs-comment"># 计算tf_idf值</span><br>mean_tf_idf = []<br><span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> tf_dict.items():<br>    <span class="hljs-built_in">print</span>(k+<span class="hljs-string">&#x27;:&#x27;</span>)<br>    tf_idf_sum = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> v:<br>        word = item[<span class="hljs-number">0</span>]<br>        tf = item[<span class="hljs-number">1</span>]<br>        tf_idf = item[<span class="hljs-number">1</span>]*log2(total_document/(<span class="hljs-number">1</span>+idf_dict[word]))<br>        tf_idf_sum += tf_idf<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%s, 频数为: %s, TF-IDF值为: %s&#x27;</span>% (word, tf, tf_idf))<br><br>    mean_tf_idf.append((k, tf_idf_sum))<br><br>sort_array = <span class="hljs-built_in">sorted</span>(mean_tf_idf, key=<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)<br>true_meaning = sort_array[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].split(<span class="hljs-string">&#x27;_&#x27;</span>)[<span class="hljs-number">1</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\n经过词义消岐，%s在该句子中的意思为 %s .&#x27;</span> % (wsd_word, true_meaning))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">[&#x27;赛季&#x27;, &#x27;初&#x27;, &#x27;时候&#x27;, &#x27;众望所归&#x27;, &#x27;西部&#x27;, &#x27;决赛&#x27;, &#x27;球队&#x27;]</span><br><span class="hljs-attribute">火箭_燃气推进装置</span><span class="hljs-punctuation">:</span><br><span class="hljs-attribute">初, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">2, TF-IDF值为: 12.49585502688717</span><br><span class="hljs-attribute">火箭_NBA球队名</span><span class="hljs-punctuation">:</span><br><span class="hljs-attribute">赛季, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">63, TF-IDF值为: 204.6194333469459</span><br><span class="hljs-attribute">初, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">1, TF-IDF值为: 6.247927513443585</span><br><span class="hljs-attribute">时候, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">1, TF-IDF值为: 8.055282435501189</span><br><span class="hljs-attribute">西部, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">16, TF-IDF值为: 80.88451896801904</span><br><span class="hljs-attribute">决赛, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">7, TF-IDF值为: 33.13348038429679</span><br><span class="hljs-attribute">球队, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">40, TF-IDF值为: 158.712783770034</span><br><br>经过词义消岐，火箭在该句子中的意思为 NBA球队名 .<br></code></pre></td></tr></table></figure><h4 id="测试">测试</h4><p>接着，我们对上面的算法和程序进行更多的测试。</p><p>输入句子为:</p><blockquote><p>三十多年前，战士们在戈壁滩白手起家，建起了我国的火箭发射基地。</p></blockquote><p>输出结果为:</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs prolog">[<span class="hljs-string">&#x27;三十多年&#x27;</span>, <span class="hljs-string">&#x27;前&#x27;</span>, <span class="hljs-string">&#x27;战士&#x27;</span>, <span class="hljs-string">&#x27;们&#x27;</span>, <span class="hljs-string">&#x27;戈壁滩&#x27;</span>, <span class="hljs-string">&#x27;白手起家&#x27;</span>, <span class="hljs-string">&#x27;建起&#x27;</span>, <span class="hljs-string">&#x27;我国&#x27;</span>, <span class="hljs-string">&#x27;发射&#x27;</span>, <span class="hljs-string">&#x27;基地&#x27;</span>]<br>火箭<span class="hljs-symbol">_</span>燃气推进装置:<br>前, 频数为: <span class="hljs-number">2</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">9.063440958888354</span><br>们, 频数为: <span class="hljs-number">1</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">6.05528243550119</span><br>我国, 频数为: <span class="hljs-number">3</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">22.410959804340102</span><br>发射, 频数为: <span class="hljs-number">89</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">253.27878721862933</span><br>基地, 频数为: <span class="hljs-number">7</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">42.38697704850833</span><br>火箭<span class="hljs-symbol">_NBA</span>球队名:<br>前, 频数为: <span class="hljs-number">3</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">13.59516143833253</span><br>们, 频数为: <span class="hljs-number">1</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">6.05528243550119</span><br><br>经过词义消岐，火箭在该句子中的意思为 燃气推进装置 .<br></code></pre></td></tr></table></figure><p>输入句子为：</p><blockquote><p>对于马刺这样级别的球队，常规赛只有屈指可数的几次交锋具有真正的意义，今天对火箭一役是其中之一。</p></blockquote><p>输出结果为：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs prolog">[<span class="hljs-string">&#x27;对于&#x27;</span>, <span class="hljs-string">&#x27;马刺&#x27;</span>, <span class="hljs-string">&#x27;这样&#x27;</span>, <span class="hljs-string">&#x27;级别&#x27;</span>, <span class="hljs-string">&#x27;球队&#x27;</span>, <span class="hljs-string">&#x27;常规赛&#x27;</span>, <span class="hljs-string">&#x27;只有&#x27;</span>, <span class="hljs-string">&#x27;屈指可数&#x27;</span>, <span class="hljs-string">&#x27;几次&#x27;</span>, <span class="hljs-string">&#x27;交锋&#x27;</span>, <span class="hljs-string">&#x27;具有&#x27;</span>, <span class="hljs-string">&#x27;真正&#x27;</span>, <span class="hljs-string">&#x27;意义&#x27;</span>, <span class="hljs-string">&#x27;今天&#x27;</span>, <span class="hljs-string">&#x27;对&#x27;</span>, <span class="hljs-string">&#x27;一役&#x27;</span>, <span class="hljs-string">&#x27;其中&#x27;</span>, <span class="hljs-string">&#x27;之一&#x27;</span>]<br>火箭<span class="hljs-symbol">_</span>燃气推进装置:<br>只有, 频数为: <span class="hljs-number">1</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">7.470319934780034</span><br>具有, 频数为: <span class="hljs-number">5</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">32.35159967390017</span><br>真正, 频数为: <span class="hljs-number">2</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">14.940639869560068</span><br>意义, 频数为: <span class="hljs-number">1</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">8.055282435501189</span><br>对, 频数为: <span class="hljs-number">5</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">24.03677461028802</span><br>其中, 频数为: <span class="hljs-number">3</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">21.16584730650357</span><br>之一, 频数为: <span class="hljs-number">2</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">14.11056487100238</span><br>火箭<span class="hljs-symbol">_NBA</span>球队名:<br>马刺, 频数为: <span class="hljs-number">1</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">7.470319934780034</span><br>球队, 频数为: <span class="hljs-number">40</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">158.712783770034</span><br>常规赛, 频数为: <span class="hljs-number">14</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">73.4709851882102</span><br>只有, 频数为: <span class="hljs-number">1</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">7.470319934780034</span><br>对, 频数为: <span class="hljs-number">10</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">48.07354922057604</span><br>之一, 频数为: <span class="hljs-number">1</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">7.05528243550119</span><br><br>经过词义消岐，火箭在该句子中的意思为 <span class="hljs-symbol">NBA</span>球队名 .<br></code></pre></td></tr></table></figure><p>输入句子为：</p><blockquote><p>姚明是火箭队的主要得分手之一。</p></blockquote><p>输出结果为：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">[&#x27;姚明&#x27;, &#x27;火箭队&#x27;, &#x27;主要&#x27;, &#x27;得分手&#x27;, &#x27;之一&#x27;]</span><br><span class="hljs-attribute">火箭_燃气推进装置</span><span class="hljs-punctuation">:</span><br><span class="hljs-attribute">主要, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">9, TF-IDF值为: 51.60018906552445</span><br><span class="hljs-attribute">之一, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">2, TF-IDF值为: 14.11056487100238</span><br><span class="hljs-attribute">火箭_NBA球队名</span><span class="hljs-punctuation">:</span><br><span class="hljs-attribute">姚明, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">18, TF-IDF值为: 90.99508383902142</span><br><span class="hljs-attribute">火箭队, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">133, TF-IDF值为: 284.1437533641371</span><br><span class="hljs-attribute">之一, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">1, TF-IDF值为: 7.05528243550119</span><br><br>经过词义消岐，火箭在该句子中的意思为 NBA球队名 .<br></code></pre></td></tr></table></figure><p>输入的句子为:</p><blockquote><p>从1992年开始研制的长征二号F型火箭，是中国航天史上技术最复杂、可靠性和安全性指标最高的运载火箭。</p></blockquote><p>输出结果为：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">[&#x27;从&#x27;, &#x27;1992&#x27;, &#x27;年&#x27;, &#x27;开始&#x27;, &#x27;研制&#x27;, &#x27;长征二号&#x27;, &#x27;F&#x27;, &#x27;型&#x27;, &#x27;中国&#x27;, &#x27;航天史&#x27;, &#x27;技术&#x27;, &#x27;最&#x27;, &#x27;复杂&#x27;, &#x27;、&#x27;, &#x27;可靠性&#x27;, &#x27;和&#x27;, &#x27;安全性&#x27;, &#x27;指标&#x27;, &#x27;最高&#x27;, &#x27;运载火箭&#x27;]</span><br><span class="hljs-attribute">火箭_燃气推进装置</span><span class="hljs-punctuation">:</span><br><span class="hljs-attribute">从, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">6, TF-IDF值为: 29.312144604353264</span><br><span class="hljs-attribute">1992, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">1, TF-IDF值为: 6.733354340613827</span><br><span class="hljs-attribute">年, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">43, TF-IDF值为: 107.52982410441274</span><br><span class="hljs-attribute">开始, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">5, TF-IDF值为: 30.27641217750595</span><br><span class="hljs-attribute">研制, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">25, TF-IDF值为: 110.28565614316162</span><br><span class="hljs-attribute">长征二号, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">37, TF-IDF值为: 159.11461253349566</span><br><span class="hljs-attribute">F, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">7, TF-IDF值为: 40.13348038429679</span><br><span class="hljs-attribute">中国, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">45, TF-IDF值为: 153.51418105769093</span><br><span class="hljs-attribute">技术, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">27, TF-IDF值为: 119.10850863461454</span><br><span class="hljs-attribute">最, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">2, TF-IDF值为: 7.614709844115208</span><br><span class="hljs-attribute">、, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">117, TF-IDF值为: 335.25857156467714</span><br><span class="hljs-attribute">可靠性, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">5, TF-IDF值为: 30.27641217750595</span><br><span class="hljs-attribute">和, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">76, TF-IDF值为: 191.22539545388003</span><br><span class="hljs-attribute">安全性, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">2, TF-IDF值为: 14.940639869560068</span><br><span class="hljs-attribute">运载火箭, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">95, TF-IDF值为: 256.28439093389505</span><br><span class="hljs-attribute">火箭_NBA球队名</span><span class="hljs-punctuation">:</span><br><span class="hljs-attribute">从, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">5, TF-IDF值为: 24.42678717029439</span><br><span class="hljs-attribute">1992, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">2, TF-IDF值为: 13.466708681227654</span><br><span class="hljs-attribute">年, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">52, TF-IDF值为: 130.0360663588247</span><br><span class="hljs-attribute">开始, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">2, TF-IDF值为: 12.11056487100238</span><br><span class="hljs-attribute">中国, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">4, TF-IDF值为: 13.64570498290586</span><br><span class="hljs-attribute">最, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">3, TF-IDF值为: 11.422064766172813</span><br><span class="hljs-attribute">、, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">16, TF-IDF值为: 45.847326025938756</span><br><span class="hljs-attribute">和, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">31, TF-IDF值为: 77.99983235618791</span><br><span class="hljs-attribute">最高, 频数为</span><span class="hljs-punctuation">:</span> <span class="hljs-string">8, TF-IDF值为: 59.76255947824027</span><br><br>经过词义消岐，火箭在该句子中的意思为 燃气推进装置 .<br></code></pre></td></tr></table></figure><p>输入句子为：</p><blockquote><p>到目前为止火箭已经在休斯顿进行了电视宣传，并在大街小巷竖起广告栏。</p></blockquote><p>输出结果为：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs prolog">[<span class="hljs-string">&#x27;到&#x27;</span>, <span class="hljs-string">&#x27;目前为止&#x27;</span>, <span class="hljs-string">&#x27;已经&#x27;</span>, <span class="hljs-string">&#x27;休斯顿&#x27;</span>, <span class="hljs-string">&#x27;进行&#x27;</span>, <span class="hljs-string">&#x27;电视&#x27;</span>, <span class="hljs-string">&#x27;宣传&#x27;</span>, <span class="hljs-string">&#x27;并&#x27;</span>, <span class="hljs-string">&#x27;大街小巷&#x27;</span>, <span class="hljs-string">&#x27;竖起&#x27;</span>, <span class="hljs-string">&#x27;广告栏&#x27;</span>]<br>火箭<span class="hljs-symbol">_</span>燃气推进装置:<br>到, 频数为: <span class="hljs-number">11</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">39.19772273088667</span><br>已经, 频数为: <span class="hljs-number">2</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">13.466708681227654</span><br>进行, 频数为: <span class="hljs-number">14</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">68.39500407682429</span><br>并, 频数为: <span class="hljs-number">11</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">49.17351928258037</span><br>火箭<span class="hljs-symbol">_NBA</span>球队名:<br>到, 频数为: <span class="hljs-number">6</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">21.38057603502909</span><br>已经, 频数为: <span class="hljs-number">2</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">13.466708681227654</span><br>休斯顿, 频数为: <span class="hljs-number">2</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">14.940639869560068</span><br>进行, 频数为: <span class="hljs-number">2</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">9.770714868117755</span><br>并, 频数为: <span class="hljs-number">5</span>, <span class="hljs-symbol">TF</span>-<span class="hljs-symbol">IDF</span>值为: <span class="hljs-number">22.351599673900168</span><br><br>经过词义消岐，火箭在该句子中的意思为 燃气推进装置 .<br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>对于笔者的这个算法，虽然有一定的效果，但是也不总是识别正确。比如，对于最后一个测试的句子，识别的结果就是错误的，其实“休斯顿”才是识别该词语义项的关键词，但很遗憾，在笔者的算法中，“休斯顿”的权重并不高。</p><p>对于词义消岐算法，如果还是笔者的这个思路，那么有以下几方面需要改进：</p><ul><li><p>语料大小及丰富程度；</p></li><li><p>停用词的扩充；</p></li><li><p>更好的算法。</p><p>笔者的这篇文章仅作为词义消岐的简介以及简单实现，希望能对读者有所启发～</p></li></ul>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>词义消岐</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP入门（八）使用CRF++实现命名实体识别(NER)</title>
    <link href="/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8CRF-%E5%AE%9E%E7%8E%B0%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB-NER/"/>
    <url>/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8CRF-%E5%AE%9E%E7%8E%B0%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB-NER/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="crf与ner简介">CRF与NER简介</h3><p>CRF，英文全称为conditional random field,中文名为条件随机场，是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型，其特点是假设输出随机变量构成马尔可夫（Markov）随机场。</p><p>较为简单的条件随机场是定义在线性链上的条件随机场，称为线性链条件随机场（linearchain conditional random field）.线性链条件随机场可以用于序列标注等问题，而本文需要解决的命名实体识别(NER)任务正好可通过序列标注方法解决。这时，在条件概率模型P(Y|X)中，Y是输出变量，表示标记序列（或状态序列），X是输入变量，表示需要标注的观测序列。学习时，利用训练数据集通过极大似然估计或正则化的极大似然估计得到条件概率模型p(Y|X)；预测时，对于给定的输入序列x，求出条件概率p(y|x)最大的输出序列y0.</p><p><img src="/img/nlp8_1.jpeg" /></p><p>命名实体识别（Named EntityRecognition，简称NER）是信息提取、问答系统、句法分析、机器翻译等应用领域的重要基础工具，在自然语言处理技术走向实用化的过程中占有重要地位。一般来说，命名实体识别的任务就是识别出待处理文本中三大类（实体类、时间类和数字类）、七小类（人名、机构名、地名、时间、日期、货币和百分比）命名实体。常见的实现NER的算法如下：</p><p><img src="/img/nlp8_2.jpeg" /></p><p>本文不准备详细介绍条件随机场的原理与实现算法，关于具体的原理与实现算法，可以参考《统计学习算法》一书。我们将借助已实现条件随机场的工具——CRF++来实现命名实体识别。关于用深度学习算法来实现命名实体识别，可以参考文章：<ahref="https://www.jianshu.com/p/ee750877ab6f">NLP入门（五）用深度学习实现命名实体识别（NER）</a>。</p><h3 id="crf">CRF++</h3><h4 id="简介">简介</h4><p>CRF++是著名的条件随机场的开源工具，也是目前综合性能最佳的CRF工具，采用C++语言编写而成。其最重要的功能我认为是采用了特征模板。这样就可以自动生成一系列的特征函数，而不用我们自己生成特征函数，我们要做的就是寻找特征，比如词性等。关于CRF++的特性，可以参考网址：<ahref="http://taku910.github.io/crfpp/">http://taku910.github.io/crfpp/</a>。</p><h4 id="安装">安装</h4><p>CRF++的安装可分为Windows环境和Linux环境下的安装。关于Linux环境下的安装，可以参考文章：<ahref="https://blog.51cto.com/wutengfei/2095715">CRFPP/CRF++编译安装与部署</a>。在Windows中CRF++不需要安装，下载解压CRF++0.58文件即可以使用，下载网址为：<ahref="https://blog.csdn.net/lilong117194/article/details/81160265">https://blog.csdn.net/lilong117194/article/details/81160265</a>。</p><h4 id="使用">使用</h4><h5 id="语料">1. 语料</h5><p>以我们本次使用的命名实体识别的语料为例，作为CRF++训练的语料（前20行，每一句话以空格隔开。）如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs bash">played VBD O<br>on IN O<br>Monday NNP O<br>( ( O<br>home NN O<br>team NN O<br><span class="hljs-keyword">in</span> IN O<br>CAPS NNP O<br>) ) O<br>: : O<br><br>American NNP B-MISC<br>League NNP I-MISC<br><br>Cleveland NNP B-ORG<br>2 CD O<br>DETROIT NNP B-ORG<br>1 CD O<br><br>BALTIMORE VB B-ORG<br></code></pre></td></tr></table></figure><p>需要注意字与标签之间的分隔符为制表符否则会导致feature_index.cpp(86)[max_size == size] inconsistent column size错误。 ##### 2. 模板模板是使用CRF++的关键，它能帮助我们自动生成一系列的特征函数，而不用我们自己生成特征函数，而特征函数正是CRF算法的核心概念之一。一个简单的模板文件如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Unigram</span><br>U00:%x[-2,0]<br>U01:%x[0,1]<br>U02:%x[0,0]<br>U03:%x[1,0]<br>U04:%x[2,0]<br>U05:%x[-2,0]/%x[-1,0]/%x[0,0]<br>U06:%x[-1,0]/%x[0,0]/%x[1,0]<br>U07:%x[0,0]/%x[1,0]/%x[2,0]<br>U08:%x[-1,0]/%x[0,0]<br>U09:%x[0,0]/%x[1,0]<br> <br><span class="hljs-comment"># Bigram</span><br>B<br></code></pre></td></tr></table></figure><p>在这里，我们需要好好理解下模板文件的规则。T**:%x[#,#]中的T表示模板类型，两个"#"分别表示相对的行偏移与列偏移。一共有两种模板：</p><ul><li>第一种模板是Unigram template:第一个字符是U，用于描述unigramfeature的模板。每一行%x[#,#]生成一个CRF中的点(state)函数: f(s, o),其中s为t时刻的的标签(output)，o为t时刻的上下文。假设<code>home NN O</code>所在行为<code>CURRENT TOKEN</code>，</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">played VBD O<br>on IN O<br>Monday NNP O<br>( ( O<br>home NN O &lt;&lt; <span class="hljs-string">CURRENT TOKEN</span><br><span class="hljs-string">team NN O</span><br><span class="hljs-string">in IN O</span><br><span class="hljs-string">CAPS NNP O</span><br><span class="hljs-string">) ) O</span><br><span class="hljs-string">: : O</span><br></code></pre></td></tr></table></figure><p>那么%x[#,#]的对应规则如下：</p><table><thead><tr class="header"><th>template</th><th>expanded feature</th></tr></thead><tbody><tr class="odd"><td>%x[0,0]</td><td>home</td></tr><tr class="even"><td>%x[0,1]</td><td>NN</td></tr><tr class="odd"><td>%x[-1,0]</td><td>(</td></tr><tr class="even"><td>%x[-2,1]</td><td>NNP</td></tr><tr class="odd"><td>%x[0,0]/%x[0,1]</td><td>home/NN</td></tr><tr class="even"><td>ABC%x[0,1]123</td><td>ABCNN123</td></tr></tbody></table><p>以“U01:%x[0,1]”为例，它在该语料中生成的示例函数如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">func1 = <span class="hljs-keyword">if</span> (output = O and feature=<span class="hljs-string">&quot;U01:NN&quot;</span>) <span class="hljs-built_in">return</span> 1 <span class="hljs-keyword">else</span> <span class="hljs-built_in">return</span> 0<br>func2 = <span class="hljs-keyword">if</span> (output = O and feature=<span class="hljs-string">&quot;U01:N&quot;</span>) <span class="hljs-built_in">return</span> 1 <span class="hljs-keyword">else</span> <span class="hljs-built_in">return</span> 0<br>func3 = <span class="hljs-keyword">if</span> (output = O and feature=<span class="hljs-string">&quot;U01:NNP&quot;</span>) <span class="hljs-built_in">return</span> 1  <span class="hljs-keyword">else</span> <span class="hljs-built_in">return</span> 0<br>....<br></code></pre></td></tr></table></figure><ul><li>第二种模板是Bigramtemplate:第一个字符是B，每一行%x[#,#]生成一个CRFs中的边(Edge)函数:f(s',s, o),其中s'为t–1时刻的标签。也就是说,Bigram类型与Unigram大致相同,只是还要考虑到t–1时刻的标签。如果只写一个B的话,默认生成f(s',s)，这意味着前一个output token和current token将组合成bigramfeatures。</li></ul><h5 id="训练">3. 训练</h5><p>CRF++的训练命令一般格式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">crf_learn  -f 3 -c 4.0 template train.data model -t<br></code></pre></td></tr></table></figure><p>其中，template为模板文件，train.data为训练语料，-t表示可以得到一个model文件和一个model.txt文件，其他可选参数说明如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs bash">-f, –freq=INT使用属性的出现次数不少于INT(默认为1)<br><br>-m, –maxiter=INT设置INT为LBFGS的最大迭代次数 (默认10k)<br><br>-c, –cost=FLOAT    设置FLOAT为代价参数，过大会过度拟合 (默认1.0)<br><br>-e, –eta=FLOAT设置终止标准FLOAT(默认0.0001)<br><br>-C, –convert将文本模式转为二进制模式<br><br>-t, –textmodel为调试建立文本模型文件<br><br>-a, –algorithm=(CRF|MIRA)    选择训练算法，默认为CRF-L2<br><br>-p, –thread=INT线程数(默认1)，利用多个CPU减少训练时间<br><br>-H, –shrinking-size=INT    设置INT为最适宜的跌代变量次数 (默认20)<br><br>-v, –version显示版本号并退出<br><br>-h, –<span class="hljs-built_in">help</span>显示帮助并退出<br></code></pre></td></tr></table></figure><p>在训练过程中，会输出一些信息，其意义如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">iter：迭代次数。当迭代次数达到maxiter时，迭代终止<br><br>terr：标记错误率<br><br>serr：句子错误率<br><br>obj：当前对象的值。当这个值收敛到一个确定值的时候，训练完成<br><br>diff：与上一个对象值之间的相对差。当此值低于eta时，训练完成<br></code></pre></td></tr></table></figure><h5 id="预测">4. 预测</h5><p>在训练完模型后，我们可以使用训练好的模型对新数据进行预测，预测命令格式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">crf_test -m model NER_predict.data &gt; predict.txt<br></code></pre></td></tr></table></figure><p><code>-m model</code>表示使用我们刚刚训练好的model模型，预测的数据文件为NER_predict.data,<code>&gt; predict.txt</code>表示将预测后的数据写入到predict.txt中。</p><h3 id="ner实现实例">NER实现实例</h3><p>接下来，我们将利用CRF++来实现英文命名实体识别功能。</p><p>本项目实现NER的语料库如下(文件名为train.txt，一共42000行，这里只展示前15行，可以在文章最后的Github地址下载该语料库)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">played on Monday ( home team <span class="hljs-keyword">in</span> CAPS ) :<br>VBD IN NNP ( NN NN IN NNP ) :<br>O O O O O O O O O O<br>American League<br>NNP NNP<br>B-MISC I-MISC<br>Cleveland 2 DETROIT 1<br>NNP CD NNP CD<br>B-ORG O B-ORG O<br>BALTIMORE 12 Oakland 11 ( 10 innings )<br>VB CD NNP CD ( CD NN )<br>B-ORG O B-ORG O O O O O<br>TORONTO 5 Minnesota 3<br>TO CD NNP CD<br>B-ORG O B-ORG O<br>......<br></code></pre></td></tr></table></figure><p>简单介绍下该语料库的结构：该语料库一共42000行，每三行为一组，其中，第一行为英语句子，第二行为句子中每个单词的词性，第三行为NER系统的标注，共分4个标注类别：PER（人名），LOC（位置），ORG（组织）以及MISC，其中B表示开始，I表示中间，O表示单字词，不计入NER，sO表示特殊单字词。</p><p>首先我们将该语料分为训练集和测试集，比例为9:1，实现的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-comment"># NER预料train.txt所在的路径</span><br><span class="hljs-built_in">dir</span> = <span class="hljs-string">&quot;/Users/Shared/CRF_4_NER/CRF_TEST&quot;</span><br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;%s/train.txt&quot;</span> % <span class="hljs-built_in">dir</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    sents = [line.strip() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f.readlines()]<br><br><span class="hljs-comment"># 训练集与测试集的比例为9:1</span><br>RATIO = <span class="hljs-number">0.9</span><br>train_num = <span class="hljs-built_in">int</span>((<span class="hljs-built_in">len</span>(sents)//<span class="hljs-number">3</span>)*RATIO)<br><br><span class="hljs-comment"># 将文件分为训练集与测试集</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;%s/NER_train.data&quot;</span> % <span class="hljs-built_in">dir</span>, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> g:<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(train_num):<br>        words = sents[<span class="hljs-number">3</span>*i].split(<span class="hljs-string">&#x27;\t&#x27;</span>)<br>        postags = sents[<span class="hljs-number">3</span>*i+<span class="hljs-number">1</span>].split(<span class="hljs-string">&#x27;\t&#x27;</span>)<br>        tags = sents[<span class="hljs-number">3</span>*i+<span class="hljs-number">2</span>].split(<span class="hljs-string">&#x27;\t&#x27;</span>)<br>        <span class="hljs-keyword">for</span> word, postag, tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(words, postags, tags):<br>            g.write(word+<span class="hljs-string">&#x27; &#x27;</span>+postag+<span class="hljs-string">&#x27; &#x27;</span>+tag+<span class="hljs-string">&#x27;\n&#x27;</span>)<br>        g.write(<span class="hljs-string">&#x27;\n&#x27;</span>)<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;%s/NER_test.data&quot;</span> % <span class="hljs-built_in">dir</span>, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> h:<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(train_num+<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(sents)//<span class="hljs-number">3</span>):<br>        words = sents[<span class="hljs-number">3</span>*i].split(<span class="hljs-string">&#x27;\t&#x27;</span>)<br>        postags = sents[<span class="hljs-number">3</span>*i+<span class="hljs-number">1</span>].split(<span class="hljs-string">&#x27;\t&#x27;</span>)<br>        tags = sents[<span class="hljs-number">3</span>*i+<span class="hljs-number">2</span>].split(<span class="hljs-string">&#x27;\t&#x27;</span>)<br>        <span class="hljs-keyword">for</span> word, postag, tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(words, postags, tags):<br>            h.write(word+<span class="hljs-string">&#x27; &#x27;</span>+postag+<span class="hljs-string">&#x27; &#x27;</span>+tag+<span class="hljs-string">&#x27;\n&#x27;</span>)<br>        h.write(<span class="hljs-string">&#x27;\n&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;OK!&#x27;</span>)<br></code></pre></td></tr></table></figure><p>运行此程序，得到NER_train.data,此为训练集数据，NER_test.data，此为测试集数据。NER_train.data的前20行数据如下（以）：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs mathematica"><span class="hljs-variable">played</span> <span class="hljs-variable">VBD</span> <span class="hljs-built_in">O</span><br><span class="hljs-variable">on</span> <span class="hljs-variable">IN</span> <span class="hljs-built_in">O</span><br><span class="hljs-built_in">Monday</span> <span class="hljs-variable">NNP</span> <span class="hljs-built_in">O</span><br><span class="hljs-punctuation">(</span> <span class="hljs-punctuation">(</span> <span class="hljs-built_in">O</span><br><span class="hljs-variable">home</span> <span class="hljs-variable">NN</span> <span class="hljs-built_in">O</span><br><span class="hljs-variable">team</span> <span class="hljs-variable">NN</span> <span class="hljs-built_in">O</span><br><span class="hljs-variable">in</span> <span class="hljs-variable">IN</span> <span class="hljs-built_in">O</span><br><span class="hljs-variable">CAPS</span> <span class="hljs-variable">NNP</span> <span class="hljs-built_in">O</span><br><span class="hljs-punctuation">)</span> <span class="hljs-punctuation">)</span> <span class="hljs-built_in">O</span><br><span class="hljs-operator">:</span> <span class="hljs-operator">:</span> <span class="hljs-built_in">O</span><br><br><span class="hljs-variable">American</span> <span class="hljs-variable">NNP</span> <span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">MISC</span><br><span class="hljs-variable">League</span> <span class="hljs-variable">NNP</span> <span class="hljs-built_in">I</span><span class="hljs-operator">-</span><span class="hljs-variable">MISC</span><br><br><span class="hljs-variable">Cleveland</span> <span class="hljs-variable">NNP</span> <span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">ORG</span><br><span class="hljs-number">2</span> <span class="hljs-variable">CD</span> <span class="hljs-built_in">O</span><br><span class="hljs-variable">DETROIT</span> <span class="hljs-variable">NNP</span> <span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">ORG</span><br><span class="hljs-number">1</span> <span class="hljs-variable">CD</span> <span class="hljs-built_in">O</span><br><br><span class="hljs-variable">BALTIMORE</span> <span class="hljs-variable">VB</span> <span class="hljs-variable">B</span><span class="hljs-operator">-</span><span class="hljs-variable">ORG</span><br></code></pre></td></tr></table></figure><p>我们使用的模板文件template内容如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># Unigram</span><br><span class="hljs-attribute">U00</span>:%x[-<span class="hljs-number">2</span>,<span class="hljs-number">0</span>]<br><span class="hljs-attribute">U01</span>:%x[-<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]<br><span class="hljs-attribute">U02</span>:%x[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]<br><span class="hljs-attribute">U03</span>:%x[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]<br><span class="hljs-attribute">U04</span>:%x[<span class="hljs-number">2</span>,<span class="hljs-number">0</span>]<br><span class="hljs-attribute">U05</span>:%x[-<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]/%x[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]<br><span class="hljs-attribute">U06</span>:%x[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]/%x[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]<br><br><span class="hljs-attribute">U10</span>:%x[-<span class="hljs-number">2</span>,<span class="hljs-number">1</span>]<br><span class="hljs-attribute">U11</span>:%x[-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]<br><span class="hljs-attribute">U12</span>:%x[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]<br><span class="hljs-attribute">U13</span>:%x[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]<br><span class="hljs-attribute">U14</span>:%x[<span class="hljs-number">2</span>,<span class="hljs-number">1</span>]<br><span class="hljs-attribute">U15</span>:%x[-<span class="hljs-number">2</span>,<span class="hljs-number">1</span>]/%x[-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]<br><span class="hljs-attribute">U16</span>:%x[-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]/%x[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]<br><span class="hljs-attribute">U17</span>:%x[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]/%x[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]<br><span class="hljs-attribute">U18</span>:%x[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]/%x[<span class="hljs-number">2</span>,<span class="hljs-number">1</span>]<br><br><span class="hljs-attribute">U20</span>:%x[-<span class="hljs-number">2</span>,<span class="hljs-number">1</span>]/%x[-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]/%x[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]<br><span class="hljs-attribute">U21</span>:%x[-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]/%x[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]/%x[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]<br><span class="hljs-attribute">U22</span>:%x[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]/%x[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]/%x[<span class="hljs-number">2</span>,<span class="hljs-number">1</span>]<br><br><span class="hljs-comment"># Bigram</span><br><span class="hljs-attribute">B</span><br></code></pre></td></tr></table></figure><p>接着训练该数据，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">crf_learn -c 3.0 template NER_train.data model -t<br></code></pre></td></tr></table></figure><p>运行时的输出信息如下：</p><p><img src="/img/nlp8_3.jpeg" /></p><p>在笔者的电脑上一共迭代了193次，运行时间为490.32秒，标记错误率为0.00004，句子错误率为0.00056。</p><p>接着，我们需要在测试集上对该模型的预测表现做评估。预测命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">crf_test -m model NER_test.data &gt; result.txt<br></code></pre></td></tr></table></figure><p>使用Python脚本统计预测的准确率，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-built_in">dir</span> = <span class="hljs-string">&quot;/Users/Shared/CRF_4_NER/CRF_TEST&quot;</span><br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;%s/result.txt&quot;</span> % <span class="hljs-built_in">dir</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    sents = [line.strip() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f.readlines() <span class="hljs-keyword">if</span> line.strip()]<br><br>total = <span class="hljs-built_in">len</span>(sents)<br><span class="hljs-built_in">print</span>(total)<br><br>count = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents:<br>    words = sent.split()<br>    <span class="hljs-comment"># print(words)</span><br>    <span class="hljs-keyword">if</span> words[-<span class="hljs-number">1</span>] == words[-<span class="hljs-number">2</span>]:<br>        count += <span class="hljs-number">1</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Accuracy: %.4f&quot;</span> %(count/total))<br><span class="hljs-comment"># 0.9706</span><br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">21487</span><br><span class="hljs-attribute">Accuracy</span>: <span class="hljs-number">0</span>.<span class="hljs-number">9706</span><br></code></pre></td></tr></table></figure><p>由此可见，在测试集上的准确率高达0.9706，效果相当好。</p><p>最后，我们对新数据进行命名实体识别，看看模型在新数据上的识别效果。实现的Python代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> nltk<br><br><span class="hljs-built_in">dir</span> = <span class="hljs-string">&quot;/Users/Shared/CRF_4_NER/CRF_TEST&quot;</span><br><br>sentence = <span class="hljs-string">&quot;Venezuelan opposition leader and self-proclaimed interim president Juan Guaidó said Thursday he will return to his country by Monday, and that a dialogue with President Nicolas Maduro won&#x27;t be possible without discussing elections.&quot;</span><br><span class="hljs-comment">#sentence = &quot;Real Madrid&#x27;s season on the brink after 3-0 Barcelona defeat&quot;</span><br><span class="hljs-comment"># sentence = &quot;British artist David Hockney is known as a voracious smoker, but the habit got him into a scrape in Amsterdam on Wednesday.&quot;</span><br><span class="hljs-comment"># sentence = &quot;India is waiting for the release of an pilot who has been in Pakistani custody since he was shot down over Kashmir on Wednesday, a goodwill gesture which could defuse the gravest crisis in the disputed border region in years.&quot;</span><br><span class="hljs-comment"># sentence = &quot;Instead, President Donald Trump&#x27;s second meeting with North Korean despot Kim Jong Un ended in a most uncharacteristic fashion for a showman commander in chief: fizzle.&quot;</span><br><span class="hljs-comment"># sentence = &quot;And in a press conference at the Civic Leadership Academy in Queens, de Blasio said the program is already working.&quot;</span><br><span class="hljs-comment">#sentence = &quot;The United States is a founding member of the United Nations, World Bank, International Monetary Fund.&quot;</span><br><br>default_wt = nltk.word_tokenize <span class="hljs-comment"># 分词</span><br>words = default_wt(sentence)<br><span class="hljs-built_in">print</span>(words)<br>postags = nltk.pos_tag(words)<br><span class="hljs-built_in">print</span>(postags)<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;%s/NER_predict.data&quot;</span> % <span class="hljs-built_in">dir</span>, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> postags:<br>        f.write(item[<span class="hljs-number">0</span>]+<span class="hljs-string">&#x27; &#x27;</span>+item[<span class="hljs-number">1</span>]+<span class="hljs-string">&#x27; O\n&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;write successfully!&quot;</span>)<br><br>os.chdir(<span class="hljs-built_in">dir</span>)<br>os.system(<span class="hljs-string">&quot;crf_test -m model NER_predict.data &gt; predict.txt&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;get predict file!&quot;</span>)<br><br><span class="hljs-comment"># 读取预测文件redict.txt</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;%s/predict.txt&quot;</span> % <span class="hljs-built_in">dir</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    sents = [line.strip() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f.readlines() <span class="hljs-keyword">if</span> line.strip()]<br><br>word = []<br>predict = []<br><br><span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents:<br>    words = sent.split()<br>    word.append(words[<span class="hljs-number">0</span>])<br>    predict.append(words[-<span class="hljs-number">1</span>])<br><br><span class="hljs-comment"># print(word)</span><br><span class="hljs-comment"># print(predict)</span><br><br><span class="hljs-comment"># 去掉NER标注为O的元素</span><br>ner_reg_list = []<br><span class="hljs-keyword">for</span> word, tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(word, predict):<br>    <span class="hljs-keyword">if</span> tag != <span class="hljs-string">&#x27;O&#x27;</span>:<br>        ner_reg_list.append((word, tag))<br><br><span class="hljs-comment"># 输出模型的NER识别结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;NER识别结果：&quot;</span>)<br><span class="hljs-keyword">if</span> ner_reg_list:<br>    <span class="hljs-keyword">for</span> i, item <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(ner_reg_list):<br>        <span class="hljs-keyword">if</span> item[<span class="hljs-number">1</span>].startswith(<span class="hljs-string">&#x27;B&#x27;</span>):<br>            end = i+<span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> end &lt;= <span class="hljs-built_in">len</span>(ner_reg_list)-<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> ner_reg_list[end][<span class="hljs-number">1</span>].startswith(<span class="hljs-string">&#x27;I&#x27;</span>):<br>                end += <span class="hljs-number">1</span><br><br>            ner_type = item[<span class="hljs-number">1</span>].split(<span class="hljs-string">&#x27;-&#x27;</span>)[<span class="hljs-number">1</span>]<br>            ner_type_dict = &#123;<span class="hljs-string">&#x27;PER&#x27;</span>: <span class="hljs-string">&#x27;PERSON: &#x27;</span>,<br>                             <span class="hljs-string">&#x27;LOC&#x27;</span>: <span class="hljs-string">&#x27;LOCATION: &#x27;</span>,<br>                             <span class="hljs-string">&#x27;ORG&#x27;</span>: <span class="hljs-string">&#x27;ORGANIZATION: &#x27;</span>,<br>                             <span class="hljs-string">&#x27;MISC&#x27;</span>: <span class="hljs-string">&#x27;MISC: &#x27;</span><br>                            &#125;<br>            <span class="hljs-built_in">print</span>(ner_type_dict[ner_type], <span class="hljs-string">&#x27; &#x27;</span>.join([item[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> ner_reg_list[i:end]]))<br></code></pre></td></tr></table></figure><p>识别的结果如下：</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">MISC:</span>  Venezuelan<br><span class="hljs-symbol">PERSON:</span>  Juan Guaidó<br><span class="hljs-symbol">PERSON:</span>  Nicolas Maduro<br></code></pre></td></tr></table></figure><p>识别有个地方不准确， Venezuelan应该是LOC，而不是MISC.我们再接着测试其它的新数据：</p><p>输入语句1：</p><blockquote><p>Real Madrid's season on the brink after 3-0 Barcelona defeat</p></blockquote><p>识别效果1：</p><blockquote><p>ORGANIZATION: Real Madrid LOCATION: Barcelona</p></blockquote><p>输入语句2：</p><blockquote><p>British artist David Hockney is known as a voracious smoker, but thehabit got him into a scrape in Amsterdam on Wednesday.</p></blockquote><p>识别效果2：</p><blockquote><p>MISC: British PERSON: David Hockney LOCATION: Amsterdam</p></blockquote><p>输入语句3：</p><blockquote><p>India is waiting for the release of an pilot who has been inPakistani custody since he was shot down over Kashmir on Wednesday, agoodwill gesture which could defuse the gravest crisis in the disputedborder region in years.</p></blockquote><p>识别效果3：</p><blockquote><p>LOCATION: India LOCATION: Pakistani LOCATION: Kashmir</p></blockquote><p>输入语句4：</p><blockquote><p>Instead, President Donald Trump's second meeting with North Koreandespot Kim Jong Un ended in a most uncharacteristic fashion for ashowman commander in chief: fizzle.</p></blockquote><p>识别效果4：</p><blockquote><p>PERSON: Donald Trump PERSON: Kim Jong Un</p></blockquote><p>输入语句5：</p><blockquote><p>And in a press conference at the Civic Leadership Academy in Queens,de Blasio said the program is already working.</p></blockquote><p>识别效果5：</p><blockquote><p>ORGANIZATION: Civic Leadership Academy LOCATION: Queens PERSON: deBlasio</p></blockquote><p>输入语句6：</p><blockquote><p>The United States is a founding member of the United Nations, WorldBank, International Monetary Fund.</p></blockquote><p>识别效果6：</p><blockquote><p>LOCATION: United States ORGANIZATION: United Nations PERSON: WorldBank ORGANIZATION: International Monetary Fund</p></blockquote><p>在这些例子中，有让我们惊喜之处：识别出了人物Donald Trump, Kim JongUn. 但也有些不足指出，如将WorldBank识别为人物，而不是组织机构。总的来说，识别效果还是让人满意的。</p><h3 id="总结">总结</h3><p>最近由于工作繁忙，无暇顾及博客。但转念一想，技术输出也是比较重要的，需要长期坚持下去～</p><p>本项目的Github地址为：<ahref="https://github.com/percent4/CRF_4_NER">https://github.com/percent4/CRF_4_NER</a>。</p><p>五一将至，祝大家假期愉快～</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>NER</tag>
      
      <tag>CRF++</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP入门（七）中文预处理之繁简体转换及获取拼音</title>
    <link href="/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%83%EF%BC%89%E4%B8%AD%E6%96%87%E9%A2%84%E5%A4%84%E7%90%86%E4%B9%8B%E7%B9%81%E7%AE%80%E4%BD%93%E8%BD%AC%E6%8D%A2%E5%8F%8A%E8%8E%B7%E5%8F%96%E6%8B%BC%E9%9F%B3/"/>
    <url>/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%83%EF%BC%89%E4%B8%AD%E6%96%87%E9%A2%84%E5%A4%84%E7%90%86%E4%B9%8B%E7%B9%81%E7%AE%80%E4%BD%93%E8%BD%AC%E6%8D%A2%E5%8F%8A%E8%8E%B7%E5%8F%96%E6%8B%BC%E9%9F%B3/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在日常的中文NLP中，经常会涉及到中文的繁简体转换以及拼音的标注等问题，本文将介绍这两个方面的实现。</p><p>首先是中文的繁简体转换，不需要使用额外的Python模块，至需要以下两个Python代码文件即可：</p><ul><li><p>langconv.py 地址： <ahref="https://raw.githubusercontent.com/skydark/nstools/master/zhtools/langconv.py">https://raw.githubusercontent.com/skydark/nstools/master/zhtools/langconv.py</a></p></li><li><p>zh_wiki.py 地址：<ahref="https://raw.githubusercontent.com/skydark/nstools/master/zhtools/zh_wiki.py">https://raw.githubusercontent.com/skydark/nstools/master/zhtools/zh_wiki.py</a></p><p>示例代码如下（将代码文件与langconv.py与zh_wiki.py放在同一目录下）：</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langconv <span class="hljs-keyword">import</span> *<br><br><span class="hljs-comment"># 转换繁体到简体</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cht_2_chs</span>(<span class="hljs-params">line</span>):<br>    line = Converter(<span class="hljs-string">&#x27;zh-hans&#x27;</span>).convert(line)<br>    line.encode(<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>    <span class="hljs-keyword">return</span> line<br><br>line_cht= <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">台北市長柯文哲今在臉書開直播，先向網友報告自己3月16日至24日要出訪美國東部4城市，接著他無預警宣布，</span><br><span class="hljs-string">2月23日要先出訪以色列，預計停留4至5天。雖他強調台北市、以色列已在資安方面有所交流，也可到當地城市交流、</span><br><span class="hljs-string">參觀產業創新等內容，但柯也說「也是去看看一個小國在這麼惡劣環境，howtosurvive，他的祕訣是什麼？」這番話，</span><br><span class="hljs-string">也被解讀，頗有更上層樓、直指總統大位的思維。</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br>line_cht = line_cht.replace(<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br>ret_chs = cht_2_chs(line_cht)<br><span class="hljs-built_in">print</span>(ret_chs)<br><br><span class="hljs-comment"># 转换简体到繁体</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">chs_2_cht</span>(<span class="hljs-params">sentence</span>):<br>    sentence = Converter(<span class="hljs-string">&#x27;zh-hant&#x27;</span>).convert(sentence)<br>    <span class="hljs-keyword">return</span> sentence<br><br>line_chs = <span class="hljs-string">&#x27;忧郁的台湾乌龟&#x27;</span><br>line_cht = chs_2_cht(line_chs)<br><span class="hljs-built_in">print</span>(line_cht)<br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><blockquote><p>台北市长柯文哲今在脸书开直播，先向网友报告自己3月16日至24日要出访美国东部4城市，接着他无预警宣布，2月23日要先出访以色列，预计停留4至5天。虽他强调台北市、以色列已在资安方面有所交流，也可到当地城市交流、参观产业创新等内容，但柯也说「也是去看看一个小国在这么恶劣环境，howtosurvive，他的祕诀是什么？」这番话，也被解读，颇有更上层楼、直指总统大位的思维。憂郁的臺灣烏龜</p></blockquote><p>接着是获取中文汉字的拼音，这方面的Python模块有xpinyin,pypinyin等。本文以xpinyin为例，展示如何获取汉字的拼音。示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> xpinyin <span class="hljs-keyword">import</span> Pinyin<br><br>p = Pinyin()<br><br><span class="hljs-comment"># 默认分隔符为-</span><br><span class="hljs-built_in">print</span>(p.get_pinyin(<span class="hljs-string">&quot;上海&quot;</span>))<br><br><span class="hljs-comment"># 显示声调</span><br><span class="hljs-built_in">print</span>(p.get_pinyin(<span class="hljs-string">&quot;上海&quot;</span>, tone_marks=<span class="hljs-string">&#x27;marks&#x27;</span>))<br><span class="hljs-built_in">print</span>(p.get_pinyin(<span class="hljs-string">&quot;上海&quot;</span>, tone_marks=<span class="hljs-string">&#x27;numbers&#x27;</span>))<br><br><span class="hljs-comment"># 去掉分隔符</span><br><span class="hljs-built_in">print</span>(p.get_pinyin(<span class="hljs-string">&quot;上海&quot;</span>, <span class="hljs-string">&#x27;&#x27;</span>))<br><span class="hljs-comment"># 设为分隔符为空格</span><br><span class="hljs-built_in">print</span>(p.get_pinyin(<span class="hljs-string">&quot;上海&quot;</span>, <span class="hljs-string">&#x27; &#x27;</span>))<br><br><span class="hljs-comment"># 获取拼音首字母</span><br><span class="hljs-built_in">print</span>(p.get_initial(<span class="hljs-string">&quot;上&quot;</span>))<br><span class="hljs-built_in">print</span>(p.get_initials(<span class="hljs-string">&quot;上海&quot;</span>))<br><span class="hljs-built_in">print</span>(p.get_initials(<span class="hljs-string">&quot;上海&quot;</span>, <span class="hljs-string">&#x27;&#x27;</span>))<br><span class="hljs-built_in">print</span>(p.get_initials(<span class="hljs-string">&quot;上海&quot;</span>, <span class="hljs-string">&#x27; &#x27;</span>))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">shang-hai</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">shàng-hǎi</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">shang4-hai3</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">shanghai</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">shang </span>hai<br>S<br>S-H<br><span class="hljs-keyword">SH</span><br><span class="hljs-keyword"></span>S H<br></code></pre></td></tr></table></figure><p>本次分享到此结束，感谢大家阅读~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>繁简体转换</tag>
      
      <tag>拼音</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP入门（六）pyltp的介绍与使用</title>
    <link href="/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AD%EF%BC%89pyltp%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    <url>/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%85%AD%EF%BC%89pyltp%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="pyltp的简介">pyltp的简介</h3><p>语言技术平台(LTP)经过哈工大社会计算与信息检索研究中心 11年的持续研发和推广，是国内外最具影响力的中文处理基础平台。它提供的功能包括中文分词、词性标注、命名实体识别、依存句法分析、语义角色标注等。</p><figure><img src="/img/nlp6_1.png" alt="语言技术平台架构" /><figcaption aria-hidden="true">语言技术平台架构</figcaption></figure><p>pyltp 是 LTP 的 Python封装，同时支持Python2和Python3版本。Python3的安装方法为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install pyltp<br></code></pre></td></tr></table></figure><ul><li><p>官网下载网址：https://pypi.org/project/pyltp/0.1.7/</p></li><li><p>官方使用说明文档：https://pyltp.readthedocs.io/zh_CN/develop/api.html</p><p>在使用该模块前，需要下载完整的模型文件，文件下载地址为：<ahref="https://pan.baidu.com/share/link?shareid=1988562907&amp;uk=2738088569#list/path=%2F">https://pan.baidu.com/share/link?shareid=1988562907&amp;uk=2738088569#list/path=%2F</a>。pyltp 的所有输入的分析文本和输出的结果的编码均为UTF-8。模型的数据文件如下：</p></li></ul><figure><img src="/img/nlp6_2.png" alt="模型数据" /><figcaption aria-hidden="true">模型数据</figcaption></figure><p>其中，cws.model用于分词模型，lexicon.txt为分词时添加的用户字典，ner.model为命名实体识别模型，parser.model为依存句法分析模型，pisrl.model为语义角色标注模型，pos为词性标注模型。</p><h3 id="pyltp的使用">pyltp的使用</h3><p>pyltp的使用示例项目结构如下：</p><figure><img src="/img/nlp6_3.png" alt="示例项目" /><figcaption aria-hidden="true">示例项目</figcaption></figure><h5 id="分句">分句</h5><p>分句指的是将一段话或一片文章中的文字按句子分开，按句子形成独立的单元。示例的Python代码sentenct_split.py如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> SentenceSplitter<br><br><span class="hljs-comment"># 分句</span><br>doc = <span class="hljs-string">&#x27;据韩联社12月28日反映，美国防部发言人杰夫·莫莱尔27日表示，美国防部长盖茨将于2011年1月14日访问韩国。&#x27;</span> \<br>      <span class="hljs-string">&#x27;盖茨原计划从明年1月9日至14日陆续访问中国和日本，目前，他决定在行程中增加对韩国的访问。莫莱尔表示，&#x27;</span> \<br>      <span class="hljs-string">&#x27;盖茨在访韩期间将会晤韩国国防部长官金宽镇，就朝鲜近日的行动交换意见，同时商讨加强韩美两军同盟关系等问题，&#x27;</span> \<br>      <span class="hljs-string">&#x27;拟定共同应对朝鲜挑衅和核计划的方案。&#x27;</span><br>sents = SentenceSplitter.split(doc)  <span class="hljs-comment"># 分句</span><br><br><br><span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents:<br>    <span class="hljs-built_in">print</span>(sent)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs dns">据韩联社<span class="hljs-number">12</span>月<span class="hljs-number">28</span>日反映，美国防部发言人杰夫·莫莱尔<span class="hljs-number">27</span>日表示，美国防部长盖茨将于<span class="hljs-number">2011年1月14</span>日访问韩国。<br>盖茨原计划从明年<span class="hljs-number">1</span>月<span class="hljs-number">9</span>日至<span class="hljs-number">14</span>日陆续访问中国和日本，目前，他决定在行程中增加对韩国的访问。<br>莫莱尔表示，盖茨在访韩期间将会晤韩国国防部长官金宽镇，就朝鲜近日的行动交换意见，同时商讨加强韩美两军同盟关系等问题，拟定共同应对朝鲜挑衅和核计划的方案。<br></code></pre></td></tr></table></figure><h5 id="分词">分词</h5><p>分词指的是将一句话按词语分开，按词语形成独立的单元。示例的Python代码words_split.py如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> Segmentor<br><br>cws_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/cws.model&#x27;</span>)  <span class="hljs-comment"># 分词模型路径，模型名称为`cws.model`</span><br>lexicon_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/lexicon.txt&#x27;</span>)  <span class="hljs-comment"># 参数lexicon是自定义词典的文件路径</span><br><br>segmentor = Segmentor()<br>segmentor.load_with_lexicon(cws_model_path, lexicon_path)<br><br>sent = <span class="hljs-string">&#x27;据韩联社12月28日反映，美国防部发言人杰夫·莫莱尔27日表示，美国防部长盖茨将于2011年1月14日访问韩国。&#x27;</span><br>words = segmentor.segment(sent)  <span class="hljs-comment"># 分词</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;/&#x27;</span>.join(words))<br><br>segmentor.release()<br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">据<span class="hljs-regexp">/韩联社/</span><span class="hljs-number">12</span>月<span class="hljs-regexp">/28日/</span>反映<span class="hljs-regexp">/，/</span>美<span class="hljs-regexp">/国防部/</span>发言人<span class="hljs-regexp">/杰夫·莫莱尔/</span><span class="hljs-number">27</span>日<span class="hljs-regexp">/表示/</span>，<span class="hljs-regexp">/美/</span>国防部长<span class="hljs-regexp">/盖茨/</span>将<span class="hljs-regexp">/于/</span><span class="hljs-number">2011</span>年<span class="hljs-regexp">/1月/</span><span class="hljs-number">14</span>日<span class="hljs-regexp">/访问/</span>韩国/。<br></code></pre></td></tr></table></figure><h5 id="词性标注">词性标注</h5><p>词性标注指的是一句话分完词后，制定每个词语的词性。示例的Python代码postagger.py如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> Segmentor, Postagger<br><br><span class="hljs-comment"># 分词</span><br>cws_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/cws.model&#x27;</span>)  <span class="hljs-comment"># 分词模型路径，模型名称为`cws.model`</span><br>lexicon_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/lexicon.txt&#x27;</span>)  <span class="hljs-comment"># 参数lexicon是自定义词典的文件路径</span><br><br>segmentor = Segmentor()<br>segmentor.load_with_lexicon(cws_model_path, lexicon_path)<br><br>sent = <span class="hljs-string">&#x27;据韩联社12月28日反映，美国防部发言人杰夫·莫莱尔27日表示，美国防部长盖茨将于2011年1月14日访问韩国。&#x27;</span><br>words = segmentor.segment(sent)  <span class="hljs-comment"># 分词</span><br><br><span class="hljs-comment"># 词性标注</span><br>pos_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/pos.model&#x27;</span>)  <span class="hljs-comment"># 词性标注模型路径，模型名称为`pos.model`</span><br><br>postagger = Postagger()  <span class="hljs-comment"># 初始化实例</span><br>postagger.load(pos_model_path)  <span class="hljs-comment"># 加载模型</span><br>postags = postagger.postag(words)  <span class="hljs-comment"># 词性标注</span><br><br><span class="hljs-keyword">for</span> word, postag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(words, postags):<br>    <span class="hljs-built_in">print</span>(word, postag)<br><br><span class="hljs-comment"># 释放模型</span><br>segmentor.release()<br>postagger.release()<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">词性标注结果说明</span><br><span class="hljs-string">https://ltp.readthedocs.io/zh_CN/latest/appendix.html#id3</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs excel">据 p<br>韩联社 ni<br><span class="hljs-number">12</span>月 nt<br><span class="hljs-number">28</span>日 nt<br>反映 v<br>， wp<br>美 j<br>国防部 <span class="hljs-built_in">n</span><br>发言人 <span class="hljs-built_in">n</span><br>杰夫·莫莱尔 nh<br><span class="hljs-number">27</span>日 nt<br>表示 v<br>， wp<br>美 j<br>国防部长 <span class="hljs-built_in">n</span><br>盖茨 nh<br>将 d<br>于 p<br><span class="hljs-number">2011</span>年 nt<br><span class="hljs-number">1</span>月 nt<br><span class="hljs-number">14</span>日 nt<br>访问 v<br>韩国 ns<br>。 wp<br></code></pre></td></tr></table></figure><p>词性标注结果可参考网址：<ahref="https://ltp.readthedocs.io/zh_CN/latest/appendix.html">https://ltp.readthedocs.io/zh_CN/latest/appendix.html</a>。</p><h5 id="命名实体识别">命名实体识别</h5><p>命名实体识别（NER）指的是识别出一句话或一段话或一片文章中的命名实体，比如人名，地名，组织机构名。示例的Python代码ner.py如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> Segmentor, Postagger<br><br><span class="hljs-comment"># 分词</span><br>cws_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/cws.model&#x27;</span>)  <span class="hljs-comment"># 分词模型路径，模型名称为`cws.model`</span><br>lexicon_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/lexicon.txt&#x27;</span>)  <span class="hljs-comment"># 参数lexicon是自定义词典的文件路径</span><br><br>segmentor = Segmentor()<br>segmentor.load_with_lexicon(cws_model_path, lexicon_path)<br><br>sent = <span class="hljs-string">&#x27;据韩联社12月28日反映，美国防部发言人杰夫·莫莱尔27日表示，美国防部长盖茨将于2011年1月14日访问韩国。&#x27;</span><br>words = segmentor.segment(sent)  <span class="hljs-comment"># 分词</span><br><br><span class="hljs-comment"># 词性标注</span><br>pos_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/pos.model&#x27;</span>)  <span class="hljs-comment"># 词性标注模型路径，模型名称为`pos.model`</span><br><br>postagger = Postagger()  <span class="hljs-comment"># 初始化实例</span><br>postagger.load(pos_model_path)  <span class="hljs-comment"># 加载模型</span><br>postags = postagger.postag(words)  <span class="hljs-comment"># 词性标注</span><br><br><br>ner_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/ner.model&#x27;</span>)   <span class="hljs-comment"># 命名实体识别模型路径，模型名称为`pos.model`</span><br><br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> NamedEntityRecognizer<br>recognizer = NamedEntityRecognizer() <span class="hljs-comment"># 初始化实例</span><br>recognizer.load(ner_model_path)  <span class="hljs-comment"># 加载模型</span><br><span class="hljs-comment"># netags = recognizer.recognize(words, postags)  # 命名实体识别</span><br><br><br><span class="hljs-comment"># 提取识别结果中的人名，地名，组织机构名</span><br><br>persons, places, orgs = <span class="hljs-built_in">set</span>(), <span class="hljs-built_in">set</span>(), <span class="hljs-built_in">set</span>()<br><br><br>netags = <span class="hljs-built_in">list</span>(recognizer.recognize(words, postags))  <span class="hljs-comment"># 命名实体识别</span><br><span class="hljs-built_in">print</span>(netags)<br><span class="hljs-comment"># print(netags)</span><br>i = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> tag, word <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(netags, words):<br>    j = i<br>    <span class="hljs-comment"># 人名</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;Nh&#x27;</span> <span class="hljs-keyword">in</span> tag:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;S&#x27;</span>):<br>            persons.add(word)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;B&#x27;</span>):<br>            union_person = word<br>            <span class="hljs-keyword">while</span> netags[j] != <span class="hljs-string">&#x27;E-Nh&#x27;</span>:<br>                j += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> j &lt; <span class="hljs-built_in">len</span>(words):<br>                    union_person += words[j]<br>            persons.add(union_person)<br>    <span class="hljs-comment"># 地名</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;Ns&#x27;</span> <span class="hljs-keyword">in</span> tag:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;S&#x27;</span>):<br>            places.add(word)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;B&#x27;</span>):<br>            union_place = word<br>            <span class="hljs-keyword">while</span> netags[j] != <span class="hljs-string">&#x27;E-Ns&#x27;</span>:<br>                j += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> j &lt; <span class="hljs-built_in">len</span>(words):<br>                    union_place += words[j]<br>            places.add(union_place)<br>    <span class="hljs-comment"># 机构名</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;Ni&#x27;</span> <span class="hljs-keyword">in</span> tag:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;S&#x27;</span>):<br>            orgs.add(word)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">str</span>(tag).startswith(<span class="hljs-string">&#x27;B&#x27;</span>):<br>            union_org = word<br>            <span class="hljs-keyword">while</span> netags[j] != <span class="hljs-string">&#x27;E-Ni&#x27;</span>:<br>                j += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> j &lt; <span class="hljs-built_in">len</span>(words):<br>                    union_org += words[j]<br>            orgs.add(union_org)<br><br>    i += <span class="hljs-number">1</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;人名：&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>.join(persons))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;地名：&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>.join(places))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;组织机构：&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>.join(orgs))<br><br><br><span class="hljs-comment"># 释放模型</span><br>segmentor.release()<br>postagger.release()<br>recognizer.release()<br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Ni&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-Ni&#x27;</span>, <span class="hljs-string">&#x27;E-Ni&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Nh&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Ns&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Nh&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;S-Ns&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]</span><br>人名： 杰夫·莫莱尔，盖茨<br>地名： 美，韩国<br>组织机构： 韩联社，美国防部<br></code></pre></td></tr></table></figure><p>命名实体识别结果可参考网址：<ahref="https://ltp.readthedocs.io/zh_CN/latest/appendix.html">https://ltp.readthedocs.io/zh_CN/latest/appendix.html</a>。</p><h4 id="依存句法分析">依存句法分析</h4><p>依存语法 (Dependency Parsing, DP)通过分析语言单位内成分之间的依存关系揭示其句法结构。直观来讲，依存句法分析识别句子中的“主谓宾”、“定状补”这些语法成分，并分析各成分之间的关系。示例的Python代码parser.py代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> Segmentor, Postagger, Parser<br><br><span class="hljs-comment"># 分词</span><br>cws_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/cws.model&#x27;</span>)  <span class="hljs-comment"># 分词模型路径，模型名称为`cws.model`</span><br>lexicon_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/lexicon.txt&#x27;</span>)  <span class="hljs-comment"># 参数lexicon是自定义词典的文件路径</span><br><br>segmentor = Segmentor()<br>segmentor.load_with_lexicon(cws_model_path, lexicon_path)<br><br>sent = <span class="hljs-string">&#x27;据韩联社12月28日反映，美国防部发言人杰夫·莫莱尔27日表示，美国防部长盖茨将于2011年1月14日访问韩国。&#x27;</span><br>words = segmentor.segment(sent)  <span class="hljs-comment"># 分词</span><br><br><span class="hljs-comment"># 词性标注</span><br>pos_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/pos.model&#x27;</span>)  <span class="hljs-comment"># 词性标注模型路径，模型名称为`pos.model`</span><br><br>postagger = Postagger()  <span class="hljs-comment"># 初始化实例</span><br>postagger.load(pos_model_path)  <span class="hljs-comment"># 加载模型</span><br>postags = postagger.postag(words)  <span class="hljs-comment"># 词性标注</span><br><br><br><span class="hljs-comment"># 依存句法分析</span><br>par_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/parser.model&#x27;</span>)  <span class="hljs-comment"># 模型路径，模型名称为`parser.model`</span><br><br>parser = Parser() <span class="hljs-comment"># 初始化实例</span><br>parser.load(par_model_path)  <span class="hljs-comment"># 加载模型</span><br>arcs = parser.parse(words, postags)  <span class="hljs-comment"># 句法分析</span><br><br>rely_id = [arc.head <span class="hljs-keyword">for</span> arc <span class="hljs-keyword">in</span> arcs]  <span class="hljs-comment"># 提取依存父节点id</span><br>relation = [arc.relation <span class="hljs-keyword">for</span> arc <span class="hljs-keyword">in</span> arcs]  <span class="hljs-comment"># 提取依存关系</span><br>heads = [<span class="hljs-string">&#x27;Root&#x27;</span> <span class="hljs-keyword">if</span> <span class="hljs-built_in">id</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> words[<span class="hljs-built_in">id</span>-<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> <span class="hljs-built_in">id</span> <span class="hljs-keyword">in</span> rely_id]  <span class="hljs-comment"># 匹配依存父节点词语</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(words)):<br>    <span class="hljs-built_in">print</span>(relation[i] + <span class="hljs-string">&#x27;(&#x27;</span> + words[i] + <span class="hljs-string">&#x27;, &#x27;</span> + heads[i] + <span class="hljs-string">&#x27;)&#x27;</span>)<br><br><span class="hljs-comment"># 释放模型</span><br>segmentor.release()<br>postagger.release()<br>parser.release()<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">ADV</span><span class="hljs-params">(据, 表示)</span></span><br><span class="hljs-function"><span class="hljs-title">SBV</span><span class="hljs-params">(韩联社, 反映)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(<span class="hljs-number">12</span>月, <span class="hljs-number">28</span>日)</span></span><br><span class="hljs-function"><span class="hljs-title">ADV</span><span class="hljs-params">(<span class="hljs-number">28</span>日, 反映)</span></span><br><span class="hljs-function"><span class="hljs-title">POB</span><span class="hljs-params">(反映, 据)</span></span><br><span class="hljs-function"><span class="hljs-title">WP</span><span class="hljs-params">(，, 据)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(美, 国防部)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(国防部, 发言人)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(发言人, 杰夫·莫莱尔)</span></span><br><span class="hljs-function"><span class="hljs-title">SBV</span><span class="hljs-params">(杰夫·莫莱尔, 表示)</span></span><br><span class="hljs-function"><span class="hljs-title">ADV</span><span class="hljs-params">(<span class="hljs-number">27</span>日, 表示)</span></span><br><span class="hljs-function"><span class="hljs-title">HED</span><span class="hljs-params">(表示, Root)</span></span><br><span class="hljs-function"><span class="hljs-title">WP</span><span class="hljs-params">(，, 表示)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(美, 国防部长)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(国防部长, 盖茨)</span></span><br><span class="hljs-function"><span class="hljs-title">SBV</span><span class="hljs-params">(盖茨, 访问)</span></span><br><span class="hljs-function"><span class="hljs-title">ADV</span><span class="hljs-params">(将, 访问)</span></span><br><span class="hljs-function"><span class="hljs-title">ADV</span><span class="hljs-params">(于, 访问)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(<span class="hljs-number">2011</span>年, <span class="hljs-number">14</span>日)</span></span><br><span class="hljs-function"><span class="hljs-title">ATT</span><span class="hljs-params">(<span class="hljs-number">1</span>月, <span class="hljs-number">14</span>日)</span></span><br><span class="hljs-function"><span class="hljs-title">POB</span><span class="hljs-params">(<span class="hljs-number">14</span>日, 于)</span></span><br><span class="hljs-function"><span class="hljs-title">VOB</span><span class="hljs-params">(访问, 表示)</span></span><br><span class="hljs-function"><span class="hljs-title">VOB</span><span class="hljs-params">(韩国, 访问)</span></span><br><span class="hljs-function"><span class="hljs-title">WP</span><span class="hljs-params">(。, 表示)</span></span><br></code></pre></td></tr></table></figure><p>依存句法分析结果可参考网址：<ahref="https://ltp.readthedocs.io/zh_CN/latest/appendix.html">https://ltp.readthedocs.io/zh_CN/latest/appendix.html</a>。</p><h5 id="语义角色标注">语义角色标注</h5><p>语义角色标注是实现浅层语义分析的一种方式。在一个句子中，谓词是对主语的陈述或说明，指出“做什么”、“是什么”或“怎么样，代表了一个事件的核心，跟谓词搭配的名词称为论元。语义角色是指论元在动词所指事件中担任的角色。主要有：施事者（Agent）、受事者（Patient）、客体（Theme）、经验者（Experiencer）、受益者（Beneficiary）、工具（Instrument）、处所（Location）、目标（Goal）和来源（Source）等。示例的Python代码rolelabel.py如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> pyltp <span class="hljs-keyword">import</span> Segmentor, Postagger, Parser, SementicRoleLabeller<br><br><span class="hljs-comment"># 分词</span><br>cws_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/cws.model&#x27;</span>)  <span class="hljs-comment"># 分词模型路径，模型名称为`cws.model`</span><br>lexicon_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/lexicon.txt&#x27;</span>)  <span class="hljs-comment"># 参数lexicon是自定义词典的文件路径</span><br><br>segmentor = Segmentor()<br>segmentor.load_with_lexicon(cws_model_path, lexicon_path)<br><br>sent = <span class="hljs-string">&#x27;据韩联社12月28日反映，美国防部发言人杰夫·莫莱尔27日表示，美国防部长盖茨将于2011年1月14日访问韩国。&#x27;</span><br>words = segmentor.segment(sent)  <span class="hljs-comment"># 分词</span><br><br><span class="hljs-comment"># 词性标注</span><br>pos_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/pos.model&#x27;</span>)  <span class="hljs-comment"># 词性标注模型路径，模型名称为`pos.model`</span><br><br>postagger = Postagger()  <span class="hljs-comment"># 初始化实例</span><br>postagger.load(pos_model_path)  <span class="hljs-comment"># 加载模型</span><br>postags = postagger.postag(words)  <span class="hljs-comment"># 词性标注</span><br><br><span class="hljs-comment"># 依存句法分析</span><br>par_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/parser.model&#x27;</span>)  <span class="hljs-comment"># 模型路径，模型名称为`parser.model`</span><br><br>parser = Parser() <span class="hljs-comment"># 初始化实例</span><br>parser.load(par_model_path)  <span class="hljs-comment"># 加载模型</span><br>arcs = parser.parse(words, postags)  <span class="hljs-comment"># 句法分析</span><br><br><span class="hljs-comment"># 语义角色标注</span><br>srl_model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data/pisrl.model&#x27;</span>)  <span class="hljs-comment"># 语义角色标注模型目录路径</span><br>labeller = SementicRoleLabeller() <span class="hljs-comment"># 初始化实例</span><br>labeller.load(srl_model_path)  <span class="hljs-comment"># 加载模型</span><br>roles = labeller.label(words, postags, arcs)  <span class="hljs-comment"># 语义角色标注</span><br><br><span class="hljs-comment"># 打印结果</span><br><span class="hljs-keyword">for</span> role <span class="hljs-keyword">in</span> roles:<br>    <span class="hljs-built_in">print</span>(words[role.index], end=<span class="hljs-string">&#x27; &#x27;</span>)<br>    <span class="hljs-built_in">print</span>(role.index, <span class="hljs-string">&quot;&quot;</span>.join([<span class="hljs-string">&quot;%s:(%d,%d)&quot;</span> % (arg.name, arg.<span class="hljs-built_in">range</span>.start, arg.<span class="hljs-built_in">range</span>.end) <span class="hljs-keyword">for</span> arg <span class="hljs-keyword">in</span> role.arguments]))<br><br><span class="hljs-comment"># 释放模型</span><br>segmentor.release()<br>postagger.release()<br>parser.release()<br>labeller.release()<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">反映 <span class="hljs-number">4</span> <span class="hljs-built_in">A0</span>:(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<span class="hljs-built_in">A0</span>:(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<br>表示 <span class="hljs-number">11</span> MNR:(<span class="hljs-number">0</span>,<span class="hljs-number">5</span>)<span class="hljs-built_in">A0</span>:(<span class="hljs-number">6</span>,<span class="hljs-number">9</span>)TMP:(<span class="hljs-number">10</span>,<span class="hljs-number">10</span>)<span class="hljs-built_in">A1</span>:(<span class="hljs-number">13</span>,<span class="hljs-number">22</span>)<br>访问 <span class="hljs-number">21</span> <span class="hljs-built_in">A0</span>:(<span class="hljs-number">13</span>,<span class="hljs-number">15</span>)ADV:(<span class="hljs-number">16</span>,<span class="hljs-number">16</span>)TMP:(<span class="hljs-number">17</span>,<span class="hljs-number">20</span>)<span class="hljs-built_in">A1</span>:(<span class="hljs-number">22</span>,<span class="hljs-number">22</span>)<br></code></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>本文介绍了中文NLP的一个杰出工具pyltp，并给出了该模块的各个功能的一个示例，希望能给读者一些思考与启示。本文到此结束，感谢大家阅读~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>pyltp</tag>
      
      <tag>NLP工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP入门（五）用深度学习实现命名实体识别（NER）</title>
    <link href="/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%94%EF%BC%89%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%8E%B0%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%EF%BC%88NER%EF%BC%89/"/>
    <url>/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%94%EF%BC%89%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%8E%B0%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%EF%BC%88NER%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="前言">前言</h3><p>在文章：<ahref="https://percent4.github.io/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%9B%9B%EF%BC%89%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%EF%BC%88NER%EF%BC%89/">NLP入门（四）命名实体识别（NER）</a>中，笔者介绍了两个实现命名实体识别的工具——NLTK和StanfordNLP。在本文中，我们将会学习到如何使用深度学习工具来自己一步步地实现NER，只要你坚持看完，就一定会很有收获的。</p><p>OK，话不多说，让我们进入正题。</p><p>几乎所有的NLP都依赖一个强大的语料库，本项目实现NER的语料库如下(文件名为train.txt，一共42000行，这里只展示前15行，可以在文章最后的Github地址下载该语料库)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">playedonMonday(hometeam<span class="hljs-keyword">in</span>CAPS):<br>VBDINNNP(NNNNINNNP):<br>OOOOOOOOOO<br>AmericanLeague<br>NNPNNP<br>B-MISCI-MISC<br>Cleveland2DETROIT1<br>NNPCDNNPCD<br>B-ORGOB-ORGO<br>BALTIMORE12Oakland11(10innings)<br>VBCDNNPCD(CDNN)<br>B-ORGOB-ORGOOOOO<br>TORONTO5Minnesota3<br>TOCDNNPCD<br>B-ORGOB-ORGO<br>......<br></code></pre></td></tr></table></figure><p>简单介绍下该语料库的结构：该语料库一共42000行，每三行为一组，其中，第一行为英语句子，第二行为每个句子的词性（关于英语单词的词性，可参考文章：<ahref="https://percent4.github.io/2023/07/06/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%E8%AF%8D%E5%BD%A2%E8%BF%98%E5%8E%9F%EF%BC%88Lemmatization%EF%BC%89/">NLP入门（三）词形还原（Lemmatization）</a>），第三行为NER系统的标注，具体的含义会在之后介绍。</p><p>我们的NER项目的名称为DL_4_NER，结构如下：</p><figure><img src="/img/nlp5_1.png" alt="NER项目名称" /><figcaption aria-hidden="true">NER项目名称</figcaption></figure><p>项目中每个文件的功能如下：</p><ul><li><p>utils.py: 项目配置及数据导入</p></li><li><p>data_processing.py: 数据探索</p></li><li><p>Bi_LSTM_Model_training.py: 模型创建及训练</p></li><li><p>Bi_LSTM_Model_predict.py: 对新句子进行NER预测</p><p>接下来，笔者将结合代码文件，分部介绍该项目的步骤，当所有步骤介绍完毕后，我们的项目就结束了，而你，也就知道了如何用深度学习实现命名实体识别（NER）。</p><p>Let's begin!</p></li></ul><h3 id="项目配置">项目配置</h3><p>第一步，是项目的配置及数据导入，在utils.py文件中实现，完整的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># basic settings for DL_4_NER Project</span><br>BASE_DIR = <span class="hljs-string">&quot;F://NERSystem&quot;</span><br>CORPUS_PATH = <span class="hljs-string">&quot;%s/train.txt&quot;</span> % BASE_DIR<br><br>KERAS_MODEL_SAVE_PATH = <span class="hljs-string">&#x27;%s/Bi-LSTM-4-NER.h5&#x27;</span> % BASE_DIR<br>WORD_DICTIONARY_PATH = <span class="hljs-string">&#x27;%s/word_dictionary.pk&#x27;</span> % BASE_DIR<br>InVERSE_WORD_DICTIONARY_PATH = <span class="hljs-string">&#x27;%s/inverse_word_dictionary.pk&#x27;</span> % BASE_DIR<br>LABEL_DICTIONARY_PATH = <span class="hljs-string">&#x27;%s/label_dictionary.pk&#x27;</span> % BASE_DIR<br>OUTPUT_DICTIONARY_PATH = <span class="hljs-string">&#x27;%s/output_dictionary.pk&#x27;</span> % BASE_DIR<br><br>CONSTANTS = [<br>             KERAS_MODEL_SAVE_PATH,<br>             InVERSE_WORD_DICTIONARY_PATH,<br>             WORD_DICTIONARY_PATH,<br>             LABEL_DICTIONARY_PATH,<br>             OUTPUT_DICTIONARY_PATH<br>             ]<br><br><span class="hljs-comment"># load data from corpus to from pandas DataFrame</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(CORPUS_PATH, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        text_data = [text.strip() <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> f.readlines()]<br>    text_data = [text_data[k].split(<span class="hljs-string">&#x27;\t&#x27;</span>) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(text_data))]<br>    index = <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(text_data), <span class="hljs-number">3</span>)<br><br>    <span class="hljs-comment"># Transforming data to matrix format for neural network</span><br>    input_data = <span class="hljs-built_in">list</span>()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(index) - <span class="hljs-number">1</span>):<br>        rows = text_data[index[i-<span class="hljs-number">1</span>]:index[i]]<br>        sentence_no = np.array([i]*<span class="hljs-built_in">len</span>(rows[<span class="hljs-number">0</span>]), dtype=<span class="hljs-built_in">str</span>)<br>        rows.append(sentence_no)<br>        rows = np.array(rows).T<br>        input_data.append(rows)<br><br>    input_data = pd.DataFrame(np.concatenate([item <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> input_data]),\<br>                               columns=[<span class="hljs-string">&#x27;word&#x27;</span>, <span class="hljs-string">&#x27;pos&#x27;</span>, <span class="hljs-string">&#x27;tag&#x27;</span>, <span class="hljs-string">&#x27;sent_no&#x27;</span>])<br><br>    <span class="hljs-keyword">return</span> input_data<br></code></pre></td></tr></table></figure><p>在该代码中，先是设置了语料库文件的路径CORPUS_PATH，KERAS模型保存路径KERAS_MODEL_SAVE_PATH，以及在项目过程中会用到的三个字典的保存路径（以pickle文件形式保存）WORD_DICTIONARY_PATH，LABEL_DICTIONARY_PATH，OUTPUT_DICTIONARY_PATH。然后是load_data()函数，它将语料库中的文本以Pandas中的DataFrame结构展示出来，该数据框的前30行如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs apache">         <span class="hljs-attribute">word</span>  pos     tag sent_no<br><span class="hljs-attribute">0</span>      played  VBD       O       <span class="hljs-number">1</span><br><span class="hljs-attribute">1</span>          <span class="hljs-literal">on</span>   IN       O       <span class="hljs-number">1</span><br><span class="hljs-attribute">2</span>      Monday  NNP       O       <span class="hljs-number">1</span><br><span class="hljs-attribute">3</span>           (    (       O       <span class="hljs-number">1</span><br><span class="hljs-attribute">4</span>        home   NN       O       <span class="hljs-number">1</span><br><span class="hljs-attribute">5</span>        team   NN       O       <span class="hljs-number">1</span><br><span class="hljs-attribute">6</span>          in   IN       O       <span class="hljs-number">1</span><br><span class="hljs-attribute">7</span>        CAPS  NNP       O       <span class="hljs-number">1</span><br><span class="hljs-attribute">8</span>           )    )       O       <span class="hljs-number">1</span><br><span class="hljs-attribute">9</span>           :    :       O       <span class="hljs-number">1</span><br><span class="hljs-attribute">10</span>   American  NNP  B-MISC       <span class="hljs-number">2</span><br><span class="hljs-attribute">11</span>     League  NNP  I-MISC       <span class="hljs-number">2</span><br><span class="hljs-attribute">12</span>  Cleveland  NNP   B-ORG       <span class="hljs-number">3</span><br><span class="hljs-attribute">13</span>          <span class="hljs-number">2</span>   CD       O       <span class="hljs-number">3</span><br><span class="hljs-attribute">14</span>    DETROIT  NNP   B-ORG       <span class="hljs-number">3</span><br><span class="hljs-attribute">15</span>          <span class="hljs-number">1</span>   CD       O       <span class="hljs-number">3</span><br><span class="hljs-attribute">16</span>  BALTIMORE   VB   B-ORG       <span class="hljs-number">4</span><br><span class="hljs-attribute">17</span>         <span class="hljs-number">12</span>   CD       O       <span class="hljs-number">4</span><br><span class="hljs-attribute">18</span>    Oakland  NNP   B-ORG       <span class="hljs-number">4</span><br><span class="hljs-attribute">19</span>         <span class="hljs-number">11</span>   CD       O       <span class="hljs-number">4</span><br><span class="hljs-attribute">20</span>          (    (       O       <span class="hljs-number">4</span><br><span class="hljs-attribute">21</span>         <span class="hljs-number">10</span>   CD       O       <span class="hljs-number">4</span><br><span class="hljs-attribute">22</span>    innings   NN       O       <span class="hljs-number">4</span><br><span class="hljs-attribute">23</span>          )    )       O       <span class="hljs-number">4</span><br><span class="hljs-attribute">24</span>    TORONTO   TO   B-ORG       <span class="hljs-number">5</span><br><span class="hljs-attribute">25</span>          <span class="hljs-number">5</span>   CD       O       <span class="hljs-number">5</span><br><span class="hljs-attribute">26</span>  Minnesota  NNP   B-ORG       <span class="hljs-number">5</span><br><span class="hljs-attribute">27</span>          <span class="hljs-number">3</span>   CD       O       <span class="hljs-number">5</span><br><span class="hljs-attribute">28</span>  Milwaukee  NNP   B-ORG       <span class="hljs-number">6</span><br><span class="hljs-attribute">29</span>          <span class="hljs-number">3</span>   CD       O       <span class="hljs-number">6</span><br></code></pre></td></tr></table></figure><p>在该数据框中，word这一列表示文本语料库中的单词，pos这一列表示该单词的词性，tag这一列表示NER的标注，sent_no这一列表示该单词在第几个句子中。</p><h3 id="数据探索">数据探索</h3><p>接着，第二步是数据探索，即对输入的数据（input_data）进行一些数据review，完整的代码（data_processing.py）如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter<br><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> accumulate<br><span class="hljs-keyword">from</span> operator <span class="hljs-keyword">import</span> itemgetter<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> BASE_DIR, CONSTANTS, load_data<br><br><span class="hljs-comment"># 设置matplotlib绘图时的字体</span><br>mpl.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>]=[<span class="hljs-string">&#x27;SimHei&#x27;</span>]<br><br><span class="hljs-comment"># 数据查看</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_review</span>():<br><br>    <span class="hljs-comment"># 数据导入</span><br>    input_data = load_data()<br><br>    <span class="hljs-comment"># 基本的数据review</span><br>    sent_num = input_data[<span class="hljs-string">&#x27;sent_no&#x27;</span>].astype(np.<span class="hljs-built_in">int</span>).<span class="hljs-built_in">max</span>()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;一共有%s个句子。\n&quot;</span>%sent_num)<br><br>    vocabulary = input_data[<span class="hljs-string">&#x27;word&#x27;</span>].unique()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;一共有%d个单词。&quot;</span>%<span class="hljs-built_in">len</span>(vocabulary))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;前10个单词为：%s.\n&quot;</span>%vocabulary[:<span class="hljs-number">11</span>])<br><br>    pos_arr = input_data[<span class="hljs-string">&#x27;pos&#x27;</span>].unique()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;单词的词性列表：%s.\n&quot;</span>%pos_arr)<br><br>    ner_tag_arr = input_data[<span class="hljs-string">&#x27;tag&#x27;</span>].unique()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;NER的标注列表：%s.\n&quot;</span> % ner_tag_arr)<br><br>    df = input_data[[<span class="hljs-string">&#x27;word&#x27;</span>, <span class="hljs-string">&#x27;sent_no&#x27;</span>]].groupby(<span class="hljs-string">&#x27;sent_no&#x27;</span>).count()<br>    sent_len_list = df[<span class="hljs-string">&#x27;word&#x27;</span>].tolist()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;句子长度及出现频数字典：\n%s.&quot;</span> % <span class="hljs-built_in">dict</span>(Counter(sent_len_list)))<br><br>    <span class="hljs-comment"># 绘制句子长度及出现频数统计图</span><br>    sort_sent_len_dist = <span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">dict</span>(Counter(sent_len_list)).items(), key=itemgetter(<span class="hljs-number">0</span>))<br>    sent_no_data = [item[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> sort_sent_len_dist]<br>    sent_count_data = [item[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> sort_sent_len_dist]<br>    plt.bar(sent_no_data, sent_count_data)<br>    plt.title(<span class="hljs-string">&quot;句子长度及出现频数统计图&quot;</span>)<br>    plt.xlabel(<span class="hljs-string">&quot;句子长度&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;句子长度出现的频数&quot;</span>)<br>    plt.savefig(<span class="hljs-string">&quot;%s/句子长度及出现频数统计图.png&quot;</span> % BASE_DIR)<br>    plt.close()<br><br>    <span class="hljs-comment"># 绘制句子长度累积分布函数(CDF)</span><br>    sent_pentage_list = [(count/sent_num) <span class="hljs-keyword">for</span> count <span class="hljs-keyword">in</span> accumulate(sent_count_data)]<br><br>    <span class="hljs-comment"># 寻找分位点为quantile的句子长度</span><br>    quantile = <span class="hljs-number">0.9992</span><br>    <span class="hljs-comment">#print(list(sent_pentage_list))</span><br>    <span class="hljs-keyword">for</span> length, per <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(sent_no_data, sent_pentage_list):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">round</span>(per, <span class="hljs-number">4</span>) == quantile:<br>            index = length<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n分位点为%s的句子长度:%d.&quot;</span> % (quantile, index))<br><br>    <span class="hljs-comment"># 绘制CDF</span><br>    plt.plot(sent_no_data, sent_pentage_list)<br>    plt.hlines(quantile, <span class="hljs-number">0</span>, index, colors=<span class="hljs-string">&quot;c&quot;</span>, linestyles=<span class="hljs-string">&quot;dashed&quot;</span>)<br>    plt.vlines(index, <span class="hljs-number">0</span>, quantile, colors=<span class="hljs-string">&quot;c&quot;</span>, linestyles=<span class="hljs-string">&quot;dashed&quot;</span>)<br>    plt.text(<span class="hljs-number">0</span>, quantile, <span class="hljs-built_in">str</span>(quantile))<br>    plt.text(index, <span class="hljs-number">0</span>, <span class="hljs-built_in">str</span>(index))<br>    plt.title(<span class="hljs-string">&quot;句子长度累积分布函数图&quot;</span>)<br>    plt.xlabel(<span class="hljs-string">&quot;句子长度&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;句子长度累积频率&quot;</span>)<br>    plt.savefig(<span class="hljs-string">&quot;%s/句子长度累积分布函数图.png&quot;</span> % BASE_DIR)<br>    plt.close()<br><br><span class="hljs-comment"># 数据处理</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_processing</span>():<br>    <span class="hljs-comment"># 数据导入</span><br>    input_data = load_data()<br><br>    <span class="hljs-comment"># 标签及词汇表</span><br>    labels, vocabulary = <span class="hljs-built_in">list</span>(input_data[<span class="hljs-string">&#x27;tag&#x27;</span>].unique()), <span class="hljs-built_in">list</span>(input_data[<span class="hljs-string">&#x27;word&#x27;</span>].unique())<br><br>    <span class="hljs-comment"># 字典列表</span><br>    word_dictionary = &#123;word: i+<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> i, word <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(vocabulary)&#125;<br>    inverse_word_dictionary = &#123;i+<span class="hljs-number">1</span>: word <span class="hljs-keyword">for</span> i, word <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(vocabulary)&#125;<br>    label_dictionary = &#123;label: i+<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels)&#125;<br>    output_dictionary = &#123;i+<span class="hljs-number">1</span>: labels <span class="hljs-keyword">for</span> i, labels <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels)&#125;<br><br>    dict_list = [word_dictionary, inverse_word_dictionary,label_dictionary, output_dictionary]<br><br>    <span class="hljs-comment"># 保存为pickle形式</span><br>    <span class="hljs-keyword">for</span> dict_item, path <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(dict_list, CONSTANTS[<span class="hljs-number">1</span>:]):<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path, <span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            pickle.dump(dict_item, f)<br><br><span class="hljs-comment">#data_review()</span><br></code></pre></td></tr></table></figure><p>调用data_review()函数，输出的结果如下：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs prolog">一共有<span class="hljs-number">13998</span>个句子。<br><br>一共有<span class="hljs-number">24339</span>个单词。<br>前<span class="hljs-number">10</span>个单词为：[<span class="hljs-string">&#x27;played&#x27;</span> <span class="hljs-string">&#x27;on&#x27;</span> <span class="hljs-string">&#x27;Monday&#x27;</span> <span class="hljs-string">&#x27;(&#x27;</span> <span class="hljs-string">&#x27;home&#x27;</span> <span class="hljs-string">&#x27;team&#x27;</span> <span class="hljs-string">&#x27;in&#x27;</span> <span class="hljs-string">&#x27;CAPS&#x27;</span> <span class="hljs-string">&#x27;)&#x27;</span> <span class="hljs-string">&#x27;:&#x27;</span> <span class="hljs-string">&#x27;American&#x27;</span>].<br><br>单词的词性列表：[<span class="hljs-string">&#x27;VBD&#x27;</span> <span class="hljs-string">&#x27;IN&#x27;</span> <span class="hljs-string">&#x27;NNP&#x27;</span> <span class="hljs-string">&#x27;(&#x27;</span> <span class="hljs-string">&#x27;NN&#x27;</span> <span class="hljs-string">&#x27;)&#x27;</span> <span class="hljs-string">&#x27;:&#x27;</span> <span class="hljs-string">&#x27;CD&#x27;</span> <span class="hljs-string">&#x27;VB&#x27;</span> <span class="hljs-string">&#x27;TO&#x27;</span> <span class="hljs-string">&#x27;NNS&#x27;</span> <span class="hljs-string">&#x27;,&#x27;</span> <span class="hljs-string">&#x27;VBP&#x27;</span> <span class="hljs-string">&#x27;VBZ&#x27;</span><br> <span class="hljs-string">&#x27;.&#x27;</span> <span class="hljs-string">&#x27;VBG&#x27;</span> <span class="hljs-string">&#x27;PRP$&#x27;</span> <span class="hljs-string">&#x27;JJ&#x27;</span> <span class="hljs-string">&#x27;CC&#x27;</span> <span class="hljs-string">&#x27;JJS&#x27;</span> <span class="hljs-string">&#x27;RB&#x27;</span> <span class="hljs-string">&#x27;DT&#x27;</span> <span class="hljs-string">&#x27;VBN&#x27;</span> <span class="hljs-string">&#x27;&quot;&#x27;</span> <span class="hljs-string">&#x27;PRP&#x27;</span> <span class="hljs-string">&#x27;WDT&#x27;</span> <span class="hljs-string">&#x27;WRB&#x27;</span><br> <span class="hljs-string">&#x27;MD&#x27;</span> <span class="hljs-string">&#x27;WP&#x27;</span> <span class="hljs-string">&#x27;POS&#x27;</span> <span class="hljs-string">&#x27;JJR&#x27;</span> <span class="hljs-string">&#x27;WP$&#x27;</span> <span class="hljs-string">&#x27;RP&#x27;</span> <span class="hljs-string">&#x27;NNPS&#x27;</span> <span class="hljs-string">&#x27;RBS&#x27;</span> <span class="hljs-string">&#x27;FW&#x27;</span> <span class="hljs-string">&#x27;$&#x27;</span> <span class="hljs-string">&#x27;RBR&#x27;</span> <span class="hljs-string">&#x27;EX&#x27;</span> <span class="hljs-string">&quot;&#x27;&#x27;&quot;</span><br> <span class="hljs-string">&#x27;PDT&#x27;</span> <span class="hljs-string">&#x27;UH&#x27;</span> <span class="hljs-string">&#x27;SYM&#x27;</span> <span class="hljs-string">&#x27;LS&#x27;</span> <span class="hljs-string">&#x27;NN|SYM&#x27;</span>].<br><br><span class="hljs-symbol">NER</span>的标注列表：[<span class="hljs-string">&#x27;O&#x27;</span> <span class="hljs-string">&#x27;B-MISC&#x27;</span> <span class="hljs-string">&#x27;I-MISC&#x27;</span> <span class="hljs-string">&#x27;B-ORG&#x27;</span> <span class="hljs-string">&#x27;I-ORG&#x27;</span> <span class="hljs-string">&#x27;B-PER&#x27;</span> <span class="hljs-string">&#x27;B-LOC&#x27;</span> <span class="hljs-string">&#x27;I-PER&#x27;</span> <span class="hljs-string">&#x27;I-LOC&#x27;</span><br> <span class="hljs-string">&#x27;sO&#x27;</span>].<br><br>句子长度及出现频数字典：<br>&#123;<span class="hljs-number">1</span>: <span class="hljs-number">177</span>, <span class="hljs-number">2</span>: <span class="hljs-number">1141</span>, <span class="hljs-number">3</span>: <span class="hljs-number">620</span>, <span class="hljs-number">4</span>: <span class="hljs-number">794</span>, <span class="hljs-number">5</span>: <span class="hljs-number">769</span>, <span class="hljs-number">6</span>: <span class="hljs-number">639</span>, <span class="hljs-number">7</span>: <span class="hljs-number">999</span>, <span class="hljs-number">8</span>: <span class="hljs-number">977</span>, <span class="hljs-number">9</span>: <span class="hljs-number">841</span>, <span class="hljs-number">10</span>: <span class="hljs-number">501</span>, <span class="hljs-number">11</span>: <span class="hljs-number">395</span>, <span class="hljs-number">12</span>: <span class="hljs-number">316</span>, <span class="hljs-number">13</span>: <span class="hljs-number">339</span>, <span class="hljs-number">14</span>: <span class="hljs-number">291</span>, <span class="hljs-number">15</span>: <span class="hljs-number">275</span>, <span class="hljs-number">16</span>: <span class="hljs-number">225</span>, <span class="hljs-number">17</span>: <span class="hljs-number">229</span>, <span class="hljs-number">18</span>: <span class="hljs-number">212</span>, <span class="hljs-number">19</span>: <span class="hljs-number">197</span>, <span class="hljs-number">20</span>: <span class="hljs-number">221</span>, <span class="hljs-number">21</span>: <span class="hljs-number">228</span>, <span class="hljs-number">22</span>: <span class="hljs-number">221</span>, <span class="hljs-number">23</span>: <span class="hljs-number">230</span>, <span class="hljs-number">24</span>: <span class="hljs-number">210</span>, <span class="hljs-number">25</span>: <span class="hljs-number">207</span>, <span class="hljs-number">26</span>: <span class="hljs-number">224</span>, <span class="hljs-number">27</span>: <span class="hljs-number">188</span>, <span class="hljs-number">28</span>: <span class="hljs-number">199</span>, <span class="hljs-number">29</span>: <span class="hljs-number">214</span>, <span class="hljs-number">30</span>: <span class="hljs-number">183</span>, <span class="hljs-number">31</span>: <span class="hljs-number">202</span>, <span class="hljs-number">32</span>: <span class="hljs-number">167</span>, <span class="hljs-number">33</span>: <span class="hljs-number">167</span>, <span class="hljs-number">34</span>: <span class="hljs-number">141</span>, <span class="hljs-number">35</span>: <span class="hljs-number">130</span>, <span class="hljs-number">36</span>: <span class="hljs-number">119</span>, <span class="hljs-number">37</span>: <span class="hljs-number">105</span>, <span class="hljs-number">38</span>: <span class="hljs-number">112</span>, <span class="hljs-number">39</span>: <span class="hljs-number">98</span>, <span class="hljs-number">40</span>: <span class="hljs-number">78</span>, <span class="hljs-number">41</span>: <span class="hljs-number">74</span>, <span class="hljs-number">42</span>: <span class="hljs-number">63</span>, <span class="hljs-number">43</span>: <span class="hljs-number">51</span>, <span class="hljs-number">44</span>: <span class="hljs-number">42</span>, <span class="hljs-number">45</span>: <span class="hljs-number">39</span>, <span class="hljs-number">46</span>: <span class="hljs-number">19</span>, <span class="hljs-number">47</span>: <span class="hljs-number">22</span>, <span class="hljs-number">48</span>: <span class="hljs-number">19</span>, <span class="hljs-number">49</span>: <span class="hljs-number">15</span>, <span class="hljs-number">50</span>: <span class="hljs-number">16</span>, <span class="hljs-number">51</span>: <span class="hljs-number">8</span>, <span class="hljs-number">52</span>: <span class="hljs-number">9</span>, <span class="hljs-number">53</span>: <span class="hljs-number">5</span>, <span class="hljs-number">54</span>: <span class="hljs-number">4</span>, <span class="hljs-number">55</span>: <span class="hljs-number">9</span>, <span class="hljs-number">56</span>: <span class="hljs-number">2</span>, <span class="hljs-number">57</span>: <span class="hljs-number">2</span>, <span class="hljs-number">58</span>: <span class="hljs-number">2</span>, <span class="hljs-number">59</span>: <span class="hljs-number">2</span>, <span class="hljs-number">60</span>: <span class="hljs-number">3</span>, <span class="hljs-number">62</span>: <span class="hljs-number">2</span>, <span class="hljs-number">66</span>: <span class="hljs-number">1</span>, <span class="hljs-number">67</span>: <span class="hljs-number">1</span>, <span class="hljs-number">69</span>: <span class="hljs-number">1</span>, <span class="hljs-number">71</span>: <span class="hljs-number">1</span>, <span class="hljs-number">72</span>: <span class="hljs-number">1</span>, <span class="hljs-number">78</span>: <span class="hljs-number">1</span>, <span class="hljs-number">80</span>: <span class="hljs-number">1</span>, <span class="hljs-number">113</span>: <span class="hljs-number">1</span>, <span class="hljs-number">124</span>: <span class="hljs-number">1</span>&#125;.<br><br>分位点为<span class="hljs-number">0.9992</span>的句子长度:<span class="hljs-number">60.</span><br></code></pre></td></tr></table></figure><p>在该语料库中，一共有13998个句子，比预期的42000/3=14000个句子少两个。一个有24339个单词，单词量还是蛮大的，当然，这里对单词没有做任何处理，直接保留了语料库中的形式（后期可以继续优化）。单词的词性可以参考文章：<ahref="https://www.jianshu.com/p/79255fe0c5b5">NLP入门（三）词形还原（Lemmatization）</a>。我们需要注意的是，NER的标注列表为['O','B-MISC', 'I-MISC', 'B-ORG' ,'I-ORG', 'B-PER' ,'B-LOC' ,'I-PER','I-LOC','sO']，因此，本项目的NER一共分为四类：PER（人名），LOC（位置），ORG（组织）以及MISC，其中B表示开始，I表示中间，O表示单字词，不计入NER，sO表示特殊单字词。</p><p>接下来，让我们考虑下句子的长度，这对后面的建模时填充的句子长度有有参考作用。句子长度及出现频数的统计图如下：</p><figure><img src="/img/nlp5_2.png" alt="句子长度及出现频数统计图" /><figcaption aria-hidden="true">句子长度及出现频数统计图</figcaption></figure><p>可以看到，句子长度基本在60以下，当然，这也可以在输出的句子长度及出现频数字典中看到。那么，我们是否可以选在一个标准作为后面模型的句子填充的长度呢？答案是，利用出现频数的累计分布函数的分位点，在这里，我们选择分位点为0.9992,对应的句子长度为60，如下图：</p><figure><img src="/img/nlp5_3.png" alt="句子长度累积分布函数图" /><figcaption aria-hidden="true">句子长度累积分布函数图</figcaption></figure><p>接着是数据处理函数data_processing()，它的功能主要是实现单词、标签字典，并保存为pickle文件形式，便于后续直接调用。</p><h3 id="建模">建模</h3><p>在第三步中，我们建立Bi-LSTM模型来训练训练，完整的Python代码（Bi_LSTM_Model_training.py）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> BASE_DIR, CONSTANTS, load_data<br><span class="hljs-keyword">from</span> data_processing <span class="hljs-keyword">import</span> data_processing<br><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> np_utils, plot_model<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential<br><span class="hljs-keyword">from</span> keras.preprocessing.sequence <span class="hljs-keyword">import</span> pad_sequences<br><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Bidirectional, LSTM, Dense, Embedding, TimeDistributed<br><br><br><span class="hljs-comment"># 模型输入数据</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">input_data_for_model</span>(<span class="hljs-params">input_shape</span>):<br><br>    <span class="hljs-comment"># 数据导入</span><br>    input_data = load_data()<br>    <span class="hljs-comment"># 数据处理</span><br>    data_processing()<br>    <span class="hljs-comment"># 导入字典</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(CONSTANTS[<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        word_dictionary = pickle.load(f)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(CONSTANTS[<span class="hljs-number">2</span>], <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        inverse_word_dictionary = pickle.load(f)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(CONSTANTS[<span class="hljs-number">3</span>], <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        label_dictionary = pickle.load(f)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(CONSTANTS[<span class="hljs-number">4</span>], <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        output_dictionary = pickle.load(f)<br>    vocab_size = <span class="hljs-built_in">len</span>(word_dictionary.keys())<br>    label_size = <span class="hljs-built_in">len</span>(label_dictionary.keys())<br><br>    <span class="hljs-comment"># 处理输入数据</span><br>    aggregate_function = <span class="hljs-keyword">lambda</span> <span class="hljs-built_in">input</span>: [(word, pos, label) <span class="hljs-keyword">for</span> word, pos, label <span class="hljs-keyword">in</span><br>                                            <span class="hljs-built_in">zip</span>(<span class="hljs-built_in">input</span>[<span class="hljs-string">&#x27;word&#x27;</span>].values.tolist(),<br>                                                <span class="hljs-built_in">input</span>[<span class="hljs-string">&#x27;pos&#x27;</span>].values.tolist(),<br>                                                <span class="hljs-built_in">input</span>[<span class="hljs-string">&#x27;tag&#x27;</span>].values.tolist())]<br><br>    grouped_input_data = input_data.groupby(<span class="hljs-string">&#x27;sent_no&#x27;</span>).apply(aggregate_function)<br>    sentences = [sentence <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> grouped_input_data]<br><br>    x = [[word_dictionary[word[<span class="hljs-number">0</span>]] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sent] <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sentences]<br>    x = pad_sequences(maxlen=input_shape, sequences=x, padding=<span class="hljs-string">&#x27;post&#x27;</span>, value=<span class="hljs-number">0</span>)<br>    y = [[label_dictionary[word[<span class="hljs-number">2</span>]] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sent] <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sentences]<br>    y = pad_sequences(maxlen=input_shape, sequences=y, padding=<span class="hljs-string">&#x27;post&#x27;</span>, value=<span class="hljs-number">0</span>)<br>    y = [np_utils.to_categorical(label, num_classes=label_size + <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> y]<br><br>    <span class="hljs-keyword">return</span> x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary<br><br><br><span class="hljs-comment"># 定义深度学习模型：Bi-LSTM</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_Bi_LSTM</span>(<span class="hljs-params">vocab_size, label_size, input_shape, output_dim, n_units, out_act, activation</span>):<br>    model = Sequential()<br>    model.add(Embedding(input_dim=vocab_size + <span class="hljs-number">1</span>, output_dim=output_dim,<br>                        input_length=input_shape, mask_zero=<span class="hljs-literal">True</span>))<br>    model.add(Bidirectional(LSTM(units=n_units, activation=activation,<br>                                 return_sequences=<span class="hljs-literal">True</span>)))<br>    model.add(TimeDistributed(Dense(label_size + <span class="hljs-number">1</span>, activation=out_act)))<br>    model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>, loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-comment"># 模型训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model_train</span>():<br><br>    <span class="hljs-comment"># 将数据集分为训练集和测试集，占比为9:1</span><br>    input_shape = <span class="hljs-number">60</span><br>    x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary = input_data_for_model(input_shape)<br>    train_end = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(x)*<span class="hljs-number">0.9</span>)<br>    train_x, train_y = x[<span class="hljs-number">0</span>:train_end], np.array(y[<span class="hljs-number">0</span>:train_end])<br>    test_x, test_y = x[train_end:], np.array(y[train_end:])<br><br>    <span class="hljs-comment"># 模型输入参数</span><br>    activation = <span class="hljs-string">&#x27;selu&#x27;</span><br>    out_act = <span class="hljs-string">&#x27;softmax&#x27;</span><br>    n_units = <span class="hljs-number">100</span><br>    batch_size = <span class="hljs-number">32</span><br>    epochs = <span class="hljs-number">10</span><br>    output_dim = <span class="hljs-number">20</span><br><br>    <span class="hljs-comment"># 模型训练</span><br>    lstm_model = create_Bi_LSTM(vocab_size, label_size, input_shape, output_dim, n_units, out_act, activation)<br>    lstm_model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 模型保存</span><br>    model_save_path = CONSTANTS[<span class="hljs-number">0</span>]<br>    lstm_model.save(model_save_path)<br>    plot_model(lstm_model, to_file=<span class="hljs-string">&#x27;%s/LSTM_model.png&#x27;</span> % BASE_DIR)<br><br>    <span class="hljs-comment"># 在测试集上的效果</span><br>    N = test_x.shape[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 测试的条数</span><br>    avg_accuracy = <span class="hljs-number">0</span>  <span class="hljs-comment"># 预测的平均准确率</span><br>    <span class="hljs-keyword">for</span> start, end <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, N, <span class="hljs-number">1</span>), <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, N+<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)):<br>        sentence = [inverse_word_dictionary[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> test_x[start] <span class="hljs-keyword">if</span> i != <span class="hljs-number">0</span>]<br>        y_predict = lstm_model.predict(test_x[start:end])<br>        input_sequences, output_sequences = [], []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(y_predict[<span class="hljs-number">0</span>])):<br>            output_sequences.append(np.argmax(y_predict[<span class="hljs-number">0</span>][i]))<br>            input_sequences.append(np.argmax(test_y[start][i]))<br><br>        <span class="hljs-built_in">eval</span> = lstm_model.evaluate(test_x[start:end], test_y[start:end])<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Test Accuracy: loss = %0.6f accuracy = %0.2f%%&#x27;</span> % (<span class="hljs-built_in">eval</span>[<span class="hljs-number">0</span>], <span class="hljs-built_in">eval</span>[<span class="hljs-number">1</span>] * <span class="hljs-number">100</span>))<br>        avg_accuracy += <span class="hljs-built_in">eval</span>[<span class="hljs-number">1</span>]<br>        output_sequences = <span class="hljs-string">&#x27; &#x27;</span>.join([output_dictionary[key] <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> output_sequences <span class="hljs-keyword">if</span> key != <span class="hljs-number">0</span>]).split()<br>        input_sequences = <span class="hljs-string">&#x27; &#x27;</span>.join([output_dictionary[key] <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> input_sequences <span class="hljs-keyword">if</span> key != <span class="hljs-number">0</span>]).split()<br>        output_input_comparison = pd.DataFrame([sentence, output_sequences, input_sequences]).T<br>        <span class="hljs-built_in">print</span>(output_input_comparison.dropna())<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;#&#x27;</span> * <span class="hljs-number">80</span>)<br><br>    avg_accuracy /= N<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;测试样本的平均预测准确率：%.2f%%.&quot;</span> % (avg_accuracy * <span class="hljs-number">100</span>))<br><br>model_train()<br></code></pre></td></tr></table></figure><p>在上面的代码中，先是通过input_data_for_model()函数来处理好进入模型的数据，其参数为input_shape，即填充句子时的长度。然后是创建Bi-LSTM模型create_Bi_LSTM()，模型的示意图如下：</p><figure><img src="/img/nlp5_4.png" alt="模型示意图" /><figcaption aria-hidden="true">模型示意图</figcaption></figure><p>最后，是在输入的数据上进行模型训练，将原始的数据分为训练集和测试集，占比为9:1，训练的周期为10次。</p><h3 id="模型训练">模型训练</h3><p>运行上述模型训练代码，一共训练10个周期，训练时间大概为500s，在训练集上的准确率达99%以上，在测试集上的平均准确率为95%以上。以下是最后几个测试集上的预测结果：</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs clean">......(前面的输出已忽略)<br>Test Accuracy: loss = <span class="hljs-number">0.000986</span> accuracy = <span class="hljs-number">100.00</span>%<br>          <span class="hljs-number">0</span>      <span class="hljs-number">1</span>      <span class="hljs-number">2</span><br><span class="hljs-number">0</span>   Cardiff  B-ORG  B-ORG<br><span class="hljs-number">1</span>         <span class="hljs-number">1</span>      O      O<br><span class="hljs-number">2</span>  Brighton  B-ORG  B-ORG<br><span class="hljs-number">3</span>         <span class="hljs-number">0</span>      O      O<br>################################################################################<br><br><span class="hljs-number">1</span>/<span class="hljs-number">1</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">10</span>ms/step<br>Test Accuracy: loss = <span class="hljs-number">0.000274</span> accuracy = <span class="hljs-number">100.00</span>%<br>          <span class="hljs-number">0</span>      <span class="hljs-number">1</span>      <span class="hljs-number">2</span><br><span class="hljs-number">0</span>  Carlisle  B-ORG  B-ORG<br><span class="hljs-number">1</span>         <span class="hljs-number">0</span>      O      O<br><span class="hljs-number">2</span>      Hull  B-ORG  B-ORG<br><span class="hljs-number">3</span>         <span class="hljs-number">0</span>      O      O<br>################################################################################<br><br><span class="hljs-number">1</span>/<span class="hljs-number">1</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">9</span>ms/step<br>Test Accuracy: loss = <span class="hljs-number">0.000479</span> accuracy = <span class="hljs-number">100.00</span>%<br>           <span class="hljs-number">0</span>      <span class="hljs-number">1</span>      <span class="hljs-number">2</span><br><span class="hljs-number">0</span>    Chester  B-ORG  B-ORG<br><span class="hljs-number">1</span>          <span class="hljs-number">1</span>      O      O<br><span class="hljs-number">2</span>  Cambridge  B-ORG  B-ORG<br><span class="hljs-number">3</span>          <span class="hljs-number">1</span>      O      O<br>################################################################################<br><br><span class="hljs-number">1</span>/<span class="hljs-number">1</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">9</span>ms/step<br>Test Accuracy: loss = <span class="hljs-number">0.003092</span> accuracy = <span class="hljs-number">100.00</span>%<br>            <span class="hljs-number">0</span>      <span class="hljs-number">1</span>      <span class="hljs-number">2</span><br><span class="hljs-number">0</span>  Darlington  B-ORG  B-ORG<br><span class="hljs-number">1</span>           <span class="hljs-number">4</span>      O      O<br><span class="hljs-number">2</span>     Swansea  B-ORG  B-ORG<br><span class="hljs-number">3</span>           <span class="hljs-number">1</span>      O      O<br>################################################################################<br><br><span class="hljs-number">1</span>/<span class="hljs-number">1</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">8</span>ms/step<br>Test Accuracy: loss = <span class="hljs-number">0.000705</span> accuracy = <span class="hljs-number">100.00</span>%<br>             <span class="hljs-number">0</span>      <span class="hljs-number">1</span>      <span class="hljs-number">2</span><br><span class="hljs-number">0</span>       Exeter  B-ORG  B-ORG<br><span class="hljs-number">1</span>            <span class="hljs-number">2</span>      O      O<br><span class="hljs-number">2</span>  Scarborough  B-ORG  B-ORG<br><span class="hljs-number">3</span>            <span class="hljs-number">2</span>      O      O<br>################################################################################<br>测试样本的平均预测准确率：<span class="hljs-number">95.55</span>%.<br></code></pre></td></tr></table></figure><p>该模型在原始数据上的识别效果还是可以的。</p><p>训练完模型后，BASE_DIR中的所有文件如下：</p><figure><img src="/img/nlp5_5.png" alt="模型训练完后的所有文件截图" /><figcaption aria-hidden="true">模型训练完后的所有文件截图</figcaption></figure><h3 id="模型预测">模型预测</h3><p>最后，也许是整个项目最为激动人心的时刻，因为，我们要在新数据集上测试模型的识别效果。预测新数据的识别结果的完整Python代码（Bi_LSTM_Model_predict.py）如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># Name entity recognition for new data</span><br><br><span class="hljs-comment"># Import the necessary modules</span><br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> CONSTANTS<br><span class="hljs-keyword">from</span> keras.preprocessing.sequence <span class="hljs-keyword">import</span> pad_sequences<br><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> load_model<br><span class="hljs-keyword">from</span> nltk <span class="hljs-keyword">import</span> word_tokenize<br><br><span class="hljs-comment"># 导入字典</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(CONSTANTS[<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    word_dictionary = pickle.load(f)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(CONSTANTS[<span class="hljs-number">4</span>], <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    output_dictionary = pickle.load(f)<br><br><span class="hljs-keyword">try</span>:<br>    <span class="hljs-comment"># 数据预处理</span><br>    input_shape = <span class="hljs-number">60</span><br>    sent = <span class="hljs-string">&#x27;New York is the biggest city in America.&#x27;</span><br>    new_sent = word_tokenize(sent)<br>    new_x = [[word_dictionary[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> new_sent]]<br>    x = pad_sequences(maxlen=input_shape, sequences=new_x, padding=<span class="hljs-string">&#x27;post&#x27;</span>, value=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># 载入模型</span><br>    model_save_path = CONSTANTS[<span class="hljs-number">0</span>]<br>    lstm_model = load_model(model_save_path)<br><br>    <span class="hljs-comment"># 模型预测</span><br>    y_predict = lstm_model.predict(x)<br><br>    ner_tag = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(new_sent)):<br>        ner_tag.append(np.argmax(y_predict[<span class="hljs-number">0</span>][i]))<br><br>    ner = [output_dictionary[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ner_tag]<br>    <span class="hljs-built_in">print</span>(new_sent)<br>    <span class="hljs-built_in">print</span>(ner)<br><br>    <span class="hljs-comment"># 去掉NER标注为O的元素</span><br>    ner_reg_list = []<br>    <span class="hljs-keyword">for</span> word, tag <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(new_sent, ner):<br>        <span class="hljs-keyword">if</span> tag != <span class="hljs-string">&#x27;O&#x27;</span>:<br>            ner_reg_list.append((word, tag))<br><br>    <span class="hljs-comment"># 输出模型的NER识别结果</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;NER识别结果：&quot;</span>)<br>    <span class="hljs-keyword">if</span> ner_reg_list:<br>        <span class="hljs-keyword">for</span> i, item <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(ner_reg_list):<br>            <span class="hljs-keyword">if</span> item[<span class="hljs-number">1</span>].startswith(<span class="hljs-string">&#x27;B&#x27;</span>):<br>                end = i+<span class="hljs-number">1</span><br>                <span class="hljs-keyword">while</span> end &lt;= <span class="hljs-built_in">len</span>(ner_reg_list)-<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> ner_reg_list[end][<span class="hljs-number">1</span>].startswith(<span class="hljs-string">&#x27;I&#x27;</span>):<br>                    end += <span class="hljs-number">1</span><br><br>                ner_type = item[<span class="hljs-number">1</span>].split(<span class="hljs-string">&#x27;-&#x27;</span>)[<span class="hljs-number">1</span>]<br>                ner_type_dict = &#123;<span class="hljs-string">&#x27;PER&#x27;</span>: <span class="hljs-string">&#x27;PERSON: &#x27;</span>,<br>                                <span class="hljs-string">&#x27;LOC&#x27;</span>: <span class="hljs-string">&#x27;LOCATION: &#x27;</span>,<br>                                <span class="hljs-string">&#x27;ORG&#x27;</span>: <span class="hljs-string">&#x27;ORGANIZATION: &#x27;</span>,<br>                                <span class="hljs-string">&#x27;MISC&#x27;</span>: <span class="hljs-string">&#x27;MISC: &#x27;</span><br>                                &#125;<br>                <span class="hljs-built_in">print</span>(ner_type_dict[ner_type],\<br>                    <span class="hljs-string">&#x27; &#x27;</span>.join([item[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> ner_reg_list[i:end]]))<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;模型并未识别任何有效命名实体。&quot;</span>)<br><br><span class="hljs-keyword">except</span> KeyError <span class="hljs-keyword">as</span> err:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;您输入的句子有单词不在词汇表中，请重新输入！&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;不在词汇表中的单词为：%s.&quot;</span> % err)<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-string">&#x27;New&#x27;</span>, <span class="hljs-string">&#x27;York&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;biggest&#x27;</span>, <span class="hljs-string">&#x27;city&#x27;</span>, <span class="hljs-string">&#x27;in&#x27;</span>, <span class="hljs-string">&#x27;America&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]<br>[<span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]<br>NER识别结果：<br><span class="hljs-keyword">LOCATION</span>:  <span class="hljs-built_in">New</span> York<br><span class="hljs-keyword">LOCATION</span>:  America<br></code></pre></td></tr></table></figure><p>接下来，再测试三个笔者自己想的句子：</p><p>输入为： <figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">sent = <span class="hljs-symbol">&#x27;James</span> <span class="hljs-keyword">is</span> a world famous actor, whose home <span class="hljs-keyword">is</span> <span class="hljs-keyword">in</span> London.&#x27;<br></code></pre></td></tr></table></figure> 输出结果为：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;James&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;world&#x27;</span>, <span class="hljs-string">&#x27;famous&#x27;</span>, <span class="hljs-string">&#x27;actor&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;whose&#x27;</span>, <span class="hljs-string">&#x27;home&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;in&#x27;</span>, <span class="hljs-string">&#x27;London&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]</span><br><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]</span><br>NER识别结果：<br>PERSON:  James<br>LOCATION:  London<br></code></pre></td></tr></table></figure><p>输入为： <figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">sent = <span class="hljs-symbol">&#x27;Oxford</span> <span class="hljs-keyword">is</span> <span class="hljs-keyword">in</span> England, Jack <span class="hljs-keyword">is</span> from here.&#x27;<br></code></pre></td></tr></table></figure> 输出为： <figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;Oxford&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;in&#x27;</span>, <span class="hljs-string">&#x27;England&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;Jack&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;from&#x27;</span>, <span class="hljs-string">&#x27;here&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]</span><br><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]</span><br>NER识别结果：<br>PERSON:  Oxford<br>LOCATION:  England<br>PERSON:  Jack<br></code></pre></td></tr></table></figure></p><p>输入为： <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">sent</span> = <span class="hljs-string">&#x27;I love Shanghai.&#x27;</span><br></code></pre></td></tr></table></figure> 输出为： <figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;love&#x27;</span>, <span class="hljs-string">&#x27;Shanghai&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]</span><br><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]</span><br>NER识别结果：<br>LOCATION:  Shanghai<br></code></pre></td></tr></table></figure></p><p>在上面的例子中，只有Oxford的识别效果不理想，模型将它识别为PERSON，其实应该是ORGANIZATION。</p><p>接下来是三个来自CNN和wikipedia的句子：</p><p>输入为： <figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">sent</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;the US runs the risk of a military defeat by China or Russia&quot;</span><br></code></pre></td></tr></table></figure> 输出为： <figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;US&#x27;</span>, <span class="hljs-string">&#x27;runs&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;risk&#x27;</span>, <span class="hljs-string">&#x27;of&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;military&#x27;</span>, <span class="hljs-string">&#x27;defeat&#x27;</span>, <span class="hljs-string">&#x27;by&#x27;</span>, <span class="hljs-string">&#x27;China&#x27;</span>, <span class="hljs-string">&#x27;or&#x27;</span>, <span class="hljs-string">&#x27;Russia&#x27;</span>]<br>[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>]<br>NER识别结果：<br><span class="hljs-keyword">LOCATION</span>:  US<br><span class="hljs-keyword">LOCATION</span>:  China<br><span class="hljs-keyword">LOCATION</span>:  Russia<br></code></pre></td></tr></table></figure> 输入为：<figure class="highlight smalltalk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">sent = <span class="hljs-comment">&quot;Home to the headquarters of the United Nations, New York is an important center for international diplomacy.&quot;</span><br></code></pre></td></tr></table></figure> 输出为： <figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;Home&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;headquarters&#x27;</span>, <span class="hljs-string">&#x27;of&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;United&#x27;</span>, <span class="hljs-string">&#x27;Nations&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;New&#x27;</span>, <span class="hljs-string">&#x27;York&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;an&#x27;</span>, <span class="hljs-string">&#x27;important&#x27;</span>, <span class="hljs-string">&#x27;center&#x27;</span>, <span class="hljs-string">&#x27;for&#x27;</span>, <span class="hljs-string">&#x27;international&#x27;</span>, <span class="hljs-string">&#x27;diplomacy&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]</span><br><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]</span><br>NER识别结果：<br>ORGANIZATION:  United Nations<br>LOCATION:  New York<br></code></pre></td></tr></table></figure></p><p>输入为： <figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">sent</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;The United States is a founding member of the United Nations, World Bank, International Monetary Fund.&quot;</span><br></code></pre></td></tr></table></figure> 输出为: <figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;The&#x27;</span>, <span class="hljs-string">&#x27;United&#x27;</span>, <span class="hljs-string">&#x27;States&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;founding&#x27;</span>, <span class="hljs-string">&#x27;member&#x27;</span>, <span class="hljs-string">&#x27;of&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;United&#x27;</span>, <span class="hljs-string">&#x27;Nations&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;World&#x27;</span>, <span class="hljs-string">&#x27;Bank&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;International&#x27;</span>, <span class="hljs-string">&#x27;Monetary&#x27;</span>, <span class="hljs-string">&#x27;Fund&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]</span><br><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]</span><br>NER识别结果：<br>LOCATION:  United States<br>ORGANIZATION:  United Nations<br>ORGANIZATION:  World Bank<br>ORGANIZATION:  International Monetary Fund<br></code></pre></td></tr></table></figure></p><p>这三个例子识别全部正确。</p><h3 id="总结">总结</h3><p>到这儿，笔者的这个项目就差不多了。我们有必要对这个项目做个总结。</p><p>首先是这个项目的优点。它的优点在于能够让你一步步地实现NER，而且除了语料库，你基本熟悉了如何创建一个识别NER系统的步骤，同时，对深度学习模型及其应用也有了深刻理解。因此，好处是显而易见的。当然，在实际工作中，语料库的整理才是最耗费时间的，能够占到90%或者更多的时间，因此，有一个好的语料库你才能展开工作。</p><p>接着讲讲这个项目的缺点。第一个，是语料库不够大，当然，约14000条句子也够了，但本项目没有对句子进行文本预处理，所以，有些单词的变形可能无法进入词汇表。第二个，缺少对新词的处理，一旦句子中出现一个新的单词，这个模型便无法处理，这是后期需要完善的地方。第三个，句子的填充长度为60，如果输入的句子长度大于60，则后面的部分将无法有效识别。</p><p>因此，后续还有更多的工作需要去做，当然，做一个中文NER也是可以考虑的。</p><p>本项目已上传Github,地址为 <ahref="https://github.com/percent4/DL_4_NER">https://github.com/percent4/DL_4_NER</a>。：欢迎大家参考~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center><h3 id="参考文献">参考文献</h3><ol type="1"><li>BOOK： Applied Natural Language Processing with Python， TawehBeysolow II</li><li>WEBSITE：https://github.com/Apress/applied-natural-language-processing-w-python</li><li>WEBSITE: NLP入门（四）命名实体识别（NER）:https://www.jianshu.com/p/16e1f6a7aaef</li></ol>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>NER</tag>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP入门（四）命名实体识别（NER）</title>
    <link href="/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%9B%9B%EF%BC%89%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%EF%BC%88NER%EF%BC%89/"/>
    <url>/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E5%9B%9B%EF%BC%89%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%EF%BC%88NER%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文将会简单介绍自然语言处理（NLP）中的命名实体识别（NER）。</p><p>命名实体识别（Named EntityRecognition，简称NER）是信息提取、问答系统、句法分析、机器翻译等应用领域的重要基础工具，在自然语言处理技术走向实用化的过程中占有重要地位。一般来说，命名实体识别的任务就是识别出待处理文本中三大类（实体类、时间类和数字类）、七小类（人名、机构名、地名、时间、日期、货币和百分比）命名实体。</p><p>举个简单的例子，在句子“小明早上8点去学校上课。”中，对其进行命名实体识别，应该能提取信息</p><blockquote><p>人名：小明，时间：早上8点，地点：学校。</p></blockquote><p>本文将会介绍几个工具用来进行命名实体识别，后续有机会的话，我们将会尝试着用HMM、CRF或深度学习来实现命名实体识别。</p><p>首先我们来看一下NLTK和StanfordNLP中对命名实体识别的分类，如下图：</p><figure><img src="/img/nlp4_1.png"alt="NLTK和Stanford NLP中对命名实体识别的分类" /><figcaption aria-hidden="true">NLTK和StanfordNLP中对命名实体识别的分类</figcaption></figure><p>在上图中，LOCATION和GPE有重合。GPE通常表示地理—政治条目，比如城市，州，国家，洲等。LOCATION除了上述内容外，还能表示名山大川等。FACILITY通常表示知名的纪念碑或人工制品等。</p><p>下面介绍两个工具来进行NER的任务：NLTK和Stanford NLP。</p><p>首先是NLTK，我们的示例文档（介绍FIFA，来源于维基百科）如下：</p><blockquote><p>FIFA was founded in 1904 to oversee international competition amongthe national associations of Belgium, Denmark, France, Germany, theNetherlands, Spain, Sweden, and Switzerland. Headquartered in Zürich,its membership now comprises 211 national associations. Member countriesmust each also be members of one of the six regional confederations intowhich the world is divided: Africa, Asia, Europe, North &amp; CentralAmerica and the Caribbean, Oceania, and South America.</p></blockquote><p>实现NER的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> nltk<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_document</span>(<span class="hljs-params">document</span>):<br>   document = re.sub(<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>, document)<br>   <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(document, <span class="hljs-built_in">str</span>):<br>       document = document<br>   <span class="hljs-keyword">else</span>:<br>       <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Document is not string!&#x27;</span>)<br>   document = document.strip()<br>   sentences = nltk.sent_tokenize(document)<br>   sentences = [sentence.strip() <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> sentences]<br>   <span class="hljs-keyword">return</span> sentences<br><br><span class="hljs-comment"># sample document</span><br>text = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">FIFA was founded in 1904 to oversee international competition among the national associations of Belgium, </span><br><span class="hljs-string">Denmark, France, Germany, the Netherlands, Spain, Sweden, and Switzerland. Headquartered in Zürich, its </span><br><span class="hljs-string">membership now comprises 211 national associations. Member countries must each also be members of one of </span><br><span class="hljs-string">the six regional confederations into which the world is divided: Africa, Asia, Europe, North &amp; Central America </span><br><span class="hljs-string">and the Caribbean, Oceania, and South America.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># tokenize sentences</span><br>sentences = parse_document(text)<br>tokenized_sentences = [nltk.word_tokenize(sentence) <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> sentences]<br><span class="hljs-comment"># tag sentences and use nltk&#x27;s Named Entity Chunker</span><br>tagged_sentences = [nltk.pos_tag(sentence) <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> tokenized_sentences]<br>ne_chunked_sents = [nltk.ne_chunk(tagged) <span class="hljs-keyword">for</span> tagged <span class="hljs-keyword">in</span> tagged_sentences]<br><span class="hljs-comment"># extract all named entities</span><br>named_entities = []<br><span class="hljs-keyword">for</span> ne_tagged_sentence <span class="hljs-keyword">in</span> ne_chunked_sents:<br>   <span class="hljs-keyword">for</span> tagged_tree <span class="hljs-keyword">in</span> ne_tagged_sentence:<br>       <span class="hljs-comment"># extract only chunks having NE labels</span><br>       <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(tagged_tree, <span class="hljs-string">&#x27;label&#x27;</span>):<br>           entity_name = <span class="hljs-string">&#x27; &#x27;</span>.join(c[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> tagged_tree.leaves()) <span class="hljs-comment">#get NE name</span><br>           entity_type = tagged_tree.label() <span class="hljs-comment"># get NE category</span><br>           named_entities.append((entity_name, entity_type))<br>           <span class="hljs-comment"># get unique named entities</span><br>           named_entities = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(named_entities))<br><br><span class="hljs-comment"># store named entities in a data frame</span><br>entity_frame = pd.DataFrame(named_entities, columns=[<span class="hljs-string">&#x27;Entity Name&#x27;</span>, <span class="hljs-string">&#x27;Entity Type&#x27;</span>])<br><span class="hljs-comment"># display results</span><br><span class="hljs-built_in">print</span>(entity_frame)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">        Entity Name   Entity Type<br><span class="hljs-number">0</span>              FIFA  <span class="hljs-keyword">ORGANIZATION</span><br><span class="hljs-keyword"></span><span class="hljs-number">1</span>   Central America  <span class="hljs-keyword">ORGANIZATION</span><br><span class="hljs-keyword"></span><span class="hljs-number">2</span>           <span class="hljs-keyword">Belgium </span>          GPE<br><span class="hljs-number">3</span>         Caribbean      LOCATION<br><span class="hljs-number">4</span>              Asia           GPE<br><span class="hljs-number">5</span>            France           GPE<br><span class="hljs-number">6</span>           Oceania           GPE<br><span class="hljs-number">7</span>           Germany           GPE<br><span class="hljs-number">8</span>     South America           GPE<br><span class="hljs-number">9</span>           Denmark           GPE<br><span class="hljs-number">10</span>           Zürich           GPE<br><span class="hljs-number">11</span>           Africa        PERSON<br><span class="hljs-number">12</span>           <span class="hljs-keyword">Sweden </span>          GPE<br><span class="hljs-number">13</span>      Netherlands           GPE<br><span class="hljs-number">14</span>            Spain           GPE<br><span class="hljs-number">15</span>      <span class="hljs-keyword">Switzerland </span>          GPE<br><span class="hljs-number">16</span>            <span class="hljs-keyword">North </span>          GPE<br><span class="hljs-number">17</span>           Europe           GPE<br></code></pre></td></tr></table></figure><p>可以看到，NLTK中的NER任务大体上完成得还是不错的，能够识别FIFA为组织（ORGANIZATION），Belgium,Asia为GPE,但是也有一些不太如人意的地方，比如，它将CentralAmerica识别为ORGANIZATION，而实际上它应该为GPE；将Africa识别为PERSON，实际上应该为GPE。</p><p>接下来，我们尝试着用StanfordNLP工具。关于该工具，我们主要使用Stanford NER标注工具。在使用这个工具之前，你需要在自己的电脑上安装Java（一般是JDK），并将Java添加到系统路径中，同时下载英语NER的文件包：stanford-ner-2018-10-16.zip（大小为172MB），下载地址为：https://nlp.stanford.edu/software/CRF-NER.shtml。以笔者的电脑为例，Java所在的路径为：C:Files.0_161.exe， 下载StanfordNER的zip文件解压后的文件夹的路径为：E://stanford-ner-2018-10-16，如下图所示：</p><p><img src="/img/nlp4_2.png" /></p><p>在classifer文件夹中有如下文件：</p><p><img src="/img/nlp4_3.png" /></p><p>它们代表的含义如下：</p><blockquote><p>3 class: Location, Person, Organization 4 class: Location, Person,Organization, Misc 7 class: Location, Person, Organization, Money,Percent, Date, Time</p></blockquote><p>可以使用Python实现Stanford NER，完整的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">from</span> nltk.tag <span class="hljs-keyword">import</span> StanfordNERTagger<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> nltk<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_document</span>(<span class="hljs-params">document</span>):<br>   document = re.sub(<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>, document)<br>   <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(document, <span class="hljs-built_in">str</span>):<br>       document = document<br>   <span class="hljs-keyword">else</span>:<br>       <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Document is not string!&#x27;</span>)<br>   document = document.strip()<br>   sentences = nltk.sent_tokenize(document)<br>   sentences = [sentence.strip() <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> sentences]<br>   <span class="hljs-keyword">return</span> sentences<br><br><span class="hljs-comment"># sample document</span><br>text = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">FIFA was founded in 1904 to oversee international competition among the national associations of Belgium, </span><br><span class="hljs-string">Denmark, France, Germany, the Netherlands, Spain, Sweden, and Switzerland. Headquartered in Zürich, its </span><br><span class="hljs-string">membership now comprises 211 national associations. Member countries must each also be members of one of </span><br><span class="hljs-string">the six regional confederations into which the world is divided: Africa, Asia, Europe, North &amp; Central America </span><br><span class="hljs-string">and the Caribbean, Oceania, and South America.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>sentences = parse_document(text)<br>tokenized_sentences = [nltk.word_tokenize(sentence) <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> sentences]<br><br><span class="hljs-comment"># set java path in environment variables</span><br>java_path = <span class="hljs-string">r&#x27;C:\Program Files\Java\jdk1.8.0_161\bin\java.exe&#x27;</span><br>os.environ[<span class="hljs-string">&#x27;JAVAHOME&#x27;</span>] = java_path<br><span class="hljs-comment"># load stanford NER</span><br>sn = StanfordNERTagger(<span class="hljs-string">&#x27;E://stanford-ner-2018-10-16/classifiers/english.muc.7class.distsim.crf.ser.gz&#x27;</span>,<br>                       path_to_jar=<span class="hljs-string">&#x27;E://stanford-ner-2018-10-16/stanford-ner.jar&#x27;</span>)<br><br><span class="hljs-comment"># tag sentences</span><br>ne_annotated_sentences = [sn.tag(sent) <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> tokenized_sentences]<br><span class="hljs-comment"># extract named entities</span><br>named_entities = []<br><span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> ne_annotated_sentences:<br>   temp_entity_name = <span class="hljs-string">&#x27;&#x27;</span><br>   temp_named_entity = <span class="hljs-literal">None</span><br>   <span class="hljs-keyword">for</span> term, tag <span class="hljs-keyword">in</span> sentence:<br>       <span class="hljs-comment"># get terms with NE tags</span><br>       <span class="hljs-keyword">if</span> tag != <span class="hljs-string">&#x27;O&#x27;</span>:<br>           temp_entity_name = <span class="hljs-string">&#x27; &#x27;</span>.join([temp_entity_name, term]).strip() <span class="hljs-comment">#get NE name</span><br>           temp_named_entity = (temp_entity_name, tag) <span class="hljs-comment"># get NE and its category</span><br>       <span class="hljs-keyword">else</span>:<br>           <span class="hljs-keyword">if</span> temp_named_entity:<br>               named_entities.append(temp_named_entity)<br>               temp_entity_name = <span class="hljs-string">&#x27;&#x27;</span><br>               temp_named_entity = <span class="hljs-literal">None</span><br><br><span class="hljs-comment"># get unique named entities</span><br>named_entities = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(named_entities))<br><span class="hljs-comment"># store named entities in a data frame</span><br>entity_frame = pd.DataFrame(named_entities, columns=[<span class="hljs-string">&#x27;Entity Name&#x27;</span>, <span class="hljs-string">&#x27;Entity Type&#x27;</span>])<br><span class="hljs-comment"># display results</span><br><span class="hljs-built_in">print</span>(entity_frame)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">                Entity Name   Entity <span class="hljs-keyword">Type</span><br><span class="hljs-number">0</span>                      <span class="hljs-number">1904</span>          <span class="hljs-keyword">DATE</span><br><span class="hljs-number">1</span>                   Denmark      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">2</span>                     Spain      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">3</span>   North &amp; Central America  ORGANIZATION<br><span class="hljs-number">4</span>             South America      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">5</span>                   Belgium      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">6</span>                    Zürich      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">7</span>           the Netherlands      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">8</span>                    France      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">9</span>                 Caribbean      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">10</span>                   Sweden      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">11</span>                  Oceania      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">12</span>                     Asia      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">13</span>                     FIFA  ORGANIZATION<br><span class="hljs-number">14</span>                   Europe      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">15</span>                   Africa      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">16</span>              Switzerland      <span class="hljs-keyword">LOCATION</span><br><span class="hljs-title">17</span>                  Germany      LOCATION<br></code></pre></td></tr></table></figure><p>可以看到，在StanfordNER的帮助下，NER的实现效果较好，将Africa识别为LOCATION，将1904识别为时间（这在NLTK中没有识别出来），但还是对North&amp; Central America识别有误，将其识别为ORGANIZATION。</p><p>值得注意的是，并不是说Stanford NER一定会比NLTKNER的效果好，两者针对的对象，预料，算法可能有差异，因此，需要根据自己的需求决定使用什么工具。</p><p>本次分享到此结束，以后有机会的话，将会尝试着用HMM、CRF或深度学习来实现命名实体识别。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>NER</tag>
      
      <tag>NLP工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP入门（三）词形还原（Lemmatization）</title>
    <link href="/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%E8%AF%8D%E5%BD%A2%E8%BF%98%E5%8E%9F%EF%BC%88Lemmatization%EF%BC%89/"/>
    <url>/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%E8%AF%8D%E5%BD%A2%E8%BF%98%E5%8E%9F%EF%BC%88Lemmatization%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>词形还原（Lemmatization）是文本预处理中的重要部分，与词干提取（stemming）很相似。</p><p>简单说来，词形还原就是去掉单词的词缀，提取单词的主干部分，通常提取后的单词会是字典中的单词，不同于词干提取（stemming），提取后的单词不一定会出现在单词中。比如，单词“cars”词形还原后的单词为“car”，单词“ate”词形还原后的单词为“eat”。</p><p>在Python的nltk模块中，使用WordNet为我们提供了稳健的词形还原的函数。如以下示例Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> nltk.stem <span class="hljs-keyword">import</span> WordNetLemmatizer<br><br>wnl = WordNetLemmatizer()<br><span class="hljs-comment"># lemmatize nouns</span><br><span class="hljs-built_in">print</span>(wnl.lemmatize(<span class="hljs-string">&#x27;cars&#x27;</span>, <span class="hljs-string">&#x27;n&#x27;</span>))<br><span class="hljs-built_in">print</span>(wnl.lemmatize(<span class="hljs-string">&#x27;men&#x27;</span>, <span class="hljs-string">&#x27;n&#x27;</span>))<br><br><span class="hljs-comment"># lemmatize verbs</span><br><span class="hljs-built_in">print</span>(wnl.lemmatize(<span class="hljs-string">&#x27;running&#x27;</span>, <span class="hljs-string">&#x27;v&#x27;</span>))<br><span class="hljs-built_in">print</span>(wnl.lemmatize(<span class="hljs-string">&#x27;ate&#x27;</span>, <span class="hljs-string">&#x27;v&#x27;</span>))<br><br><span class="hljs-comment"># lemmatize adjectives</span><br><span class="hljs-built_in">print</span>(wnl.lemmatize(<span class="hljs-string">&#x27;saddest&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>))<br><span class="hljs-built_in">print</span>(wnl.lemmatize(<span class="hljs-string">&#x27;fancier&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><blockquote><p>car men run eat sad fancy</p></blockquote><p>在以上代码中，wnl.lemmatize()函数可以进行词形还原，第一个参数为单词，第二个参数为该单词的词性，如名词，动词，形容词等，返回的结果为输入单词的词形还原后的结果。</p><p>词形还原一般是简单的，但具体我们在使用时，指定单词的词性很重要，不然词形还原可能效果不好，如以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> nltk.stem <span class="hljs-keyword">import</span> WordNetLemmatizer<br><br>wnl = WordNetLemmatizer()<br><span class="hljs-built_in">print</span>(wnl.lemmatize(<span class="hljs-string">&#x27;ate&#x27;</span>, <span class="hljs-string">&#x27;n&#x27;</span>))<br><span class="hljs-built_in">print</span>(wnl.lemmatize(<span class="hljs-string">&#x27;fancier&#x27;</span>, <span class="hljs-string">&#x27;v&#x27;</span>))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><blockquote><p>ate fancier</p></blockquote><p>那么，如何获取单词的词性呢？在NLP中，使用Parts ofspeech（POS）技术实现。在nltk中，可以使用nltk.pos_tag()获取单词在句子中的词性，如以下Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">sentence = <span class="hljs-string">&#x27;The brown fox is quick and he is jumping over the lazy dog&#x27;</span><br><span class="hljs-keyword">import</span> nltk<br>tokens = nltk.word_tokenize(sentence)<br>tagged_sent = nltk.pos_tag(tokens)<br><span class="hljs-built_in">print</span>(tagged_sent)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><blockquote><p>[('The', 'DT'), ('brown', 'JJ'), ('fox', 'NN'), ('is', 'VBZ'),('quick', 'JJ'), ('and', 'CC'), ('he', 'PRP'), ('is', 'VBZ'),('jumping', 'VBG'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'),('dog', 'NN')]</p></blockquote><p>关于上述词性的说明，可以参考下表：</p><figure><img src="/img/nlp3_1.webp" alt="词性说明表1" /><figcaption aria-hidden="true">词性说明表1</figcaption></figure><figure><img src="/img/nlp3_2.webp" alt="词性说明表2" /><figcaption aria-hidden="true">词性说明表2</figcaption></figure><p>OK，知道了获取单词在句子中的词性，再结合词形还原，就能很好地完成词形还原功能。示例的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> nltk <span class="hljs-keyword">import</span> word_tokenize, pos_tag<br><span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> wordnet<br><span class="hljs-keyword">from</span> nltk.stem <span class="hljs-keyword">import</span> WordNetLemmatizer<br><br><span class="hljs-comment"># 获取单词的词性</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_wordnet_pos</span>(<span class="hljs-params">tag</span>):<br>    <span class="hljs-keyword">if</span> tag.startswith(<span class="hljs-string">&#x27;J&#x27;</span>):<br>        <span class="hljs-keyword">return</span> wordnet.ADJ<br>    <span class="hljs-keyword">elif</span> tag.startswith(<span class="hljs-string">&#x27;V&#x27;</span>):<br>        <span class="hljs-keyword">return</span> wordnet.VERB<br>    <span class="hljs-keyword">elif</span> tag.startswith(<span class="hljs-string">&#x27;N&#x27;</span>):<br>        <span class="hljs-keyword">return</span> wordnet.NOUN<br>    <span class="hljs-keyword">elif</span> tag.startswith(<span class="hljs-string">&#x27;R&#x27;</span>):<br>        <span class="hljs-keyword">return</span> wordnet.ADV<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br>sentence = <span class="hljs-string">&#x27;football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.&#x27;</span><br>tokens = word_tokenize(sentence)  <span class="hljs-comment"># 分词</span><br>tagged_sent = pos_tag(tokens)     <span class="hljs-comment"># 获取单词词性</span><br><br>wnl = WordNetLemmatizer()<br>lemmas_sent = []<br><span class="hljs-keyword">for</span> tag <span class="hljs-keyword">in</span> tagged_sent:<br>    wordnet_pos = get_wordnet_pos(tag[<span class="hljs-number">1</span>]) <span class="hljs-keyword">or</span> wordnet.NOUN<br>    lemmas_sent.append(wnl.lemmatize(tag[<span class="hljs-number">0</span>], pos=wordnet_pos)) <span class="hljs-comment"># 词形还原</span><br><br><span class="hljs-built_in">print</span>(lemmas_sent)<br><br></code></pre></td></tr></table></figure><p>输出结果如下：</p><blockquote><p>['football', 'be', 'a', 'family', 'of', 'team', 'sport', 'that','involve', ',', 'to', 'vary', 'degree', ',', 'kick', 'a', 'ball', 'to','score', 'a', 'goal', '.']</p></blockquote><p>输出的结果就是对句子中的单词进行词形还原后的结果。本次分享到此结束，欢迎大家交流~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>词形还原</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP入门（二）探究TF-IDF的原理</title>
    <link href="/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%8C%EF%BC%89%E6%8E%A2%E7%A9%B6TF-IDF%E7%9A%84%E5%8E%9F%E7%90%86/"/>
    <url>/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%8C%EF%BC%89%E6%8E%A2%E7%A9%B6TF-IDF%E7%9A%84%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="tf-idf介绍">TF-IDF介绍</h3><p>TF-IDF是NLP中一种常用的统计方法，用以评估一个字词对于一个文件集或一个语料库中的其中一份文件的重要程度，通常用于提取文本的特征，即关键词。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。</p><p>在NLP中，TF-IDF的计算公式如下：</p><p><span class="math display">\[tfidf = tf*idf.\]</span></p><p>其中，tf是词频(Term Frequency)，idf为逆向文件频率(Inverse DocumentFrequency)。</p><p>tf为词频，即一个词语在文档中的出现频率，假设一个词语在整个文档中出现了i次，而整个文档有N个词语，则tf的值为i/N.</p><p>idf为逆向文件频率，假设整个文档有n篇文章，而一个词语在k篇文章中出现，则idf值为</p><p><span class="math display">\[idf=\log_{2}(\frac{n}{k}).\]</span></p><p>当然，不同地方的idf值计算公式会有稍微的不同。比如有些地方会在分母的k上加1，防止分母为0，还有些地方会让分子，分母都加上1，这是smoothing技巧。在本文中，还是采用最原始的idf值计算公式，因为这与gensim里面的计算公式一致。</p><p>假设整个文档有D篇文章，则单词i在第j篇文章中的tfidf值为</p><figure><img src="/img/nlp2_1.webp" alt="gensim中tfidf的计算公式" /><figcaption aria-hidden="true">gensim中tfidf的计算公式</figcaption></figure><p>以上就是TF-IDF的计算方法。</p><h3 id="文本介绍及预处理">文本介绍及预处理</h3><p>我们将采用以下三个示例文本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python">text1 =<span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal. </span><br><span class="hljs-string">Unqualified, the word football is understood to refer to whichever form of football is the most popular </span><br><span class="hljs-string">in the regional context in which the word appears. Sports commonly called football in certain places </span><br><span class="hljs-string">include association football (known as soccer in some countries); gridiron football (specifically American </span><br><span class="hljs-string">football or Canadian football); Australian rules football; rugby football (either rugby league or rugby union); </span><br><span class="hljs-string">and Gaelic football. These different variations of football are known as football codes.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>text2 = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Basketball is a team sport in which two teams of five players, opposing one another on a rectangular court, </span><br><span class="hljs-string">compete with the primary objective of shooting a basketball (approximately 9.4 inches (24 cm) in diameter) </span><br><span class="hljs-string">through the defender&#x27;s hoop (a basket 18 inches (46 cm) in diameter mounted 10 feet (3.048 m) high to a backboard </span><br><span class="hljs-string">at each end of the court) while preventing the opposing team from shooting through their own hoop. A field goal is </span><br><span class="hljs-string">worth two points, unless made from behind the three-point line, when it is worth three. After a foul, timed play stops </span><br><span class="hljs-string">and the player fouled or designated to shoot a technical foul is given one or more one-point free throws. The team with </span><br><span class="hljs-string">the most points at the end of the game wins, but if regulation play expires with the score tied, an additional period </span><br><span class="hljs-string">of play (overtime) is mandated.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>text3 = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Volleyball, game played by two teams, usually of six players on a side, in which the players use their hands to bat a </span><br><span class="hljs-string">ball back and forth over a high net, trying to make the ball touch the court within the opponents’ playing area before </span><br><span class="hljs-string">it can be returned. To prevent this a player on the opposing team bats the ball up and toward a teammate before it touches </span><br><span class="hljs-string">the court surface—that teammate may then volley it back across the net or bat it to a third teammate who volleys it across </span><br><span class="hljs-string">the net. A team is allowed only three touches of the ball before it must be returned over the net.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><p>这三篇文章分别是关于足球，篮球，排球的介绍，它们组成一篇文档。</p><p>接下来是文本的预处理部分。</p><p>首先是对文本去掉换行符，然后是分句，分词，再去掉其中的标点，完整的Python代码如下，输入的参数为文章text:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> nltk<br><span class="hljs-keyword">import</span> string<br><br><span class="hljs-comment"># 文本预处理</span><br><span class="hljs-comment"># 函数：text文件分句，分词，并去掉标点</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_tokens</span>(<span class="hljs-params">text</span>):<br>    text = text.replace(<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br>    sents = nltk.sent_tokenize(text)  <span class="hljs-comment"># 分句</span><br>    tokens = []<br>    <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents:<br>        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> nltk.word_tokenize(sent):  <span class="hljs-comment"># 分词</span><br>            <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> string.punctuation: <span class="hljs-comment"># 去掉标点</span><br>                tokens.append(word)<br>    <span class="hljs-keyword">return</span> tokens<br></code></pre></td></tr></table></figure><p>接着，去掉文章中的通用词（stopwords），然后统计每个单词的出现次数，完整的Python代码如下，输入的参数为文章text:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> stopwords     <span class="hljs-comment">#停用词</span><br><br><span class="hljs-comment"># 对原始的text文件去掉停用词</span><br><span class="hljs-comment"># 生成count字典，即每个单词的出现次数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_count</span>(<span class="hljs-params">text</span>):<br>    tokens = get_tokens(text)<br>    filtered = [w <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> w <span class="hljs-keyword">in</span> stopwords.words(<span class="hljs-string">&#x27;english&#x27;</span>)]    <span class="hljs-comment">#去掉停用词</span><br>    count = Counter(filtered)<br>    <span class="hljs-keyword">return</span> count<br></code></pre></td></tr></table></figure><p>以text3为例，生成的count字典如下：</p><blockquote><p>Counter({'ball': 4, 'net': 4, 'teammate': 3, 'returned': 2, 'bat': 2,'court': 2, 'team': 2, 'across': 2, 'touches': 2, 'back': 2, 'players':2, 'touch': 1, 'must': 1, 'usually': 1, 'side': 1, 'player': 1, 'area':1, 'Volleyball': 1, 'hands': 1, 'may': 1, 'toward': 1, 'A': 1, 'third':1, 'two': 1, 'six': 1, 'opposing': 1, 'within': 1, 'prevent': 1,'allowed': 1, '’': 1, 'playing': 1, 'played': 1, 'volley': 1,'surface—that': 1, 'volleys': 1, 'opponents': 1, 'use': 1, 'high': 1,'teams': 1, 'bats': 1, 'To': 1, 'game': 1, 'make': 1, 'forth': 1,'three': 1, 'trying': 1})</p></blockquote><h3 id="gensim中的tf-idf">Gensim中的TF-IDF</h3><p>对文本进行预处理后，对于以上三个示例文本，我们都会得到一个count字典，里面是每个文本中单词的出现次数。下面，我们将用gensim中的已实现的TF-IDF模型，来输出每篇文章中TF-IDF排名前三的单词及它们的tfidf值，完整的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> stopwords     <span class="hljs-comment">#停用词</span><br><span class="hljs-keyword">from</span> gensim <span class="hljs-keyword">import</span> corpora, models, matutils<br><br><span class="hljs-comment">#training by gensim&#x27;s Ifidf Model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_words</span>(<span class="hljs-params">text</span>):<br>    tokens = get_tokens(text)<br>    filtered = [w <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> w <span class="hljs-keyword">in</span> stopwords.words(<span class="hljs-string">&#x27;english&#x27;</span>)]<br>    <span class="hljs-keyword">return</span> filtered<br><br><span class="hljs-comment"># get text</span><br>count1, count2, count3 = get_words(text1), get_words(text2), get_words(text3)<br>countlist = [count1, count2, count3]<br><span class="hljs-comment"># training by TfidfModel in gensim</span><br>dictionary = corpora.Dictionary(countlist)<br>new_dict = &#123;v:k <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> dictionary.token2id.items()&#125;<br>corpus2 = [dictionary.doc2bow(count) <span class="hljs-keyword">for</span> count <span class="hljs-keyword">in</span> countlist]<br>tfidf2 = models.TfidfModel(corpus2)<br>corpus_tfidf = tfidf2[corpus2]<br><br><span class="hljs-comment"># output</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nTraining by gensim Tfidf Model.......\n&quot;</span>)<br><span class="hljs-keyword">for</span> i, doc <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(corpus_tfidf):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Top words in document %d&quot;</span>%(i + <span class="hljs-number">1</span>))<br>    sorted_words = <span class="hljs-built_in">sorted</span>(doc, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)    <span class="hljs-comment">#type=list</span><br>    <span class="hljs-keyword">for</span> num, score <span class="hljs-keyword">in</span> sorted_words[:<span class="hljs-number">3</span>]:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;    Word: %s, TF-IDF: %s&quot;</span>%(new_dict[num], <span class="hljs-built_in">round</span>(score, <span class="hljs-number">5</span>)))<br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Training</span> by gensim Tfidf Model.......<br><br><span class="hljs-attribute">Top</span> words in document <span class="hljs-number">1</span><br>    <span class="hljs-attribute">Word</span>: football, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">84766</span><br>    <span class="hljs-attribute">Word</span>: rugby, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">21192</span><br>    <span class="hljs-attribute">Word</span>: known, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">14128</span><br><span class="hljs-attribute">Top</span> words in document <span class="hljs-number">2</span><br>    <span class="hljs-attribute">Word</span>: play, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">29872</span><br>    <span class="hljs-attribute">Word</span>: cm, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">19915</span><br>    <span class="hljs-attribute">Word</span>: diameter, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">19915</span><br><span class="hljs-attribute">Top</span> words in document <span class="hljs-number">3</span><br>    <span class="hljs-attribute">Word</span>: net, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">45775</span><br>    <span class="hljs-attribute">Word</span>: teammate, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">34331</span><br>    <span class="hljs-attribute">Word</span>: across, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">22888</span><br></code></pre></td></tr></table></figure><p>输出的结果还是比较符合我们的预期的，比如关于足球的文章中提取了football,rugby关键词，关于篮球的文章中提取了plat,cm关键词，关于排球的文章中提取了net, teammate关键词。</p><h3 id="自己动手实践tf-idf模型">自己动手实践TF-IDF模型</h3><p>有了以上我们对TF-IDF模型的理解，其实我们自己也可以动手实践一把，这是学习算法的最佳方式！</p><p>以下是笔者实践TF-IDF的代码（接文本预处理代码）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><br><span class="hljs-comment"># 计算tf</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tf</span>(<span class="hljs-params">word, count</span>):<br>    <span class="hljs-keyword">return</span> count[word] / <span class="hljs-built_in">sum</span>(count.values())<br><span class="hljs-comment"># 计算count_list有多少个文件包含word</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">n_containing</span>(<span class="hljs-params">word, count_list</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> count <span class="hljs-keyword">in</span> count_list <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> count)<br><br><span class="hljs-comment"># 计算idf</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">idf</span>(<span class="hljs-params">word, count_list</span>):<br>    <span class="hljs-keyword">return</span> math.log2(<span class="hljs-built_in">len</span>(count_list) / (n_containing(word, count_list)))    <span class="hljs-comment">#对数以2为底</span><br><span class="hljs-comment"># 计算tf-idf</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tfidf</span>(<span class="hljs-params">word, count, count_list</span>):<br>    <span class="hljs-keyword">return</span> tf(word, count) * idf(word, count_list)<br><br><span class="hljs-comment"># TF-IDF测试</span><br>count1, count2, count3 = make_count(text1), make_count(text2), make_count(text3)<br>countlist = [count1, count2, count3]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Training by original algorithm......\n&quot;</span>)<br><span class="hljs-keyword">for</span> i, count <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(countlist):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Top words in document %d&quot;</span>%(i + <span class="hljs-number">1</span>))<br>    scores = &#123;word: tfidf(word, count, countlist) <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> count&#125;<br>    sorted_words = <span class="hljs-built_in">sorted</span>(scores.items(), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)    <span class="hljs-comment">#type=list</span><br>    <span class="hljs-comment"># sorted_words = matutils.unitvec(sorted_words)</span><br>    <span class="hljs-keyword">for</span> word, score <span class="hljs-keyword">in</span> sorted_words[:<span class="hljs-number">3</span>]:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;    Word: %s, TF-IDF: %s&quot;</span>%(word, <span class="hljs-built_in">round</span>(score, <span class="hljs-number">5</span>)))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Training</span> by original algorithm......<br><br><span class="hljs-attribute">Top</span> words in document <span class="hljs-number">1</span><br>    <span class="hljs-attribute">Word</span>: football, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">30677</span><br>    <span class="hljs-attribute">Word</span>: rugby, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">07669</span><br>    <span class="hljs-attribute">Word</span>: known, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">05113</span><br><span class="hljs-attribute">Top</span> words in document <span class="hljs-number">2</span><br>    <span class="hljs-attribute">Word</span>: play, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">05283</span><br>    <span class="hljs-attribute">Word</span>: inches, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">03522</span><br>    <span class="hljs-attribute">Word</span>: worth, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">03522</span><br><span class="hljs-attribute">Top</span> words in document <span class="hljs-number">3</span><br>    <span class="hljs-attribute">Word</span>: net, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">10226</span><br>    <span class="hljs-attribute">Word</span>: teammate, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">07669</span><br>    <span class="hljs-attribute">Word</span>: across, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">05113</span><br></code></pre></td></tr></table></figure><p>可以看到，笔者自己动手实践的TF-IDF模型提取的关键词与gensim一致，至于篮球中为什么后两个单词不一致，是因为这些单词的tfidf一样，随机选择的结果不同而已。但是有一个问题，那就是计算得到的tfidf值不一样，这是什么原因呢？</p><p>查阅gensim中计算tf-idf值的源代码（https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/tfidfmodel.py）：</p><figure><img src="/img/nlp2_2.webp" alt="TfidfModel类的参数" /><figcaption aria-hidden="true">TfidfModel类的参数</figcaption></figure><figure><img src="/img/nlp2_3.webp" alt="normalize参数的说明" /><figcaption aria-hidden="true">normalize参数的说明</figcaption></figure><p>也就是说，gensim对得到的tf-idf向量做了规范化（normalize），将其转化为单位向量。因此，我们需要在刚才的代码中加入规范化这一步，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 对向量做规范化, normalize</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">unitvec</span>(<span class="hljs-params">sorted_words</span>):<br>    lst = [item[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> sorted_words]<br>    L2Norm = math.sqrt(<span class="hljs-built_in">sum</span>(np.array(lst)*np.array(lst)))<br>    unit_vector = [(item[<span class="hljs-number">0</span>], item[<span class="hljs-number">1</span>]/L2Norm) <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> sorted_words]<br>    <span class="hljs-keyword">return</span> unit_vector<br><br><span class="hljs-comment"># TF-IDF测试</span><br>count1, count2, count3 = make_count(text1), make_count(text2), make_count(text3)<br>countlist = [count1, count2, count3]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Training by original algorithm......\n&quot;</span>)<br><span class="hljs-keyword">for</span> i, count <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(countlist):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Top words in document %d&quot;</span>%(i + <span class="hljs-number">1</span>))<br>    scores = &#123;word: tfidf(word, count, countlist) <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> count&#125;<br>    sorted_words = <span class="hljs-built_in">sorted</span>(scores.items(), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)    <span class="hljs-comment">#type=list</span><br>    sorted_words = unitvec(sorted_words)   <span class="hljs-comment"># normalize</span><br>    <span class="hljs-keyword">for</span> word, score <span class="hljs-keyword">in</span> sorted_words[:<span class="hljs-number">3</span>]:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;    Word: %s, TF-IDF: %s&quot;</span>%(word, <span class="hljs-built_in">round</span>(score, <span class="hljs-number">5</span>)))<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Training</span> by original algorithm......<br><br><span class="hljs-attribute">Top</span> words in document <span class="hljs-number">1</span><br>    <span class="hljs-attribute">Word</span>: football, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">84766</span><br>    <span class="hljs-attribute">Word</span>: rugby, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">21192</span><br>    <span class="hljs-attribute">Word</span>: known, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">14128</span><br><span class="hljs-attribute">Top</span> words in document <span class="hljs-number">2</span><br>    <span class="hljs-attribute">Word</span>: play, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">29872</span><br>    <span class="hljs-attribute">Word</span>: shooting, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">19915</span><br>    <span class="hljs-attribute">Word</span>: diameter, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">19915</span><br><span class="hljs-attribute">Top</span> words in document <span class="hljs-number">3</span><br>    <span class="hljs-attribute">Word</span>: net, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">45775</span><br>    <span class="hljs-attribute">Word</span>: teammate, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">34331</span><br>    <span class="hljs-attribute">Word</span>: back, TF-IDF: <span class="hljs-number">0</span>.<span class="hljs-number">22888</span><br></code></pre></td></tr></table></figure><p>现在的输出结果与gensim得到的结果一致！</p><h3 id="总结">总结</h3><p>Gensim是Python做NLP时鼎鼎大名的模块，有空还是多读读源码吧！以后，我们还会继续介绍TF-IDF在其它方面的应用，欢迎大家交流~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center><p>本文的完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> nltk<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> string<br><span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> stopwords     <span class="hljs-comment">#停用词</span><br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter       <span class="hljs-comment">#计数</span><br><span class="hljs-keyword">from</span> gensim <span class="hljs-keyword">import</span> corpora, models, matutils<br><br>text1 =<span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal. </span><br><span class="hljs-string">Unqualified, the word football is understood to refer to whichever form of football is the most popular </span><br><span class="hljs-string">in the regional context in which the word appears. Sports commonly called football in certain places </span><br><span class="hljs-string">include association football (known as soccer in some countries); gridiron football (specifically American </span><br><span class="hljs-string">football or Canadian football); Australian rules football; rugby football (either rugby league or rugby union); </span><br><span class="hljs-string">and Gaelic football. These different variations of football are known as football codes.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>text2 = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Basketball is a team sport in which two teams of five players, opposing one another on a rectangular court, </span><br><span class="hljs-string">compete with the primary objective of shooting a basketball (approximately 9.4 inches (24 cm) in diameter) </span><br><span class="hljs-string">through the defender&#x27;s hoop (a basket 18 inches (46 cm) in diameter mounted 10 feet (3.048 m) high to a backboard </span><br><span class="hljs-string">at each end of the court) while preventing the opposing team from shooting through their own hoop. A field goal is </span><br><span class="hljs-string">worth two points, unless made from behind the three-point line, when it is worth three. After a foul, timed play stops </span><br><span class="hljs-string">and the player fouled or designated to shoot a technical foul is given one or more one-point free throws. The team with </span><br><span class="hljs-string">the most points at the end of the game wins, but if regulation play expires with the score tied, an additional period </span><br><span class="hljs-string">of play (overtime) is mandated.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>text3 = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Volleyball, game played by two teams, usually of six players on a side, in which the players use their hands to bat a </span><br><span class="hljs-string">ball back and forth over a high net, trying to make the ball touch the court within the opponents’ playing area before </span><br><span class="hljs-string">it can be returned. To prevent this a player on the opposing team bats the ball up and toward a teammate before it touches </span><br><span class="hljs-string">the court surface—that teammate may then volley it back across the net or bat it to a third teammate who volleys it across </span><br><span class="hljs-string">the net. A team is allowed only three touches of the ball before it must be returned over the net.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># 文本预处理</span><br><span class="hljs-comment"># 函数：text文件分句，分词，并去掉标点</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_tokens</span>(<span class="hljs-params">text</span>):<br>    text = text.replace(<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br>    sents = nltk.sent_tokenize(text)  <span class="hljs-comment"># 分句</span><br>    tokens = []<br>    <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents:<br>        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> nltk.word_tokenize(sent):  <span class="hljs-comment"># 分词</span><br>            <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> string.punctuation: <span class="hljs-comment"># 去掉标点</span><br>                tokens.append(word)<br>    <span class="hljs-keyword">return</span> tokens<br><br><span class="hljs-comment"># 对原始的text文件去掉停用词</span><br><span class="hljs-comment"># 生成count字典，即每个单词的出现次数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_count</span>(<span class="hljs-params">text</span>):<br>    tokens = get_tokens(text)<br>    filtered = [w <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> w <span class="hljs-keyword">in</span> stopwords.words(<span class="hljs-string">&#x27;english&#x27;</span>)]    <span class="hljs-comment">#去掉停用词</span><br>    count = Counter(filtered)<br>    <span class="hljs-keyword">return</span> count<br><br><span class="hljs-comment"># 计算tf</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tf</span>(<span class="hljs-params">word, count</span>):<br>    <span class="hljs-keyword">return</span> count[word] / <span class="hljs-built_in">sum</span>(count.values())<br><span class="hljs-comment"># 计算count_list有多少个文件包含word</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">n_containing</span>(<span class="hljs-params">word, count_list</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> count <span class="hljs-keyword">in</span> count_list <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> count)<br><br><span class="hljs-comment"># 计算idf</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">idf</span>(<span class="hljs-params">word, count_list</span>):<br>    <span class="hljs-keyword">return</span> math.log2(<span class="hljs-built_in">len</span>(count_list) / (n_containing(word, count_list)))    <span class="hljs-comment">#对数以2为底</span><br><span class="hljs-comment"># 计算tf-idf</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tfidf</span>(<span class="hljs-params">word, count, count_list</span>):<br>    <span class="hljs-keyword">return</span> tf(word, count) * idf(word, count_list)<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 对向量做规范化, normalize</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">unitvec</span>(<span class="hljs-params">sorted_words</span>):<br>    lst = [item[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> sorted_words]<br>    L2Norm = math.sqrt(<span class="hljs-built_in">sum</span>(np.array(lst)*np.array(lst)))<br>    unit_vector = [(item[<span class="hljs-number">0</span>], item[<span class="hljs-number">1</span>]/L2Norm) <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> sorted_words]<br>    <span class="hljs-keyword">return</span> unit_vector<br><br><span class="hljs-comment"># TF-IDF测试</span><br>count1, count2, count3 = make_count(text1), make_count(text2), make_count(text3)<br>countlist = [count1, count2, count3]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Training by original algorithm......\n&quot;</span>)<br><span class="hljs-keyword">for</span> i, count <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(countlist):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Top words in document %d&quot;</span>%(i + <span class="hljs-number">1</span>))<br>    scores = &#123;word: tfidf(word, count, countlist) <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> count&#125;<br>    sorted_words = <span class="hljs-built_in">sorted</span>(scores.items(), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)    <span class="hljs-comment">#type=list</span><br>    sorted_words = unitvec(sorted_words)   <span class="hljs-comment"># normalize</span><br>    <span class="hljs-keyword">for</span> word, score <span class="hljs-keyword">in</span> sorted_words[:<span class="hljs-number">3</span>]:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;    Word: %s, TF-IDF: %s&quot;</span>%(word, <span class="hljs-built_in">round</span>(score, <span class="hljs-number">5</span>)))<br><br><span class="hljs-comment">#training by gensim&#x27;s Ifidf Model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_words</span>(<span class="hljs-params">text</span>):<br>    tokens = get_tokens(text)<br>    filtered = [w <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> w <span class="hljs-keyword">in</span> stopwords.words(<span class="hljs-string">&#x27;english&#x27;</span>)]<br>    <span class="hljs-keyword">return</span> filtered<br><br><span class="hljs-comment"># get text</span><br>count1, count2, count3 = get_words(text1), get_words(text2), get_words(text3)<br>countlist = [count1, count2, count3]<br><span class="hljs-comment"># training by TfidfModel in gensim</span><br>dictionary = corpora.Dictionary(countlist)<br>new_dict = &#123;v:k <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> dictionary.token2id.items()&#125;<br>corpus2 = [dictionary.doc2bow(count) <span class="hljs-keyword">for</span> count <span class="hljs-keyword">in</span> countlist]<br>tfidf2 = models.TfidfModel(corpus2)<br>corpus_tfidf = tfidf2[corpus2]<br><br><span class="hljs-comment"># output</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nTraining by gensim Tfidf Model.......\n&quot;</span>)<br><span class="hljs-keyword">for</span> i, doc <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(corpus_tfidf):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Top words in document %d&quot;</span>%(i + <span class="hljs-number">1</span>))<br>    sorted_words = <span class="hljs-built_in">sorted</span>(doc, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)    <span class="hljs-comment">#type=list</span><br>    <span class="hljs-keyword">for</span> num, score <span class="hljs-keyword">in</span> sorted_words[:<span class="hljs-number">3</span>]:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;    Word: %s, TF-IDF: %s&quot;</span>%(new_dict[num], <span class="hljs-built_in">round</span>(score, <span class="hljs-number">5</span>)))<br>        <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">输出结果：</span><br><span class="hljs-string"></span><br><span class="hljs-string">Training by original algorithm......</span><br><span class="hljs-string"></span><br><span class="hljs-string">Top words in document 1</span><br><span class="hljs-string">    Word: football, TF-IDF: 0.84766</span><br><span class="hljs-string">    Word: rugby, TF-IDF: 0.21192</span><br><span class="hljs-string">    Word: word, TF-IDF: 0.14128</span><br><span class="hljs-string">Top words in document 2</span><br><span class="hljs-string">    Word: play, TF-IDF: 0.29872</span><br><span class="hljs-string">    Word: inches, TF-IDF: 0.19915</span><br><span class="hljs-string">    Word: points, TF-IDF: 0.19915</span><br><span class="hljs-string">Top words in document 3</span><br><span class="hljs-string">    Word: net, TF-IDF: 0.45775</span><br><span class="hljs-string">    Word: teammate, TF-IDF: 0.34331</span><br><span class="hljs-string">    Word: bat, TF-IDF: 0.22888</span><br><span class="hljs-string"></span><br><span class="hljs-string">Training by gensim Tfidf Model.......</span><br><span class="hljs-string"></span><br><span class="hljs-string">Top words in document 1</span><br><span class="hljs-string">    Word: football, TF-IDF: 0.84766</span><br><span class="hljs-string">    Word: rugby, TF-IDF: 0.21192</span><br><span class="hljs-string">    Word: known, TF-IDF: 0.14128</span><br><span class="hljs-string">Top words in document 2</span><br><span class="hljs-string">    Word: play, TF-IDF: 0.29872</span><br><span class="hljs-string">    Word: cm, TF-IDF: 0.19915</span><br><span class="hljs-string">    Word: diameter, TF-IDF: 0.19915</span><br><span class="hljs-string">Top words in document 3</span><br><span class="hljs-string">    Word: net, TF-IDF: 0.45775</span><br><span class="hljs-string">    Word: teammate, TF-IDF: 0.34331</span><br><span class="hljs-string">    Word: across, TF-IDF: 0.22888</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>TF-IDF</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP入门（一）词袋模型及句子相似度</title>
    <link href="/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%8F%A5%E5%AD%90%E7%9B%B8%E4%BC%BC%E5%BA%A6/"/>
    <url>/NLP%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%8F%A5%E5%AD%90%E7%9B%B8%E4%BC%BC%E5%BA%A6/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文作为笔者NLP入门系列文章第一篇，以后我们就要步入NLP时代。</p><p>本文将会介绍NLP中常见的词袋模型（Bag ofWords）以及如何利用词袋模型来计算句子间的相似度（余弦相似度，cosinesimilarity）。</p><p>首先，让我们来看一下，什么是词袋模型。我们以下面两个简单句子为例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">sent1 = <span class="hljs-string">&quot;I love sky, I love sea.&quot;</span><br>sent2 = <span class="hljs-string">&quot;I like running, I love reading.&quot;</span><br></code></pre></td></tr></table></figure><p>通常，NLP无法一下子处理完整的段落或句子，因此，第一步往往是分句和分词。这里只有句子，因此我们只需要分词即可。对于英语句子，可以使用NLTK中的word_tokenize函数，对于中文句子，则可使用jieba模块。故第一步为分词，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> nltk <span class="hljs-keyword">import</span> word_tokenize<br>sents = [sent1, sent2]<br>texts = [[word <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> word_tokenize(sent)] <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents]<br></code></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[[<span class="hljs-symbol">&#x27;I</span>&#x27;, <span class="hljs-symbol">&#x27;love</span>&#x27;, <span class="hljs-symbol">&#x27;sky</span>&#x27;, &#x27;,&#x27;, <span class="hljs-symbol">&#x27;I</span>&#x27;, <span class="hljs-symbol">&#x27;love</span>&#x27;, <span class="hljs-symbol">&#x27;sea</span>&#x27;, <span class="hljs-symbol">&#x27;.</span>&#x27;], [<span class="hljs-symbol">&#x27;I</span>&#x27;, <span class="hljs-symbol">&#x27;like</span>&#x27;, <span class="hljs-symbol">&#x27;running</span>&#x27;, &#x27;,&#x27;, <span class="hljs-symbol">&#x27;I</span>&#x27;, <span class="hljs-symbol">&#x27;love</span>&#x27;, <span class="hljs-symbol">&#x27;reading</span>&#x27;, <span class="hljs-symbol">&#x27;.</span>&#x27;]]<br></code></pre></td></tr></table></figure><p>分词完毕。下一步是构建语料库，即所有句子中出现的单词及标点。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">all_list = []<br><span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts:<br>    all_list += text<br>corpus = <span class="hljs-built_in">set</span>(all_list)<br><span class="hljs-built_in">print</span>(corpus)<br></code></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c">&#123;&#x27;love&#x27;, &#x27;running&#x27;, &#x27;reading&#x27;, &#x27;sky&#x27;, &#x27;.&#x27;, &#x27;I&#x27;, &#x27;like&#x27;, &#x27;sea&#x27;, &#x27;,&#x27;&#125;<br></code></pre></td></tr></table></figure><p>可以看到，语料库中一共是8个单词及标点。接下来，对语料库中的单词及标点建立数字映射，便于后续的句子的向量表示。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">corpus_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(corpus, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(corpus))))<br><span class="hljs-built_in">print</span>(corpus_dict)<br></code></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c">&#123;&#x27;running&#x27;: <span class="hljs-number">1</span>, &#x27;reading&#x27;: <span class="hljs-number">2</span>, &#x27;love&#x27;: <span class="hljs-number">0</span>, &#x27;sky&#x27;: <span class="hljs-number">3</span>, &#x27;.&#x27;: <span class="hljs-number">4</span>, &#x27;I&#x27;: <span class="hljs-number">5</span>, &#x27;like&#x27;: <span class="hljs-number">6</span>, &#x27;sea&#x27;: <span class="hljs-number">7</span>, &#x27;,&#x27;: <span class="hljs-number">8</span>&#125;<br></code></pre></td></tr></table></figure><p>虽然单词及标点并没有按照它们出现的顺序来建立数字映射，不过这并不会影响句子的向量表示及后续的句子间的相似度。</p><p>下一步，也就是词袋模型的关键一步，就是建立句子的向量表示。这个表示向量并不是简单地以单词或标点出现与否来选择0，1数字，而是把单词或标点的出现频数作为其对应的数字表示，结合刚才的语料库字典，句子的向量表示的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 建立句子的向量表示</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">vector_rep</span>(<span class="hljs-params">text, corpus_dict</span>):<br>    vec = []<br>    <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> corpus_dict.keys():<br>        <span class="hljs-keyword">if</span> key <span class="hljs-keyword">in</span> text:<br>            vec.append((corpus_dict[key], text.count(key)))<br>        <span class="hljs-keyword">else</span>:<br>            vec.append((corpus_dict[key], <span class="hljs-number">0</span>))<br><br>    vec = <span class="hljs-built_in">sorted</span>(vec, key= <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">0</span>])<br><br>    <span class="hljs-keyword">return</span> vec<br><br>vec1 = vector_rep(texts[<span class="hljs-number">0</span>], corpus_dict)<br>vec2 = vector_rep(texts[<span class="hljs-number">1</span>], corpus_dict)<br><span class="hljs-built_in">print</span>(vec1)<br><span class="hljs-built_in">print</span>(vec2)<br></code></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[(<span class="hljs-name">0</span>, <span class="hljs-number">2</span>), (<span class="hljs-name">1</span>, <span class="hljs-number">0</span>), (<span class="hljs-name">2</span>, <span class="hljs-number">0</span>), (<span class="hljs-name">3</span>, <span class="hljs-number">1</span>), (<span class="hljs-name">4</span>, <span class="hljs-number">1</span>), (<span class="hljs-name">5</span>, <span class="hljs-number">2</span>), (<span class="hljs-name">6</span>, <span class="hljs-number">0</span>), (<span class="hljs-name">7</span>, <span class="hljs-number">1</span>), (<span class="hljs-name">8</span>, <span class="hljs-number">1</span>)]<br>[(<span class="hljs-name">0</span>, <span class="hljs-number">1</span>), (<span class="hljs-name">1</span>, <span class="hljs-number">1</span>), (<span class="hljs-name">2</span>, <span class="hljs-number">1</span>), (<span class="hljs-name">3</span>, <span class="hljs-number">0</span>), (<span class="hljs-name">4</span>, <span class="hljs-number">1</span>), (<span class="hljs-name">5</span>, <span class="hljs-number">2</span>), (<span class="hljs-name">6</span>, <span class="hljs-number">1</span>), (<span class="hljs-name">7</span>, <span class="hljs-number">0</span>), (<span class="hljs-name">8</span>, <span class="hljs-number">1</span>)]<br></code></pre></td></tr></table></figure><p>让我们稍微逗留一会儿，来看看这个向量。在第一句中I出现了两次，在预料库字典中，I对应的数字为5，因此在第一句中5出现2次，在列表中的元组即为(5,2)，代表单词I在第一句中出现了2次。以上的输出可能并不那么直观，真实的两个句子的代表向量应为：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-string">[2, 0, 0, 1, 1, 2, 0, 1, 1]</span><br><span class="hljs-string">[1, 1, 1, 0, 1, 2, 1, 0, 1]</span><br></code></pre></td></tr></table></figure><p>OK，词袋模型到此结束。接下来，我们会利用刚才得到的词袋模型，即两个句子的向量表示，来计算相似度。</p><p>在NLP中，如果得到了两个句子的向量表示，那么，一般会选择用余弦相似度作为它们的相似度，而向量的余弦相似度即为两个向量的夹角的余弦值。其计算的Python代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> sqrt<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">similarity_with_2_sents</span>(<span class="hljs-params">vec1, vec2</span>):<br>    inner_product = <span class="hljs-number">0</span><br>    square_length_vec1 = <span class="hljs-number">0</span><br>    square_length_vec2 = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> tup1, tup2 <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(vec1, vec2):<br>        inner_product += tup1[<span class="hljs-number">1</span>]*tup2[<span class="hljs-number">1</span>]<br>        square_length_vec1 += tup1[<span class="hljs-number">1</span>]**<span class="hljs-number">2</span><br>        square_length_vec2 += tup2[<span class="hljs-number">1</span>]**<span class="hljs-number">2</span><br><br>    <span class="hljs-keyword">return</span> (inner_product/sqrt(square_length_vec1*square_length_vec2))<br><br><br>cosine_sim = similarity_with_2_sents(vec1, vec2)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;两个句子的余弦相似度为： %.4f。&#x27;</span>%cosine_sim)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">两个句子的余弦相似度为： 0.7303。<br></code></pre></td></tr></table></figure><p>这样，我们就通过句子的词袋模型，得到了它们间的句子相似度。</p><p>当然，在实际的NLP项目中，如果需要计算两个句子的相似度，我们只需调用gensim模块即可，它是NLP的利器，能够帮助我们处理很多NLP任务。下面为用gensim计算两个句子的相似度的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">sent1 = <span class="hljs-string">&quot;I love sky, I love sea.&quot;</span><br>sent2 = <span class="hljs-string">&quot;I like running, I love reading.&quot;</span><br><br><span class="hljs-keyword">from</span> nltk <span class="hljs-keyword">import</span> word_tokenize<br>sents = [sent1, sent2]<br>texts = [[word <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> word_tokenize(sent)] <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents]<br><span class="hljs-built_in">print</span>(texts)<br><br><span class="hljs-keyword">from</span> gensim <span class="hljs-keyword">import</span> corpora<br><span class="hljs-keyword">from</span> gensim.similarities <span class="hljs-keyword">import</span> Similarity<br><br><span class="hljs-comment">#  语料库</span><br>dictionary = corpora.Dictionary(texts)<br><br><span class="hljs-comment"># 利用doc2bow作为词袋模型</span><br>corpus = [dictionary.doc2bow(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts]<br>similarity = Similarity(<span class="hljs-string">&#x27;-Similarity-index&#x27;</span>, corpus, num_features=<span class="hljs-built_in">len</span>(dictionary))<br><span class="hljs-built_in">print</span>(similarity)<br><span class="hljs-comment"># 获取句子的相似度</span><br>new_sensence = sent1<br>test_corpus_1 = dictionary.doc2bow(word_tokenize(new_sensence))<br><br>cosine_sim = similarity[test_corpus_1][<span class="hljs-number">1</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;利用gensim计算得到两个句子的相似度： %.4f。&quot;</span>%cosine_sim)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs delphi">[[<span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;love&#x27;</span>, <span class="hljs-string">&#x27;sky&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;love&#x27;</span>, <span class="hljs-string">&#x27;sea&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>], [<span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;like&#x27;</span>, <span class="hljs-string">&#x27;running&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;love&#x27;</span>, <span class="hljs-string">&#x27;reading&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]]<br>Similarity <span class="hljs-keyword">index</span> <span class="hljs-keyword">with</span> <span class="hljs-number">2</span> documents <span class="hljs-keyword">in</span> <span class="hljs-number">0</span> shards (<span class="hljs-keyword">stored</span> under -Similarity-<span class="hljs-keyword">index</span>)<br>利用gensim计算得到两个句子的相似度： <span class="hljs-number">0.7303</span>。<br></code></pre></td></tr></table></figure><p>注意，如果在运行代码时出现以下warning:</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">gensim\utils.py:<span class="hljs-number">1209</span>: UserWarning: detected Windows; aliasing chunkize <span class="hljs-keyword">to</span> chunkize_serial<br>  warnings.warn(&quot;detected Windows; aliasing chunkize to chunkize_serial&quot;)<br><br>gensim\matutils.py:<span class="hljs-number">737</span>: FutureWarning: <span class="hljs-keyword">Conversion</span> <span class="hljs-keyword">of</span> the second argument <span class="hljs-keyword">of</span> issubdtype <span class="hljs-keyword">from</span> `<span class="hljs-type">int</span>` <span class="hljs-keyword">to</span> `np.signedinteger` <span class="hljs-keyword">is</span> deprecated. <span class="hljs-keyword">In</span> future, it will be treated <span class="hljs-keyword">as</span> `np.int32 == np.dtype(<span class="hljs-type">int</span>).<span class="hljs-keyword">type</span>`.<br>  <span class="hljs-keyword">if</span> np.issubdtype(vec.dtype, np.int):<br></code></pre></td></tr></table></figure><p>如果想要去掉这些warning，则在导入gensim模块的代码前添加以下代码即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(action=<span class="hljs-string">&#x27;ignore&#x27;</span>,category=UserWarning,module=<span class="hljs-string">&#x27;gensim&#x27;</span>)<br>warnings.filterwarnings(action=<span class="hljs-string">&#x27;ignore&#x27;</span>,category=FutureWarning,module=<span class="hljs-string">&#x27;gensim&#x27;</span>)<br></code></pre></td></tr></table></figure><p>本文到此结束，感谢阅读！如果不当之处，请速联系笔者，欢迎大家交流！祝您好运~</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>词袋模型</tag>
      
      <tag>句子相似度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>技术文章写作计划</title>
    <link href="/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0%E5%86%99%E4%BD%9C%E8%AE%A1%E5%88%92/"/>
    <url>/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0%E5%86%99%E4%BD%9C%E8%AE%A1%E5%88%92/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><table><thead><tr><th>序号</th><th>拟定题目</th><th>提出日期</th><th>状态</th><th>完成日期</th></tr></thead><tbody><tr><td>1</td><td>滑动验证码的识别</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>2</td><td>滑动验证码的获取</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>3</td><td>点选验证码的识别</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>4</td><td>ELK简单搭建的demo</td><td>/</td><td>✅</td><td>2023.12.23</td></tr><tr><td>5</td><td>文本聚类</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>6</td><td>智能问答</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>7</td><td>车牌的识别</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>8</td><td>个人足迹地图（WEB服务）</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>9</td><td>别名发现系统</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>10</td><td>读取doc和docx文档</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>11</td><td>利用celery实现定时任务</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>12</td><td>文本标注工具Doccano</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>13</td><td>利用Conda创建Python虚拟环境</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>14</td><td>利用SFTP连接Linux服务器并上传、下载文件</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>15</td><td>Flask学习之RESTful API</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>16</td><td>Flask学习之JWT认证</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>17</td><td>BSON文件读取</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>18</td><td>Flask学习之Flask-SQLALCHEMY</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>19</td><td>设计模式（三篇：单例模式、工厂模式、监听模式）</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>20</td><td>Redis进阶</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>21</td><td>supervisor使用</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>22</td><td>tornado之文件下载（包含中文文件下载）</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>23</td><td>利用CRF实现中文分词</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>24</td><td>利用CRF实现模型预测</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>25</td><td>protobuf的初次使用</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>26</td><td>更新tensorflow/serving中的models.config文件中的model_version_policy</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>27</td><td>tensorflow同时使用多个session</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>28</td><td>如何离线安装tensorflow模块</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>29</td><td>tensorboard查看ckpt和pb文件模型</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>30</td><td>将ckpt转化为pb文件</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>31</td><td>tensorflow/serving之BERT模型部署和预测</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>32</td><td>tensorflow/serving实现模型部署</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>33</td><td>@property</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>34</td><td>tf_record</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>35</td><td>指代关系抽取</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>36</td><td>实体链接（百度实体链接比赛、武器装备知识图谱）</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>37</td><td>文本多分类BERT微调</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>38</td><td>文本多标签分类BERT微调</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>39</td><td>文本序列标注BERT微调</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>40</td><td>keras-bert English系列（3个模型稍微调整即可）</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>41</td><td>keras-bert调用ALBERT</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>42</td><td>keras-bert模型部署</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>43</td><td>h5文件转化为pb文件进行部署</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>44</td><td>tensorflow/serving高效调用</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>45</td><td>tensorflow_hub实现英文文本二分类</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>46</td><td>tensorflow2.0和transformers实现文本多分类</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>47</td><td>抽取式问答</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>48</td><td>完形填空与文本纠错</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>49</td><td>transformers实现中文序列标注</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>50</td><td>tokenizers中的token使用方法</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>51</td><td>BPE token 算法</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>52</td><td>Keras: K折交叉验证</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>53</td><td>使用Prothemus对tensorflow/serving进行服务监控</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>54</td><td>seqeval获取序列标注实体识别结果</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>55</td><td>ES进阶</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>56</td><td>从荷兰国旗问题到快速排序</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>57</td><td>中英文大模型调研</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>58</td><td>LLaMA模型的介绍及其使用</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>59</td><td>Fine-tune LLaMA模型</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>60</td><td>OpenAI的tokenizer调研</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>61</td><td>Gitlab CI/CD 入门</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>62</td><td>LangChain使用</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>63</td><td>Flask部署</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>64</td><td>LangChain构建阅读助手（文档问答）</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>65</td><td>使用LoRA训练Flan-T5-XXL模型</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>66</td><td>VSCode连接远程服务器进行开发</td><td>/</td><td>✅</td><td>2023.10.17</td></tr><tr><td>67</td><td>Streamlit使用</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>68</td><td>Baichuan-13B-Chat的使用探索</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>69</td><td>HuggingFace中的Dataset</td><td>/</td><td>✅</td><td>/</td></tr><tr><td>70</td><td>HuggingFace中的模型训练与评估</td><td>/</td><td>✅</td><td>2023.9.2</td></tr><tr><td>71</td><td>使用Baichuan进行人物关系分类微调</td><td>/</td><td>✅</td><td>2023.7.30</td></tr><tr><td>72</td><td>PyTorch入门之模型量化</td><td>/</td><td>✅</td><td>2023.9.2</td></tr><tr><td>73</td><td>语言模型中的常见解码方法</td><td>/</td><td>🤔</td><td>/</td></tr><tr><td>74</td><td>配置中心Apollo的使用</td><td>2023.8.9</td><td>✅</td><td>2023.9.12</td></tr><tr><td>75</td><td>Python中的retry模块的使用（retry &amp; tenacity）</td><td>2023.8.10</td><td>🤔</td><td>/</td></tr><tr><td>76</td><td>文本生成中的控制策略（stopping, logits）</td><td>2023.8.10</td><td>🤔</td><td>/</td></tr><tr><td>77</td><td>Gradio使用</td><td>2023.8.12</td><td>🤔</td><td>/</td></tr><tr><td>78</td><td>trl模块介绍</td><td>2023.8.12</td><td>🤔</td><td>/</td></tr><tr><td>79</td><td>向量数据库（Faiss, Milvus）的使用</td><td>2023.8.12</td><td>🤔</td><td>/</td></tr><tr><td>80</td><td>Gitlab持续部署（CD）</td><td>2023.8.12</td><td>🤔</td><td>/</td></tr><tr><td>81</td><td>人物关系分类可用BaiChuan-13B模型训练，效果比7B好</td><td>2023.8.16</td><td>🤔</td><td>/</td></tr><tr><td>82</td><td>使用LLM进行开放领域三元组抽取</td><td>2023.8.16</td><td>✅</td><td>2023.9.30</td></tr><tr><td>83</td><td>Flask服务监控</td><td>2023.8.16</td><td>🤔</td><td>/</td></tr><tr><td>84</td><td>vLLM使用</td><td>2023.8.16</td><td>🤔</td><td>/</td></tr><tr><td>85</td><td>coverage模块的高级用法</td><td>2023.8.19</td><td>✅</td><td>2023.8.19</td></tr><tr><td>86</td><td>gradio的示例用法（表格，高亮，模型输入、输出）</td><td>2023.8.19</td><td>✅</td><td>2023.8.30</td></tr><tr><td>87</td><td>代码风格PEP 8 和 注释风格</td><td>2023.8.30</td><td>✅</td><td>2023.9.15</td></tr><tr><td>88</td><td>LLAMA 2微调RACE数据集</td><td>2023.9.10</td><td>✅</td><td>2023.9.10</td></tr><tr><td>89</td><td>Python异步编码asyncio</td><td>2023.9.19</td><td>✅</td><td>2023.9.19</td></tr><tr><td>90</td><td>LangChain流式接口调用（使用异步）</td><td>2023.9.19</td><td>✅</td><td>2023.9.20</td></tr><tr><td>91</td><td>Web框架Sanic介绍</td><td>2023.9.19</td><td>🤔</td><td>/</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>写作计划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作计划</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用Hexo+Github搭建个人博客网站</title>
    <link href="/%E4%BD%BF%E7%94%A8Hexo-Github%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/"/>
    <url>/%E4%BD%BF%E7%94%A8Hexo-Github%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>曾几何时，笔者也幻想过写个项目来搭建属于自己的个人博客。但是，写程序以及维护的成本，不禁让我犹豫再三，最后还是选择了CSDN等博客网站。将近六年的博客生涯，我尝试了不同的博客网站，各有各的利和弊，不变的是广告，这让人很不爽。直到今天，我看到了别人写的利用Hexo+Github来搭建个人博客网站，如获至宝。折腾了一阵以后，轻松完成了个人博客的搭建，这种清爽的界面风格，让人耳目一新，同时它又是免费的，功能繁多的，便于维护的。下面，我将会介绍如何来使用Hexo+Github搭建个人博客网站。</p><h3 id="准备工作">准备工作</h3><p>为了顺利地完成个人博客网站的搭建，需要做以下准备工作：</p><ul><li>安装Git和NodeJs（版本为18.16.1）；</li><li>安装Hexo（命令为<code>npm i -g hexo</code>）;</li><li>Github账号</li></ul><h3 id="搭建博客">搭建博客</h3><p>下面将分步来介绍如何使用Hexo和Github来搭建个人博客网站。</p><h4 id="创建github仓库">创建Github仓库</h4><p>在Github中新建一个名为username.github.io的空仓库，其中username是你在GitHub上的用户名，比如笔者的仓库名为percent.github.io。</p><h4 id="配置ssh">配置SSH</h4><p>如果想要使用远程从你的电脑上传文件至你的github仓库，那么，你就需要配置SSH。点击你个人Github上的Settings选项，在<code>SSH and GPG keys</code>中配置SSH的公钥，一般公钥位于<code>.ssh/id_rsa.pub</code>中，如下图：<img src="/img/hexo1.png" alt="配置SSH" /></p><h4 id="博客初始化">博客初始化</h4><p>新建一个空的文件夹，比如笔者新建了文件夹<code>github_blog</code>，使用<code>hexo init</code>命令初始化博客。初始化后的文件夹结构如下：<figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs 1c">.<br>├── _config.yml<br>├── package.json<br>├── scaffolds<br>├── source<br><span class="hljs-string">|   ├── _drafts</span><br><span class="hljs-string">|   └── _posts</span><br>└── themes<br></code></pre></td></tr></table></figure> 上述文件说明如下：</p><ul><li>_config.yml 网站的 配置 信息，您可以在此配置大部分的参数。</li><li>package.json：应用程序的信息。EJS, Stylus 和 Markdown renderer已默认安装，您可以自由移除。</li><li>scaffolds：模版文件夹。当您新建文章时，Hexo会根据 scaffold来建立文件。</li><li>source：资源文件夹是存放用户资源的地方。</li><li>themes：主题文件夹。Hexo 会根据主题来生成静态页面。</li></ul><h4 id="生成个人博客网站">生成个人博客网站</h4><p>配置_config.yml文件，配置信息如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Deployment</span><br><span class="hljs-comment">## Docs: https://hexo.io/docs/deployment.html</span><br><span class="hljs-attr">deploy:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">git</span><br>  <span class="hljs-attr">repo:</span> <span class="hljs-string">https://github.com/percent4/percent4.github.io.git(第一步创建的Github仓库)</span><br>  <span class="hljs-attr">branch:</span> <span class="hljs-string">master</span><br></code></pre></td></tr></table></figure><p>安装插件<code>npm install hexo-deployer-git --save</code>后，运行如下命令：<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">hexo</span> clean<span class="hljs-comment"># 清除数据</span><br>hexo d -g<span class="hljs-comment"># 生成博客</span><br></code></pre></td></tr></table></figure>这时候，你会看到博客数据会提交至Github的信息，而第一步创建的空仓库也有了提交内容，当然，你的个人博客也搭建搭建完毕，访问网址为：https://username.github.io/，其中username是你在GitHub上的用户名。界面如下： <imgsrc="/img/hexo2.png" alt="Hexo界面" /></p><h3 id="博客维护">博客维护</h3><p>Hexo提供了一套维护博客的优雅的办法。笔者在此仅介绍如何新建一篇博客。新建博客格式为markdown格式，比如我想创建一篇名为<code>利用Tornado搭建文档预览系统</code>的博客，可以使用以下命令：</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs haxe">hexo <span class="hljs-keyword">new</span> <span class="hljs-type"></span>利用Tornado搭建文档预览系统<br></code></pre></td></tr></table></figure><p>这时候会在你当前目录下的source/_posts文件夹下生成<code>利用Tornado搭建文档预览系统.md</code>,其中内容如下：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">利用Tornado搭建文档预览系统</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2020-06-09 18:32:29</span><br><span class="hljs-attr">tags:</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure>其中title为博客标题，date为博客时间，tags为博客标签。在<code>---</code>后面可以写博客正文的内容。写完博客后，使用命令 <figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">hexo</span> clean<span class="hljs-comment"># 清除数据</span><br>hexo d -g<span class="hljs-comment"># 生成博客</span><br></code></pre></td></tr></table></figure> 就会更新个人博客。</p><h3 id="更换主题">更换主题</h3><p>Hexo提供的默认主题为landscape,我们想替换主题为Fluid.Hexo替换主题为Fluid的步骤如下：</p><ol type="1"><li>通过<code>npm</code>直接安装，进入博客目录执行命令：<code>npm install --save hexo-theme-fluid</code></li><li>将node_modules文件夹下的hexo-theme-fluid复制到themes文件夹，并重名为fluid</li><li>在博客目录下创建_config.fluid.yml，将主题的_config.yml内容复制进去，并将<code>theme:</code>后面的主题修改为fluid</li><li>使用<code>hexo s</code>进行本地部署，如无问题，则使用命令<code>hexo d -g</code>进行远程部署</li></ol><h3 id="总结">总结</h3><p>当然，Hexo还提供了许多丰富的功能，比如theme（主题）的个性化定制等，这会使得你的博客内容更加丰富，功能更加完善。</p><p>笔者大家的个人博客网站为：<ahref="https://percent4.github.io/">https://percent4.github.io/</a>，欢迎大家访问。以后，笔者将会逐渐往个人博客网站倾斜，而减少使用公开的博客社区。</p>欢迎关注我的公众号<strong>NLP奇幻之旅</strong>，原创技术文章第一时间推送。<center><img src="https://s2.loli.net/2023/09/07/BFUl9i4872wWATx.jpg" style="width:200px;"></center><p>欢迎关注我的知识星球“<strong>自然语言处理奇幻之旅</strong>”，笔者正在努力构建自己的技术社区。</p><center><img src="https://s2.loli.net/2023/09/07/bYtEecQBfjRlUd1.jpg" style="width:200px;"></center>]]></content>
    
    
    <categories>
      
      <category>Hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Github</tag>
      
      <tag>个人博客</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何使用Hexo？</title>
    <link href="/hello-world/"/>
    <url>/hello-world/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>欢迎来到 <a href="https://hexo.io/">Hexo</a>! 这是我的第一篇博客。查阅 <a href="https://hexo.io/docs/">documentation</a> 获取更多信息。 如果你在使用Hexo遇到问题，你可以在这里找到答案 <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> ，或者你可以在这上面提问：<a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="快速开始">快速开始</h2><h3 id="创建一篇新的博客">创建一篇新的博客</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>更新信息: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="运行服务">运行服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>更新信息: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="产生静态文件">产生静态文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>更新信息: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="远程部署">远程部署</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>更新信息: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    <categories>
      
      <category>Hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
